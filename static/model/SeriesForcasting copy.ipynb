{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: curl: command not found\n"
     ]
    }
   ],
   "source": [
    "!curl -o ETTh1.csv https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 336\n",
    "label_size = 96\n",
    "offset = 1\n",
    "train_size = 0.7\n",
    "val_size = 0.1\n",
    "num_epochs = 1_000_000\n",
    "patience = 20\n",
    "learning_rate = 0.001\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "ele = 5\n",
    "target_name = 'OT'\n",
    "date_column = 'date'\n",
    "file_path = '../assets/ETTh1.csv'\n",
    "\n",
    "plot_dir = 'plots'\n",
    "weight_dir = 'weights'\n",
    "results =  []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataLoader:\n",
    "    def __init__(self, file_path, input_size, label_size, offset, train_size, val_size, date_column=None, target_name=None, features_type='M', batch_size=64):\n",
    "        if offset < label_size:\n",
    "            print(f'Offset will be change from {offset} to {label_size}')\n",
    "            offset = label_size\n",
    "        self.input_size = input_size\n",
    "        self.label_size = label_size\n",
    "        self.offset = offset\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.target_name = target_name\n",
    "        self.features_type = features_type\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.df = pl.read_csv(file_path)\n",
    "        if date_column is not None: \n",
    "            self.df = self.df.drop('date')\n",
    "        if features_type == 'S':\n",
    "            self.in_variable = 1\n",
    "            self.out_variable = 1\n",
    "        elif features_type == 'M':\n",
    "            self.in_variable = len(self.df.columns)\n",
    "            self.out_variable = len(self.df.columns)\n",
    "        elif features_type == 'MS':\n",
    "            self.in_variable = len(self.df.columns)\n",
    "            self.out_variable = 1\n",
    "        else:\n",
    "            raise ValueError('Features type must be S, M or MS')\n",
    "        \n",
    "        self.X_train, self.y_train = self.__create_dataset(0, int(train_size*len(self.df)))\n",
    "        print(f'{self.X_train.shape=}')\n",
    "        print(f'{self.y_train.shape=}')\n",
    "        self.X_val, self.y_val = self.__create_dataset(int(train_size*len(self.df)), int((train_size+val_size)*len(self.df)))\n",
    "        print(f'{self.X_val.shape=}')\n",
    "        print(f'{self.y_val.shape=}')\n",
    "        self.X_test, self.y_test = self.__create_dataset(int((train_size+val_size)*len(self.df)), None)\n",
    "\n",
    "        self.train_loader = self.__create_dataloader(self.X_train, self.y_train)\n",
    "        self.val_loader = self.__create_dataloader(self.X_val, self.y_val)\n",
    "        self.test_loader = self.__create_dataloader(self.X_test, self.y_test)\n",
    "\n",
    "    def __create_dataset(self, start_idx, end_idx):\n",
    "        if end_idx is None:\n",
    "            end_idx = len(self.df) - self.label_size - self.offset\n",
    "        start_idx += self.input_size + self.offset\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            feature_start_idx = idx - self.input_size - self.offset \n",
    "            feature_end_idx = feature_start_idx + self.input_size\n",
    "\n",
    "            label_start_idx = idx - 1\n",
    "            label_end_idx = label_start_idx + self.label_size\n",
    "\n",
    "            if self.features_type == 'S':\n",
    "                feature = self.df.select(self.target_name)[feature_start_idx:feature_end_idx]\n",
    "                label = self.df.select(self.target_name)[label_start_idx:label_end_idx]\n",
    "            elif self.features_type == 'M':\n",
    "                feature = self.df[feature_start_idx:feature_end_idx]\n",
    "                label = self.df[label_start_idx:label_end_idx]\n",
    "            elif self.features_type == 'MS':\n",
    "                feature = self.df[feature_start_idx:feature_end_idx]\n",
    "                label = self.df.select(self.target_name)[label_start_idx:label_end_idx]\n",
    "            else:\n",
    "                raise ValueError('Features type must be S, M or MS')\n",
    "            features.append(feature.to_numpy())\n",
    "            labels.append(label.to_numpy())\n",
    "            self.out_features = label.columns\n",
    "            self.in_features = label.columns\n",
    "        return np.array(features), np.array(labels)\n",
    "    def __create_dataloader(self, X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset will be change from 1 to 96\n",
      "self.X_train.shape=(11762, 336, 7)\n",
      "self.y_train.shape=(11762, 96, 1)\n",
      "self.X_val.shape=(1309, 336, 7)\n",
      "self.y_val.shape=(1309, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "features_type = 'MS'\n",
    "sub_dir = 'multi2uni'\n",
    "os.makedirs(os.path.join(weight_dir, sub_dir), exist_ok=True)\n",
    "multi2uni_loader = TimeSeriesDataLoader(file_path, input_size = input_size, label_size= label_size, offset=offset,train_size=train_size, val_size=val_size, target_name=target_name, features_type=features_type, date_column=date_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset will be change from 1 to 96\n",
      "self.X_train.shape=(11762, 336, 7)\n",
      "self.y_train.shape=(11762, 96, 7)\n",
      "self.X_val.shape=(1309, 336, 7)\n",
      "self.y_val.shape=(1309, 96, 7)\n"
     ]
    }
   ],
   "source": [
    "features_type = 'M'\n",
    "sub_dir = 'multi2multi'\n",
    "os.makedirs(os.path.join(weight_dir, sub_dir), exist_ok=True)\n",
    "multi2multi_loader = TimeSeriesDataLoader(file_path, input_size = input_size, label_size= label_size, offset=offset,train_size=train_size, val_size=val_size, target_name=target_name, features_type=features_type, date_column=date_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.68400002,  2.21000004, -0.71100003, ...,  4.11199999,\n",
       "         0.94400001,  3.79900002],\n",
       "       [13.32900047,  2.74600005,  8.49300003, ...,  4.72100019,\n",
       "         0.82200003,  3.58800006],\n",
       "       [15.60599995,  2.94700003, 10.27000046, ...,  5.23899984,\n",
       "         0.91399997,  3.79900002],\n",
       "       ...,\n",
       "       [10.85099983,  1.40699995,  6.75199986, ...,  4.17299986,\n",
       "         0.60900003,  3.09500003],\n",
       "       [11.65499973,  1.54100001,  7.42700005, ...,  4.26399994,\n",
       "         0.579     ,  3.09500003],\n",
       "       [13.39599991,  1.80799997,  9.02600002, ...,  4.44700003,\n",
       "         0.54799998,  3.16599989]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi2multi_loader.X_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MOdel Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    def __init__(self, model, train_loader, val_loader=None, lr=0.0001, patience=100):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.patience = patience\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self.train_loss_per_epoch = []\n",
    "        self.val_loss_per_epoch = []\n",
    "\n",
    "    def train(self, num_epochs, save_dir='.'):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f'best-{self.model.__class__.__name__}.pth')\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            self.model.train()\n",
    "            total_train_loss = 0\n",
    "            for inputs, targets in self.train_loader:\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                total_train_loss += loss.item()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            avg_train_loss = total_train_loss / len(self.train_loader)\n",
    "            val_loss = self.evaluate(loader=self.val_loader) \n",
    "\n",
    "            if self.early_stopping(val_loss, save_path):\n",
    "                print(f'Early stopping on epoch {epoch + 1}')\n",
    "                return\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, train_loss: {avg_train_loss:.4f}, val_loss: {val_loss:.4f}, time: {time.time() - start_time:.2f}s')\n",
    "        self.save_model(save_path)\n",
    "    \n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in loader:\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        return avg_loss\n",
    "\n",
    "    def early_stopping(self, val_loss, save_path):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_model(save_path)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        return self.counter >= self.patience\n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "        print(f'Model saved to {save_path}')\n",
    "    \n",
    "    def load_model(self, load_path):\n",
    "        self.model.load_state_dict(torch.load(load_path))\n",
    "        print(f'Model loaded from {load_path}')\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        self.model.eval()\n",
    "        if isinstance(input_data, DataLoader):\n",
    "            predictions = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, _ in input_data:\n",
    "                    outputs = self.model(inputs)\n",
    "                    predictions.append(outputs)\n",
    "            predictions = torch.cat(predictions, dim=0)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                predictions = self.model(input_data).unsqueeze(0)\n",
    "        return predictions\n",
    "\n",
    "    def plot(self, y, yhat, feature_names=None, save_dir='.', save_plots=True, num_elements=None):\n",
    "        if feature_names is None: \n",
    "            feature_names = [f'Feature {i+1}' for i in range(y.shape[2])]\n",
    "            \n",
    "        if num_elements is not None:\n",
    "            y = y[:num_elements]\n",
    "            yhat = yhat[:num_elements]\n",
    "\n",
    "        for feature_index, feature_name in enumerate(feature_names):\n",
    "            plt.figure(figsize=(10,5))\n",
    "            plt.plot(y[:,:,feature_index].flatten(), label='y', linestyle='-')\n",
    "            plt.plot(yhat[:,:,feature_index].flatten(), label='y_hat', linestyle='--')\n",
    "            plt.title(f'{feature_name} Forecast')\n",
    "            plt.xlabel('Time Steps')\n",
    "            plt.ylabel('Values')\n",
    "            plt.legend()\n",
    "            if save_plots:\n",
    "                os.makedirs(os.path.join(save_dir, self.model.__class__.__name__), exist_ok=True)\n",
    "                save_path = os.path.join(save_dir, self.model.__class__.__name__, f'{feature_name}.png')\n",
    "                plt.savefig(save_path)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "class MachineLearningModelManager(ModelManager):\n",
    "    def __init__(self, model, xtrain, ytrain, xval, yval):\n",
    "        self.model = model\n",
    "        self.xtrain = xtrain\n",
    "        self.ytrain = ytrain\n",
    "        self.xval = xval\n",
    "        self.yval = yval\n",
    "    def preprocessing(self, x):\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        import pickle\n",
    "        with open(save_path, 'wb') as model_file:\n",
    "            pickle.dump(self.model, model_file)\n",
    "        print(f'Model saved to {save_path}')\n",
    "    def train(self, save_dir='.'):\n",
    "        self.model.fit(self.preprocessing(self.xtrain), self.preprocessing(self.ytrain),eval_set=[(self.preprocessing(self.xval), self.preprocessing(self.yval))])\n",
    "        save_path = os.path.join(save_dir, f'best={self.model.__class__.__name__}.pkl')\n",
    "        self.save_model(save_path=save_path)\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(self.preprocessing(x))\n",
    "    def evaluate(self, x, y):\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        return mean_absolute_error(self.preprocessing(y), self.preprocessing(x))\n",
    "    def plot(self, y, yhat, feature_names=None, save_dir='.', save_plots=True, num_elements=None):\n",
    "        yhat = yhat.reshape(y.shape[0], y.shape[1], -1)\n",
    "        super().plot(y, yhat, feature_names=feature_names, save_dir=save_dir, save_plots=save_plots, num_elements=num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_config = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'booster': 'gbtree',\n",
    "    'n_estimators': num_epochs,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'early_stopping_rounds': patience,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:3.43701\n",
      "[1]\tvalidation_0-mae:3.26450\n",
      "[2]\tvalidation_0-mae:3.12015\n",
      "[3]\tvalidation_0-mae:2.99788\n",
      "[4]\tvalidation_0-mae:2.89048\n",
      "[5]\tvalidation_0-mae:2.79511\n",
      "[6]\tvalidation_0-mae:2.71269\n",
      "[7]\tvalidation_0-mae:2.64030\n",
      "[8]\tvalidation_0-mae:2.57559\n",
      "[9]\tvalidation_0-mae:2.51784\n",
      "[10]\tvalidation_0-mae:2.46626\n",
      "[11]\tvalidation_0-mae:2.42100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m XGBoost_multi2multi \u001b[38;5;241m=\u001b[39m XGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mxgboost_config)\n\u001b[1;32m      2\u001b[0m XGBoost_multi2multi_manager \u001b[38;5;241m=\u001b[39m MachineLearningModelManager(model \u001b[38;5;241m=\u001b[39m XGBoost_multi2multi, xtrain \u001b[38;5;241m=\u001b[39m multi2multi_loader\u001b[38;5;241m.\u001b[39mX_train, ytrain \u001b[38;5;241m=\u001b[39m multi2multi_loader\u001b[38;5;241m.\u001b[39my_train, xval \u001b[38;5;241m=\u001b[39m multi2multi_loader\u001b[38;5;241m.\u001b[39mX_val, yval \u001b[38;5;241m=\u001b[39m multi2multi_loader\u001b[38;5;241m.\u001b[39my_val)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mXGBoost_multi2multi_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: XGBoost_multi2multi_manager\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m: sub_dir,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: XGBoost_multi2multi_manager\u001b[38;5;241m.\u001b[39mevaluate(x\u001b[38;5;241m=\u001b[39mmulti2multi_loader\u001b[38;5;241m.\u001b[39mX_test, y\u001b[38;5;241m=\u001b[39mmulti2multi_loader\u001b[38;5;241m.\u001b[39my_test)\n\u001b[1;32m      8\u001b[0m })\n\u001b[1;32m      9\u001b[0m results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[7], line 117\u001b[0m, in \u001b[0;36mMachineLearningModelManager.train\u001b[0;34m(self, save_dir)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(save_path\u001b[38;5;241m=\u001b[39msave_path)\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/xgboost/sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m (\n\u001b[1;32m   1082\u001b[0m     model,\n\u001b[1;32m   1083\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1089\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "XGBoost_multi2multi = XGBRegressor(**xgboost_config)\n",
    "XGBoost_multi2multi_manager = MachineLearningModelManager(model = XGBoost_multi2multi, xtrain = multi2multi_loader.X_train, ytrain = multi2multi_loader.y_train, xval = multi2multi_loader.X_val, yval = multi2multi_loader.y_val)\n",
    "XGBoost_multi2multi_manager.train(save_dir=os.path.join(weight_dir, sub_dir))\n",
    "results.append({\n",
    "    \"Name\": XGBoost_multi2multi_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": XGBoost_multi2multi_manager.evaluate(x=multi2multi_loader.X_test, y=multi2multi_loader.y_test)\n",
    "})\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the training data\n",
    "test_predictions = LSTM_multi2multi_manager.predict(multi2multi_loader.train_loader)\n",
    "\n",
    "# Get the true values\n",
    "y_true = multi2multi_loader.y_train\n",
    "\n",
    "# Plot the true values against the predictions\n",
    "LSTM_multi2multi_manager.plot(y=y_true, yhat=test_predictions, feature_names=[\"HUFL\",\"HULL\",\"MUFL\",\"MULL\",\"LUFL\",\"LULL\",\"OT\"], num_elements=4, save_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, ahead):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size * ahead)\n",
    "        self.ahead = ahead\n",
    "        self.output_size=output_size\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.view(-1, self.ahead, self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_multi2uni = MLP(input_size=multi2uni_loader.in_variable*input_size, hidden_size=hidden_size, output_size=multi2uni_loader.out_variable, ahead=label_size)\n",
    "\n",
    "MLP_multi2uni_manager = ModelManager(model=MLP_multi2uni, train_loader=multi2uni_loader.train_loader,val_loader=multi2uni_loader.val_loader, lr=learning_rate, patience=patience)\n",
    "MLP_multi2uni_manager.train(num_epochs=num_epochs, save_dir=os.path.join(weight_dir, sub_dir))\n",
    "results.append({\n",
    "    \"Name\": MLP_multi2uni_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    'MAE': MLP_multi2uni_manager.evaluate(loader=multi2uni_loader.test_loader),\n",
    "})\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11762, 336, 7)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = multi2uni_loader.X_train\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= multi2uni_loader.train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'y_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'y_train'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions on the training data\n",
    "test_predictions = MLP_multi2uni_manager.predict(multi2uni_loader.train_loader)\n",
    "\n",
    "# Get the true values\n",
    "y_true = multi2uni_loader.y_train\n",
    "\n",
    "# Plot the true values against the predictions\n",
    "MLP_multi2uni_manager.plot(y=y_true, yhat=test_predictions, feature_names=['OT'], num_elements=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m multi2uni_loader\u001b[38;5;241m.\u001b[39mtrain_loader\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 96, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, ahead):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.ahead = ahead\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size * ahead)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out).view(-1, self.ahead, self.output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackcait/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([64, 96, 1])) that is different to the input size (torch.Size([64, 96, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/blackcait/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([50, 96, 1])) that is different to the input size (torch.Size([50, 96, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/blackcait/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([29, 96, 1])) that is different to the input size (torch.Size([29, 96, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to weights/multi2multi/best-LSTM.pth\n",
      "Epoch 1/1000000, train_loss: 10.1477, val_loss: 8.2267, time: 38.76s\n",
      "Epoch 2/1000000, train_loss: 6.2537, val_loss: 11.2143, time: 29.03s\n",
      "Model saved to weights/multi2multi/best-LSTM.pth\n",
      "Epoch 3/1000000, train_loss: 6.0879, val_loss: 7.0469, time: 28.59s\n",
      "Model saved to weights/multi2multi/best-LSTM.pth\n",
      "Epoch 4/1000000, train_loss: 4.3576, val_loss: 5.0302, time: 21.05s\n",
      "Epoch 5/1000000, train_loss: 3.5280, val_loss: 5.7553, time: 24.38s\n",
      "Epoch 6/1000000, train_loss: 3.1669, val_loss: 6.4820, time: 28.05s\n",
      "Epoch 7/1000000, train_loss: 2.8095, val_loss: 6.4279, time: 29.02s\n",
      "Epoch 8/1000000, train_loss: 2.5714, val_loss: 6.4377, time: 27.70s\n",
      "Epoch 9/1000000, train_loss: 2.3972, val_loss: 6.5103, time: 27.58s\n",
      "Epoch 10/1000000, train_loss: 2.2899, val_loss: 6.6362, time: 27.05s\n",
      "Epoch 11/1000000, train_loss: 2.2332, val_loss: 6.5645, time: 27.09s\n",
      "Epoch 12/1000000, train_loss: 2.1694, val_loss: 6.3304, time: 26.24s\n",
      "Epoch 13/1000000, train_loss: 2.1103, val_loss: 7.1900, time: 28.07s\n",
      "Epoch 14/1000000, train_loss: 2.0833, val_loss: 6.6418, time: 28.77s\n",
      "Epoch 15/1000000, train_loss: 2.2420, val_loss: 7.6391, time: 28.12s\n",
      "Epoch 16/1000000, train_loss: 2.1798, val_loss: 7.7574, time: 28.32s\n",
      "Epoch 17/1000000, train_loss: 2.1002, val_loss: 7.9128, time: 28.10s\n",
      "Epoch 18/1000000, train_loss: 2.1276, val_loss: 7.3003, time: 27.39s\n",
      "Epoch 19/1000000, train_loss: 2.0645, val_loss: 7.0461, time: 29.98s\n",
      "Epoch 20/1000000, train_loss: 2.0205, val_loss: 7.1377, time: 26.87s\n",
      "Epoch 21/1000000, train_loss: 1.9962, val_loss: 7.1353, time: 27.13s\n",
      "Epoch 22/1000000, train_loss: 1.9795, val_loss: 6.7680, time: 28.51s\n",
      "Epoch 23/1000000, train_loss: 1.9700, val_loss: 7.0129, time: 27.37s\n",
      "Early stopping on epoch 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'LSTM', 'Type': 'multi2multi', 'MAE': 7.304619566599528}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_multi2multi = LSTM(input_size=multi2multi_loader.in_variable, hidden_size=hidden_size,\n",
    "                        output_size=multi2multi_loader.out_variable,\n",
    "                        ahead=label_size,\n",
    "                        num_layers=num_layers)\n",
    "\n",
    "LSTM_multi2multi_manager = ModelManager(model=LSTM_multi2multi,\n",
    "                                        train_loader=multi2uni_loader.train_loader,\n",
    "                                        val_loader=multi2uni_loader.val_loader,\n",
    "                                        lr=learning_rate,\n",
    "                                        patience=patience)\n",
    "\n",
    "LSTM_multi2multi_manager.train(num_epochs=num_epochs, save_dir=os.path.join(weight_dir, sub_dir))\n",
    "\n",
    "results.append({\n",
    "    \"Name\": LSTM_multi2multi_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": LSTM_multi2multi_manager.evaluate(loader=multi2multi_loader.test_loader),\n",
    "})      \n",
    "\n",
    "results[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11762, 96, 7)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11762, 96, 7])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions on the training data\n",
    "test_predictions = LSTM_multi2multi_manager.predict(multi2multi_loader.train_loader)\n",
    "\n",
    "# Get the true values\n",
    "y_true = multi2multi_loader.y_train\n",
    "\n",
    "# Plot the true values against the predictions\n",
    "LSTM_multi2multi_manager.plot(y=y_true, yhat=test_predictions, feature_names=[\"HUFL\",\"HULL\",\"MUFL\",\"MULL\",\"LUFL\",\"LULL\",\"OT\"], num_elements=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to weights/multi2multi/best-LSTM.pth\n",
      "Epoch 1/1000000, train_loss: 10.1028, val_loss: 8.2895, time: 45.24s\n",
      "Epoch 2/1000000, train_loss: 6.2407, val_loss: 11.2853, time: 38.38s\n",
      "Epoch 3/1000000, train_loss: 6.1142, val_loss: 11.4676, time: 35.74s\n",
      "Model saved to weights/multi2multi/best-LSTM.pth\n",
      "Epoch 4/1000000, train_loss: 5.7244, val_loss: 5.6687, time: 35.30s\n",
      "Model saved to weights/multi2multi/best-LSTM.pth\n",
      "Epoch 5/1000000, train_loss: 3.9237, val_loss: 5.2450, time: 26.41s\n",
      "Epoch 6/1000000, train_loss: 3.4281, val_loss: 5.5760, time: 26.88s\n",
      "Epoch 7/1000000, train_loss: 3.1199, val_loss: 5.2714, time: 27.97s\n",
      "Epoch 8/1000000, train_loss: 2.8517, val_loss: 5.7720, time: 28.08s\n",
      "Model saved to weights/multi2multi/best-LSTM.pth\n",
      "Epoch 9/1000000, train_loss: 2.6984, val_loss: 5.1645, time: 30.89s\n",
      "Epoch 10/1000000, train_loss: 2.5935, val_loss: 5.7579, time: 28.73s\n",
      "Epoch 11/1000000, train_loss: 2.5323, val_loss: 6.7428, time: 27.93s\n",
      "Epoch 12/1000000, train_loss: 2.4500, val_loss: 6.3067, time: 28.90s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m LSTM_multi2uni \u001b[38;5;241m=\u001b[39m LSTM(input_size\u001b[38;5;241m=\u001b[39mmulti2uni_loader\u001b[38;5;241m.\u001b[39min_variable, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size, output_size\u001b[38;5;241m=\u001b[39mmulti2uni_loader\u001b[38;5;241m.\u001b[39mout_variable, ahead\u001b[38;5;241m=\u001b[39mlabel_size, num_layers\u001b[38;5;241m=\u001b[39mnum_layers)\n\u001b[1;32m      2\u001b[0m LSTM_multi2uni_manager \u001b[38;5;241m=\u001b[39m ModelManager(model\u001b[38;5;241m=\u001b[39mLSTM_multi2uni, train_loader\u001b[38;5;241m=\u001b[39mmulti2uni_loader\u001b[38;5;241m.\u001b[39mtrain_loader, val_loader\u001b[38;5;241m=\u001b[39mmulti2uni_loader\u001b[38;5;241m.\u001b[39mval_loader, lr\u001b[38;5;241m=\u001b[39mlearning_rate, patience\u001b[38;5;241m=\u001b[39mpatience)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mLSTM_multi2uni_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: LSTM_multi2uni_manager\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m: sub_dir,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: LSTM_multi2uni_manager\u001b[38;5;241m.\u001b[39mevaluate(loader\u001b[38;5;241m=\u001b[39mmulti2uni_loader\u001b[38;5;241m.\u001b[39mtest_loader),\n\u001b[1;32m      8\u001b[0m })\n\u001b[1;32m      9\u001b[0m results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[31], line 22\u001b[0m, in \u001b[0;36mModelManager.train\u001b[0;34m(self, num_epochs, save_dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m total_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[0;32m---> 22\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, targets)\n\u001b[1;32m     24\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 14\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m     13\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m---> 14\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     16\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mahead, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size)\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/rnn.py:911\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    908\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    915\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTM_multi2uni = LSTM(input_size=multi2uni_loader.in_variable, hidden_size=hidden_size, output_size=multi2uni_loader.out_variable, ahead=label_size, num_layers=num_layers)\n",
    "LSTM_multi2uni_manager = ModelManager(model=LSTM_multi2uni, train_loader=multi2uni_loader.train_loader, val_loader=multi2uni_loader.val_loader, lr=learning_rate, patience=patience)\n",
    "LSTM_multi2uni_manager.train(num_epochs=num_epochs, save_dir=os.path.join(weight_dir, sub_dir))\n",
    "results.append({\n",
    "    \"Name\": LSTM_multi2uni_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": LSTM_multi2uni_manager.evaluate(loader=multi2uni_loader.test_loader),\n",
    "})\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'LSTM', 'Type': 'multi2multi', 'MAE': 36.09023829868862}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.append({\n",
    "    \"Name\": LSTM_multi2uni_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": LSTM_multi2uni_manager.evaluate(loader=multi2uni_loader.test_loader),\n",
    "})\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, ahead):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.ahead = ahead\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size * ahead)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out).view(-1, self.ahead, self.output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1/1000000, train_loss: 63.2555, val_loss: 95.1433, time: 0.12s\n",
      "Epoch 2/1000000, train_loss: 63.2324, val_loss: 95.4776, time: 0.11s\n",
      "Epoch 3/1000000, train_loss: 63.2189, val_loss: 95.2150, time: 0.12s\n",
      "Epoch 4/1000000, train_loss: 63.2141, val_loss: 95.3013, time: 0.12s\n",
      "Epoch 5/1000000, train_loss: 63.1907, val_loss: 95.1751, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 6/1000000, train_loss: 63.1813, val_loss: 94.8467, time: 0.12s\n",
      "Epoch 7/1000000, train_loss: 63.1917, val_loss: 95.0604, time: 0.12s\n",
      "Epoch 8/1000000, train_loss: 63.1813, val_loss: 94.9795, time: 0.12s\n",
      "Epoch 9/1000000, train_loss: 63.1564, val_loss: 95.0982, time: 0.12s\n",
      "Epoch 10/1000000, train_loss: 63.1138, val_loss: 94.9423, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 11/1000000, train_loss: 63.1026, val_loss: 94.8319, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 12/1000000, train_loss: 63.1343, val_loss: 94.8315, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 13/1000000, train_loss: 63.0687, val_loss: 94.7655, time: 0.12s\n",
      "Epoch 14/1000000, train_loss: 63.1089, val_loss: 95.0571, time: 0.12s\n",
      "Epoch 15/1000000, train_loss: 63.0854, val_loss: 94.8930, time: 0.12s\n",
      "Epoch 16/1000000, train_loss: 63.0684, val_loss: 95.0979, time: 0.12s\n",
      "Epoch 17/1000000, train_loss: 63.0569, val_loss: 94.7822, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 18/1000000, train_loss: 63.0495, val_loss: 94.7496, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 19/1000000, train_loss: 63.0656, val_loss: 94.7066, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 20/1000000, train_loss: 63.0483, val_loss: 94.7000, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 21/1000000, train_loss: 63.0410, val_loss: 94.5476, time: 0.12s\n",
      "Epoch 22/1000000, train_loss: 63.0050, val_loss: 94.7565, time: 0.12s\n",
      "Epoch 23/1000000, train_loss: 62.9896, val_loss: 94.6381, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 24/1000000, train_loss: 62.9811, val_loss: 94.4482, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 25/1000000, train_loss: 62.9645, val_loss: 94.4237, time: 0.12s\n",
      "Epoch 26/1000000, train_loss: 62.9610, val_loss: 94.4919, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 27/1000000, train_loss: 62.9764, val_loss: 94.3203, time: 0.12s\n",
      "Epoch 28/1000000, train_loss: 62.9465, val_loss: 94.4377, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 29/1000000, train_loss: 62.9296, val_loss: 94.1908, time: 0.12s\n",
      "Epoch 30/1000000, train_loss: 62.9249, val_loss: 94.3399, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 31/1000000, train_loss: 62.9077, val_loss: 94.1556, time: 0.12s\n",
      "Epoch 32/1000000, train_loss: 62.8896, val_loss: 94.2554, time: 0.13s\n",
      "Epoch 33/1000000, train_loss: 62.8823, val_loss: 94.2697, time: 0.12s\n",
      "Epoch 34/1000000, train_loss: 62.8750, val_loss: 94.1646, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 35/1000000, train_loss: 62.8795, val_loss: 94.1470, time: 0.12s\n",
      "Epoch 36/1000000, train_loss: 62.8891, val_loss: 94.2068, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 37/1000000, train_loss: 62.8295, val_loss: 94.0285, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 38/1000000, train_loss: 62.8244, val_loss: 93.9266, time: 0.12s\n",
      "Epoch 39/1000000, train_loss: 62.8243, val_loss: 93.9297, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 40/1000000, train_loss: 62.8095, val_loss: 93.8784, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 41/1000000, train_loss: 62.7901, val_loss: 93.7399, time: 0.12s\n",
      "Epoch 42/1000000, train_loss: 62.7894, val_loss: 93.9957, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 43/1000000, train_loss: 62.7671, val_loss: 93.7217, time: 0.12s\n",
      "Epoch 44/1000000, train_loss: 62.7878, val_loss: 93.9287, time: 0.12s\n",
      "Epoch 45/1000000, train_loss: 62.7694, val_loss: 93.8322, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 46/1000000, train_loss: 62.7340, val_loss: 93.6635, time: 0.12s\n",
      "Epoch 47/1000000, train_loss: 62.7510, val_loss: 93.6992, time: 0.12s\n",
      "Epoch 48/1000000, train_loss: 62.7420, val_loss: 93.7430, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 49/1000000, train_loss: 62.7294, val_loss: 93.5706, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 50/1000000, train_loss: 62.7093, val_loss: 93.5646, time: 0.12s\n",
      "Epoch 51/1000000, train_loss: 62.7311, val_loss: 93.5985, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 52/1000000, train_loss: 62.7154, val_loss: 93.3341, time: 0.12s\n",
      "Epoch 53/1000000, train_loss: 62.6778, val_loss: 93.5158, time: 0.12s\n",
      "Epoch 54/1000000, train_loss: 62.7054, val_loss: 93.5672, time: 0.12s\n",
      "Epoch 55/1000000, train_loss: 62.6844, val_loss: 93.4698, time: 0.12s\n",
      "Epoch 56/1000000, train_loss: 62.6608, val_loss: 93.3508, time: 0.12s\n",
      "Epoch 57/1000000, train_loss: 62.6303, val_loss: 93.4154, time: 0.12s\n",
      "Epoch 58/1000000, train_loss: 62.6070, val_loss: 93.5227, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 59/1000000, train_loss: 62.6478, val_loss: 93.1624, time: 0.12s\n",
      "Epoch 60/1000000, train_loss: 62.6087, val_loss: 93.2462, time: 0.12s\n",
      "Epoch 61/1000000, train_loss: 62.5902, val_loss: 93.2544, time: 0.12s\n",
      "Epoch 62/1000000, train_loss: 62.5924, val_loss: 93.3715, time: 0.12s\n",
      "Epoch 63/1000000, train_loss: 62.5656, val_loss: 93.2881, time: 0.12s\n",
      "Epoch 64/1000000, train_loss: 62.5613, val_loss: 93.2104, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 65/1000000, train_loss: 62.5169, val_loss: 93.1213, time: 0.12s\n",
      "Epoch 66/1000000, train_loss: 62.5033, val_loss: 93.2642, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 67/1000000, train_loss: 62.5112, val_loss: 93.0294, time: 0.12s\n",
      "Epoch 68/1000000, train_loss: 62.4790, val_loss: 93.0857, time: 0.12s\n",
      "Epoch 69/1000000, train_loss: 62.4812, val_loss: 93.1078, time: 0.12s\n",
      "Epoch 70/1000000, train_loss: 62.4463, val_loss: 93.1755, time: 0.11s\n",
      "Epoch 71/1000000, train_loss: 62.4719, val_loss: 93.0701, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 72/1000000, train_loss: 62.4476, val_loss: 92.9953, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 73/1000000, train_loss: 62.4109, val_loss: 92.7205, time: 0.11s\n",
      "Epoch 74/1000000, train_loss: 62.4381, val_loss: 92.7601, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 75/1000000, train_loss: 62.3805, val_loss: 92.7175, time: 0.11s\n",
      "Epoch 76/1000000, train_loss: 62.3877, val_loss: 92.8876, time: 0.11s\n",
      "Epoch 77/1000000, train_loss: 62.3493, val_loss: 92.8738, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 78/1000000, train_loss: 62.3697, val_loss: 92.6711, time: 0.11s\n",
      "Epoch 79/1000000, train_loss: 62.3652, val_loss: 92.8791, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 80/1000000, train_loss: 62.3199, val_loss: 92.6643, time: 0.11s\n",
      "Epoch 81/1000000, train_loss: 62.3256, val_loss: 92.6681, time: 0.11s\n",
      "Epoch 82/1000000, train_loss: 62.3181, val_loss: 92.6746, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 83/1000000, train_loss: 62.2845, val_loss: 92.4967, time: 0.11s\n",
      "Epoch 84/1000000, train_loss: 62.2904, val_loss: 92.5682, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 85/1000000, train_loss: 62.2711, val_loss: 92.4965, time: 0.11s\n",
      "Epoch 86/1000000, train_loss: 62.2619, val_loss: 92.6262, time: 0.11s\n",
      "Epoch 87/1000000, train_loss: 62.2696, val_loss: 92.5013, time: 0.11s\n",
      "Epoch 88/1000000, train_loss: 62.2514, val_loss: 92.6256, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 89/1000000, train_loss: 62.2355, val_loss: 92.4782, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 90/1000000, train_loss: 62.2287, val_loss: 92.3263, time: 0.12s\n",
      "Epoch 91/1000000, train_loss: 62.2080, val_loss: 92.3361, time: 0.12s\n",
      "Epoch 92/1000000, train_loss: 62.1691, val_loss: 92.3893, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 93/1000000, train_loss: 62.1253, val_loss: 92.2997, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 94/1000000, train_loss: 62.1062, val_loss: 92.2674, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 95/1000000, train_loss: 62.0976, val_loss: 92.1155, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 96/1000000, train_loss: 62.0523, val_loss: 92.1081, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 97/1000000, train_loss: 62.0502, val_loss: 92.0941, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 98/1000000, train_loss: 62.0073, val_loss: 92.0114, time: 0.12s\n",
      "Epoch 99/1000000, train_loss: 62.0195, val_loss: 92.2609, time: 0.12s\n",
      "Epoch 100/1000000, train_loss: 62.0031, val_loss: 92.1744, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 101/1000000, train_loss: 61.9691, val_loss: 91.9677, time: 0.12s\n",
      "Epoch 102/1000000, train_loss: 61.9676, val_loss: 92.1000, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 103/1000000, train_loss: 61.9320, val_loss: 91.9308, time: 0.12s\n",
      "Epoch 104/1000000, train_loss: 61.9394, val_loss: 91.9585, time: 0.12s\n",
      "Epoch 105/1000000, train_loss: 61.9533, val_loss: 91.9851, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 106/1000000, train_loss: 61.9328, val_loss: 91.9227, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 107/1000000, train_loss: 61.9207, val_loss: 91.9193, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 108/1000000, train_loss: 61.9042, val_loss: 91.7418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 109/1000000, train_loss: 61.8874, val_loss: 91.5936, time: 0.11s\n",
      "Epoch 110/1000000, train_loss: 61.8798, val_loss: 91.8388, time: 0.11s\n",
      "Epoch 111/1000000, train_loss: 61.8675, val_loss: 91.8741, time: 0.11s\n",
      "Epoch 112/1000000, train_loss: 61.8253, val_loss: 91.9977, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 113/1000000, train_loss: 61.8228, val_loss: 91.4661, time: 0.11s\n",
      "Epoch 114/1000000, train_loss: 61.7901, val_loss: 91.7445, time: 0.11s\n",
      "Epoch 115/1000000, train_loss: 61.7682, val_loss: 91.5358, time: 0.11s\n",
      "Epoch 116/1000000, train_loss: 61.7841, val_loss: 91.6490, time: 0.11s\n",
      "Epoch 117/1000000, train_loss: 61.7514, val_loss: 91.5490, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 118/1000000, train_loss: 61.7300, val_loss: 91.4636, time: 0.12s\n",
      "Epoch 119/1000000, train_loss: 61.7413, val_loss: 91.6194, time: 0.12s\n",
      "Epoch 120/1000000, train_loss: 61.7263, val_loss: 91.4657, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 121/1000000, train_loss: 61.6677, val_loss: 91.4396, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 122/1000000, train_loss: 61.6789, val_loss: 91.3058, time: 0.12s\n",
      "Epoch 123/1000000, train_loss: 61.7206, val_loss: 91.4232, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 124/1000000, train_loss: 61.6976, val_loss: 91.2363, time: 0.11s\n",
      "Epoch 125/1000000, train_loss: 61.6651, val_loss: 91.3278, time: 0.11s\n",
      "Epoch 126/1000000, train_loss: 61.6420, val_loss: 91.4524, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 127/1000000, train_loss: 61.6498, val_loss: 91.2136, time: 0.12s\n",
      "Epoch 128/1000000, train_loss: 61.6352, val_loss: 91.2469, time: 0.12s\n",
      "Epoch 129/1000000, train_loss: 61.6124, val_loss: 91.2683, time: 0.11s\n",
      "Epoch 130/1000000, train_loss: 61.5916, val_loss: 91.2833, time: 0.11s\n",
      "Epoch 131/1000000, train_loss: 61.5801, val_loss: 91.2681, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 132/1000000, train_loss: 61.6036, val_loss: 90.9702, time: 0.12s\n",
      "Epoch 133/1000000, train_loss: 61.5481, val_loss: 91.0444, time: 0.12s\n",
      "Epoch 134/1000000, train_loss: 61.5387, val_loss: 91.1747, time: 0.11s\n",
      "Epoch 135/1000000, train_loss: 61.5363, val_loss: 91.1385, time: 0.11s\n",
      "Epoch 136/1000000, train_loss: 61.4983, val_loss: 91.0176, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 137/1000000, train_loss: 61.5126, val_loss: 90.9395, time: 0.12s\n",
      "Epoch 138/1000000, train_loss: 61.5035, val_loss: 90.9715, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 139/1000000, train_loss: 61.4891, val_loss: 90.8532, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 140/1000000, train_loss: 61.4754, val_loss: 90.8170, time: 0.12s\n",
      "Epoch 141/1000000, train_loss: 61.4603, val_loss: 90.8667, time: 0.12s\n",
      "Epoch 142/1000000, train_loss: 61.4507, val_loss: 90.8732, time: 0.11s\n",
      "Epoch 143/1000000, train_loss: 61.4328, val_loss: 90.8919, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 144/1000000, train_loss: 61.4161, val_loss: 90.6347, time: 0.11s\n",
      "Epoch 145/1000000, train_loss: 61.3884, val_loss: 90.6764, time: 0.11s\n",
      "Epoch 146/1000000, train_loss: 61.3920, val_loss: 90.7961, time: 0.11s\n",
      "Epoch 147/1000000, train_loss: 61.3772, val_loss: 90.6427, time: 0.12s\n",
      "Epoch 148/1000000, train_loss: 61.3711, val_loss: 90.7360, time: 0.11s\n",
      "Epoch 149/1000000, train_loss: 61.3482, val_loss: 90.8198, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 150/1000000, train_loss: 61.3395, val_loss: 90.5255, time: 0.11s\n",
      "Epoch 151/1000000, train_loss: 61.3215, val_loss: 90.6288, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 152/1000000, train_loss: 61.3294, val_loss: 90.5142, time: 0.12s\n",
      "Epoch 153/1000000, train_loss: 61.3203, val_loss: 90.5878, time: 0.12s\n",
      "Epoch 154/1000000, train_loss: 61.2922, val_loss: 90.5818, time: 0.11s\n",
      "Epoch 155/1000000, train_loss: 61.2640, val_loss: 90.6488, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 156/1000000, train_loss: 61.2672, val_loss: 90.4299, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 157/1000000, train_loss: 61.2541, val_loss: 90.2861, time: 0.11s\n",
      "Epoch 158/1000000, train_loss: 61.2295, val_loss: 90.3054, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 159/1000000, train_loss: 61.2237, val_loss: 90.2354, time: 0.11s\n",
      "Epoch 160/1000000, train_loss: 61.3287, val_loss: 90.4677, time: 0.12s\n",
      "Epoch 161/1000000, train_loss: 61.2226, val_loss: 90.2404, time: 0.12s\n",
      "Epoch 162/1000000, train_loss: 61.2101, val_loss: 90.2810, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 163/1000000, train_loss: 61.1717, val_loss: 90.1523, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 164/1000000, train_loss: 61.1243, val_loss: 90.1265, time: 0.12s\n",
      "Epoch 165/1000000, train_loss: 61.1659, val_loss: 90.3205, time: 0.12s\n",
      "Epoch 166/1000000, train_loss: 61.1409, val_loss: 90.1465, time: 0.12s\n",
      "Epoch 167/1000000, train_loss: 61.1298, val_loss: 90.1754, time: 0.12s\n",
      "Epoch 168/1000000, train_loss: 61.1490, val_loss: 90.2182, time: 0.12s\n",
      "Epoch 169/1000000, train_loss: 61.0859, val_loss: 90.1524, time: 0.11s\n",
      "Epoch 170/1000000, train_loss: 61.1008, val_loss: 90.1757, time: 0.12s\n",
      "Epoch 171/1000000, train_loss: 61.0864, val_loss: 90.1949, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 172/1000000, train_loss: 61.0745, val_loss: 89.9332, time: 0.12s\n",
      "Epoch 173/1000000, train_loss: 61.0694, val_loss: 89.9793, time: 0.12s\n",
      "Epoch 174/1000000, train_loss: 61.0361, val_loss: 90.0328, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 175/1000000, train_loss: 61.0460, val_loss: 89.8488, time: 0.11s\n",
      "Epoch 176/1000000, train_loss: 61.0140, val_loss: 89.9747, time: 0.11s\n",
      "Epoch 177/1000000, train_loss: 61.0064, val_loss: 89.8599, time: 0.11s\n",
      "Epoch 178/1000000, train_loss: 61.0038, val_loss: 89.9460, time: 0.11s\n",
      "Epoch 179/1000000, train_loss: 61.0005, val_loss: 89.9460, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 180/1000000, train_loss: 60.9691, val_loss: 89.7404, time: 0.12s\n",
      "Epoch 181/1000000, train_loss: 60.9484, val_loss: 89.8532, time: 0.11s\n",
      "Epoch 182/1000000, train_loss: 60.9604, val_loss: 89.8482, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 183/1000000, train_loss: 60.9446, val_loss: 89.7183, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 184/1000000, train_loss: 60.9252, val_loss: 89.6715, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 185/1000000, train_loss: 60.9194, val_loss: 89.4426, time: 0.12s\n",
      "Epoch 186/1000000, train_loss: 60.8798, val_loss: 89.6547, time: 0.11s\n",
      "Epoch 187/1000000, train_loss: 60.8791, val_loss: 89.5350, time: 0.12s\n",
      "Epoch 188/1000000, train_loss: 60.8809, val_loss: 89.4516, time: 0.11s\n",
      "Epoch 189/1000000, train_loss: 60.8562, val_loss: 89.5309, time: 0.11s\n",
      "Epoch 190/1000000, train_loss: 60.8460, val_loss: 89.4837, time: 0.12s\n",
      "Epoch 191/1000000, train_loss: 60.8384, val_loss: 89.5215, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 192/1000000, train_loss: 60.8295, val_loss: 89.3953, time: 0.12s\n",
      "Epoch 193/1000000, train_loss: 60.8197, val_loss: 89.5473, time: 0.12s\n",
      "Epoch 194/1000000, train_loss: 60.8063, val_loss: 89.4560, time: 0.12s\n",
      "Epoch 195/1000000, train_loss: 60.7757, val_loss: 89.4411, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 196/1000000, train_loss: 60.7771, val_loss: 89.2827, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 197/1000000, train_loss: 60.7746, val_loss: 89.2823, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 198/1000000, train_loss: 60.7522, val_loss: 89.1244, time: 0.12s\n",
      "Epoch 199/1000000, train_loss: 60.7464, val_loss: 89.3104, time: 0.11s\n",
      "Epoch 200/1000000, train_loss: 60.7047, val_loss: 89.1985, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 201/1000000, train_loss: 60.7577, val_loss: 89.0911, time: 0.12s\n",
      "Epoch 202/1000000, train_loss: 60.6810, val_loss: 89.2098, time: 0.11s\n",
      "Epoch 203/1000000, train_loss: 60.6747, val_loss: 89.1845, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 204/1000000, train_loss: 60.6689, val_loss: 89.0684, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 205/1000000, train_loss: 60.6726, val_loss: 88.9636, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 206/1000000, train_loss: 60.6852, val_loss: 88.9437, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 207/1000000, train_loss: 60.6497, val_loss: 88.9302, time: 0.11s\n",
      "Epoch 208/1000000, train_loss: 60.6360, val_loss: 89.0837, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 209/1000000, train_loss: 60.6188, val_loss: 88.9085, time: 0.11s\n",
      "Epoch 210/1000000, train_loss: 60.6009, val_loss: 88.9359, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 211/1000000, train_loss: 60.5982, val_loss: 88.8983, time: 0.11s\n",
      "Epoch 212/1000000, train_loss: 60.6158, val_loss: 89.0614, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 213/1000000, train_loss: 60.6548, val_loss: 88.7340, time: 0.12s\n",
      "Epoch 214/1000000, train_loss: 60.5620, val_loss: 88.9933, time: 0.11s\n",
      "Epoch 215/1000000, train_loss: 60.5637, val_loss: 88.7882, time: 0.12s\n",
      "Epoch 216/1000000, train_loss: 60.5410, val_loss: 88.7617, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 217/1000000, train_loss: 60.5256, val_loss: 88.6716, time: 0.12s\n",
      "Epoch 218/1000000, train_loss: 60.5158, val_loss: 88.7249, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 219/1000000, train_loss: 60.6352, val_loss: 88.6432, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 220/1000000, train_loss: 60.5188, val_loss: 88.5043, time: 0.12s\n",
      "Epoch 221/1000000, train_loss: 60.4739, val_loss: 88.5838, time: 0.14s\n",
      "Epoch 222/1000000, train_loss: 60.4738, val_loss: 88.6009, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 223/1000000, train_loss: 60.4260, val_loss: 88.4346, time: 0.12s\n",
      "Epoch 224/1000000, train_loss: 60.4632, val_loss: 88.4954, time: 0.12s\n",
      "Epoch 225/1000000, train_loss: 60.4123, val_loss: 88.5487, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 226/1000000, train_loss: 60.4223, val_loss: 88.4328, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 227/1000000, train_loss: 60.4011, val_loss: 88.3725, time: 0.12s\n",
      "Epoch 228/1000000, train_loss: 60.4082, val_loss: 88.4952, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 229/1000000, train_loss: 60.3835, val_loss: 88.2837, time: 0.12s\n",
      "Epoch 230/1000000, train_loss: 60.3697, val_loss: 88.3157, time: 0.11s\n",
      "Epoch 231/1000000, train_loss: 60.3564, val_loss: 88.3574, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 232/1000000, train_loss: 60.3353, val_loss: 88.1838, time: 0.12s\n",
      "Epoch 233/1000000, train_loss: 60.3300, val_loss: 88.3304, time: 0.11s\n",
      "Epoch 234/1000000, train_loss: 60.3085, val_loss: 88.2379, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 235/1000000, train_loss: 60.2902, val_loss: 88.1511, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 236/1000000, train_loss: 60.2867, val_loss: 88.0965, time: 0.11s\n",
      "Epoch 237/1000000, train_loss: 60.2820, val_loss: 88.1739, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 238/1000000, train_loss: 60.2827, val_loss: 88.0053, time: 0.12s\n",
      "Epoch 239/1000000, train_loss: 60.2562, val_loss: 88.1716, time: 0.11s\n",
      "Epoch 240/1000000, train_loss: 60.2599, val_loss: 88.0871, time: 0.11s\n",
      "Epoch 241/1000000, train_loss: 60.2427, val_loss: 88.0857, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 242/1000000, train_loss: 60.2223, val_loss: 87.8947, time: 0.11s\n",
      "Epoch 243/1000000, train_loss: 60.2058, val_loss: 88.0854, time: 0.11s\n",
      "Epoch 244/1000000, train_loss: 60.1962, val_loss: 87.8968, time: 0.12s\n",
      "Epoch 245/1000000, train_loss: 60.1901, val_loss: 87.9050, time: 0.12s\n",
      "Epoch 246/1000000, train_loss: 60.1471, val_loss: 88.0329, time: 0.12s\n",
      "Epoch 247/1000000, train_loss: 60.1772, val_loss: 87.9674, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 248/1000000, train_loss: 60.1271, val_loss: 87.7194, time: 0.12s\n",
      "Epoch 249/1000000, train_loss: 60.1519, val_loss: 87.8768, time: 0.12s\n",
      "Epoch 250/1000000, train_loss: 60.1128, val_loss: 87.8556, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 251/1000000, train_loss: 60.1004, val_loss: 87.6048, time: 0.17s\n",
      "Epoch 252/1000000, train_loss: 60.1216, val_loss: 87.6391, time: 0.14s\n",
      "Epoch 253/1000000, train_loss: 60.0962, val_loss: 87.7234, time: 0.11s\n",
      "Epoch 254/1000000, train_loss: 60.0626, val_loss: 87.6759, time: 0.11s\n",
      "Epoch 255/1000000, train_loss: 60.0746, val_loss: 87.6884, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 256/1000000, train_loss: 60.0612, val_loss: 87.5366, time: 0.12s\n",
      "Epoch 257/1000000, train_loss: 60.0387, val_loss: 87.6115, time: 0.11s\n",
      "Epoch 258/1000000, train_loss: 60.0386, val_loss: 87.5638, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 259/1000000, train_loss: 59.9790, val_loss: 87.5076, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 260/1000000, train_loss: 59.9969, val_loss: 87.4825, time: 0.12s\n",
      "Epoch 261/1000000, train_loss: 59.9848, val_loss: 87.4927, time: 0.11s\n",
      "Epoch 262/1000000, train_loss: 59.9656, val_loss: 87.5929, time: 0.11s\n",
      "Epoch 263/1000000, train_loss: 59.9672, val_loss: 87.5965, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 264/1000000, train_loss: 59.9846, val_loss: 87.3727, time: 0.12s\n",
      "Epoch 265/1000000, train_loss: 59.9736, val_loss: 87.3776, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 266/1000000, train_loss: 59.9763, val_loss: 87.3601, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 267/1000000, train_loss: 59.9617, val_loss: 87.3155, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 268/1000000, train_loss: 59.9721, val_loss: 87.1707, time: 0.12s\n",
      "Epoch 269/1000000, train_loss: 59.9221, val_loss: 87.2003, time: 0.12s\n",
      "Epoch 270/1000000, train_loss: 59.9292, val_loss: 87.2703, time: 0.11s\n",
      "Epoch 271/1000000, train_loss: 59.9084, val_loss: 87.1735, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 272/1000000, train_loss: 59.9039, val_loss: 87.0658, time: 0.11s\n",
      "Epoch 273/1000000, train_loss: 59.8866, val_loss: 87.1435, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 274/1000000, train_loss: 59.8478, val_loss: 87.0571, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 275/1000000, train_loss: 59.8325, val_loss: 87.0282, time: 0.11s\n",
      "Epoch 276/1000000, train_loss: 59.8395, val_loss: 87.0862, time: 0.11s\n",
      "Epoch 277/1000000, train_loss: 59.7976, val_loss: 87.0916, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 278/1000000, train_loss: 59.8047, val_loss: 86.9052, time: 0.12s\n",
      "Epoch 279/1000000, train_loss: 59.7725, val_loss: 87.0096, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 280/1000000, train_loss: 59.7662, val_loss: 86.8154, time: 0.12s\n",
      "Epoch 281/1000000, train_loss: 59.7461, val_loss: 86.9550, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 282/1000000, train_loss: 59.7530, val_loss: 86.8081, time: 0.11s\n",
      "Epoch 283/1000000, train_loss: 59.7279, val_loss: 86.8922, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 284/1000000, train_loss: 59.7307, val_loss: 86.7753, time: 0.12s\n",
      "Epoch 285/1000000, train_loss: 59.7049, val_loss: 86.8129, time: 0.11s\n",
      "Epoch 286/1000000, train_loss: 59.6990, val_loss: 86.9553, time: 0.11s\n",
      "Epoch 287/1000000, train_loss: 59.7028, val_loss: 86.8599, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 288/1000000, train_loss: 59.6769, val_loss: 86.6215, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 289/1000000, train_loss: 59.6428, val_loss: 86.5603, time: 0.12s\n",
      "Epoch 290/1000000, train_loss: 59.6529, val_loss: 86.6611, time: 0.12s\n",
      "Epoch 291/1000000, train_loss: 59.6370, val_loss: 86.5975, time: 0.12s\n",
      "Epoch 292/1000000, train_loss: 59.6352, val_loss: 86.5956, time: 0.11s\n",
      "Epoch 293/1000000, train_loss: 59.6246, val_loss: 86.6266, time: 0.11s\n",
      "Epoch 294/1000000, train_loss: 59.5967, val_loss: 86.6272, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 295/1000000, train_loss: 59.5932, val_loss: 86.4502, time: 0.12s\n",
      "Epoch 296/1000000, train_loss: 59.5654, val_loss: 86.5839, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 297/1000000, train_loss: 59.5722, val_loss: 86.3639, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 298/1000000, train_loss: 59.5667, val_loss: 86.3499, time: 0.11s\n",
      "Epoch 299/1000000, train_loss: 59.5286, val_loss: 86.4195, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 300/1000000, train_loss: 59.5211, val_loss: 86.3391, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 301/1000000, train_loss: 59.5177, val_loss: 86.3093, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 302/1000000, train_loss: 59.4860, val_loss: 86.2376, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 303/1000000, train_loss: 59.4838, val_loss: 86.2303, time: 0.12s\n",
      "Epoch 304/1000000, train_loss: 59.4888, val_loss: 86.3210, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 305/1000000, train_loss: 59.4606, val_loss: 86.1149, time: 0.12s\n",
      "Epoch 306/1000000, train_loss: 59.4536, val_loss: 86.1266, time: 0.11s\n",
      "Epoch 307/1000000, train_loss: 59.4179, val_loss: 86.1960, time: 0.14s\n",
      "Epoch 308/1000000, train_loss: 59.4467, val_loss: 86.1395, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 309/1000000, train_loss: 59.3995, val_loss: 86.0716, time: 0.11s\n",
      "Epoch 310/1000000, train_loss: 59.4206, val_loss: 86.1743, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 311/1000000, train_loss: 59.3783, val_loss: 86.0642, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 312/1000000, train_loss: 59.3455, val_loss: 86.0435, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 313/1000000, train_loss: 59.3607, val_loss: 85.9796, time: 0.11s\n",
      "Epoch 314/1000000, train_loss: 59.3451, val_loss: 85.9846, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 315/1000000, train_loss: 59.3510, val_loss: 85.9305, time: 0.11s\n",
      "Epoch 316/1000000, train_loss: 59.3185, val_loss: 86.0471, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 317/1000000, train_loss: 59.3362, val_loss: 85.7596, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 318/1000000, train_loss: 59.3161, val_loss: 85.7068, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 319/1000000, train_loss: 59.2826, val_loss: 85.7025, time: 0.11s\n",
      "Epoch 320/1000000, train_loss: 59.2887, val_loss: 85.7819, time: 0.11s\n",
      "Epoch 321/1000000, train_loss: 59.2572, val_loss: 85.7391, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 322/1000000, train_loss: 59.2714, val_loss: 85.6277, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 323/1000000, train_loss: 59.2222, val_loss: 85.5751, time: 0.12s\n",
      "Epoch 324/1000000, train_loss: 59.2518, val_loss: 85.7072, time: 0.12s\n",
      "Epoch 325/1000000, train_loss: 59.2189, val_loss: 85.6079, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 326/1000000, train_loss: 59.2111, val_loss: 85.5634, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 327/1000000, train_loss: 59.1951, val_loss: 85.5173, time: 0.11s\n",
      "Epoch 328/1000000, train_loss: 59.1828, val_loss: 85.6207, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 329/1000000, train_loss: 59.1654, val_loss: 85.4992, time: 0.11s\n",
      "Epoch 330/1000000, train_loss: 59.1618, val_loss: 85.5654, time: 0.12s\n",
      "Epoch 331/1000000, train_loss: 59.1605, val_loss: 85.6031, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 332/1000000, train_loss: 59.1270, val_loss: 85.4315, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 333/1000000, train_loss: 59.1362, val_loss: 85.3698, time: 0.11s\n",
      "Epoch 334/1000000, train_loss: 59.1102, val_loss: 85.5667, time: 0.11s\n",
      "Epoch 335/1000000, train_loss: 59.0937, val_loss: 85.4772, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 336/1000000, train_loss: 59.0761, val_loss: 85.2877, time: 0.12s\n",
      "Epoch 337/1000000, train_loss: 59.0749, val_loss: 85.3929, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 338/1000000, train_loss: 59.0656, val_loss: 85.2791, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 339/1000000, train_loss: 59.0292, val_loss: 85.1788, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 340/1000000, train_loss: 59.0439, val_loss: 85.1124, time: 0.11s\n",
      "Epoch 341/1000000, train_loss: 59.0343, val_loss: 85.1951, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 342/1000000, train_loss: 58.9927, val_loss: 85.1017, time: 0.12s\n",
      "Epoch 343/1000000, train_loss: 58.9719, val_loss: 85.2082, time: 0.12s\n",
      "Epoch 344/1000000, train_loss: 58.9763, val_loss: 85.1297, time: 0.13s\n",
      "Epoch 345/1000000, train_loss: 58.9742, val_loss: 85.1357, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 346/1000000, train_loss: 58.9418, val_loss: 85.0078, time: 0.12s\n",
      "Epoch 347/1000000, train_loss: 58.9407, val_loss: 85.0954, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 348/1000000, train_loss: 58.9499, val_loss: 84.9270, time: 0.12s\n",
      "Epoch 349/1000000, train_loss: 58.9174, val_loss: 85.0401, time: 0.13s\n",
      "Epoch 350/1000000, train_loss: 58.9117, val_loss: 84.9516, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 351/1000000, train_loss: 58.8901, val_loss: 84.8421, time: 0.11s\n",
      "Epoch 352/1000000, train_loss: 58.8769, val_loss: 84.9279, time: 0.12s\n",
      "Epoch 353/1000000, train_loss: 58.8642, val_loss: 84.8897, time: 0.12s\n",
      "Epoch 354/1000000, train_loss: 58.8803, val_loss: 84.8833, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 355/1000000, train_loss: 58.8485, val_loss: 84.8121, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 356/1000000, train_loss: 58.7997, val_loss: 84.5931, time: 0.12s\n",
      "Epoch 357/1000000, train_loss: 58.8422, val_loss: 84.7228, time: 0.11s\n",
      "Epoch 358/1000000, train_loss: 58.8126, val_loss: 84.6906, time: 0.11s\n",
      "Epoch 359/1000000, train_loss: 58.7890, val_loss: 84.6613, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 360/1000000, train_loss: 58.7799, val_loss: 84.4611, time: 0.11s\n",
      "Epoch 361/1000000, train_loss: 58.7789, val_loss: 84.6787, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 362/1000000, train_loss: 58.7491, val_loss: 84.4239, time: 0.12s\n",
      "Epoch 363/1000000, train_loss: 58.7225, val_loss: 84.6960, time: 0.12s\n",
      "Epoch 364/1000000, train_loss: 58.7192, val_loss: 84.4914, time: 0.12s\n",
      "Epoch 365/1000000, train_loss: 58.7155, val_loss: 84.4829, time: 0.12s\n",
      "Epoch 366/1000000, train_loss: 58.7047, val_loss: 84.4402, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 367/1000000, train_loss: 58.7036, val_loss: 84.3115, time: 0.12s\n",
      "Epoch 368/1000000, train_loss: 58.6831, val_loss: 84.4490, time: 0.11s\n",
      "Epoch 369/1000000, train_loss: 58.6794, val_loss: 84.4173, time: 0.12s\n",
      "Epoch 370/1000000, train_loss: 58.6618, val_loss: 84.4324, time: 0.11s\n",
      "Epoch 371/1000000, train_loss: 58.6574, val_loss: 84.4015, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 372/1000000, train_loss: 58.6350, val_loss: 84.2431, time: 0.12s\n",
      "Epoch 373/1000000, train_loss: 58.6429, val_loss: 84.3596, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 374/1000000, train_loss: 58.5843, val_loss: 84.2097, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 375/1000000, train_loss: 58.5864, val_loss: 84.2025, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 376/1000000, train_loss: 58.5519, val_loss: 84.1378, time: 0.12s\n",
      "Epoch 377/1000000, train_loss: 58.5882, val_loss: 84.2104, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 378/1000000, train_loss: 58.5510, val_loss: 84.0789, time: 0.12s\n",
      "Epoch 379/1000000, train_loss: 58.5456, val_loss: 84.1037, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 380/1000000, train_loss: 58.5276, val_loss: 83.9206, time: 0.12s\n",
      "Epoch 381/1000000, train_loss: 58.5165, val_loss: 83.9391, time: 0.12s\n",
      "Epoch 382/1000000, train_loss: 58.5395, val_loss: 84.0037, time: 0.11s\n",
      "Epoch 383/1000000, train_loss: 58.4975, val_loss: 84.0135, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 384/1000000, train_loss: 58.5072, val_loss: 83.7906, time: 0.12s\n",
      "Epoch 385/1000000, train_loss: 58.4606, val_loss: 84.0161, time: 0.12s\n",
      "Epoch 386/1000000, train_loss: 58.4498, val_loss: 83.8754, time: 0.12s\n",
      "Epoch 387/1000000, train_loss: 58.4400, val_loss: 83.8300, time: 0.12s\n",
      "Epoch 388/1000000, train_loss: 58.4454, val_loss: 83.8110, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 389/1000000, train_loss: 58.4174, val_loss: 83.7431, time: 0.12s\n",
      "Epoch 390/1000000, train_loss: 58.4174, val_loss: 83.9444, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 391/1000000, train_loss: 58.3837, val_loss: 83.7423, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 392/1000000, train_loss: 58.3966, val_loss: 83.7187, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 393/1000000, train_loss: 58.3538, val_loss: 83.6938, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 394/1000000, train_loss: 58.3483, val_loss: 83.6359, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 395/1000000, train_loss: 58.3551, val_loss: 83.5839, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 396/1000000, train_loss: 58.3359, val_loss: 83.5331, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 397/1000000, train_loss: 58.4034, val_loss: 83.5103, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 398/1000000, train_loss: 58.3065, val_loss: 83.4759, time: 0.12s\n",
      "Epoch 399/1000000, train_loss: 58.3132, val_loss: 83.4883, time: 0.11s\n",
      "Epoch 400/1000000, train_loss: 58.2666, val_loss: 83.4983, time: 0.11s\n",
      "Epoch 401/1000000, train_loss: 58.2640, val_loss: 83.5135, time: 0.11s\n",
      "Epoch 402/1000000, train_loss: 58.2538, val_loss: 83.5045, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 403/1000000, train_loss: 58.2516, val_loss: 83.4186, time: 0.12s\n",
      "Epoch 404/1000000, train_loss: 58.2182, val_loss: 83.4571, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 405/1000000, train_loss: 58.2082, val_loss: 83.3167, time: 0.12s\n",
      "Epoch 406/1000000, train_loss: 58.2140, val_loss: 83.3931, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 407/1000000, train_loss: 58.1723, val_loss: 83.2642, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 408/1000000, train_loss: 58.1961, val_loss: 83.2144, time: 0.12s\n",
      "Epoch 409/1000000, train_loss: 58.1708, val_loss: 83.2619, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 410/1000000, train_loss: 58.1853, val_loss: 83.1906, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 411/1000000, train_loss: 58.1324, val_loss: 83.0718, time: 0.12s\n",
      "Epoch 412/1000000, train_loss: 58.1177, val_loss: 83.1288, time: 0.12s\n",
      "Epoch 413/1000000, train_loss: 58.1394, val_loss: 83.0929, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 414/1000000, train_loss: 58.1084, val_loss: 82.9912, time: 0.12s\n",
      "Epoch 415/1000000, train_loss: 58.0909, val_loss: 83.0881, time: 0.12s\n",
      "Epoch 416/1000000, train_loss: 58.0653, val_loss: 83.0097, time: 0.12s\n",
      "Epoch 417/1000000, train_loss: 58.0841, val_loss: 83.0294, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 418/1000000, train_loss: 58.0574, val_loss: 82.8933, time: 0.12s\n",
      "Epoch 419/1000000, train_loss: 58.0437, val_loss: 83.0629, time: 0.12s\n",
      "Epoch 420/1000000, train_loss: 58.0454, val_loss: 82.9581, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 421/1000000, train_loss: 58.0084, val_loss: 82.8724, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 422/1000000, train_loss: 58.0155, val_loss: 82.8528, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 423/1000000, train_loss: 58.0107, val_loss: 82.7469, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 424/1000000, train_loss: 58.0006, val_loss: 82.7416, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 425/1000000, train_loss: 57.9799, val_loss: 82.7145, time: 0.11s\n",
      "Epoch 426/1000000, train_loss: 57.9563, val_loss: 82.8278, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 427/1000000, train_loss: 57.9450, val_loss: 82.5848, time: 0.11s\n",
      "Epoch 428/1000000, train_loss: 57.9166, val_loss: 82.5994, time: 0.11s\n",
      "Epoch 429/1000000, train_loss: 57.9240, val_loss: 82.6484, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 430/1000000, train_loss: 57.9070, val_loss: 82.5751, time: 0.12s\n",
      "Epoch 431/1000000, train_loss: 57.9213, val_loss: 82.5913, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 432/1000000, train_loss: 57.8938, val_loss: 82.5498, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 433/1000000, train_loss: 57.8832, val_loss: 82.5161, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 434/1000000, train_loss: 57.8708, val_loss: 82.2738, time: 0.12s\n",
      "Epoch 435/1000000, train_loss: 57.8375, val_loss: 82.5065, time: 0.11s\n",
      "Epoch 436/1000000, train_loss: 57.8321, val_loss: 82.5714, time: 0.12s\n",
      "Epoch 437/1000000, train_loss: 57.8112, val_loss: 82.3942, time: 0.12s\n",
      "Epoch 438/1000000, train_loss: 57.7882, val_loss: 82.4286, time: 0.12s\n",
      "Epoch 439/1000000, train_loss: 57.7842, val_loss: 82.4502, time: 0.12s\n",
      "Epoch 440/1000000, train_loss: 57.7791, val_loss: 82.3165, time: 0.11s\n",
      "Epoch 441/1000000, train_loss: 57.7654, val_loss: 82.2986, time: 0.12s\n",
      "Epoch 442/1000000, train_loss: 57.7644, val_loss: 82.3724, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 443/1000000, train_loss: 57.7375, val_loss: 82.2324, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 444/1000000, train_loss: 57.7305, val_loss: 82.1880, time: 0.11s\n",
      "Epoch 445/1000000, train_loss: 57.7335, val_loss: 82.1933, time: 0.12s\n",
      "Epoch 446/1000000, train_loss: 57.6837, val_loss: 82.3173, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 447/1000000, train_loss: 57.6790, val_loss: 82.1422, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 448/1000000, train_loss: 57.6759, val_loss: 82.0956, time: 0.12s\n",
      "Epoch 449/1000000, train_loss: 57.7012, val_loss: 82.1535, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 450/1000000, train_loss: 57.6699, val_loss: 82.0228, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 451/1000000, train_loss: 57.6523, val_loss: 81.9509, time: 0.12s\n",
      "Epoch 452/1000000, train_loss: 57.6166, val_loss: 81.9777, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 453/1000000, train_loss: 57.6147, val_loss: 81.8182, time: 0.12s\n",
      "Epoch 454/1000000, train_loss: 57.6130, val_loss: 81.8896, time: 0.12s\n",
      "Epoch 455/1000000, train_loss: 57.5871, val_loss: 81.9894, time: 0.12s\n",
      "Epoch 456/1000000, train_loss: 57.5831, val_loss: 81.8311, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 457/1000000, train_loss: 57.5685, val_loss: 81.6529, time: 0.12s\n",
      "Epoch 458/1000000, train_loss: 57.5526, val_loss: 81.7976, time: 0.11s\n",
      "Epoch 459/1000000, train_loss: 57.5396, val_loss: 81.7710, time: 0.12s\n",
      "Epoch 460/1000000, train_loss: 57.5440, val_loss: 81.7140, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 461/1000000, train_loss: 57.5092, val_loss: 81.5447, time: 0.12s\n",
      "Epoch 462/1000000, train_loss: 57.5042, val_loss: 81.8393, time: 0.11s\n",
      "Epoch 463/1000000, train_loss: 57.5035, val_loss: 81.6463, time: 0.11s\n",
      "Epoch 464/1000000, train_loss: 57.4845, val_loss: 81.6563, time: 0.11s\n",
      "Epoch 465/1000000, train_loss: 57.4708, val_loss: 81.7134, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 466/1000000, train_loss: 57.4421, val_loss: 81.5325, time: 0.12s\n",
      "Epoch 467/1000000, train_loss: 57.4390, val_loss: 81.5677, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 468/1000000, train_loss: 57.4366, val_loss: 81.4167, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 469/1000000, train_loss: 57.3937, val_loss: 81.2919, time: 0.12s\n",
      "Epoch 470/1000000, train_loss: 57.3696, val_loss: 81.4765, time: 0.11s\n",
      "Epoch 471/1000000, train_loss: 57.3867, val_loss: 81.4182, time: 0.11s\n",
      "Epoch 472/1000000, train_loss: 57.3897, val_loss: 81.4705, time: 0.11s\n",
      "Epoch 473/1000000, train_loss: 57.3656, val_loss: 81.4264, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 474/1000000, train_loss: 57.3637, val_loss: 81.2629, time: 0.11s\n",
      "Epoch 475/1000000, train_loss: 57.3341, val_loss: 81.3112, time: 0.12s\n",
      "Epoch 476/1000000, train_loss: 57.3429, val_loss: 81.2904, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 477/1000000, train_loss: 57.3262, val_loss: 81.2084, time: 0.12s\n",
      "Epoch 478/1000000, train_loss: 57.3071, val_loss: 81.2422, time: 0.11s\n",
      "Epoch 479/1000000, train_loss: 57.2832, val_loss: 81.2730, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 480/1000000, train_loss: 57.2580, val_loss: 81.1394, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 481/1000000, train_loss: 57.2748, val_loss: 81.0782, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 482/1000000, train_loss: 57.2300, val_loss: 81.0668, time: 0.12s\n",
      "Epoch 483/1000000, train_loss: 57.2446, val_loss: 81.1290, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 484/1000000, train_loss: 57.2416, val_loss: 81.0431, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 485/1000000, train_loss: 57.2078, val_loss: 80.9669, time: 0.12s\n",
      "Epoch 486/1000000, train_loss: 57.2044, val_loss: 80.9892, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 487/1000000, train_loss: 57.1826, val_loss: 80.8486, time: 0.12s\n",
      "Epoch 488/1000000, train_loss: 57.1875, val_loss: 80.9079, time: 0.11s\n",
      "Epoch 489/1000000, train_loss: 57.1834, val_loss: 80.9835, time: 0.12s\n",
      "Epoch 490/1000000, train_loss: 57.1636, val_loss: 81.0249, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 491/1000000, train_loss: 57.1509, val_loss: 80.8338, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 492/1000000, train_loss: 57.1268, val_loss: 80.7699, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 493/1000000, train_loss: 57.1150, val_loss: 80.7149, time: 0.12s\n",
      "Epoch 494/1000000, train_loss: 57.1156, val_loss: 80.8293, time: 0.12s\n",
      "Epoch 495/1000000, train_loss: 57.0945, val_loss: 80.7806, time: 0.12s\n",
      "Epoch 496/1000000, train_loss: 57.0920, val_loss: 80.7351, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 497/1000000, train_loss: 57.0367, val_loss: 80.6509, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 498/1000000, train_loss: 57.0465, val_loss: 80.6458, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 499/1000000, train_loss: 57.0319, val_loss: 80.5279, time: 0.12s\n",
      "Epoch 500/1000000, train_loss: 57.0087, val_loss: 80.5585, time: 0.12s\n",
      "Epoch 501/1000000, train_loss: 57.0058, val_loss: 80.5703, time: 0.12s\n",
      "Epoch 502/1000000, train_loss: 56.9855, val_loss: 80.5712, time: 0.12s\n",
      "Epoch 503/1000000, train_loss: 56.9694, val_loss: 80.5738, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 504/1000000, train_loss: 56.9696, val_loss: 80.4804, time: 0.11s\n",
      "Epoch 505/1000000, train_loss: 56.9718, val_loss: 80.5471, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 506/1000000, train_loss: 56.9855, val_loss: 80.3521, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 507/1000000, train_loss: 57.0349, val_loss: 80.2041, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 508/1000000, train_loss: 57.0100, val_loss: 80.1967, time: 0.12s\n",
      "Epoch 509/1000000, train_loss: 56.9740, val_loss: 80.4066, time: 0.12s\n",
      "Epoch 510/1000000, train_loss: 56.9050, val_loss: 80.3237, time: 0.12s\n",
      "Epoch 511/1000000, train_loss: 56.9232, val_loss: 80.3105, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 512/1000000, train_loss: 56.9103, val_loss: 80.1666, time: 0.12s\n",
      "Epoch 513/1000000, train_loss: 56.9119, val_loss: 80.2084, time: 0.11s\n",
      "Epoch 514/1000000, train_loss: 56.8707, val_loss: 80.2812, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 515/1000000, train_loss: 56.8629, val_loss: 80.1073, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 516/1000000, train_loss: 56.8689, val_loss: 80.0799, time: 0.12s\n",
      "Epoch 517/1000000, train_loss: 56.8533, val_loss: 80.0988, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 518/1000000, train_loss: 56.8750, val_loss: 80.0398, time: 0.12s\n",
      "Epoch 519/1000000, train_loss: 56.8812, val_loss: 80.1517, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 520/1000000, train_loss: 56.8546, val_loss: 79.9832, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 521/1000000, train_loss: 56.8468, val_loss: 79.9043, time: 0.12s\n",
      "Epoch 522/1000000, train_loss: 56.7752, val_loss: 79.9410, time: 0.11s\n",
      "Epoch 523/1000000, train_loss: 56.7334, val_loss: 79.9473, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 524/1000000, train_loss: 56.7548, val_loss: 79.8852, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 525/1000000, train_loss: 56.7301, val_loss: 79.7326, time: 0.17s\n",
      "Epoch 526/1000000, train_loss: 56.7141, val_loss: 79.9030, time: 0.13s\n",
      "Epoch 527/1000000, train_loss: 56.6886, val_loss: 79.7630, time: 0.12s\n",
      "Epoch 528/1000000, train_loss: 56.6870, val_loss: 79.7402, time: 0.12s\n",
      "Epoch 529/1000000, train_loss: 56.6774, val_loss: 79.8325, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 530/1000000, train_loss: 56.6350, val_loss: 79.6341, time: 0.12s\n",
      "Epoch 531/1000000, train_loss: 56.6539, val_loss: 79.7036, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 532/1000000, train_loss: 56.6336, val_loss: 79.5435, time: 0.12s\n",
      "Epoch 533/1000000, train_loss: 56.6218, val_loss: 79.5717, time: 0.12s\n",
      "Epoch 534/1000000, train_loss: 56.6109, val_loss: 79.6280, time: 0.12s\n",
      "Epoch 535/1000000, train_loss: 56.5779, val_loss: 79.6150, time: 0.12s\n",
      "Epoch 536/1000000, train_loss: 56.5621, val_loss: 79.5512, time: 0.12s\n",
      "Epoch 537/1000000, train_loss: 56.5718, val_loss: 79.5827, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 538/1000000, train_loss: 56.5442, val_loss: 79.5056, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 539/1000000, train_loss: 56.5581, val_loss: 79.4515, time: 0.12s\n",
      "Epoch 540/1000000, train_loss: 56.5220, val_loss: 79.4904, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 541/1000000, train_loss: 56.5182, val_loss: 79.3620, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 542/1000000, train_loss: 56.5163, val_loss: 79.3372, time: 0.12s\n",
      "Epoch 543/1000000, train_loss: 56.4985, val_loss: 79.3407, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 544/1000000, train_loss: 56.4990, val_loss: 79.2778, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 545/1000000, train_loss: 56.4758, val_loss: 79.2421, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 546/1000000, train_loss: 56.4623, val_loss: 79.2296, time: 0.12s\n",
      "Epoch 547/1000000, train_loss: 56.4656, val_loss: 79.2489, time: 0.12s\n",
      "Epoch 548/1000000, train_loss: 56.4261, val_loss: 79.3232, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 549/1000000, train_loss: 56.4330, val_loss: 79.1577, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 550/1000000, train_loss: 56.4151, val_loss: 79.0573, time: 0.12s\n",
      "Epoch 551/1000000, train_loss: 56.4097, val_loss: 79.1392, time: 0.12s\n",
      "Epoch 552/1000000, train_loss: 56.3946, val_loss: 79.1476, time: 0.12s\n",
      "Epoch 553/1000000, train_loss: 56.3701, val_loss: 79.1270, time: 0.12s\n",
      "Epoch 554/1000000, train_loss: 56.3654, val_loss: 79.1205, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 555/1000000, train_loss: 56.3762, val_loss: 78.9654, time: 0.12s\n",
      "Epoch 556/1000000, train_loss: 56.3549, val_loss: 78.9931, time: 0.12s\n",
      "Epoch 557/1000000, train_loss: 56.3258, val_loss: 78.9917, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 558/1000000, train_loss: 56.3394, val_loss: 78.8663, time: 0.12s\n",
      "Epoch 559/1000000, train_loss: 56.3039, val_loss: 79.0021, time: 0.12s\n",
      "Epoch 560/1000000, train_loss: 56.3030, val_loss: 78.9256, time: 0.11s\n",
      "Epoch 561/1000000, train_loss: 56.2975, val_loss: 78.9162, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 562/1000000, train_loss: 56.2554, val_loss: 78.8549, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 563/1000000, train_loss: 56.2488, val_loss: 78.7395, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 564/1000000, train_loss: 56.2506, val_loss: 78.6978, time: 0.12s\n",
      "Epoch 565/1000000, train_loss: 56.2142, val_loss: 78.7381, time: 0.11s\n",
      "Epoch 566/1000000, train_loss: 56.2361, val_loss: 78.7108, time: 0.11s\n",
      "Epoch 567/1000000, train_loss: 56.2077, val_loss: 78.7199, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 568/1000000, train_loss: 56.2128, val_loss: 78.6173, time: 0.11s\n",
      "Epoch 569/1000000, train_loss: 56.1686, val_loss: 78.6279, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 570/1000000, train_loss: 56.1556, val_loss: 78.5706, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 571/1000000, train_loss: 56.1726, val_loss: 78.5673, time: 0.12s\n",
      "Epoch 572/1000000, train_loss: 56.1439, val_loss: 78.6582, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 573/1000000, train_loss: 56.1191, val_loss: 78.4705, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 574/1000000, train_loss: 56.1193, val_loss: 78.3569, time: 0.11s\n",
      "Epoch 575/1000000, train_loss: 56.0993, val_loss: 78.4096, time: 0.11s\n",
      "Epoch 576/1000000, train_loss: 56.1014, val_loss: 78.4225, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 577/1000000, train_loss: 56.0844, val_loss: 78.2510, time: 0.11s\n",
      "Epoch 578/1000000, train_loss: 56.0717, val_loss: 78.4241, time: 0.11s\n",
      "Epoch 579/1000000, train_loss: 56.0598, val_loss: 78.3067, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 580/1000000, train_loss: 56.0399, val_loss: 78.2316, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 581/1000000, train_loss: 56.0364, val_loss: 78.2068, time: 0.12s\n",
      "Epoch 582/1000000, train_loss: 56.0286, val_loss: 78.2565, time: 0.12s\n",
      "Epoch 583/1000000, train_loss: 56.0100, val_loss: 78.2167, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 584/1000000, train_loss: 56.0020, val_loss: 78.1149, time: 0.11s\n",
      "Epoch 585/1000000, train_loss: 55.9825, val_loss: 78.2613, time: 0.11s\n",
      "Epoch 586/1000000, train_loss: 55.9772, val_loss: 78.1406, time: 0.11s\n",
      "Epoch 587/1000000, train_loss: 55.9675, val_loss: 78.1362, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 588/1000000, train_loss: 55.9485, val_loss: 78.0645, time: 0.11s\n",
      "Epoch 589/1000000, train_loss: 55.9227, val_loss: 78.1360, time: 0.11s\n",
      "Epoch 590/1000000, train_loss: 55.9241, val_loss: 78.0893, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 591/1000000, train_loss: 55.9048, val_loss: 78.0386, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 592/1000000, train_loss: 55.8858, val_loss: 77.8828, time: 0.11s\n",
      "Epoch 593/1000000, train_loss: 55.8910, val_loss: 77.9747, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 594/1000000, train_loss: 55.8720, val_loss: 77.8523, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 595/1000000, train_loss: 55.8504, val_loss: 77.8201, time: 0.11s\n",
      "Epoch 596/1000000, train_loss: 55.8449, val_loss: 77.8509, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 597/1000000, train_loss: 55.8330, val_loss: 77.7673, time: 0.12s\n",
      "Epoch 598/1000000, train_loss: 55.8199, val_loss: 77.7890, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 599/1000000, train_loss: 55.8060, val_loss: 77.6709, time: 0.11s\n",
      "Epoch 600/1000000, train_loss: 55.8024, val_loss: 77.7163, time: 0.11s\n",
      "Epoch 601/1000000, train_loss: 55.7880, val_loss: 77.7062, time: 0.11s\n",
      "Epoch 602/1000000, train_loss: 55.7631, val_loss: 77.6970, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 603/1000000, train_loss: 55.7598, val_loss: 77.5839, time: 0.11s\n",
      "Epoch 604/1000000, train_loss: 55.7613, val_loss: 77.6529, time: 0.11s\n",
      "Epoch 605/1000000, train_loss: 55.7421, val_loss: 77.7258, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 606/1000000, train_loss: 55.7128, val_loss: 77.5671, time: 0.11s\n",
      "Epoch 607/1000000, train_loss: 55.7150, val_loss: 77.5968, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 608/1000000, train_loss: 55.6968, val_loss: 77.4744, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 609/1000000, train_loss: 55.6706, val_loss: 77.3585, time: 0.11s\n",
      "Epoch 610/1000000, train_loss: 55.7017, val_loss: 77.5239, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 611/1000000, train_loss: 55.6604, val_loss: 77.3565, time: 0.11s\n",
      "Epoch 612/1000000, train_loss: 55.6664, val_loss: 77.4279, time: 0.11s\n",
      "Epoch 613/1000000, train_loss: 55.6561, val_loss: 77.3736, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 614/1000000, train_loss: 55.6231, val_loss: 77.3297, time: 0.11s\n",
      "Epoch 615/1000000, train_loss: 55.6167, val_loss: 77.3556, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 616/1000000, train_loss: 55.5947, val_loss: 77.2575, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 617/1000000, train_loss: 55.5913, val_loss: 77.1975, time: 0.12s\n",
      "Epoch 618/1000000, train_loss: 55.5898, val_loss: 77.2192, time: 0.11s\n",
      "Epoch 619/1000000, train_loss: 55.5830, val_loss: 77.2987, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 620/1000000, train_loss: 55.6035, val_loss: 77.1905, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 621/1000000, train_loss: 55.6340, val_loss: 77.1478, time: 0.12s\n",
      "Epoch 622/1000000, train_loss: 55.5495, val_loss: 77.1517, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 623/1000000, train_loss: 55.5160, val_loss: 76.9263, time: 0.12s\n",
      "Epoch 624/1000000, train_loss: 55.5077, val_loss: 77.0526, time: 0.12s\n",
      "Epoch 625/1000000, train_loss: 55.4884, val_loss: 77.0170, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 626/1000000, train_loss: 55.4773, val_loss: 76.8585, time: 0.12s\n",
      "Epoch 627/1000000, train_loss: 55.4626, val_loss: 76.9142, time: 0.12s\n",
      "Epoch 628/1000000, train_loss: 55.4438, val_loss: 76.9757, time: 0.11s\n",
      "Epoch 629/1000000, train_loss: 55.4465, val_loss: 76.9508, time: 0.11s\n",
      "Epoch 630/1000000, train_loss: 55.4411, val_loss: 76.9356, time: 0.12s\n",
      "Epoch 631/1000000, train_loss: 55.4020, val_loss: 76.8873, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 632/1000000, train_loss: 55.3990, val_loss: 76.7703, time: 0.11s\n",
      "Epoch 633/1000000, train_loss: 55.3970, val_loss: 76.7797, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 634/1000000, train_loss: 55.3876, val_loss: 76.7537, time: 0.12s\n",
      "Epoch 635/1000000, train_loss: 55.3733, val_loss: 76.7573, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 636/1000000, train_loss: 55.3527, val_loss: 76.6957, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 637/1000000, train_loss: 55.3579, val_loss: 76.6647, time: 0.11s\n",
      "Epoch 638/1000000, train_loss: 55.3447, val_loss: 76.8293, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 639/1000000, train_loss: 55.4319, val_loss: 76.5279, time: 0.11s\n",
      "Epoch 640/1000000, train_loss: 55.3723, val_loss: 76.6245, time: 0.11s\n",
      "Epoch 641/1000000, train_loss: 55.4469, val_loss: 76.5474, time: 0.11s\n",
      "Epoch 642/1000000, train_loss: 55.4249, val_loss: 76.5461, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 643/1000000, train_loss: 55.3487, val_loss: 76.4992, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 644/1000000, train_loss: 55.2704, val_loss: 76.4813, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 645/1000000, train_loss: 55.2583, val_loss: 76.3459, time: 0.11s\n",
      "Epoch 646/1000000, train_loss: 55.2099, val_loss: 76.5676, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 647/1000000, train_loss: 55.1909, val_loss: 76.3191, time: 0.11s\n",
      "Epoch 648/1000000, train_loss: 55.1712, val_loss: 76.3589, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 649/1000000, train_loss: 55.1713, val_loss: 76.3098, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 650/1000000, train_loss: 55.1573, val_loss: 76.1635, time: 0.11s\n",
      "Epoch 651/1000000, train_loss: 55.1466, val_loss: 76.2621, time: 0.11s\n",
      "Epoch 652/1000000, train_loss: 55.1332, val_loss: 76.2440, time: 0.21s\n",
      "Epoch 653/1000000, train_loss: 55.1105, val_loss: 76.1734, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 654/1000000, train_loss: 55.1260, val_loss: 76.1533, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 655/1000000, train_loss: 55.1072, val_loss: 76.0916, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 656/1000000, train_loss: 55.0957, val_loss: 76.0415, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 657/1000000, train_loss: 55.0817, val_loss: 76.0267, time: 0.12s\n",
      "Epoch 658/1000000, train_loss: 55.0550, val_loss: 76.0587, time: 0.12s\n",
      "Epoch 659/1000000, train_loss: 55.0426, val_loss: 76.0811, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 660/1000000, train_loss: 55.0167, val_loss: 75.9980, time: 0.12s\n",
      "Epoch 661/1000000, train_loss: 55.0127, val_loss: 76.0250, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 662/1000000, train_loss: 54.9927, val_loss: 75.9878, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 663/1000000, train_loss: 55.0026, val_loss: 75.8223, time: 0.12s\n",
      "Epoch 664/1000000, train_loss: 54.9863, val_loss: 75.9042, time: 0.11s\n",
      "Epoch 665/1000000, train_loss: 54.9676, val_loss: 75.8769, time: 0.12s\n",
      "Epoch 666/1000000, train_loss: 54.9544, val_loss: 75.9254, time: 0.12s\n",
      "Epoch 667/1000000, train_loss: 54.9595, val_loss: 75.8752, time: 0.12s\n",
      "Epoch 668/1000000, train_loss: 54.9334, val_loss: 75.8577, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 669/1000000, train_loss: 54.9310, val_loss: 75.7298, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 670/1000000, train_loss: 54.8983, val_loss: 75.6967, time: 0.12s\n",
      "Epoch 671/1000000, train_loss: 54.8906, val_loss: 75.7161, time: 0.12s\n",
      "Epoch 672/1000000, train_loss: 54.9072, val_loss: 75.7274, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 673/1000000, train_loss: 54.8576, val_loss: 75.6798, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 674/1000000, train_loss: 54.8717, val_loss: 75.5876, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 675/1000000, train_loss: 54.8457, val_loss: 75.5720, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 676/1000000, train_loss: 54.8446, val_loss: 75.5126, time: 0.12s\n",
      "Epoch 677/1000000, train_loss: 54.8022, val_loss: 75.5505, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 678/1000000, train_loss: 54.8115, val_loss: 75.4542, time: 0.12s\n",
      "Epoch 679/1000000, train_loss: 54.7892, val_loss: 75.5415, time: 0.11s\n",
      "Epoch 680/1000000, train_loss: 54.7942, val_loss: 75.4606, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 681/1000000, train_loss: 54.7594, val_loss: 75.4350, time: 0.11s\n",
      "Epoch 682/1000000, train_loss: 54.7515, val_loss: 75.4526, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 683/1000000, train_loss: 54.7385, val_loss: 75.3259, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 684/1000000, train_loss: 54.7379, val_loss: 75.2221, time: 0.11s\n",
      "Epoch 685/1000000, train_loss: 54.7171, val_loss: 75.2424, time: 0.11s\n",
      "Epoch 686/1000000, train_loss: 54.7130, val_loss: 75.2664, time: 0.11s\n",
      "Epoch 687/1000000, train_loss: 54.7091, val_loss: 75.2326, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 688/1000000, train_loss: 54.7009, val_loss: 75.1620, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 689/1000000, train_loss: 54.6733, val_loss: 75.1538, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 690/1000000, train_loss: 54.6541, val_loss: 75.0381, time: 0.11s\n",
      "Epoch 691/1000000, train_loss: 54.6347, val_loss: 75.1770, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 692/1000000, train_loss: 54.6503, val_loss: 75.0188, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 693/1000000, train_loss: 54.6062, val_loss: 75.0107, time: 0.11s\n",
      "Epoch 694/1000000, train_loss: 54.6010, val_loss: 75.0490, time: 0.11s\n",
      "Epoch 695/1000000, train_loss: 54.5945, val_loss: 75.0369, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 696/1000000, train_loss: 54.5823, val_loss: 74.8994, time: 0.11s\n",
      "Epoch 697/1000000, train_loss: 54.5795, val_loss: 74.9100, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 698/1000000, train_loss: 54.5604, val_loss: 74.8244, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 699/1000000, train_loss: 54.5462, val_loss: 74.7745, time: 0.11s\n",
      "Epoch 700/1000000, train_loss: 54.6942, val_loss: 74.7993, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 701/1000000, train_loss: 54.6423, val_loss: 74.7575, time: 0.11s\n",
      "Epoch 702/1000000, train_loss: 54.5686, val_loss: 74.8803, time: 0.11s\n",
      "Epoch 703/1000000, train_loss: 54.8934, val_loss: 74.8666, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 704/1000000, train_loss: 54.6514, val_loss: 74.6742, time: 0.11s\n",
      "Epoch 705/1000000, train_loss: 54.4902, val_loss: 74.7358, time: 0.11s\n",
      "Epoch 706/1000000, train_loss: 54.4659, val_loss: 74.7317, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 707/1000000, train_loss: 54.4414, val_loss: 74.6712, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 708/1000000, train_loss: 54.4264, val_loss: 74.5594, time: 0.11s\n",
      "Epoch 709/1000000, train_loss: 54.4173, val_loss: 74.6098, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 710/1000000, train_loss: 54.3965, val_loss: 74.5171, time: 0.11s\n",
      "Epoch 711/1000000, train_loss: 54.4021, val_loss: 74.5336, time: 0.11s\n",
      "Epoch 712/1000000, train_loss: 54.3857, val_loss: 74.5529, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 713/1000000, train_loss: 54.3802, val_loss: 74.4731, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 714/1000000, train_loss: 54.3488, val_loss: 74.4408, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 715/1000000, train_loss: 54.3512, val_loss: 74.4060, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 716/1000000, train_loss: 54.3361, val_loss: 74.3914, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 717/1000000, train_loss: 54.3277, val_loss: 74.3298, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 718/1000000, train_loss: 54.3076, val_loss: 74.2146, time: 0.11s\n",
      "Epoch 719/1000000, train_loss: 54.2974, val_loss: 74.2671, time: 0.11s\n",
      "Epoch 720/1000000, train_loss: 54.2841, val_loss: 74.3185, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 721/1000000, train_loss: 54.2715, val_loss: 74.1521, time: 0.11s\n",
      "Epoch 722/1000000, train_loss: 54.2733, val_loss: 74.2619, time: 0.11s\n",
      "Epoch 723/1000000, train_loss: 54.2463, val_loss: 74.1722, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 724/1000000, train_loss: 54.2450, val_loss: 74.0617, time: 0.11s\n",
      "Epoch 725/1000000, train_loss: 54.2267, val_loss: 74.1022, time: 0.11s\n",
      "Epoch 726/1000000, train_loss: 54.2136, val_loss: 74.0706, time: 0.11s\n",
      "Epoch 727/1000000, train_loss: 54.1897, val_loss: 74.0840, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 728/1000000, train_loss: 54.1972, val_loss: 74.0273, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 729/1000000, train_loss: 54.1742, val_loss: 73.9716, time: 0.11s\n",
      "Epoch 730/1000000, train_loss: 54.1702, val_loss: 74.0733, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 731/1000000, train_loss: 54.1540, val_loss: 73.9379, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 732/1000000, train_loss: 54.1486, val_loss: 73.8380, time: 0.11s\n",
      "Epoch 733/1000000, train_loss: 54.1014, val_loss: 73.9289, time: 0.11s\n",
      "Epoch 734/1000000, train_loss: 54.1165, val_loss: 74.0030, time: 0.11s\n",
      "Epoch 735/1000000, train_loss: 54.1024, val_loss: 73.8628, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 736/1000000, train_loss: 54.0706, val_loss: 73.7238, time: 0.11s\n",
      "Epoch 737/1000000, train_loss: 54.0821, val_loss: 73.8139, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 738/1000000, train_loss: 54.0316, val_loss: 73.6642, time: 0.11s\n",
      "Epoch 739/1000000, train_loss: 54.0478, val_loss: 73.7332, time: 0.11s\n",
      "Epoch 740/1000000, train_loss: 54.0431, val_loss: 73.6842, time: 0.12s\n",
      "Epoch 741/1000000, train_loss: 54.0185, val_loss: 73.7529, time: 0.11s\n",
      "Epoch 742/1000000, train_loss: 54.0220, val_loss: 73.6736, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 743/1000000, train_loss: 54.0040, val_loss: 73.6283, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 744/1000000, train_loss: 54.1330, val_loss: 73.6006, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 745/1000000, train_loss: 54.0775, val_loss: 73.5738, time: 0.12s\n",
      "Epoch 746/1000000, train_loss: 54.0437, val_loss: 73.5795, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 747/1000000, train_loss: 54.0457, val_loss: 73.4985, time: 0.12s\n",
      "Epoch 748/1000000, train_loss: 53.9652, val_loss: 73.5169, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 749/1000000, train_loss: 54.0020, val_loss: 73.3316, time: 0.11s\n",
      "Epoch 750/1000000, train_loss: 53.9177, val_loss: 73.4526, time: 0.11s\n",
      "Epoch 751/1000000, train_loss: 53.9172, val_loss: 73.3897, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 752/1000000, train_loss: 53.8994, val_loss: 73.2824, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 753/1000000, train_loss: 53.8923, val_loss: 73.2385, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 754/1000000, train_loss: 53.8592, val_loss: 73.1654, time: 0.11s\n",
      "Epoch 755/1000000, train_loss: 53.8470, val_loss: 73.2460, time: 0.11s\n",
      "Epoch 756/1000000, train_loss: 53.8470, val_loss: 73.2714, time: 0.12s\n",
      "Epoch 757/1000000, train_loss: 53.8425, val_loss: 73.2165, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 758/1000000, train_loss: 53.8265, val_loss: 73.1214, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 759/1000000, train_loss: 53.8113, val_loss: 73.1155, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 760/1000000, train_loss: 53.7870, val_loss: 73.0779, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 761/1000000, train_loss: 53.7786, val_loss: 73.0129, time: 0.12s\n",
      "Epoch 762/1000000, train_loss: 53.7661, val_loss: 73.0154, time: 0.12s\n",
      "Epoch 763/1000000, train_loss: 53.7410, val_loss: 73.0156, time: 0.12s\n",
      "Epoch 764/1000000, train_loss: 53.7317, val_loss: 73.1191, time: 0.12s\n",
      "Epoch 765/1000000, train_loss: 53.7277, val_loss: 73.0165, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 766/1000000, train_loss: 53.7211, val_loss: 72.8098, time: 0.12s\n",
      "Epoch 767/1000000, train_loss: 53.6939, val_loss: 72.9108, time: 0.11s\n",
      "Epoch 768/1000000, train_loss: 53.6907, val_loss: 72.8410, time: 0.12s\n",
      "Epoch 769/1000000, train_loss: 53.6887, val_loss: 72.8992, time: 0.11s\n",
      "Epoch 770/1000000, train_loss: 53.6519, val_loss: 72.8399, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 771/1000000, train_loss: 53.6608, val_loss: 72.8086, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 772/1000000, train_loss: 53.6355, val_loss: 72.7739, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 773/1000000, train_loss: 53.6640, val_loss: 72.7026, time: 0.11s\n",
      "Epoch 774/1000000, train_loss: 53.6194, val_loss: 72.7416, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 775/1000000, train_loss: 53.6180, val_loss: 72.6720, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 776/1000000, train_loss: 53.5985, val_loss: 72.6572, time: 0.12s\n",
      "Epoch 777/1000000, train_loss: 53.5646, val_loss: 72.6736, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 778/1000000, train_loss: 53.5820, val_loss: 72.6333, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 779/1000000, train_loss: 53.5503, val_loss: 72.6311, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 780/1000000, train_loss: 53.5347, val_loss: 72.5167, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 781/1000000, train_loss: 53.5359, val_loss: 72.4363, time: 0.11s\n",
      "Epoch 782/1000000, train_loss: 53.5304, val_loss: 72.5717, time: 0.12s\n",
      "Epoch 783/1000000, train_loss: 53.4921, val_loss: 72.4613, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 784/1000000, train_loss: 53.5068, val_loss: 72.4057, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 785/1000000, train_loss: 53.4745, val_loss: 72.3800, time: 0.11s\n",
      "Epoch 786/1000000, train_loss: 53.5510, val_loss: 72.3844, time: 0.12s\n",
      "Epoch 787/1000000, train_loss: 53.4958, val_loss: 72.3830, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 788/1000000, train_loss: 53.4363, val_loss: 72.3626, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 789/1000000, train_loss: 53.4347, val_loss: 72.2126, time: 0.12s\n",
      "Epoch 790/1000000, train_loss: 53.4426, val_loss: 72.2731, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 791/1000000, train_loss: 53.4184, val_loss: 72.2048, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 792/1000000, train_loss: 53.3896, val_loss: 72.1147, time: 0.12s\n",
      "Epoch 793/1000000, train_loss: 53.3928, val_loss: 72.1787, time: 0.12s\n",
      "Epoch 794/1000000, train_loss: 53.3501, val_loss: 72.1506, time: 0.12s\n",
      "Epoch 795/1000000, train_loss: 53.3723, val_loss: 72.1320, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 796/1000000, train_loss: 53.3375, val_loss: 72.0282, time: 0.11s\n",
      "Epoch 797/1000000, train_loss: 53.3332, val_loss: 72.0354, time: 0.11s\n",
      "Epoch 798/1000000, train_loss: 53.3073, val_loss: 72.0707, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 799/1000000, train_loss: 53.2942, val_loss: 72.0057, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 800/1000000, train_loss: 53.3032, val_loss: 71.9288, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 801/1000000, train_loss: 53.2839, val_loss: 71.9228, time: 0.11s\n",
      "Epoch 802/1000000, train_loss: 53.2606, val_loss: 71.9564, time: 0.11s\n",
      "Epoch 803/1000000, train_loss: 53.2598, val_loss: 71.9394, time: 0.11s\n",
      "Epoch 804/1000000, train_loss: 53.2537, val_loss: 71.9414, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 805/1000000, train_loss: 53.2435, val_loss: 71.8762, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 806/1000000, train_loss: 53.2179, val_loss: 71.7876, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 807/1000000, train_loss: 53.2207, val_loss: 71.7798, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 808/1000000, train_loss: 53.2118, val_loss: 71.7386, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 809/1000000, train_loss: 53.1946, val_loss: 71.7268, time: 0.12s\n",
      "Epoch 810/1000000, train_loss: 53.1690, val_loss: 71.8233, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 811/1000000, train_loss: 53.1529, val_loss: 71.6566, time: 0.12s\n",
      "Epoch 812/1000000, train_loss: 53.1395, val_loss: 71.7145, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 813/1000000, train_loss: 53.1531, val_loss: 71.5998, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 814/1000000, train_loss: 53.1309, val_loss: 71.5895, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 815/1000000, train_loss: 53.1241, val_loss: 71.5653, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 816/1000000, train_loss: 53.0977, val_loss: 71.4856, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 817/1000000, train_loss: 53.0938, val_loss: 71.4325, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 818/1000000, train_loss: 53.0986, val_loss: 71.3751, time: 0.12s\n",
      "Epoch 819/1000000, train_loss: 53.0531, val_loss: 71.5311, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 820/1000000, train_loss: 53.0498, val_loss: 71.3419, time: 0.12s\n",
      "Epoch 821/1000000, train_loss: 53.0416, val_loss: 71.3496, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 822/1000000, train_loss: 53.0285, val_loss: 71.3331, time: 0.12s\n",
      "Epoch 823/1000000, train_loss: 52.9977, val_loss: 71.3354, time: 0.11s\n",
      "Epoch 824/1000000, train_loss: 53.0110, val_loss: 71.3431, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 825/1000000, train_loss: 52.9832, val_loss: 71.3082, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 826/1000000, train_loss: 52.9581, val_loss: 71.1819, time: 0.12s\n",
      "Epoch 827/1000000, train_loss: 52.9529, val_loss: 71.2090, time: 0.12s\n",
      "Epoch 828/1000000, train_loss: 52.9937, val_loss: 71.2172, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 829/1000000, train_loss: 52.9351, val_loss: 71.1504, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 830/1000000, train_loss: 52.9139, val_loss: 71.1232, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 831/1000000, train_loss: 53.0288, val_loss: 71.0630, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 832/1000000, train_loss: 52.9680, val_loss: 70.9885, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 833/1000000, train_loss: 52.8974, val_loss: 70.9674, time: 0.12s\n",
      "Epoch 834/1000000, train_loss: 52.8808, val_loss: 71.0070, time: 0.12s\n",
      "Epoch 835/1000000, train_loss: 52.8758, val_loss: 71.0300, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 836/1000000, train_loss: 52.8572, val_loss: 70.8538, time: 0.12s\n",
      "Epoch 837/1000000, train_loss: 52.8314, val_loss: 70.9567, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 838/1000000, train_loss: 52.8152, val_loss: 70.8443, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 839/1000000, train_loss: 52.8089, val_loss: 70.7957, time: 0.12s\n",
      "Epoch 840/1000000, train_loss: 52.8064, val_loss: 70.8826, time: 0.11s\n",
      "Epoch 841/1000000, train_loss: 52.7836, val_loss: 70.8464, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 842/1000000, train_loss: 52.7863, val_loss: 70.7476, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 843/1000000, train_loss: 52.7493, val_loss: 70.7256, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 844/1000000, train_loss: 52.7562, val_loss: 70.6507, time: 0.11s\n",
      "Epoch 845/1000000, train_loss: 52.7391, val_loss: 70.7654, time: 0.11s\n",
      "Epoch 846/1000000, train_loss: 52.7246, val_loss: 70.7251, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 847/1000000, train_loss: 52.6946, val_loss: 70.6147, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 848/1000000, train_loss: 52.7057, val_loss: 70.6098, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 849/1000000, train_loss: 52.6860, val_loss: 70.5357, time: 0.11s\n",
      "Epoch 850/1000000, train_loss: 52.6668, val_loss: 70.6156, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 851/1000000, train_loss: 52.6638, val_loss: 70.4523, time: 0.11s\n",
      "Epoch 852/1000000, train_loss: 52.6564, val_loss: 70.4901, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 853/1000000, train_loss: 52.6597, val_loss: 70.4038, time: 0.11s\n",
      "Epoch 854/1000000, train_loss: 52.6371, val_loss: 70.4594, time: 0.11s\n",
      "Epoch 855/1000000, train_loss: 52.6055, val_loss: 70.4152, time: 0.11s\n",
      "Epoch 856/1000000, train_loss: 52.6053, val_loss: 70.4286, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 857/1000000, train_loss: 52.5801, val_loss: 70.3387, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 858/1000000, train_loss: 52.5797, val_loss: 70.2788, time: 0.11s\n",
      "Epoch 859/1000000, train_loss: 52.5558, val_loss: 70.3540, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 860/1000000, train_loss: 52.5503, val_loss: 70.2362, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 861/1000000, train_loss: 52.5296, val_loss: 70.1633, time: 0.11s\n",
      "Epoch 862/1000000, train_loss: 52.5239, val_loss: 70.2479, time: 0.11s\n",
      "Epoch 863/1000000, train_loss: 52.5247, val_loss: 70.2555, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 864/1000000, train_loss: 52.5175, val_loss: 70.0977, time: 0.11s\n",
      "Epoch 865/1000000, train_loss: 52.4835, val_loss: 70.1216, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 866/1000000, train_loss: 52.4606, val_loss: 70.0822, time: 0.11s\n",
      "Epoch 867/1000000, train_loss: 52.4672, val_loss: 70.1242, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 868/1000000, train_loss: 52.4485, val_loss: 69.9485, time: 0.11s\n",
      "Epoch 869/1000000, train_loss: 52.4565, val_loss: 70.0401, time: 0.11s\n",
      "Epoch 870/1000000, train_loss: 52.6195, val_loss: 69.9676, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 871/1000000, train_loss: 52.4539, val_loss: 69.9341, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 872/1000000, train_loss: 52.3882, val_loss: 69.8966, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 873/1000000, train_loss: 52.4049, val_loss: 69.8409, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 874/1000000, train_loss: 52.3698, val_loss: 69.7856, time: 0.11s\n",
      "Epoch 875/1000000, train_loss: 52.3803, val_loss: 69.8713, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 876/1000000, train_loss: 52.3628, val_loss: 69.7633, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 877/1000000, train_loss: 52.3381, val_loss: 69.7610, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 878/1000000, train_loss: 52.3185, val_loss: 69.7169, time: 0.11s\n",
      "Epoch 879/1000000, train_loss: 52.3223, val_loss: 69.7579, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 880/1000000, train_loss: 52.3132, val_loss: 69.6429, time: 0.12s\n",
      "Epoch 881/1000000, train_loss: 52.2842, val_loss: 69.6576, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 882/1000000, train_loss: 52.2812, val_loss: 69.6117, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 883/1000000, train_loss: 52.2677, val_loss: 69.5576, time: 0.12s\n",
      "Epoch 884/1000000, train_loss: 52.2593, val_loss: 69.6305, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 885/1000000, train_loss: 52.2477, val_loss: 69.4613, time: 0.11s\n",
      "Epoch 886/1000000, train_loss: 52.2336, val_loss: 69.5031, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 887/1000000, train_loss: 52.2323, val_loss: 69.3676, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 888/1000000, train_loss: 52.1974, val_loss: 69.3574, time: 0.11s\n",
      "Epoch 889/1000000, train_loss: 52.1978, val_loss: 69.4211, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 890/1000000, train_loss: 52.1888, val_loss: 69.3437, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 891/1000000, train_loss: 52.1678, val_loss: 69.3254, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 892/1000000, train_loss: 52.1505, val_loss: 69.2590, time: 0.11s\n",
      "Epoch 893/1000000, train_loss: 52.1413, val_loss: 69.2741, time: 0.11s\n",
      "Epoch 894/1000000, train_loss: 52.1457, val_loss: 69.2603, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 895/1000000, train_loss: 52.1177, val_loss: 69.2284, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 896/1000000, train_loss: 52.1008, val_loss: 69.2085, time: 0.11s\n",
      "Epoch 897/1000000, train_loss: 52.0953, val_loss: 69.2994, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 898/1000000, train_loss: 52.0954, val_loss: 69.1673, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 899/1000000, train_loss: 52.0653, val_loss: 69.1134, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 900/1000000, train_loss: 52.0676, val_loss: 69.1059, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 901/1000000, train_loss: 52.0373, val_loss: 69.1027, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 902/1000000, train_loss: 52.0405, val_loss: 69.0688, time: 0.12s\n",
      "Epoch 903/1000000, train_loss: 52.0007, val_loss: 69.0745, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 904/1000000, train_loss: 52.0061, val_loss: 69.0021, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 905/1000000, train_loss: 51.9854, val_loss: 68.9074, time: 0.12s\n",
      "Epoch 906/1000000, train_loss: 51.9866, val_loss: 68.9435, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 907/1000000, train_loss: 51.9808, val_loss: 68.8903, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 908/1000000, train_loss: 51.9429, val_loss: 68.8638, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 909/1000000, train_loss: 52.1700, val_loss: 68.8545, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 910/1000000, train_loss: 52.0237, val_loss: 68.7604, time: 0.17s\n",
      "Epoch 911/1000000, train_loss: 51.9804, val_loss: 68.8111, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 912/1000000, train_loss: 51.9620, val_loss: 68.7423, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 913/1000000, train_loss: 51.9375, val_loss: 68.6513, time: 0.11s\n",
      "Epoch 914/1000000, train_loss: 51.9145, val_loss: 68.6647, time: 0.11s\n",
      "Epoch 915/1000000, train_loss: 51.8821, val_loss: 68.6714, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 916/1000000, train_loss: 51.8713, val_loss: 68.5992, time: 0.11s\n",
      "Epoch 917/1000000, train_loss: 51.8658, val_loss: 68.6349, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 918/1000000, train_loss: 51.8279, val_loss: 68.5762, time: 0.11s\n",
      "Epoch 919/1000000, train_loss: 51.8309, val_loss: 68.6057, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 920/1000000, train_loss: 51.8200, val_loss: 68.4754, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 921/1000000, train_loss: 51.8102, val_loss: 68.4604, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 922/1000000, train_loss: 51.7802, val_loss: 68.4526, time: 0.11s\n",
      "Epoch 923/1000000, train_loss: 51.7726, val_loss: 68.5205, time: 0.10s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 924/1000000, train_loss: 51.7609, val_loss: 68.3740, time: 0.11s\n",
      "Epoch 925/1000000, train_loss: 51.7371, val_loss: 68.4387, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 926/1000000, train_loss: 51.7394, val_loss: 68.3062, time: 0.11s\n",
      "Epoch 927/1000000, train_loss: 51.7266, val_loss: 68.3410, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 928/1000000, train_loss: 51.6957, val_loss: 68.2643, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 929/1000000, train_loss: 51.6947, val_loss: 68.1885, time: 0.11s\n",
      "Epoch 930/1000000, train_loss: 51.6753, val_loss: 68.2006, time: 0.11s\n",
      "Epoch 931/1000000, train_loss: 51.6613, val_loss: 68.2355, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 932/1000000, train_loss: 51.6722, val_loss: 68.1538, time: 0.11s\n",
      "Epoch 933/1000000, train_loss: 51.6486, val_loss: 68.2629, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 934/1000000, train_loss: 51.6295, val_loss: 68.1358, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 935/1000000, train_loss: 51.6310, val_loss: 68.1320, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 936/1000000, train_loss: 51.6041, val_loss: 68.0477, time: 0.11s\n",
      "Epoch 937/1000000, train_loss: 51.5746, val_loss: 68.1029, time: 0.12s\n",
      "Epoch 938/1000000, train_loss: 51.5994, val_loss: 68.0738, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 939/1000000, train_loss: 51.5745, val_loss: 67.9955, time: 0.11s\n",
      "Epoch 940/1000000, train_loss: 51.5660, val_loss: 68.0144, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 941/1000000, train_loss: 51.5642, val_loss: 67.9116, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 942/1000000, train_loss: 51.5525, val_loss: 67.8778, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 943/1000000, train_loss: 51.5051, val_loss: 67.8644, time: 0.11s\n",
      "Epoch 944/1000000, train_loss: 51.5175, val_loss: 67.8729, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 945/1000000, train_loss: 51.4814, val_loss: 67.7785, time: 0.11s\n",
      "Epoch 946/1000000, train_loss: 51.4931, val_loss: 67.8377, time: 0.11s\n",
      "Epoch 947/1000000, train_loss: 51.4765, val_loss: 67.8586, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 948/1000000, train_loss: 51.4606, val_loss: 67.6917, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 949/1000000, train_loss: 51.4559, val_loss: 67.6719, time: 0.11s\n",
      "Epoch 950/1000000, train_loss: 51.4341, val_loss: 67.6867, time: 0.11s\n",
      "Epoch 951/1000000, train_loss: 51.4119, val_loss: 67.7089, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 952/1000000, train_loss: 51.4325, val_loss: 67.6523, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 953/1000000, train_loss: 51.3813, val_loss: 67.5601, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 954/1000000, train_loss: 51.4077, val_loss: 67.5264, time: 0.11s\n",
      "Epoch 955/1000000, train_loss: 51.3717, val_loss: 67.5635, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 956/1000000, train_loss: 51.3368, val_loss: 67.4566, time: 0.11s\n",
      "Epoch 957/1000000, train_loss: 51.3271, val_loss: 67.4808, time: 0.11s\n",
      "Epoch 958/1000000, train_loss: 51.3319, val_loss: 67.5035, time: 0.11s\n",
      "Epoch 959/1000000, train_loss: 51.3241, val_loss: 67.4575, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 960/1000000, train_loss: 51.2932, val_loss: 67.4236, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 961/1000000, train_loss: 51.2865, val_loss: 67.3483, time: 0.11s\n",
      "Epoch 962/1000000, train_loss: 51.2869, val_loss: 67.3853, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 963/1000000, train_loss: 51.2829, val_loss: 67.2642, time: 0.11s\n",
      "Epoch 964/1000000, train_loss: 51.2453, val_loss: 67.3222, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 965/1000000, train_loss: 51.2477, val_loss: 67.1619, time: 0.11s\n",
      "Epoch 966/1000000, train_loss: 51.2381, val_loss: 67.2097, time: 0.11s\n",
      "Epoch 967/1000000, train_loss: 51.2336, val_loss: 67.3234, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 968/1000000, train_loss: 51.2653, val_loss: 67.1436, time: 0.11s\n",
      "Epoch 969/1000000, train_loss: 51.2605, val_loss: 67.1490, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 970/1000000, train_loss: 51.2103, val_loss: 67.0423, time: 0.11s\n",
      "Epoch 971/1000000, train_loss: 51.1630, val_loss: 67.1163, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 972/1000000, train_loss: 51.1726, val_loss: 67.0268, time: 0.11s\n",
      "Epoch 973/1000000, train_loss: 51.1343, val_loss: 67.3168, time: 0.11s\n",
      "Epoch 974/1000000, train_loss: 51.0676, val_loss: 67.0939, time: 0.11s\n",
      "Epoch 975/1000000, train_loss: 51.0636, val_loss: 67.2419, time: 0.11s\n",
      "Epoch 976/1000000, train_loss: 51.0458, val_loss: 67.2352, time: 0.11s\n",
      "Epoch 977/1000000, train_loss: 51.0492, val_loss: 67.1399, time: 0.11s\n",
      "Epoch 978/1000000, train_loss: 51.0069, val_loss: 67.1158, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 979/1000000, train_loss: 51.0094, val_loss: 66.9272, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 980/1000000, train_loss: 50.9983, val_loss: 66.8836, time: 0.11s\n",
      "Epoch 981/1000000, train_loss: 50.9737, val_loss: 66.8932, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 982/1000000, train_loss: 50.9905, val_loss: 66.8352, time: 0.11s\n",
      "Epoch 983/1000000, train_loss: 50.9385, val_loss: 66.9314, time: 0.11s\n",
      "Epoch 984/1000000, train_loss: 50.9421, val_loss: 67.0196, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 985/1000000, train_loss: 50.9254, val_loss: 66.8057, time: 0.11s\n",
      "Epoch 986/1000000, train_loss: 50.9069, val_loss: 66.8432, time: 0.11s\n",
      "Epoch 987/1000000, train_loss: 50.9105, val_loss: 66.8914, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 988/1000000, train_loss: 50.8828, val_loss: 66.6323, time: 0.11s\n",
      "Epoch 989/1000000, train_loss: 50.8738, val_loss: 66.7511, time: 0.11s\n",
      "Epoch 990/1000000, train_loss: 50.8678, val_loss: 66.6601, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 991/1000000, train_loss: 50.8658, val_loss: 66.5925, time: 0.11s\n",
      "Epoch 992/1000000, train_loss: 50.8202, val_loss: 66.8799, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 993/1000000, train_loss: 50.8595, val_loss: 66.5587, time: 0.11s\n",
      "Epoch 994/1000000, train_loss: 50.8187, val_loss: 66.6542, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 995/1000000, train_loss: 50.8048, val_loss: 66.4806, time: 0.11s\n",
      "Epoch 996/1000000, train_loss: 50.7980, val_loss: 66.5335, time: 0.11s\n",
      "Epoch 997/1000000, train_loss: 50.7709, val_loss: 66.6467, time: 0.11s\n",
      "Epoch 998/1000000, train_loss: 50.7525, val_loss: 66.5865, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 999/1000000, train_loss: 50.7651, val_loss: 66.4030, time: 0.11s\n",
      "Epoch 1000/1000000, train_loss: 50.7483, val_loss: 66.4417, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1001/1000000, train_loss: 50.7330, val_loss: 66.2752, time: 0.11s\n",
      "Epoch 1002/1000000, train_loss: 50.7119, val_loss: 66.7250, time: 0.11s\n",
      "Epoch 1003/1000000, train_loss: 50.6947, val_loss: 66.3585, time: 0.11s\n",
      "Epoch 1004/1000000, train_loss: 50.6918, val_loss: 66.4132, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1005/1000000, train_loss: 50.6929, val_loss: 66.2211, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1006/1000000, train_loss: 50.6675, val_loss: 66.1236, time: 0.11s\n",
      "Epoch 1007/1000000, train_loss: 50.6407, val_loss: 66.1659, time: 0.11s\n",
      "Epoch 1008/1000000, train_loss: 50.6477, val_loss: 66.1288, time: 0.11s\n",
      "Epoch 1009/1000000, train_loss: 50.6709, val_loss: 66.1456, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1010/1000000, train_loss: 50.6260, val_loss: 66.0691, time: 0.11s\n",
      "Epoch 1011/1000000, train_loss: 50.6119, val_loss: 66.3457, time: 0.11s\n",
      "Epoch 1012/1000000, train_loss: 50.5839, val_loss: 66.4052, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1013/1000000, train_loss: 50.5848, val_loss: 65.9544, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1014/1000000, train_loss: 50.5710, val_loss: 65.9447, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1015/1000000, train_loss: 50.5577, val_loss: 65.8607, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1016/1000000, train_loss: 50.5247, val_loss: 65.8385, time: 0.11s\n",
      "Epoch 1017/1000000, train_loss: 50.5435, val_loss: 65.8393, time: 0.11s\n",
      "Epoch 1018/1000000, train_loss: 50.5100, val_loss: 65.8854, time: 0.11s\n",
      "Epoch 1019/1000000, train_loss: 50.5006, val_loss: 66.1551, time: 0.11s\n",
      "Epoch 1020/1000000, train_loss: 50.4735, val_loss: 65.8784, time: 0.11s\n",
      "Epoch 1021/1000000, train_loss: 50.8605, val_loss: 69.1540, time: 0.11s\n",
      "Epoch 1022/1000000, train_loss: 50.9282, val_loss: 68.9865, time: 0.11s\n",
      "Epoch 1023/1000000, train_loss: 50.9096, val_loss: 68.4240, time: 0.11s\n",
      "Epoch 1024/1000000, train_loss: 50.9071, val_loss: 68.3613, time: 0.11s\n",
      "Epoch 1025/1000000, train_loss: 50.8827, val_loss: 68.3898, time: 0.11s\n",
      "Epoch 1026/1000000, train_loss: 50.8652, val_loss: 66.9286, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1027/1000000, train_loss: 50.7656, val_loss: 65.7133, time: 0.11s\n",
      "Epoch 1028/1000000, train_loss: 50.6697, val_loss: 65.7233, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1029/1000000, train_loss: 50.6593, val_loss: 65.6133, time: 0.11s\n",
      "Epoch 1030/1000000, train_loss: 50.6321, val_loss: 65.7825, time: 0.11s\n",
      "Epoch 1031/1000000, train_loss: 50.6120, val_loss: 65.8059, time: 0.11s\n",
      "Epoch 1032/1000000, train_loss: 50.6007, val_loss: 65.8073, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1033/1000000, train_loss: 50.5736, val_loss: 65.5853, time: 0.14s\n",
      "Epoch 1034/1000000, train_loss: 50.5590, val_loss: 65.6383, time: 0.11s\n",
      "Epoch 1035/1000000, train_loss: 50.5637, val_loss: 65.7002, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1036/1000000, train_loss: 50.5392, val_loss: 65.5067, time: 0.11s\n",
      "Epoch 1037/1000000, train_loss: 50.5201, val_loss: 65.5072, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1038/1000000, train_loss: 50.5243, val_loss: 65.5057, time: 0.11s\n",
      "Epoch 1039/1000000, train_loss: 50.5185, val_loss: 65.6273, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1040/1000000, train_loss: 50.4974, val_loss: 65.4544, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1041/1000000, train_loss: 50.4802, val_loss: 65.4161, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1042/1000000, train_loss: 50.4614, val_loss: 65.2886, time: 0.11s\n",
      "Epoch 1043/1000000, train_loss: 50.4534, val_loss: 65.3075, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1044/1000000, train_loss: 50.4283, val_loss: 65.2370, time: 0.11s\n",
      "Epoch 1045/1000000, train_loss: 50.4300, val_loss: 65.3172, time: 0.11s\n",
      "Epoch 1046/1000000, train_loss: 50.4117, val_loss: 65.2981, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1047/1000000, train_loss: 50.3882, val_loss: 65.1909, time: 0.11s\n",
      "Epoch 1048/1000000, train_loss: 50.3876, val_loss: 65.2052, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1049/1000000, train_loss: 50.3807, val_loss: 65.1287, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1050/1000000, train_loss: 50.3508, val_loss: 65.1174, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1051/1000000, train_loss: 50.3461, val_loss: 65.0363, time: 0.11s\n",
      "Epoch 1052/1000000, train_loss: 50.3234, val_loss: 65.0565, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1053/1000000, train_loss: 50.3283, val_loss: 64.9417, time: 0.11s\n",
      "Epoch 1054/1000000, train_loss: 50.2974, val_loss: 65.0780, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1055/1000000, train_loss: 50.2920, val_loss: 64.8168, time: 0.11s\n",
      "Epoch 1056/1000000, train_loss: 50.2860, val_loss: 64.9023, time: 0.11s\n",
      "Epoch 1057/1000000, train_loss: 50.2769, val_loss: 64.8345, time: 0.11s\n",
      "Epoch 1058/1000000, train_loss: 50.2436, val_loss: 64.8428, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1059/1000000, train_loss: 50.2338, val_loss: 64.6748, time: 0.11s\n",
      "Epoch 1060/1000000, train_loss: 50.2141, val_loss: 64.6947, time: 0.11s\n",
      "Epoch 1061/1000000, train_loss: 50.1959, val_loss: 64.8350, time: 0.11s\n",
      "Epoch 1062/1000000, train_loss: 50.1826, val_loss: 64.8011, time: 0.11s\n",
      "Epoch 1063/1000000, train_loss: 50.1800, val_loss: 64.7074, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1064/1000000, train_loss: 50.1724, val_loss: 64.4924, time: 0.11s\n",
      "Epoch 1065/1000000, train_loss: 50.1499, val_loss: 64.5576, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1066/1000000, train_loss: 50.0917, val_loss: 64.4734, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1067/1000000, train_loss: 50.0291, val_loss: 64.4661, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1068/1000000, train_loss: 50.0054, val_loss: 64.4140, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1069/1000000, train_loss: 49.9864, val_loss: 64.3526, time: 0.11s\n",
      "Epoch 1070/1000000, train_loss: 49.9719, val_loss: 64.4802, time: 0.11s\n",
      "Epoch 1071/1000000, train_loss: 49.9571, val_loss: 64.3747, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1072/1000000, train_loss: 49.9514, val_loss: 64.2549, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1073/1000000, train_loss: 49.9394, val_loss: 64.2029, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1074/1000000, train_loss: 49.9137, val_loss: 64.1510, time: 0.11s\n",
      "Epoch 1075/1000000, train_loss: 49.9273, val_loss: 64.2210, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1076/1000000, train_loss: 49.8898, val_loss: 64.1378, time: 0.11s\n",
      "Epoch 1077/1000000, train_loss: 49.8812, val_loss: 64.2314, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1078/1000000, train_loss: 49.8750, val_loss: 64.0769, time: 0.11s\n",
      "Epoch 1079/1000000, train_loss: 49.8615, val_loss: 64.0780, time: 0.11s\n",
      "Epoch 1080/1000000, train_loss: 49.8280, val_loss: 64.2194, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1081/1000000, train_loss: 49.8315, val_loss: 64.0228, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1082/1000000, train_loss: 49.8198, val_loss: 63.9703, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1083/1000000, train_loss: 49.7880, val_loss: 63.9699, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1084/1000000, train_loss: 49.7527, val_loss: 63.9212, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1085/1000000, train_loss: 49.6964, val_loss: 63.8851, time: 0.11s\n",
      "Epoch 1086/1000000, train_loss: 49.6909, val_loss: 63.9060, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1087/1000000, train_loss: 49.6685, val_loss: 63.8087, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1088/1000000, train_loss: 49.6611, val_loss: 63.8003, time: 0.11s\n",
      "Epoch 1089/1000000, train_loss: 49.6456, val_loss: 63.8747, time: 0.11s\n",
      "Epoch 1090/1000000, train_loss: 49.6427, val_loss: 63.8144, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1091/1000000, train_loss: 49.6282, val_loss: 63.7463, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1092/1000000, train_loss: 49.6148, val_loss: 63.6864, time: 0.11s\n",
      "Epoch 1093/1000000, train_loss: 49.5920, val_loss: 63.6907, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1094/1000000, train_loss: 49.5879, val_loss: 63.6485, time: 0.11s\n",
      "Epoch 1095/1000000, train_loss: 49.5642, val_loss: 63.6532, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1096/1000000, train_loss: 49.5393, val_loss: 63.5239, time: 0.11s\n",
      "Epoch 1097/1000000, train_loss: 49.5401, val_loss: 63.5484, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1098/1000000, train_loss: 49.5324, val_loss: 63.4880, time: 0.11s\n",
      "Epoch 1099/1000000, train_loss: 49.5224, val_loss: 63.4982, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1100/1000000, train_loss: 49.5093, val_loss: 63.4088, time: 0.11s\n",
      "Epoch 1101/1000000, train_loss: 49.5039, val_loss: 63.4266, time: 0.11s\n",
      "Epoch 1102/1000000, train_loss: 49.4681, val_loss: 63.4650, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1103/1000000, train_loss: 49.4713, val_loss: 63.3571, time: 0.11s\n",
      "Epoch 1104/1000000, train_loss: 49.4638, val_loss: 63.3811, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1105/1000000, train_loss: 49.4633, val_loss: 63.2819, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1106/1000000, train_loss: 49.4299, val_loss: 63.2022, time: 0.11s\n",
      "Epoch 1107/1000000, train_loss: 49.4064, val_loss: 63.2808, time: 0.11s\n",
      "Epoch 1108/1000000, train_loss: 49.3978, val_loss: 63.2172, time: 0.11s\n",
      "Epoch 1109/1000000, train_loss: 49.4134, val_loss: 63.2522, time: 0.11s\n",
      "Epoch 1110/1000000, train_loss: 49.3676, val_loss: 63.2071, time: 0.11s\n",
      "Epoch 1111/1000000, train_loss: 49.3716, val_loss: 63.2343, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1112/1000000, train_loss: 49.3573, val_loss: 63.1532, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1113/1000000, train_loss: 49.3368, val_loss: 63.1258, time: 0.11s\n",
      "Epoch 1114/1000000, train_loss: 49.3338, val_loss: 63.2021, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1115/1000000, train_loss: 49.3112, val_loss: 63.0449, time: 0.11s\n",
      "Epoch 1116/1000000, train_loss: 49.3238, val_loss: 63.1869, time: 0.11s\n",
      "Epoch 1117/1000000, train_loss: 49.2901, val_loss: 63.1843, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1118/1000000, train_loss: 49.2740, val_loss: 62.9303, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1119/1000000, train_loss: 49.2652, val_loss: 62.8916, time: 0.11s\n",
      "Epoch 1120/1000000, train_loss: 49.2541, val_loss: 62.9042, time: 0.11s\n",
      "Epoch 1121/1000000, train_loss: 49.2467, val_loss: 62.9423, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1122/1000000, train_loss: 49.2298, val_loss: 62.7869, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1123/1000000, train_loss: 49.2111, val_loss: 62.7728, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1124/1000000, train_loss: 49.1992, val_loss: 62.7503, time: 0.11s\n",
      "Epoch 1125/1000000, train_loss: 49.1926, val_loss: 62.9042, time: 0.11s\n",
      "Epoch 1126/1000000, train_loss: 49.1816, val_loss: 62.7906, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1127/1000000, train_loss: 49.1697, val_loss: 62.6893, time: 0.11s\n",
      "Epoch 1128/1000000, train_loss: 49.1595, val_loss: 62.7251, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1129/1000000, train_loss: 49.1370, val_loss: 62.6844, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1130/1000000, train_loss: 49.1281, val_loss: 62.6578, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1131/1000000, train_loss: 49.1163, val_loss: 62.5934, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1132/1000000, train_loss: 49.0998, val_loss: 62.4428, time: 0.11s\n",
      "Epoch 1133/1000000, train_loss: 49.0911, val_loss: 62.5179, time: 0.11s\n",
      "Epoch 1134/1000000, train_loss: 49.0853, val_loss: 62.5698, time: 0.11s\n",
      "Epoch 1135/1000000, train_loss: 49.0630, val_loss: 62.5058, time: 0.11s\n",
      "Epoch 1136/1000000, train_loss: 49.0542, val_loss: 62.5814, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1137/1000000, train_loss: 49.0370, val_loss: 62.4150, time: 0.11s\n",
      "Epoch 1138/1000000, train_loss: 49.0259, val_loss: 62.4176, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1139/1000000, train_loss: 49.0278, val_loss: 62.3970, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1140/1000000, train_loss: 48.9978, val_loss: 62.3415, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1141/1000000, train_loss: 49.0007, val_loss: 62.2713, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1142/1000000, train_loss: 48.9831, val_loss: 62.2248, time: 0.11s\n",
      "Epoch 1143/1000000, train_loss: 48.9753, val_loss: 62.3202, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1144/1000000, train_loss: 48.9513, val_loss: 62.1881, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1145/1000000, train_loss: 48.9301, val_loss: 62.1137, time: 0.11s\n",
      "Epoch 1146/1000000, train_loss: 48.9240, val_loss: 62.1471, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1147/1000000, train_loss: 48.9116, val_loss: 62.0524, time: 0.11s\n",
      "Epoch 1148/1000000, train_loss: 48.8932, val_loss: 62.1690, time: 0.11s\n",
      "Epoch 1149/1000000, train_loss: 48.8815, val_loss: 62.1872, time: 0.11s\n",
      "Epoch 1150/1000000, train_loss: 48.8766, val_loss: 62.0697, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1151/1000000, train_loss: 48.8581, val_loss: 61.9977, time: 0.11s\n",
      "Epoch 1152/1000000, train_loss: 48.8507, val_loss: 62.0857, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1153/1000000, train_loss: 48.8445, val_loss: 61.9797, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1154/1000000, train_loss: 48.8286, val_loss: 61.9177, time: 0.11s\n",
      "Epoch 1155/1000000, train_loss: 48.8156, val_loss: 61.9275, time: 0.11s\n",
      "Epoch 1156/1000000, train_loss: 48.8098, val_loss: 61.9736, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1157/1000000, train_loss: 48.7997, val_loss: 61.8130, time: 0.11s\n",
      "Epoch 1158/1000000, train_loss: 48.7862, val_loss: 61.8285, time: 0.11s\n",
      "Epoch 1159/1000000, train_loss: 48.7649, val_loss: 61.8354, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1160/1000000, train_loss: 48.7675, val_loss: 61.7469, time: 0.17s\n",
      "Epoch 1161/1000000, train_loss: 48.7374, val_loss: 61.7612, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1162/1000000, train_loss: 48.7248, val_loss: 61.6618, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1163/1000000, train_loss: 48.7194, val_loss: 61.6476, time: 0.11s\n",
      "Epoch 1164/1000000, train_loss: 48.7109, val_loss: 61.7185, time: 0.11s\n",
      "Epoch 1165/1000000, train_loss: 48.6868, val_loss: 61.7239, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1166/1000000, train_loss: 48.6873, val_loss: 61.5875, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1167/1000000, train_loss: 48.6714, val_loss: 61.5063, time: 0.11s\n",
      "Epoch 1168/1000000, train_loss: 48.6444, val_loss: 61.5933, time: 0.11s\n",
      "Epoch 1169/1000000, train_loss: 48.6279, val_loss: 61.5549, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1170/1000000, train_loss: 48.6376, val_loss: 61.4995, time: 0.11s\n",
      "Epoch 1171/1000000, train_loss: 48.6304, val_loss: 61.5185, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1172/1000000, train_loss: 48.6006, val_loss: 61.4742, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1173/1000000, train_loss: 48.5935, val_loss: 61.4678, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1174/1000000, train_loss: 48.5657, val_loss: 61.3210, time: 0.11s\n",
      "Epoch 1175/1000000, train_loss: 48.5709, val_loss: 61.3455, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1176/1000000, train_loss: 48.5594, val_loss: 61.2990, time: 0.11s\n",
      "Epoch 1177/1000000, train_loss: 48.5397, val_loss: 61.3828, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1178/1000000, train_loss: 48.5381, val_loss: 61.2567, time: 0.11s\n",
      "Epoch 1179/1000000, train_loss: 48.5205, val_loss: 61.3988, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1180/1000000, train_loss: 48.4926, val_loss: 61.1982, time: 0.11s\n",
      "Epoch 1181/1000000, train_loss: 48.5030, val_loss: 61.2500, time: 0.11s\n",
      "Epoch 1182/1000000, train_loss: 48.4802, val_loss: 61.2992, time: 0.11s\n",
      "Epoch 1183/1000000, train_loss: 48.4807, val_loss: 61.2083, time: 0.11s\n",
      "Epoch 1184/1000000, train_loss: 48.4411, val_loss: 61.2398, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1185/1000000, train_loss: 48.6328, val_loss: 61.0328, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1186/1000000, train_loss: 48.5809, val_loss: 61.0040, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1187/1000000, train_loss: 48.4900, val_loss: 60.9080, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1188/1000000, train_loss: 48.4839, val_loss: 60.9044, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1189/1000000, train_loss: 48.4620, val_loss: 60.8192, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1190/1000000, train_loss: 48.4439, val_loss: 60.7906, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1191/1000000, train_loss: 48.3820, val_loss: 60.7782, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1192/1000000, train_loss: 48.3700, val_loss: 60.7437, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1193/1000000, train_loss: 48.3525, val_loss: 60.6858, time: 0.11s\n",
      "Epoch 1194/1000000, train_loss: 48.3457, val_loss: 60.6971, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1195/1000000, train_loss: 48.3302, val_loss: 60.6259, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1196/1000000, train_loss: 48.3037, val_loss: 60.6137, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1197/1000000, train_loss: 48.2972, val_loss: 60.6126, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1198/1000000, train_loss: 48.2752, val_loss: 60.5521, time: 0.11s\n",
      "Epoch 1199/1000000, train_loss: 48.2819, val_loss: 60.5724, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1200/1000000, train_loss: 48.2516, val_loss: 60.5401, time: 0.11s\n",
      "Epoch 1201/1000000, train_loss: 48.2545, val_loss: 60.5833, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1202/1000000, train_loss: 48.2379, val_loss: 60.4798, time: 0.11s\n",
      "Epoch 1203/1000000, train_loss: 48.2251, val_loss: 60.4984, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1204/1000000, train_loss: 48.2176, val_loss: 60.4435, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1205/1000000, train_loss: 48.2020, val_loss: 60.3823, time: 0.11s\n",
      "Epoch 1206/1000000, train_loss: 48.1797, val_loss: 60.4216, time: 0.11s\n",
      "Epoch 1207/1000000, train_loss: 48.1704, val_loss: 60.3839, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1208/1000000, train_loss: 48.1577, val_loss: 60.3160, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1209/1000000, train_loss: 48.1466, val_loss: 60.2974, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1210/1000000, train_loss: 48.1394, val_loss: 60.2383, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1211/1000000, train_loss: 48.1135, val_loss: 60.2083, time: 0.11s\n",
      "Epoch 1212/1000000, train_loss: 48.1049, val_loss: 60.2388, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1213/1000000, train_loss: 48.1041, val_loss: 60.1675, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1214/1000000, train_loss: 48.0873, val_loss: 60.1390, time: 0.11s\n",
      "Epoch 1215/1000000, train_loss: 48.0807, val_loss: 60.1507, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1216/1000000, train_loss: 48.0756, val_loss: 60.1022, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1217/1000000, train_loss: 48.0507, val_loss: 59.9969, time: 0.11s\n",
      "Epoch 1218/1000000, train_loss: 48.0385, val_loss: 60.0336, time: 0.11s\n",
      "Epoch 1219/1000000, train_loss: 48.0219, val_loss: 60.0422, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1220/1000000, train_loss: 48.0037, val_loss: 59.9894, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1221/1000000, train_loss: 47.9872, val_loss: 59.9082, time: 0.11s\n",
      "Epoch 1222/1000000, train_loss: 48.0104, val_loss: 59.9189, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1223/1000000, train_loss: 47.9771, val_loss: 59.8893, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1224/1000000, train_loss: 47.9661, val_loss: 59.8287, time: 0.11s\n",
      "Epoch 1225/1000000, train_loss: 47.9519, val_loss: 59.9167, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1226/1000000, train_loss: 47.9333, val_loss: 59.7711, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1227/1000000, train_loss: 47.9298, val_loss: 59.7209, time: 0.11s\n",
      "Epoch 1228/1000000, train_loss: 47.9266, val_loss: 59.8165, time: 0.11s\n",
      "Epoch 1229/1000000, train_loss: 47.8974, val_loss: 59.7887, time: 0.11s\n",
      "Epoch 1230/1000000, train_loss: 47.8938, val_loss: 59.7493, time: 0.11s\n",
      "Epoch 1231/1000000, train_loss: 47.8661, val_loss: 59.7244, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1232/1000000, train_loss: 47.8567, val_loss: 59.6795, time: 0.11s\n",
      "Epoch 1233/1000000, train_loss: 47.8545, val_loss: 59.6798, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1234/1000000, train_loss: 47.8432, val_loss: 59.6029, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1235/1000000, train_loss: 47.8290, val_loss: 59.5554, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1236/1000000, train_loss: 47.8140, val_loss: 59.5022, time: 0.11s\n",
      "Epoch 1237/1000000, train_loss: 47.7932, val_loss: 59.5780, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1238/1000000, train_loss: 47.7826, val_loss: 59.4932, time: 0.11s\n",
      "Epoch 1239/1000000, train_loss: 47.7574, val_loss: 59.4956, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1240/1000000, train_loss: 47.7666, val_loss: 59.4821, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1241/1000000, train_loss: 47.7471, val_loss: 59.4063, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1242/1000000, train_loss: 47.7571, val_loss: 59.3741, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1243/1000000, train_loss: 47.7121, val_loss: 59.3649, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1244/1000000, train_loss: 47.7079, val_loss: 59.3127, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1245/1000000, train_loss: 47.7030, val_loss: 59.2758, time: 0.11s\n",
      "Epoch 1246/1000000, train_loss: 47.6935, val_loss: 59.4139, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1247/1000000, train_loss: 47.6806, val_loss: 59.2670, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1248/1000000, train_loss: 47.6766, val_loss: 59.2168, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1249/1000000, train_loss: 47.6378, val_loss: 59.1261, time: 0.11s\n",
      "Epoch 1250/1000000, train_loss: 47.6473, val_loss: 59.2476, time: 0.11s\n",
      "Epoch 1251/1000000, train_loss: 47.6230, val_loss: 59.1275, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1252/1000000, train_loss: 47.6085, val_loss: 59.0644, time: 0.11s\n",
      "Epoch 1253/1000000, train_loss: 47.5941, val_loss: 59.0718, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1254/1000000, train_loss: 47.5994, val_loss: 59.0271, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1255/1000000, train_loss: 47.5623, val_loss: 58.9919, time: 0.11s\n",
      "Epoch 1256/1000000, train_loss: 47.5521, val_loss: 59.0099, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1257/1000000, train_loss: 47.5539, val_loss: 58.8977, time: 0.11s\n",
      "Epoch 1258/1000000, train_loss: 47.5722, val_loss: 58.9140, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1259/1000000, train_loss: 47.5289, val_loss: 58.8815, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1260/1000000, train_loss: 47.5170, val_loss: 58.7944, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1261/1000000, train_loss: 47.4919, val_loss: 58.7854, time: 0.11s\n",
      "Epoch 1262/1000000, train_loss: 47.4850, val_loss: 58.8751, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1263/1000000, train_loss: 47.4744, val_loss: 58.7595, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1264/1000000, train_loss: 47.4628, val_loss: 58.6739, time: 0.11s\n",
      "Epoch 1265/1000000, train_loss: 47.4382, val_loss: 58.6753, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1266/1000000, train_loss: 47.4292, val_loss: 58.6191, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1267/1000000, train_loss: 47.4328, val_loss: 58.6052, time: 0.11s\n",
      "Epoch 1268/1000000, train_loss: 47.4128, val_loss: 58.7533, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1269/1000000, train_loss: 47.4336, val_loss: 58.5902, time: 0.11s\n",
      "Epoch 1270/1000000, train_loss: 47.3727, val_loss: 58.6910, time: 0.11s\n",
      "Epoch 1271/1000000, train_loss: 47.3850, val_loss: 58.6326, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1272/1000000, train_loss: 47.3764, val_loss: 58.5325, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1273/1000000, train_loss: 47.3573, val_loss: 58.4562, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1274/1000000, train_loss: 47.3372, val_loss: 58.4183, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1275/1000000, train_loss: 47.3290, val_loss: 58.3784, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1276/1000000, train_loss: 47.2984, val_loss: 58.3529, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1277/1000000, train_loss: 47.2935, val_loss: 58.3153, time: 0.11s\n",
      "Epoch 1278/1000000, train_loss: 47.2694, val_loss: 58.4596, time: 0.18s\n",
      "Epoch 1279/1000000, train_loss: 47.2744, val_loss: 58.3652, time: 0.11s\n",
      "Epoch 1280/1000000, train_loss: 47.2528, val_loss: 58.3195, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1281/1000000, train_loss: 47.2393, val_loss: 58.2844, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1282/1000000, train_loss: 47.2913, val_loss: 58.1487, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1283/1000000, train_loss: 47.2311, val_loss: 58.1217, time: 0.11s\n",
      "Epoch 1284/1000000, train_loss: 47.2419, val_loss: 58.1714, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1285/1000000, train_loss: 47.2086, val_loss: 58.0508, time: 0.11s\n",
      "Epoch 1286/1000000, train_loss: 47.1914, val_loss: 58.1291, time: 0.11s\n",
      "Epoch 1287/1000000, train_loss: 47.1800, val_loss: 58.0858, time: 0.11s\n",
      "Epoch 1288/1000000, train_loss: 47.1614, val_loss: 58.0753, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1289/1000000, train_loss: 47.1736, val_loss: 58.0185, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1290/1000000, train_loss: 47.1289, val_loss: 58.0116, time: 0.11s\n",
      "Epoch 1291/1000000, train_loss: 47.1165, val_loss: 58.0767, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1292/1000000, train_loss: 47.1179, val_loss: 57.8611, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1293/1000000, train_loss: 47.1034, val_loss: 57.8586, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1294/1000000, train_loss: 47.0853, val_loss: 57.8521, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1295/1000000, train_loss: 47.0780, val_loss: 57.8245, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1296/1000000, train_loss: 47.0636, val_loss: 57.7603, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1297/1000000, train_loss: 47.0536, val_loss: 57.7213, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1298/1000000, train_loss: 47.0293, val_loss: 57.7148, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1299/1000000, train_loss: 47.0242, val_loss: 57.6769, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1300/1000000, train_loss: 47.0252, val_loss: 57.6421, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1301/1000000, train_loss: 47.0049, val_loss: 57.6254, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1302/1000000, train_loss: 46.9888, val_loss: 57.5835, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1303/1000000, train_loss: 47.0293, val_loss: 57.5548, time: 0.11s\n",
      "Epoch 1304/1000000, train_loss: 46.9653, val_loss: 57.5621, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1305/1000000, train_loss: 46.9464, val_loss: 57.5387, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1306/1000000, train_loss: 46.9335, val_loss: 57.4849, time: 0.11s\n",
      "Epoch 1307/1000000, train_loss: 47.2779, val_loss: 60.3127, time: 0.11s\n",
      "Epoch 1308/1000000, train_loss: 47.5058, val_loss: 57.8376, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1309/1000000, train_loss: 47.3689, val_loss: 57.4002, time: 0.11s\n",
      "Epoch 1310/1000000, train_loss: 47.2377, val_loss: 57.4874, time: 0.11s\n",
      "Epoch 1311/1000000, train_loss: 47.2347, val_loss: 57.4127, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1312/1000000, train_loss: 47.2033, val_loss: 57.2800, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1313/1000000, train_loss: 47.2917, val_loss: 57.2298, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1314/1000000, train_loss: 47.2732, val_loss: 57.1854, time: 0.11s\n",
      "Epoch 1315/1000000, train_loss: 47.2792, val_loss: 57.2025, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1316/1000000, train_loss: 47.2672, val_loss: 57.1366, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1317/1000000, train_loss: 47.2299, val_loss: 57.1162, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1318/1000000, train_loss: 47.2397, val_loss: 57.1108, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1319/1000000, train_loss: 47.2110, val_loss: 57.0550, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1320/1000000, train_loss: 47.1989, val_loss: 57.0174, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1321/1000000, train_loss: 47.1906, val_loss: 56.9727, time: 0.11s\n",
      "Epoch 1322/1000000, train_loss: 47.1833, val_loss: 56.9815, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1323/1000000, train_loss: 47.1726, val_loss: 56.9245, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1324/1000000, train_loss: 47.1587, val_loss: 56.9214, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1325/1000000, train_loss: 47.1303, val_loss: 56.8930, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1326/1000000, train_loss: 47.1305, val_loss: 56.8530, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1327/1000000, train_loss: 47.1192, val_loss: 56.8209, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1328/1000000, train_loss: 47.1039, val_loss: 56.8204, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1329/1000000, train_loss: 47.0821, val_loss: 56.8188, time: 0.10s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1330/1000000, train_loss: 47.0767, val_loss: 56.7557, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1331/1000000, train_loss: 47.0190, val_loss: 56.6950, time: 0.12s\n",
      "Epoch 1332/1000000, train_loss: 46.9299, val_loss: 56.7032, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1333/1000000, train_loss: 46.9385, val_loss: 56.6810, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1334/1000000, train_loss: 46.9232, val_loss: 56.6682, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1335/1000000, train_loss: 46.9084, val_loss: 56.6195, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1336/1000000, train_loss: 46.8767, val_loss: 56.5997, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1337/1000000, train_loss: 46.8595, val_loss: 56.5276, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1338/1000000, train_loss: 46.8409, val_loss: 56.5193, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1339/1000000, train_loss: 46.8079, val_loss: 56.5144, time: 0.11s\n",
      "Epoch 1340/1000000, train_loss: 46.7508, val_loss: 56.5213, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1341/1000000, train_loss: 46.7037, val_loss: 56.4512, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1342/1000000, train_loss: 46.6997, val_loss: 56.4198, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1343/1000000, train_loss: 46.6995, val_loss: 56.3867, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1344/1000000, train_loss: 46.6707, val_loss: 56.3453, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1345/1000000, train_loss: 46.6495, val_loss: 56.3432, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1346/1000000, train_loss: 46.6457, val_loss: 56.2905, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1347/1000000, train_loss: 46.6395, val_loss: 56.2469, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1348/1000000, train_loss: 46.6215, val_loss: 56.2349, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1349/1000000, train_loss: 46.6085, val_loss: 56.2091, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1350/1000000, train_loss: 46.5881, val_loss: 56.1980, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1351/1000000, train_loss: 46.5764, val_loss: 56.1636, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1352/1000000, train_loss: 46.5548, val_loss: 56.1329, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1353/1000000, train_loss: 46.5565, val_loss: 56.1167, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1354/1000000, train_loss: 46.5324, val_loss: 56.0752, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1355/1000000, train_loss: 46.5151, val_loss: 56.0493, time: 0.11s\n",
      "Epoch 1356/1000000, train_loss: 46.5180, val_loss: 56.0621, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1357/1000000, train_loss: 46.4955, val_loss: 55.9867, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1358/1000000, train_loss: 46.4894, val_loss: 55.9803, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1359/1000000, train_loss: 46.4835, val_loss: 55.9260, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1360/1000000, train_loss: 46.4342, val_loss: 55.8859, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1361/1000000, train_loss: 46.3875, val_loss: 55.8515, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1362/1000000, train_loss: 46.3717, val_loss: 55.8476, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1363/1000000, train_loss: 46.3651, val_loss: 55.8222, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1364/1000000, train_loss: 46.3600, val_loss: 55.7821, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1365/1000000, train_loss: 46.3412, val_loss: 55.7580, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1366/1000000, train_loss: 46.3246, val_loss: 55.7254, time: 0.11s\n",
      "Epoch 1367/1000000, train_loss: 46.2921, val_loss: 55.7273, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1368/1000000, train_loss: 46.3040, val_loss: 55.6700, time: 0.11s\n",
      "Epoch 1369/1000000, train_loss: 46.2862, val_loss: 55.6723, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1370/1000000, train_loss: 46.2703, val_loss: 55.6455, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1371/1000000, train_loss: 46.2634, val_loss: 55.5865, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1372/1000000, train_loss: 46.2500, val_loss: 55.5609, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1373/1000000, train_loss: 46.2473, val_loss: 55.5372, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1374/1000000, train_loss: 46.2153, val_loss: 55.5063, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1375/1000000, train_loss: 46.2115, val_loss: 55.4625, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1376/1000000, train_loss: 46.1806, val_loss: 55.4370, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1377/1000000, train_loss: 46.1865, val_loss: 55.4155, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1378/1000000, train_loss: 46.1686, val_loss: 55.3770, time: 0.11s\n",
      "Epoch 1379/1000000, train_loss: 46.1730, val_loss: 55.3797, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1380/1000000, train_loss: 46.1471, val_loss: 55.3393, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1381/1000000, train_loss: 46.1318, val_loss: 55.3017, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1382/1000000, train_loss: 46.1233, val_loss: 55.2851, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1383/1000000, train_loss: 46.1099, val_loss: 55.2841, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1384/1000000, train_loss: 46.0944, val_loss: 55.2293, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1385/1000000, train_loss: 46.0825, val_loss: 55.1966, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1386/1000000, train_loss: 46.0554, val_loss: 55.1472, time: 0.11s\n",
      "Epoch 1387/1000000, train_loss: 46.0643, val_loss: 55.1679, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1388/1000000, train_loss: 46.0550, val_loss: 55.1106, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1389/1000000, train_loss: 46.0380, val_loss: 55.0790, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1390/1000000, train_loss: 46.0206, val_loss: 55.0688, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1391/1000000, train_loss: 46.0091, val_loss: 55.0254, time: 0.11s\n",
      "Epoch 1392/1000000, train_loss: 45.9436, val_loss: 55.0711, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1393/1000000, train_loss: 45.8964, val_loss: 54.9751, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1394/1000000, train_loss: 45.8821, val_loss: 54.9611, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1395/1000000, train_loss: 45.8678, val_loss: 54.9550, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1396/1000000, train_loss: 45.8462, val_loss: 54.8899, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1397/1000000, train_loss: 45.8333, val_loss: 54.8710, time: 0.11s\n",
      "Epoch 1398/1000000, train_loss: 45.8083, val_loss: 54.8909, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1399/1000000, train_loss: 45.7939, val_loss: 54.8185, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1400/1000000, train_loss: 45.8050, val_loss: 54.7907, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1401/1000000, train_loss: 45.7771, val_loss: 54.7697, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1402/1000000, train_loss: 45.7681, val_loss: 54.7382, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1403/1000000, train_loss: 45.7661, val_loss: 54.6832, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1404/1000000, train_loss: 45.7494, val_loss: 54.6658, time: 0.11s\n",
      "Epoch 1405/1000000, train_loss: 45.7239, val_loss: 54.6796, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1406/1000000, train_loss: 45.7257, val_loss: 54.5904, time: 0.11s\n",
      "Epoch 1407/1000000, train_loss: 45.7111, val_loss: 54.6374, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1408/1000000, train_loss: 45.7005, val_loss: 54.5588, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1409/1000000, train_loss: 45.6757, val_loss: 54.5478, time: 0.11s\n",
      "Epoch 1410/1000000, train_loss: 45.6770, val_loss: 54.5536, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1411/1000000, train_loss: 45.7352, val_loss: 54.4770, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1412/1000000, train_loss: 45.6573, val_loss: 54.4340, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1413/1000000, train_loss: 45.6675, val_loss: 54.4134, time: 0.11s\n",
      "Epoch 1414/1000000, train_loss: 45.6447, val_loss: 54.4355, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1415/1000000, train_loss: 45.6224, val_loss: 54.3697, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1416/1000000, train_loss: 45.6587, val_loss: 54.3222, time: 0.11s\n",
      "Epoch 1417/1000000, train_loss: 45.6239, val_loss: 54.3405, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1418/1000000, train_loss: 45.6251, val_loss: 54.2861, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1419/1000000, train_loss: 45.5944, val_loss: 54.2384, time: 0.11s\n",
      "Epoch 1420/1000000, train_loss: 45.5492, val_loss: 54.2414, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1421/1000000, train_loss: 45.5917, val_loss: 54.2016, time: 0.11s\n",
      "Epoch 1422/1000000, train_loss: 45.5888, val_loss: 54.2172, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1423/1000000, train_loss: 45.5667, val_loss: 54.1490, time: 0.11s\n",
      "Epoch 1424/1000000, train_loss: 45.5570, val_loss: 54.1785, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1425/1000000, train_loss: 45.5464, val_loss: 54.1002, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1426/1000000, train_loss: 45.5351, val_loss: 54.0721, time: 0.11s\n",
      "Epoch 1427/1000000, train_loss: 45.5129, val_loss: 54.1155, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1428/1000000, train_loss: 45.4797, val_loss: 54.0082, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1429/1000000, train_loss: 45.4931, val_loss: 53.9967, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1430/1000000, train_loss: 45.4844, val_loss: 53.9657, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1431/1000000, train_loss: 45.4654, val_loss: 53.9426, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1432/1000000, train_loss: 45.4538, val_loss: 53.8929, time: 0.11s\n",
      "Epoch 1433/1000000, train_loss: 45.4308, val_loss: 53.9631, time: 0.11s\n",
      "Epoch 1434/1000000, train_loss: 45.4218, val_loss: 53.9379, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1435/1000000, train_loss: 45.4240, val_loss: 53.8367, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1436/1000000, train_loss: 45.4098, val_loss: 53.8027, time: 0.11s\n",
      "Epoch 1437/1000000, train_loss: 45.3906, val_loss: 53.8750, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1438/1000000, train_loss: 45.3738, val_loss: 53.7402, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1439/1000000, train_loss: 45.3586, val_loss: 53.7265, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1440/1000000, train_loss: 45.3391, val_loss: 53.7171, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1441/1000000, train_loss: 45.3516, val_loss: 53.6682, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1442/1000000, train_loss: 45.3372, val_loss: 53.6342, time: 0.11s\n",
      "Epoch 1443/1000000, train_loss: 45.3124, val_loss: 53.6395, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1444/1000000, train_loss: 45.3052, val_loss: 53.5906, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1445/1000000, train_loss: 45.2923, val_loss: 53.5720, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1446/1000000, train_loss: 45.2862, val_loss: 53.5448, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1447/1000000, train_loss: 45.2568, val_loss: 53.5240, time: 0.11s\n",
      "Epoch 1448/1000000, train_loss: 45.2663, val_loss: 53.5727, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1449/1000000, train_loss: 45.2368, val_loss: 53.4572, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1450/1000000, train_loss: 45.1898, val_loss: 53.4268, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1451/1000000, train_loss: 45.2092, val_loss: 53.4062, time: 0.11s\n",
      "Epoch 1452/1000000, train_loss: 45.2030, val_loss: 53.4838, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1453/1000000, train_loss: 45.1951, val_loss: 53.3510, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1454/1000000, train_loss: 45.1820, val_loss: 53.3447, time: 0.11s\n",
      "Epoch 1455/1000000, train_loss: 45.1265, val_loss: 53.3833, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1456/1000000, train_loss: 45.1514, val_loss: 53.2900, time: 0.11s\n",
      "Epoch 1457/1000000, train_loss: 45.1130, val_loss: 53.3353, time: 0.11s\n",
      "Epoch 1458/1000000, train_loss: 45.1195, val_loss: 53.3406, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1459/1000000, train_loss: 45.1152, val_loss: 53.1964, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1460/1000000, train_loss: 45.1130, val_loss: 53.1497, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1461/1000000, train_loss: 45.0723, val_loss: 53.1409, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1462/1000000, train_loss: 45.0879, val_loss: 53.0955, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1463/1000000, train_loss: 45.0224, val_loss: 53.0868, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1464/1000000, train_loss: 45.0595, val_loss: 53.0231, time: 0.11s\n",
      "Epoch 1465/1000000, train_loss: 45.0042, val_loss: 53.0264, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1466/1000000, train_loss: 44.9871, val_loss: 52.9970, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1467/1000000, train_loss: 44.9547, val_loss: 52.9668, time: 0.11s\n",
      "Epoch 1468/1000000, train_loss: 44.9682, val_loss: 53.0481, time: 0.11s\n",
      "Epoch 1469/1000000, train_loss: 44.9760, val_loss: 53.0519, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1470/1000000, train_loss: 44.9616, val_loss: 52.9014, time: 0.11s\n",
      "Epoch 1471/1000000, train_loss: 44.9054, val_loss: 52.9714, time: 0.11s\n",
      "Epoch 1472/1000000, train_loss: 44.9479, val_loss: 52.9042, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1473/1000000, train_loss: 44.9014, val_loss: 52.8146, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1474/1000000, train_loss: 44.9129, val_loss: 52.7357, time: 0.11s\n",
      "Epoch 1475/1000000, train_loss: 44.8961, val_loss: 52.7529, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1476/1000000, train_loss: 44.9029, val_loss: 52.6801, time: 0.15s\n",
      "Epoch 1477/1000000, train_loss: 44.8642, val_loss: 52.6896, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1478/1000000, train_loss: 44.8220, val_loss: 52.6596, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1479/1000000, train_loss: 44.8116, val_loss: 52.6503, time: 0.11s\n",
      "Epoch 1480/1000000, train_loss: 44.8467, val_loss: 52.6659, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1481/1000000, train_loss: 44.8062, val_loss: 52.5839, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1482/1000000, train_loss: 44.7792, val_loss: 52.5183, time: 0.11s\n",
      "Epoch 1483/1000000, train_loss: 44.7393, val_loss: 52.6212, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1484/1000000, train_loss: 44.7466, val_loss: 52.5008, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1485/1000000, train_loss: 44.7328, val_loss: 52.4523, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1486/1000000, train_loss: 44.7756, val_loss: 52.4503, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1487/1000000, train_loss: 44.7125, val_loss: 52.3734, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1488/1000000, train_loss: 44.6951, val_loss: 52.3444, time: 0.11s\n",
      "Epoch 1489/1000000, train_loss: 44.6898, val_loss: 52.5691, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1490/1000000, train_loss: 44.7032, val_loss: 52.3178, time: 0.11s\n",
      "Epoch 1491/1000000, train_loss: 44.6497, val_loss: 52.4053, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1492/1000000, train_loss: 44.6394, val_loss: 52.2582, time: 0.11s\n",
      "Epoch 1493/1000000, train_loss: 44.6515, val_loss: 52.2829, time: 0.11s\n",
      "Epoch 1494/1000000, train_loss: 44.6711, val_loss: 52.3873, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1495/1000000, train_loss: 44.6120, val_loss: 52.2531, time: 0.11s\n",
      "Epoch 1496/1000000, train_loss: 44.5871, val_loss: 52.2550, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1497/1000000, train_loss: 44.5783, val_loss: 52.1289, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1498/1000000, train_loss: 44.6192, val_loss: 52.0698, time: 0.11s\n",
      "Epoch 1499/1000000, train_loss: 44.5807, val_loss: 52.0806, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1500/1000000, train_loss: 44.5519, val_loss: 52.0198, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1501/1000000, train_loss: 44.5803, val_loss: 51.9494, time: 0.11s\n",
      "Epoch 1502/1000000, train_loss: 44.5140, val_loss: 51.9741, time: 0.11s\n",
      "Epoch 1503/1000000, train_loss: 44.5029, val_loss: 52.0834, time: 0.11s\n",
      "Epoch 1504/1000000, train_loss: 44.5214, val_loss: 52.0399, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1505/1000000, train_loss: 44.5344, val_loss: 51.8788, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1506/1000000, train_loss: 44.4707, val_loss: 51.8495, time: 0.11s\n",
      "Epoch 1507/1000000, train_loss: 44.4611, val_loss: 51.8580, time: 0.11s\n",
      "Epoch 1508/1000000, train_loss: 44.4568, val_loss: 51.8498, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1509/1000000, train_loss: 44.4306, val_loss: 51.7453, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1510/1000000, train_loss: 44.4266, val_loss: 51.7430, time: 0.11s\n",
      "Epoch 1511/1000000, train_loss: 44.4310, val_loss: 51.8227, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1512/1000000, train_loss: 44.4013, val_loss: 51.6425, time: 0.11s\n",
      "Epoch 1513/1000000, train_loss: 44.3927, val_loss: 51.6432, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1514/1000000, train_loss: 44.4389, val_loss: 51.5974, time: 0.11s\n",
      "Epoch 1515/1000000, train_loss: 44.3720, val_loss: 51.6249, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1516/1000000, train_loss: 44.3565, val_loss: 51.5525, time: 0.11s\n",
      "Epoch 1517/1000000, train_loss: 44.3407, val_loss: 51.5798, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1518/1000000, train_loss: 44.3112, val_loss: 51.5084, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1519/1000000, train_loss: 44.3059, val_loss: 51.4622, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1520/1000000, train_loss: 44.3062, val_loss: 51.4054, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1521/1000000, train_loss: 44.2879, val_loss: 51.3597, time: 0.11s\n",
      "Epoch 1522/1000000, train_loss: 44.2781, val_loss: 51.4076, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1523/1000000, train_loss: 44.2531, val_loss: 51.3065, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1524/1000000, train_loss: 44.2506, val_loss: 51.3011, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1525/1000000, train_loss: 44.2604, val_loss: 51.2763, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1526/1000000, train_loss: 44.2243, val_loss: 51.2174, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1527/1000000, train_loss: 44.2185, val_loss: 51.2108, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1528/1000000, train_loss: 44.2132, val_loss: 51.1565, time: 0.11s\n",
      "Epoch 1529/1000000, train_loss: 44.2120, val_loss: 51.3210, time: 0.11s\n",
      "Epoch 1530/1000000, train_loss: 44.1772, val_loss: 51.3005, time: 0.11s\n",
      "Epoch 1531/1000000, train_loss: 44.1661, val_loss: 51.2977, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1532/1000000, train_loss: 44.1529, val_loss: 51.0680, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1533/1000000, train_loss: 44.1379, val_loss: 51.0421, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1534/1000000, train_loss: 44.1383, val_loss: 50.9997, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1535/1000000, train_loss: 44.0986, val_loss: 50.9504, time: 0.11s\n",
      "Epoch 1536/1000000, train_loss: 44.1285, val_loss: 50.9980, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1537/1000000, train_loss: 44.0998, val_loss: 50.8576, time: 0.11s\n",
      "Epoch 1538/1000000, train_loss: 44.0805, val_loss: 50.9965, time: 0.11s\n",
      "Epoch 1539/1000000, train_loss: 44.3100, val_loss: 50.9257, time: 0.11s\n",
      "Epoch 1540/1000000, train_loss: 44.1525, val_loss: 50.8926, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1541/1000000, train_loss: 44.1161, val_loss: 50.7564, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1542/1000000, train_loss: 44.0914, val_loss: 50.7267, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1543/1000000, train_loss: 44.0282, val_loss: 50.7223, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1544/1000000, train_loss: 44.0054, val_loss: 50.6971, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1545/1000000, train_loss: 43.9925, val_loss: 50.6393, time: 0.11s\n",
      "Epoch 1546/1000000, train_loss: 43.9804, val_loss: 50.7397, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1547/1000000, train_loss: 43.9673, val_loss: 50.5768, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1548/1000000, train_loss: 43.9491, val_loss: 50.5526, time: 0.11s\n",
      "Epoch 1549/1000000, train_loss: 43.9325, val_loss: 50.5612, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1550/1000000, train_loss: 43.9266, val_loss: 50.4949, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1551/1000000, train_loss: 43.9106, val_loss: 50.4310, time: 0.11s\n",
      "Epoch 1552/1000000, train_loss: 43.8969, val_loss: 50.4630, time: 0.11s\n",
      "Epoch 1553/1000000, train_loss: 43.9169, val_loss: 50.4773, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1554/1000000, train_loss: 43.8648, val_loss: 50.4212, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1555/1000000, train_loss: 43.8535, val_loss: 50.3907, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1556/1000000, train_loss: 43.8529, val_loss: 50.3183, time: 0.15s\n",
      "Epoch 1557/1000000, train_loss: 43.8585, val_loss: 50.3343, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1558/1000000, train_loss: 43.8263, val_loss: 50.2919, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1559/1000000, train_loss: 43.8163, val_loss: 50.2375, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1560/1000000, train_loss: 43.8138, val_loss: 50.1947, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1561/1000000, train_loss: 43.7778, val_loss: 50.1811, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1562/1000000, train_loss: 43.7633, val_loss: 50.1276, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1563/1000000, train_loss: 43.7470, val_loss: 50.1185, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1564/1000000, train_loss: 43.7323, val_loss: 50.1182, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1565/1000000, train_loss: 43.7450, val_loss: 50.1068, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1566/1000000, train_loss: 43.7254, val_loss: 50.1052, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1567/1000000, train_loss: 43.7075, val_loss: 50.0811, time: 0.11s\n",
      "Epoch 1568/1000000, train_loss: 43.6951, val_loss: 50.0895, time: 0.11s\n",
      "Epoch 1569/1000000, train_loss: 43.7192, val_loss: 50.1347, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1570/1000000, train_loss: 43.7101, val_loss: 49.9042, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1571/1000000, train_loss: 43.6700, val_loss: 49.8686, time: 0.11s\n",
      "Epoch 1572/1000000, train_loss: 43.6649, val_loss: 49.8895, time: 0.11s\n",
      "Epoch 1573/1000000, train_loss: 43.6584, val_loss: 49.9396, time: 0.11s\n",
      "Epoch 1574/1000000, train_loss: 43.6168, val_loss: 49.8927, time: 0.11s\n",
      "Epoch 1575/1000000, train_loss: 43.5988, val_loss: 49.8698, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1576/1000000, train_loss: 43.5902, val_loss: 49.8061, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1577/1000000, train_loss: 43.5830, val_loss: 49.7141, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1578/1000000, train_loss: 43.5639, val_loss: 49.6975, time: 0.11s\n",
      "Epoch 1579/1000000, train_loss: 43.5532, val_loss: 49.7557, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1580/1000000, train_loss: 43.5432, val_loss: 49.6721, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1581/1000000, train_loss: 43.5461, val_loss: 49.6303, time: 0.11s\n",
      "Epoch 1582/1000000, train_loss: 43.5235, val_loss: 49.6326, time: 0.11s\n",
      "Epoch 1583/1000000, train_loss: 43.5144, val_loss: 49.6526, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1584/1000000, train_loss: 43.4963, val_loss: 49.5445, time: 0.11s\n",
      "Epoch 1585/1000000, train_loss: 43.4944, val_loss: 49.5607, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1586/1000000, train_loss: 43.4969, val_loss: 49.4551, time: 0.11s\n",
      "Epoch 1587/1000000, train_loss: 43.4648, val_loss: 49.4640, time: 0.11s\n",
      "Epoch 1588/1000000, train_loss: 43.4399, val_loss: 49.5228, time: 0.11s\n",
      "Epoch 1589/1000000, train_loss: 43.4783, val_loss: 49.4792, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1590/1000000, train_loss: 43.4625, val_loss: 49.4381, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1591/1000000, train_loss: 43.4114, val_loss: 49.3505, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1592/1000000, train_loss: 43.3994, val_loss: 49.2981, time: 0.15s\n",
      "Epoch 1593/1000000, train_loss: 43.3699, val_loss: 49.3553, time: 0.17s\n",
      "Epoch 1594/1000000, train_loss: 43.3721, val_loss: 49.3588, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1595/1000000, train_loss: 43.3798, val_loss: 49.2920, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1596/1000000, train_loss: 43.3646, val_loss: 49.2242, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1597/1000000, train_loss: 43.3372, val_loss: 49.1480, time: 0.11s\n",
      "Epoch 1598/1000000, train_loss: 43.3209, val_loss: 49.1712, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1599/1000000, train_loss: 43.2985, val_loss: 49.0619, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1600/1000000, train_loss: 43.2916, val_loss: 49.0610, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1601/1000000, train_loss: 43.2938, val_loss: 49.0465, time: 0.11s\n",
      "Epoch 1602/1000000, train_loss: 43.2823, val_loss: 49.0608, time: 0.11s\n",
      "Epoch 1603/1000000, train_loss: 43.2503, val_loss: 49.1282, time: 0.11s\n",
      "Epoch 1604/1000000, train_loss: 43.2744, val_loss: 49.0691, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1605/1000000, train_loss: 43.2533, val_loss: 48.9062, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1606/1000000, train_loss: 43.2397, val_loss: 48.8602, time: 0.11s\n",
      "Epoch 1607/1000000, train_loss: 43.2057, val_loss: 48.9635, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1608/1000000, train_loss: 43.1879, val_loss: 48.7921, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1609/1000000, train_loss: 43.1844, val_loss: 48.7827, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1610/1000000, train_loss: 43.1658, val_loss: 48.7638, time: 0.11s\n",
      "Epoch 1611/1000000, train_loss: 43.1460, val_loss: 48.7641, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1612/1000000, train_loss: 43.1397, val_loss: 48.7440, time: 0.11s\n",
      "Epoch 1613/1000000, train_loss: 43.1268, val_loss: 48.7624, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1614/1000000, train_loss: 43.1254, val_loss: 48.6634, time: 0.11s\n",
      "Epoch 1615/1000000, train_loss: 43.1107, val_loss: 48.6706, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1616/1000000, train_loss: 43.0905, val_loss: 48.5837, time: 0.11s\n",
      "Epoch 1617/1000000, train_loss: 43.0807, val_loss: 48.6479, time: 0.11s\n",
      "Epoch 1618/1000000, train_loss: 43.0704, val_loss: 48.6185, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1619/1000000, train_loss: 43.0680, val_loss: 48.5291, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1620/1000000, train_loss: 43.2359, val_loss: 48.4474, time: 0.11s\n",
      "Epoch 1621/1000000, train_loss: 43.0680, val_loss: 48.4748, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1622/1000000, train_loss: 43.0323, val_loss: 48.3735, time: 0.11s\n",
      "Epoch 1623/1000000, train_loss: 43.0179, val_loss: 48.3937, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1624/1000000, train_loss: 43.0011, val_loss: 48.3347, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1625/1000000, train_loss: 42.9914, val_loss: 48.2996, time: 0.11s\n",
      "Epoch 1626/1000000, train_loss: 42.9689, val_loss: 48.3355, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1627/1000000, train_loss: 42.9488, val_loss: 48.2742, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1628/1000000, train_loss: 42.9411, val_loss: 48.2095, time: 0.11s\n",
      "Epoch 1629/1000000, train_loss: 42.9317, val_loss: 48.2445, time: 0.11s\n",
      "Epoch 1630/1000000, train_loss: 42.9256, val_loss: 48.2603, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1631/1000000, train_loss: 42.8972, val_loss: 48.1277, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1632/1000000, train_loss: 42.8853, val_loss: 48.1242, time: 0.11s\n",
      "Epoch 1633/1000000, train_loss: 42.8837, val_loss: 48.1732, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1634/1000000, train_loss: 42.8622, val_loss: 48.0421, time: 0.11s\n",
      "Epoch 1635/1000000, train_loss: 42.8435, val_loss: 48.0427, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1636/1000000, train_loss: 42.8469, val_loss: 47.9852, time: 0.11s\n",
      "Epoch 1637/1000000, train_loss: 42.8472, val_loss: 48.0028, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1638/1000000, train_loss: 42.8220, val_loss: 47.9214, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1639/1000000, train_loss: 42.7958, val_loss: 47.9047, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1640/1000000, train_loss: 42.8099, val_loss: 47.8791, time: 0.11s\n",
      "Epoch 1641/1000000, train_loss: 42.7751, val_loss: 47.8904, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1642/1000000, train_loss: 42.7598, val_loss: 47.8289, time: 0.11s\n",
      "Epoch 1643/1000000, train_loss: 42.8393, val_loss: 48.4543, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1644/1000000, train_loss: 42.7643, val_loss: 47.7936, time: 0.11s\n",
      "Epoch 1645/1000000, train_loss: 42.7196, val_loss: 47.8388, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1646/1000000, train_loss: 42.8149, val_loss: 47.7212, time: 0.11s\n",
      "Epoch 1647/1000000, train_loss: 42.7233, val_loss: 47.7931, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1648/1000000, train_loss: 42.7748, val_loss: 47.6826, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1649/1000000, train_loss: 42.6671, val_loss: 47.6225, time: 0.11s\n",
      "Epoch 1650/1000000, train_loss: 42.7280, val_loss: 47.6297, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1651/1000000, train_loss: 42.6379, val_loss: 47.5963, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1652/1000000, train_loss: 42.6524, val_loss: 47.5381, time: 0.11s\n",
      "Epoch 1653/1000000, train_loss: 42.6202, val_loss: 47.6219, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1654/1000000, train_loss: 42.6368, val_loss: 47.4697, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1655/1000000, train_loss: 42.6167, val_loss: 47.4481, time: 0.11s\n",
      "Epoch 1656/1000000, train_loss: 42.5993, val_loss: 47.4601, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1657/1000000, train_loss: 42.5743, val_loss: 47.3875, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1658/1000000, train_loss: 42.5679, val_loss: 47.3688, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1659/1000000, train_loss: 42.5608, val_loss: 47.3475, time: 0.11s\n",
      "Epoch 1660/1000000, train_loss: 42.5446, val_loss: 47.3662, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1661/1000000, train_loss: 42.5258, val_loss: 47.2735, time: 0.11s\n",
      "Epoch 1662/1000000, train_loss: 42.5155, val_loss: 47.3074, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1663/1000000, train_loss: 42.5241, val_loss: 47.2624, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1664/1000000, train_loss: 42.4939, val_loss: 47.1938, time: 0.11s\n",
      "Epoch 1665/1000000, train_loss: 42.4738, val_loss: 47.2070, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1666/1000000, train_loss: 42.5447, val_loss: 47.1928, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1667/1000000, train_loss: 42.4699, val_loss: 47.0917, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1668/1000000, train_loss: 42.4681, val_loss: 47.0895, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1669/1000000, train_loss: 42.4201, val_loss: 47.0385, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1670/1000000, train_loss: 42.4149, val_loss: 47.0195, time: 0.12s\n",
      "Epoch 1671/1000000, train_loss: 42.3908, val_loss: 47.0414, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1672/1000000, train_loss: 42.3935, val_loss: 47.0187, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1673/1000000, train_loss: 42.3679, val_loss: 46.9568, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1674/1000000, train_loss: 42.4020, val_loss: 46.9121, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1675/1000000, train_loss: 42.3889, val_loss: 46.8927, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1676/1000000, train_loss: 42.4631, val_loss: 46.8798, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1677/1000000, train_loss: 42.3144, val_loss: 46.8334, time: 0.11s\n",
      "Epoch 1678/1000000, train_loss: 42.3144, val_loss: 46.9435, time: 0.11s\n",
      "Epoch 1679/1000000, train_loss: 42.3967, val_loss: 46.8361, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1680/1000000, train_loss: 42.2887, val_loss: 46.7173, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1681/1000000, train_loss: 42.2812, val_loss: 46.6962, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1682/1000000, train_loss: 42.2734, val_loss: 46.6729, time: 0.11s\n",
      "Epoch 1683/1000000, train_loss: 42.3167, val_loss: 48.2727, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1684/1000000, train_loss: 42.2334, val_loss: 46.6338, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1685/1000000, train_loss: 42.2289, val_loss: 46.5979, time: 0.11s\n",
      "Epoch 1686/1000000, train_loss: 42.2249, val_loss: 46.6610, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1687/1000000, train_loss: 42.1893, val_loss: 46.5402, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1688/1000000, train_loss: 42.1939, val_loss: 46.5057, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1689/1000000, train_loss: 42.1852, val_loss: 46.4987, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1690/1000000, train_loss: 42.2449, val_loss: 46.4282, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1691/1000000, train_loss: 42.5065, val_loss: 46.4237, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1692/1000000, train_loss: 42.3039, val_loss: 46.3997, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1693/1000000, train_loss: 42.2384, val_loss: 46.3596, time: 0.11s\n",
      "Epoch 1694/1000000, train_loss: 42.2216, val_loss: 46.3833, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1695/1000000, train_loss: 42.1870, val_loss: 46.2710, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1696/1000000, train_loss: 42.1882, val_loss: 46.2553, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1697/1000000, train_loss: 42.1651, val_loss: 46.2349, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1698/1000000, train_loss: 42.0872, val_loss: 46.2269, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1699/1000000, train_loss: 42.0658, val_loss: 46.1694, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1700/1000000, train_loss: 42.0565, val_loss: 46.1493, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1701/1000000, train_loss: 42.0282, val_loss: 46.1326, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1702/1000000, train_loss: 42.0228, val_loss: 46.0781, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1703/1000000, train_loss: 42.0149, val_loss: 46.0564, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1704/1000000, train_loss: 41.9894, val_loss: 46.0473, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1705/1000000, train_loss: 41.9837, val_loss: 45.9952, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1706/1000000, train_loss: 41.9618, val_loss: 45.9520, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1707/1000000, train_loss: 41.9584, val_loss: 45.9278, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1708/1000000, train_loss: 41.9400, val_loss: 45.8975, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1709/1000000, train_loss: 41.9403, val_loss: 45.8791, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1710/1000000, train_loss: 41.9218, val_loss: 45.8524, time: 0.11s\n",
      "Epoch 1711/1000000, train_loss: 41.8985, val_loss: 45.8707, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1712/1000000, train_loss: 41.8868, val_loss: 45.7875, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1713/1000000, train_loss: 41.8651, val_loss: 45.7667, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1714/1000000, train_loss: 41.8713, val_loss: 45.7480, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1715/1000000, train_loss: 41.8619, val_loss: 45.7343, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1716/1000000, train_loss: 41.8408, val_loss: 45.7028, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1717/1000000, train_loss: 41.8413, val_loss: 45.6828, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1718/1000000, train_loss: 41.8176, val_loss: 45.6280, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1719/1000000, train_loss: 41.8229, val_loss: 45.6090, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1720/1000000, train_loss: 41.7991, val_loss: 45.5454, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1721/1000000, train_loss: 41.7799, val_loss: 45.5413, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1722/1000000, train_loss: 41.7738, val_loss: 45.5239, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1723/1000000, train_loss: 41.7534, val_loss: 45.4757, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1724/1000000, train_loss: 41.7386, val_loss: 45.4439, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1725/1000000, train_loss: 41.7384, val_loss: 45.4425, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1726/1000000, train_loss: 41.7236, val_loss: 45.3849, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1727/1000000, train_loss: 41.7072, val_loss: 45.3722, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1728/1000000, train_loss: 41.6878, val_loss: 45.3234, time: 0.11s\n",
      "Epoch 1729/1000000, train_loss: 41.6906, val_loss: 45.3650, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1730/1000000, train_loss: 41.6703, val_loss: 45.2851, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1731/1000000, train_loss: 41.6575, val_loss: 45.2499, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1732/1000000, train_loss: 41.6513, val_loss: 45.2279, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1733/1000000, train_loss: 41.6263, val_loss: 45.2144, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1734/1000000, train_loss: 41.6095, val_loss: 45.1645, time: 0.11s\n",
      "Epoch 1735/1000000, train_loss: 41.6102, val_loss: 45.1998, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1736/1000000, train_loss: 41.5940, val_loss: 45.1093, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1737/1000000, train_loss: 41.5715, val_loss: 45.0442, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1738/1000000, train_loss: 41.5717, val_loss: 45.0369, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1739/1000000, train_loss: 41.5515, val_loss: 45.0054, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1740/1000000, train_loss: 41.5380, val_loss: 44.9881, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1741/1000000, train_loss: 41.5289, val_loss: 44.9456, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1742/1000000, train_loss: 41.5069, val_loss: 44.9310, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1743/1000000, train_loss: 41.5229, val_loss: 44.9022, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1744/1000000, train_loss: 41.4962, val_loss: 44.8876, time: 0.11s\n",
      "Epoch 1745/1000000, train_loss: 41.4701, val_loss: 44.9021, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1746/1000000, train_loss: 41.4677, val_loss: 44.8442, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1747/1000000, train_loss: 41.4618, val_loss: 44.7737, time: 0.11s\n",
      "Epoch 1748/1000000, train_loss: 41.4530, val_loss: 44.7768, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1749/1000000, train_loss: 41.4390, val_loss: 44.7482, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1750/1000000, train_loss: 41.4493, val_loss: 44.7112, time: 0.11s\n",
      "Epoch 1751/1000000, train_loss: 41.4433, val_loss: 44.7584, time: 0.11s\n",
      "Epoch 1752/1000000, train_loss: 41.3877, val_loss: 44.7408, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1753/1000000, train_loss: 41.3834, val_loss: 44.6224, time: 0.11s\n",
      "Epoch 1754/1000000, train_loss: 41.3685, val_loss: 44.6301, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1755/1000000, train_loss: 41.3418, val_loss: 44.5492, time: 0.11s\n",
      "Epoch 1756/1000000, train_loss: 41.3325, val_loss: 44.5809, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1757/1000000, train_loss: 41.3237, val_loss: 44.5218, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1758/1000000, train_loss: 41.3067, val_loss: 44.4311, time: 0.11s\n",
      "Epoch 1759/1000000, train_loss: 41.3058, val_loss: 44.4753, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1760/1000000, train_loss: 41.3086, val_loss: 44.4216, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1761/1000000, train_loss: 41.2741, val_loss: 44.3864, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1762/1000000, train_loss: 41.2690, val_loss: 44.3508, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1763/1000000, train_loss: 41.2635, val_loss: 44.3348, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1764/1000000, train_loss: 41.2381, val_loss: 44.2923, time: 0.11s\n",
      "Epoch 1765/1000000, train_loss: 41.2331, val_loss: 44.3601, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1766/1000000, train_loss: 41.2267, val_loss: 44.2185, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1767/1000000, train_loss: 41.2058, val_loss: 44.2069, time: 0.11s\n",
      "Epoch 1768/1000000, train_loss: 41.1866, val_loss: 44.2111, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1769/1000000, train_loss: 41.1686, val_loss: 44.1465, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1770/1000000, train_loss: 41.2004, val_loss: 44.1360, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1771/1000000, train_loss: 41.1550, val_loss: 44.1066, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1772/1000000, train_loss: 41.1625, val_loss: 44.0728, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1773/1000000, train_loss: 41.1376, val_loss: 44.0370, time: 0.11s\n",
      "Epoch 1774/1000000, train_loss: 41.1002, val_loss: 44.0694, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1775/1000000, train_loss: 41.1127, val_loss: 44.0029, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1776/1000000, train_loss: 41.0939, val_loss: 43.9885, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1777/1000000, train_loss: 41.0806, val_loss: 43.9230, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1778/1000000, train_loss: 41.0633, val_loss: 43.9084, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1779/1000000, train_loss: 41.0503, val_loss: 43.8714, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1780/1000000, train_loss: 41.0479, val_loss: 43.8028, time: 0.11s\n",
      "Epoch 1781/1000000, train_loss: 41.0289, val_loss: 43.8086, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1782/1000000, train_loss: 41.0186, val_loss: 43.7789, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1783/1000000, train_loss: 41.0024, val_loss: 43.7501, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1784/1000000, train_loss: 41.0061, val_loss: 43.7314, time: 0.11s\n",
      "Epoch 1785/1000000, train_loss: 41.0450, val_loss: 43.7833, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1786/1000000, train_loss: 40.9526, val_loss: 43.6501, time: 0.11s\n",
      "Epoch 1787/1000000, train_loss: 40.9838, val_loss: 43.7199, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1788/1000000, train_loss: 40.9597, val_loss: 43.6485, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1789/1000000, train_loss: 40.9364, val_loss: 43.5784, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1790/1000000, train_loss: 40.9247, val_loss: 43.5646, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1791/1000000, train_loss: 40.9090, val_loss: 43.5463, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1792/1000000, train_loss: 40.8918, val_loss: 43.4652, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1793/1000000, train_loss: 40.8814, val_loss: 43.4373, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1794/1000000, train_loss: 40.8712, val_loss: 43.4137, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1795/1000000, train_loss: 40.8466, val_loss: 43.4084, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1796/1000000, train_loss: 40.8317, val_loss: 43.3698, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1797/1000000, train_loss: 40.8246, val_loss: 43.3256, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1798/1000000, train_loss: 40.8637, val_loss: 43.3101, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1799/1000000, train_loss: 40.8165, val_loss: 43.2861, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1800/1000000, train_loss: 40.7883, val_loss: 43.2496, time: 0.11s\n",
      "Epoch 1801/1000000, train_loss: 40.7868, val_loss: 43.2743, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1802/1000000, train_loss: 40.7682, val_loss: 43.2129, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1803/1000000, train_loss: 40.7783, val_loss: 43.1969, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1804/1000000, train_loss: 40.7334, val_loss: 43.1171, time: 0.11s\n",
      "Epoch 1805/1000000, train_loss: 40.7753, val_loss: 43.1751, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1806/1000000, train_loss: 40.7168, val_loss: 43.1070, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1807/1000000, train_loss: 40.7101, val_loss: 43.0591, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1808/1000000, train_loss: 40.6913, val_loss: 43.0316, time: 0.11s\n",
      "Epoch 1809/1000000, train_loss: 40.6840, val_loss: 43.0346, time: 0.11s\n",
      "Epoch 1810/1000000, train_loss: 40.6693, val_loss: 43.0891, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1811/1000000, train_loss: 40.6510, val_loss: 42.9743, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1812/1000000, train_loss: 40.6350, val_loss: 42.9051, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1813/1000000, train_loss: 40.6135, val_loss: 42.8965, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1814/1000000, train_loss: 40.7655, val_loss: 42.8689, time: 0.11s\n",
      "Epoch 1815/1000000, train_loss: 40.6220, val_loss: 42.8691, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1816/1000000, train_loss: 40.6000, val_loss: 42.7973, time: 0.11s\n",
      "Epoch 1817/1000000, train_loss: 40.5721, val_loss: 42.8493, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1818/1000000, train_loss: 40.5652, val_loss: 42.7016, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1819/1000000, train_loss: 40.5537, val_loss: 42.6911, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1820/1000000, train_loss: 40.5334, val_loss: 42.6843, time: 0.11s\n",
      "Epoch 1821/1000000, train_loss: 40.5179, val_loss: 42.7147, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1822/1000000, train_loss: 40.5173, val_loss: 42.6492, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1823/1000000, train_loss: 40.4917, val_loss: 42.6477, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1824/1000000, train_loss: 40.4827, val_loss: 42.6066, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1825/1000000, train_loss: 40.4902, val_loss: 42.5289, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1826/1000000, train_loss: 40.4645, val_loss: 42.5026, time: 0.11s\n",
      "Epoch 1827/1000000, train_loss: 40.5242, val_loss: 42.5627, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1828/1000000, train_loss: 40.6156, val_loss: 42.4965, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1829/1000000, train_loss: 40.4205, val_loss: 42.4365, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1830/1000000, train_loss: 40.4197, val_loss: 42.4034, time: 0.11s\n",
      "Epoch 1831/1000000, train_loss: 40.4009, val_loss: 42.4719, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1832/1000000, train_loss: 40.3994, val_loss: 42.3175, time: 0.11s\n",
      "Epoch 1833/1000000, train_loss: 40.3689, val_loss: 42.3250, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1834/1000000, train_loss: 40.3536, val_loss: 42.3095, time: 0.11s\n",
      "Epoch 1835/1000000, train_loss: 40.3467, val_loss: 42.4042, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1836/1000000, train_loss: 40.3281, val_loss: 42.2374, time: 0.11s\n",
      "Epoch 1837/1000000, train_loss: 40.3292, val_loss: 42.2612, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1838/1000000, train_loss: 40.3146, val_loss: 42.1576, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1839/1000000, train_loss: 40.3010, val_loss: 42.1310, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1840/1000000, train_loss: 40.2948, val_loss: 42.0936, time: 0.11s\n",
      "Epoch 1841/1000000, train_loss: 40.2776, val_loss: 42.1192, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1842/1000000, train_loss: 40.2555, val_loss: 42.0409, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1843/1000000, train_loss: 40.2864, val_loss: 42.0400, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1844/1000000, train_loss: 40.2437, val_loss: 41.9702, time: 0.11s\n",
      "Epoch 1845/1000000, train_loss: 40.4400, val_loss: 42.0363, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1846/1000000, train_loss: 40.3745, val_loss: 41.9612, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1847/1000000, train_loss: 40.2143, val_loss: 41.9007, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1848/1000000, train_loss: 40.1921, val_loss: 41.8925, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1849/1000000, train_loss: 40.1650, val_loss: 41.8338, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1850/1000000, train_loss: 40.1620, val_loss: 41.7989, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1851/1000000, train_loss: 40.1372, val_loss: 41.7730, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1852/1000000, train_loss: 40.1384, val_loss: 41.7648, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1853/1000000, train_loss: 40.1314, val_loss: 41.7005, time: 0.11s\n",
      "Epoch 1854/1000000, train_loss: 40.4757, val_loss: 41.7126, time: 0.11s\n",
      "Epoch 1855/1000000, train_loss: 40.4226, val_loss: 41.7082, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1856/1000000, train_loss: 40.3056, val_loss: 41.6543, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1857/1000000, train_loss: 40.1876, val_loss: 41.6085, time: 0.11s\n",
      "Epoch 1858/1000000, train_loss: 40.1729, val_loss: 41.6279, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1859/1000000, train_loss: 40.1500, val_loss: 41.5660, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1860/1000000, train_loss: 40.0591, val_loss: 41.5195, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1861/1000000, train_loss: 40.0429, val_loss: 41.4974, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1862/1000000, train_loss: 40.0150, val_loss: 41.4647, time: 0.11s\n",
      "Epoch 1863/1000000, train_loss: 40.0099, val_loss: 41.4761, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1864/1000000, train_loss: 39.9873, val_loss: 41.3903, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1865/1000000, train_loss: 39.9743, val_loss: 41.3373, time: 0.11s\n",
      "Epoch 1866/1000000, train_loss: 39.9685, val_loss: 41.3590, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1867/1000000, train_loss: 39.9480, val_loss: 41.3076, time: 0.11s\n",
      "Epoch 1868/1000000, train_loss: 39.9371, val_loss: 41.3083, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1869/1000000, train_loss: 39.9153, val_loss: 41.2579, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1870/1000000, train_loss: 39.9246, val_loss: 41.2122, time: 0.11s\n",
      "Epoch 1871/1000000, train_loss: 39.9004, val_loss: 41.2392, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1872/1000000, train_loss: 39.8958, val_loss: 41.1678, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1873/1000000, train_loss: 39.8821, val_loss: 41.1658, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1874/1000000, train_loss: 39.8707, val_loss: 41.1001, time: 0.11s\n",
      "Epoch 1875/1000000, train_loss: 39.8474, val_loss: 41.1148, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1876/1000000, train_loss: 39.8437, val_loss: 41.0950, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1877/1000000, train_loss: 39.8190, val_loss: 40.9832, time: 0.11s\n",
      "Epoch 1878/1000000, train_loss: 39.8187, val_loss: 41.0568, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1879/1000000, train_loss: 39.8040, val_loss: 40.9721, time: 0.11s\n",
      "Epoch 1880/1000000, train_loss: 39.7939, val_loss: 40.9790, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1881/1000000, train_loss: 39.7709, val_loss: 40.8949, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1882/1000000, train_loss: 39.7608, val_loss: 40.8856, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1883/1000000, train_loss: 39.7520, val_loss: 40.8281, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1884/1000000, train_loss: 39.7276, val_loss: 40.8163, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1885/1000000, train_loss: 39.7202, val_loss: 40.8040, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1886/1000000, train_loss: 39.7196, val_loss: 40.7147, time: 0.11s\n",
      "Epoch 1887/1000000, train_loss: 39.7118, val_loss: 40.7669, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1888/1000000, train_loss: 39.6797, val_loss: 40.7097, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1889/1000000, train_loss: 39.6865, val_loss: 40.6744, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1890/1000000, train_loss: 39.6667, val_loss: 40.6691, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1891/1000000, train_loss: 39.6491, val_loss: 40.6485, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1892/1000000, train_loss: 39.6357, val_loss: 40.5822, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1893/1000000, train_loss: 39.6194, val_loss: 40.5606, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1894/1000000, train_loss: 39.6225, val_loss: 40.5418, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1895/1000000, train_loss: 39.5994, val_loss: 40.4623, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1896/1000000, train_loss: 39.6329, val_loss: 40.4416, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1897/1000000, train_loss: 39.5882, val_loss: 40.4255, time: 0.11s\n",
      "Epoch 1898/1000000, train_loss: 39.5676, val_loss: 40.4350, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1899/1000000, train_loss: 39.5510, val_loss: 40.3920, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1900/1000000, train_loss: 39.5491, val_loss: 40.3890, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1901/1000000, train_loss: 39.5277, val_loss: 40.3192, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1902/1000000, train_loss: 39.5209, val_loss: 40.3174, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1903/1000000, train_loss: 39.5185, val_loss: 40.2789, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1904/1000000, train_loss: 39.4898, val_loss: 40.2597, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1905/1000000, train_loss: 39.4732, val_loss: 40.2290, time: 0.18s\n",
      "Epoch 1906/1000000, train_loss: 39.4687, val_loss: 40.2297, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1907/1000000, train_loss: 39.4580, val_loss: 40.1867, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1908/1000000, train_loss: 39.4394, val_loss: 40.1479, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1909/1000000, train_loss: 39.4285, val_loss: 40.1215, time: 0.11s\n",
      "Epoch 1910/1000000, train_loss: 39.4234, val_loss: 40.1621, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1911/1000000, train_loss: 39.4112, val_loss: 40.0530, time: 0.11s\n",
      "Epoch 1912/1000000, train_loss: 39.3933, val_loss: 40.0756, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1913/1000000, train_loss: 39.3903, val_loss: 39.9779, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1914/1000000, train_loss: 39.3728, val_loss: 39.9488, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1915/1000000, train_loss: 39.3433, val_loss: 39.9431, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1916/1000000, train_loss: 39.3360, val_loss: 39.9404, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1917/1000000, train_loss: 39.3248, val_loss: 39.8816, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1918/1000000, train_loss: 39.3221, val_loss: 39.8149, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1919/1000000, train_loss: 39.2965, val_loss: 39.8127, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1920/1000000, train_loss: 39.2959, val_loss: 39.8013, time: 0.11s\n",
      "Epoch 1921/1000000, train_loss: 39.2766, val_loss: 39.8286, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1922/1000000, train_loss: 39.2745, val_loss: 39.7404, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1923/1000000, train_loss: 39.2450, val_loss: 39.7172, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1924/1000000, train_loss: 39.2408, val_loss: 39.6748, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1925/1000000, train_loss: 39.2201, val_loss: 39.6282, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1926/1000000, train_loss: 39.2092, val_loss: 39.5720, time: 0.11s\n",
      "Epoch 1927/1000000, train_loss: 39.2078, val_loss: 39.5926, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1928/1000000, train_loss: 39.1986, val_loss: 39.5183, time: 0.11s\n",
      "Epoch 1929/1000000, train_loss: 39.1771, val_loss: 39.5208, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1930/1000000, train_loss: 39.1801, val_loss: 39.4778, time: 0.11s\n",
      "Epoch 1931/1000000, train_loss: 39.1513, val_loss: 39.4924, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1932/1000000, train_loss: 39.1411, val_loss: 39.4096, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1933/1000000, train_loss: 39.1275, val_loss: 39.3893, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1934/1000000, train_loss: 39.1153, val_loss: 39.3513, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1935/1000000, train_loss: 39.1157, val_loss: 39.3218, time: 0.11s\n",
      "Epoch 1936/1000000, train_loss: 39.0951, val_loss: 39.3419, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1937/1000000, train_loss: 39.0887, val_loss: 39.2773, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1938/1000000, train_loss: 39.0655, val_loss: 39.2421, time: 0.11s\n",
      "Epoch 1939/1000000, train_loss: 39.0479, val_loss: 39.2422, time: 0.11s\n",
      "Epoch 1940/1000000, train_loss: 39.0373, val_loss: 39.3750, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1941/1000000, train_loss: 39.0239, val_loss: 39.1626, time: 0.11s\n",
      "Epoch 1942/1000000, train_loss: 39.3893, val_loss: 39.2022, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1943/1000000, train_loss: 39.3036, val_loss: 39.1576, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1944/1000000, train_loss: 39.1109, val_loss: 39.1415, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1945/1000000, train_loss: 39.0974, val_loss: 39.1041, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1946/1000000, train_loss: 39.0591, val_loss: 39.0695, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1947/1000000, train_loss: 39.0136, val_loss: 39.0080, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1948/1000000, train_loss: 38.9651, val_loss: 38.9317, time: 0.11s\n",
      "Epoch 1949/1000000, train_loss: 38.9379, val_loss: 38.9829, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1950/1000000, train_loss: 38.9165, val_loss: 38.9194, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1951/1000000, train_loss: 38.9097, val_loss: 38.9024, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1952/1000000, train_loss: 38.9012, val_loss: 38.8839, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1953/1000000, train_loss: 38.8783, val_loss: 38.8756, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1954/1000000, train_loss: 38.8653, val_loss: 38.8131, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1955/1000000, train_loss: 38.8471, val_loss: 38.7766, time: 0.11s\n",
      "Epoch 1956/1000000, train_loss: 38.8400, val_loss: 38.7957, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1957/1000000, train_loss: 38.8326, val_loss: 38.7343, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1958/1000000, train_loss: 38.8096, val_loss: 38.6514, time: 0.11s\n",
      "Epoch 1959/1000000, train_loss: 38.8008, val_loss: 38.6694, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1960/1000000, train_loss: 38.8019, val_loss: 38.6341, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1961/1000000, train_loss: 38.7727, val_loss: 38.6212, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1962/1000000, train_loss: 38.7708, val_loss: 38.5871, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1963/1000000, train_loss: 38.7507, val_loss: 38.5419, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1964/1000000, train_loss: 38.7683, val_loss: 38.5386, time: 0.11s\n",
      "Epoch 1965/1000000, train_loss: 38.7577, val_loss: 38.5673, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1966/1000000, train_loss: 38.7175, val_loss: 38.4753, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1967/1000000, train_loss: 38.7055, val_loss: 38.4416, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1968/1000000, train_loss: 38.7071, val_loss: 38.4373, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1969/1000000, train_loss: 38.6707, val_loss: 38.3790, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1970/1000000, train_loss: 38.6623, val_loss: 38.3511, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1971/1000000, train_loss: 38.6515, val_loss: 38.2691, time: 0.11s\n",
      "Epoch 1972/1000000, train_loss: 38.6354, val_loss: 38.2826, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1973/1000000, train_loss: 38.6298, val_loss: 38.2585, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1974/1000000, train_loss: 38.6168, val_loss: 38.2486, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1975/1000000, train_loss: 38.6071, val_loss: 38.2339, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1976/1000000, train_loss: 38.5949, val_loss: 38.1882, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1977/1000000, train_loss: 38.5712, val_loss: 38.1351, time: 0.11s\n",
      "Epoch 1978/1000000, train_loss: 38.5613, val_loss: 38.1471, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1979/1000000, train_loss: 38.5474, val_loss: 38.0756, time: 0.11s\n",
      "Epoch 1980/1000000, train_loss: 38.5328, val_loss: 38.1021, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1981/1000000, train_loss: 38.5268, val_loss: 38.0477, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1982/1000000, train_loss: 38.5091, val_loss: 38.0188, time: 0.11s\n",
      "Epoch 1983/1000000, train_loss: 38.4972, val_loss: 38.0563, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1984/1000000, train_loss: 38.4874, val_loss: 37.9917, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1985/1000000, train_loss: 38.4765, val_loss: 37.9290, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1986/1000000, train_loss: 38.4633, val_loss: 37.8632, time: 0.11s\n",
      "Epoch 1987/1000000, train_loss: 38.4587, val_loss: 37.8683, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1988/1000000, train_loss: 38.4432, val_loss: 37.8503, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1989/1000000, train_loss: 38.4241, val_loss: 37.7888, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1990/1000000, train_loss: 38.4203, val_loss: 37.7690, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1991/1000000, train_loss: 38.3942, val_loss: 37.7080, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1992/1000000, train_loss: 38.3819, val_loss: 37.6837, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1993/1000000, train_loss: 38.3657, val_loss: 37.6520, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1994/1000000, train_loss: 38.3663, val_loss: 37.6372, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1995/1000000, train_loss: 38.3461, val_loss: 37.6060, time: 0.11s\n",
      "Epoch 1996/1000000, train_loss: 38.3417, val_loss: 37.6530, time: 0.11s\n",
      "Epoch 1997/1000000, train_loss: 38.3206, val_loss: 37.6120, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1998/1000000, train_loss: 38.3226, val_loss: 37.5288, time: 0.11s\n",
      "Epoch 1999/1000000, train_loss: 38.3057, val_loss: 37.5728, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2000/1000000, train_loss: 38.3253, val_loss: 37.4936, time: 0.11s\n",
      "Epoch 2001/1000000, train_loss: 38.2811, val_loss: 37.5122, time: 0.11s\n",
      "Epoch 2002/1000000, train_loss: 38.2487, val_loss: 37.4941, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2003/1000000, train_loss: 38.2596, val_loss: 37.3840, time: 0.11s\n",
      "Epoch 2004/1000000, train_loss: 38.2420, val_loss: 37.4108, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2005/1000000, train_loss: 38.3154, val_loss: 37.3475, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2006/1000000, train_loss: 38.2133, val_loss: 37.3196, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2007/1000000, train_loss: 38.1919, val_loss: 37.2817, time: 0.14s\n",
      "Epoch 2008/1000000, train_loss: 38.1795, val_loss: 37.2947, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2009/1000000, train_loss: 38.1813, val_loss: 37.2809, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2010/1000000, train_loss: 38.1594, val_loss: 37.2005, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2011/1000000, train_loss: 38.1576, val_loss: 37.1812, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2012/1000000, train_loss: 38.1311, val_loss: 37.1488, time: 0.11s\n",
      "Epoch 2013/1000000, train_loss: 38.1269, val_loss: 37.1557, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2014/1000000, train_loss: 38.1713, val_loss: 37.1291, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2015/1000000, train_loss: 38.1299, val_loss: 37.0865, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2016/1000000, train_loss: 38.0893, val_loss: 37.0438, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2017/1000000, train_loss: 38.0803, val_loss: 37.0346, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2018/1000000, train_loss: 38.0780, val_loss: 37.0219, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2019/1000000, train_loss: 38.0535, val_loss: 36.9939, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2020/1000000, train_loss: 38.0291, val_loss: 36.9641, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2021/1000000, train_loss: 38.0369, val_loss: 36.8889, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2022/1000000, train_loss: 38.0096, val_loss: 36.8475, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2023/1000000, train_loss: 38.0029, val_loss: 36.8347, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2024/1000000, train_loss: 37.9980, val_loss: 36.8315, time: 0.11s\n",
      "Epoch 2025/1000000, train_loss: 37.9743, val_loss: 36.8320, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2026/1000000, train_loss: 37.9621, val_loss: 36.7474, time: 0.11s\n",
      "Epoch 2027/1000000, train_loss: 37.9498, val_loss: 36.7604, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2028/1000000, train_loss: 37.9396, val_loss: 36.6646, time: 0.11s\n",
      "Epoch 2029/1000000, train_loss: 37.9166, val_loss: 36.6666, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2030/1000000, train_loss: 37.9031, val_loss: 36.6118, time: 0.11s\n",
      "Epoch 2031/1000000, train_loss: 37.9077, val_loss: 36.6433, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2032/1000000, train_loss: 38.0292, val_loss: 36.5740, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2033/1000000, train_loss: 37.8847, val_loss: 36.5505, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2034/1000000, train_loss: 37.8731, val_loss: 36.5048, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2035/1000000, train_loss: 37.8752, val_loss: 36.4876, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2036/1000000, train_loss: 37.8407, val_loss: 36.4437, time: 0.11s\n",
      "Epoch 2037/1000000, train_loss: 37.8218, val_loss: 36.4751, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2038/1000000, train_loss: 37.8144, val_loss: 36.3797, time: 0.11s\n",
      "Epoch 2039/1000000, train_loss: 37.8028, val_loss: 36.3971, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2040/1000000, train_loss: 37.7924, val_loss: 36.3497, time: 0.11s\n",
      "Epoch 2041/1000000, train_loss: 37.7825, val_loss: 36.3693, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2042/1000000, train_loss: 37.7634, val_loss: 36.2820, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2043/1000000, train_loss: 37.7490, val_loss: 36.2079, time: 0.11s\n",
      "Epoch 2044/1000000, train_loss: 37.7383, val_loss: 36.2612, time: 0.11s\n",
      "Epoch 2045/1000000, train_loss: 37.7242, val_loss: 36.2473, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2046/1000000, train_loss: 37.8354, val_loss: 36.1364, time: 0.11s\n",
      "Epoch 2047/1000000, train_loss: 37.7143, val_loss: 36.2077, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2048/1000000, train_loss: 37.6756, val_loss: 36.1238, time: 0.11s\n",
      "Epoch 2049/1000000, train_loss: 37.6761, val_loss: 36.1581, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2050/1000000, train_loss: 37.6608, val_loss: 36.0507, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2051/1000000, train_loss: 37.6500, val_loss: 36.0214, time: 0.11s\n",
      "Epoch 2052/1000000, train_loss: 37.6385, val_loss: 36.0589, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2053/1000000, train_loss: 37.6149, val_loss: 35.9420, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2054/1000000, train_loss: 37.6072, val_loss: 35.9062, time: 0.11s\n",
      "Epoch 2055/1000000, train_loss: 37.6022, val_loss: 35.9103, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2056/1000000, train_loss: 37.5876, val_loss: 35.8793, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2057/1000000, train_loss: 37.5780, val_loss: 35.8441, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2058/1000000, train_loss: 37.5655, val_loss: 35.8292, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2059/1000000, train_loss: 37.5763, val_loss: 35.8033, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2060/1000000, train_loss: 37.5343, val_loss: 35.7677, time: 0.11s\n",
      "Epoch 2061/1000000, train_loss: 37.5274, val_loss: 35.7772, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2062/1000000, train_loss: 37.5193, val_loss: 35.6671, time: 0.11s\n",
      "Epoch 2063/1000000, train_loss: 37.5195, val_loss: 35.7411, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2064/1000000, train_loss: 37.4841, val_loss: 35.6395, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2065/1000000, train_loss: 37.4660, val_loss: 35.6374, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2066/1000000, train_loss: 37.4490, val_loss: 35.6164, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2067/1000000, train_loss: 37.4455, val_loss: 35.5478, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2068/1000000, train_loss: 37.4965, val_loss: 35.5006, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2069/1000000, train_loss: 37.4416, val_loss: 35.4921, time: 0.11s\n",
      "Epoch 2070/1000000, train_loss: 37.4015, val_loss: 35.4967, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2071/1000000, train_loss: 37.5083, val_loss: 35.3931, time: 0.11s\n",
      "Epoch 2072/1000000, train_loss: 37.6201, val_loss: 35.3992, time: 0.11s\n",
      "Epoch 2073/1000000, train_loss: 37.3957, val_loss: 35.4182, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2074/1000000, train_loss: 37.3730, val_loss: 35.3379, time: 0.11s\n",
      "Epoch 2075/1000000, train_loss: 37.3524, val_loss: 35.3789, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2076/1000000, train_loss: 37.3473, val_loss: 35.3254, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2077/1000000, train_loss: 37.3284, val_loss: 35.2991, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2078/1000000, train_loss: 37.3013, val_loss: 35.2738, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2079/1000000, train_loss: 37.2935, val_loss: 35.1993, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2080/1000000, train_loss: 37.2788, val_loss: 35.1876, time: 0.11s\n",
      "Epoch 2081/1000000, train_loss: 37.3132, val_loss: 35.1921, time: 0.11s\n",
      "Epoch 2082/1000000, train_loss: 37.2675, val_loss: 35.1946, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2083/1000000, train_loss: 37.2404, val_loss: 35.1439, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2084/1000000, train_loss: 37.2301, val_loss: 35.1137, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2085/1000000, train_loss: 37.2152, val_loss: 35.0223, time: 0.11s\n",
      "Epoch 2086/1000000, train_loss: 37.2084, val_loss: 35.1206, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2087/1000000, train_loss: 37.1856, val_loss: 34.9974, time: 0.11s\n",
      "Epoch 2088/1000000, train_loss: 37.1811, val_loss: 35.0117, time: 0.11s\n",
      "Epoch 2089/1000000, train_loss: 37.1949, val_loss: 35.0121, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2090/1000000, train_loss: 37.1716, val_loss: 34.8409, time: 0.11s\n",
      "Epoch 2091/1000000, train_loss: 37.1434, val_loss: 34.8540, time: 0.11s\n",
      "Epoch 2092/1000000, train_loss: 37.1564, val_loss: 34.9661, time: 0.11s\n",
      "Epoch 2093/1000000, train_loss: 37.1244, val_loss: 34.8427, time: 0.11s\n",
      "Epoch 2094/1000000, train_loss: 37.1132, val_loss: 34.8426, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2095/1000000, train_loss: 37.1204, val_loss: 34.7444, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2096/1000000, train_loss: 37.0861, val_loss: 34.7136, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2097/1000000, train_loss: 37.0815, val_loss: 34.6892, time: 0.11s\n",
      "Epoch 2098/1000000, train_loss: 37.0612, val_loss: 34.7207, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2099/1000000, train_loss: 37.0444, val_loss: 34.6256, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2100/1000000, train_loss: 37.0379, val_loss: 34.6002, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2101/1000000, train_loss: 37.0167, val_loss: 34.5714, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2102/1000000, train_loss: 37.0117, val_loss: 34.4883, time: 0.11s\n",
      "Epoch 2103/1000000, train_loss: 36.9948, val_loss: 34.5036, time: 0.11s\n",
      "Epoch 2104/1000000, train_loss: 36.9935, val_loss: 34.5236, time: 0.11s\n",
      "Epoch 2105/1000000, train_loss: 36.9730, val_loss: 34.5371, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2106/1000000, train_loss: 36.9566, val_loss: 34.3679, time: 0.11s\n",
      "Epoch 2107/1000000, train_loss: 36.9462, val_loss: 34.3905, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2108/1000000, train_loss: 36.9144, val_loss: 34.3275, time: 0.11s\n",
      "Epoch 2109/1000000, train_loss: 36.9140, val_loss: 34.3697, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2110/1000000, train_loss: 36.9091, val_loss: 34.3153, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2111/1000000, train_loss: 36.9313, val_loss: 34.2860, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2112/1000000, train_loss: 37.0395, val_loss: 34.2305, time: 0.11s\n",
      "Epoch 2113/1000000, train_loss: 36.8640, val_loss: 34.2453, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2114/1000000, train_loss: 36.8620, val_loss: 34.1731, time: 0.11s\n",
      "Epoch 2115/1000000, train_loss: 36.9580, val_loss: 34.1968, time: 0.11s\n",
      "Epoch 2116/1000000, train_loss: 36.8339, val_loss: 34.1986, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2117/1000000, train_loss: 36.8216, val_loss: 34.1014, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2118/1000000, train_loss: 36.8052, val_loss: 34.0509, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2119/1000000, train_loss: 36.8000, val_loss: 34.0362, time: 0.11s\n",
      "Epoch 2120/1000000, train_loss: 36.7677, val_loss: 34.0388, time: 0.12s\n",
      "Epoch 2121/1000000, train_loss: 36.9897, val_loss: 34.1212, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2122/1000000, train_loss: 36.9197, val_loss: 34.0306, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2123/1000000, train_loss: 36.8854, val_loss: 33.9151, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2124/1000000, train_loss: 36.8644, val_loss: 33.9088, time: 0.11s\n",
      "Epoch 2125/1000000, train_loss: 36.8278, val_loss: 33.9269, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2126/1000000, train_loss: 37.1122, val_loss: 33.8852, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2127/1000000, train_loss: 36.7015, val_loss: 33.8312, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2128/1000000, train_loss: 36.6909, val_loss: 33.8289, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2129/1000000, train_loss: 36.6725, val_loss: 33.8036, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2130/1000000, train_loss: 36.6518, val_loss: 33.7665, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2131/1000000, train_loss: 36.6498, val_loss: 33.7076, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2132/1000000, train_loss: 36.6296, val_loss: 33.7069, time: 0.11s\n",
      "Epoch 2133/1000000, train_loss: 36.6225, val_loss: 33.7350, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2134/1000000, train_loss: 36.6124, val_loss: 33.6208, time: 0.11s\n",
      "Epoch 2135/1000000, train_loss: 36.6017, val_loss: 33.6388, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2136/1000000, train_loss: 36.5809, val_loss: 33.5704, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2137/1000000, train_loss: 36.5745, val_loss: 33.5524, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2138/1000000, train_loss: 36.5632, val_loss: 33.4539, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2139/1000000, train_loss: 36.5406, val_loss: 33.4315, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2140/1000000, train_loss: 36.5269, val_loss: 33.3600, time: 0.12s\n",
      "Epoch 2141/1000000, train_loss: 36.5277, val_loss: 33.4433, time: 0.11s\n",
      "Epoch 2142/1000000, train_loss: 36.5099, val_loss: 33.4522, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2143/1000000, train_loss: 36.5053, val_loss: 33.3398, time: 0.11s\n",
      "Epoch 2144/1000000, train_loss: 36.4817, val_loss: 33.3665, time: 0.11s\n",
      "Epoch 2145/1000000, train_loss: 36.4587, val_loss: 33.3650, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2146/1000000, train_loss: 36.4528, val_loss: 33.2669, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2147/1000000, train_loss: 36.4423, val_loss: 33.2238, time: 0.11s\n",
      "Epoch 2148/1000000, train_loss: 36.4352, val_loss: 33.2376, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2149/1000000, train_loss: 36.4160, val_loss: 33.2203, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2150/1000000, train_loss: 36.3999, val_loss: 33.1716, time: 0.11s\n",
      "Epoch 2151/1000000, train_loss: 38.8108, val_loss: 122.5501, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2152/1000000, train_loss: 37.0012, val_loss: 33.0912, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2153/1000000, train_loss: 36.3747, val_loss: 33.0461, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2154/1000000, train_loss: 36.3723, val_loss: 32.9754, time: 0.11s\n",
      "Epoch 2155/1000000, train_loss: 36.3559, val_loss: 33.0272, time: 0.11s\n",
      "Epoch 2156/1000000, train_loss: 36.3361, val_loss: 32.9976, time: 0.11s\n",
      "Epoch 2157/1000000, train_loss: 36.3188, val_loss: 33.0391, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2158/1000000, train_loss: 36.3161, val_loss: 32.9489, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2159/1000000, train_loss: 36.2969, val_loss: 32.8633, time: 0.11s\n",
      "Epoch 2160/1000000, train_loss: 36.2747, val_loss: 32.9972, time: 0.11s\n",
      "Epoch 2161/1000000, train_loss: 36.2660, val_loss: 32.8805, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2162/1000000, train_loss: 36.2528, val_loss: 32.8420, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2163/1000000, train_loss: 36.2402, val_loss: 32.7926, time: 0.11s\n",
      "Epoch 2164/1000000, train_loss: 36.2390, val_loss: 32.8122, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2165/1000000, train_loss: 36.2248, val_loss: 32.6745, time: 0.11s\n",
      "Epoch 2166/1000000, train_loss: 36.1983, val_loss: 32.6870, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2167/1000000, train_loss: 36.1895, val_loss: 32.6313, time: 0.11s\n",
      "Epoch 2168/1000000, train_loss: 36.1748, val_loss: 32.6788, time: 0.11s\n",
      "Epoch 2169/1000000, train_loss: 36.1623, val_loss: 32.6900, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2170/1000000, train_loss: 36.1363, val_loss: 32.5392, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2171/1000000, train_loss: 36.1531, val_loss: 32.5281, time: 0.11s\n",
      "Epoch 2172/1000000, train_loss: 36.1161, val_loss: 32.5923, time: 0.11s\n",
      "Epoch 2173/1000000, train_loss: 36.1032, val_loss: 32.5741, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2174/1000000, train_loss: 36.1111, val_loss: 32.4097, time: 0.11s\n",
      "Epoch 2175/1000000, train_loss: 36.0846, val_loss: 32.4587, time: 0.11s\n",
      "Epoch 2176/1000000, train_loss: 36.0705, val_loss: 32.4107, time: 0.11s\n",
      "Epoch 2177/1000000, train_loss: 36.0663, val_loss: 32.4383, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2178/1000000, train_loss: 36.0620, val_loss: 32.3876, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2179/1000000, train_loss: 36.0407, val_loss: 32.3844, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2180/1000000, train_loss: 36.0322, val_loss: 32.2860, time: 0.11s\n",
      "Epoch 2181/1000000, train_loss: 36.0460, val_loss: 32.3210, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2182/1000000, train_loss: 36.0059, val_loss: 32.2418, time: 0.11s\n",
      "Epoch 2183/1000000, train_loss: 36.0675, val_loss: 32.3022, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2184/1000000, train_loss: 35.9843, val_loss: 32.2269, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2185/1000000, train_loss: 35.9718, val_loss: 32.2047, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2186/1000000, train_loss: 35.9566, val_loss: 32.1473, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2187/1000000, train_loss: 35.9294, val_loss: 32.1103, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2188/1000000, train_loss: 35.9463, val_loss: 32.0395, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2189/1000000, train_loss: 35.9160, val_loss: 31.9968, time: 0.11s\n",
      "Epoch 2190/1000000, train_loss: 35.9069, val_loss: 32.0040, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2191/1000000, train_loss: 35.8957, val_loss: 31.9640, time: 0.11s\n",
      "Epoch 2192/1000000, train_loss: 35.8756, val_loss: 31.9741, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2193/1000000, train_loss: 35.8671, val_loss: 31.9627, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2194/1000000, train_loss: 35.8656, val_loss: 31.8827, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2195/1000000, train_loss: 35.8283, val_loss: 31.8598, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2196/1000000, train_loss: 35.8320, val_loss: 31.8558, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2197/1000000, train_loss: 35.8161, val_loss: 31.8010, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2198/1000000, train_loss: 35.7997, val_loss: 31.7322, time: 0.11s\n",
      "Epoch 2199/1000000, train_loss: 35.7873, val_loss: 31.7760, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2200/1000000, train_loss: 35.8083, val_loss: 31.7301, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2201/1000000, train_loss: 35.7832, val_loss: 31.7269, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2202/1000000, train_loss: 35.7513, val_loss: 31.7007, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2203/1000000, train_loss: 35.8785, val_loss: 31.6463, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2204/1000000, train_loss: 35.7389, val_loss: 31.6094, time: 0.11s\n",
      "Epoch 2205/1000000, train_loss: 35.7135, val_loss: 31.6175, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2206/1000000, train_loss: 35.7115, val_loss: 31.5692, time: 0.11s\n",
      "Epoch 2207/1000000, train_loss: 35.6955, val_loss: 31.6215, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2208/1000000, train_loss: 35.6773, val_loss: 31.5544, time: 0.11s\n",
      "Epoch 2209/1000000, train_loss: 35.6667, val_loss: 31.5630, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2210/1000000, train_loss: 35.7570, val_loss: 31.4740, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2211/1000000, train_loss: 35.6383, val_loss: 31.4135, time: 0.11s\n",
      "Epoch 2212/1000000, train_loss: 35.6726, val_loss: 31.4173, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2213/1000000, train_loss: 35.6357, val_loss: 31.3387, time: 0.11s\n",
      "Epoch 2214/1000000, train_loss: 35.6084, val_loss: 31.4030, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2215/1000000, train_loss: 35.5965, val_loss: 31.2951, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2216/1000000, train_loss: 35.5797, val_loss: 31.2759, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2217/1000000, train_loss: 35.5694, val_loss: 31.2221, time: 0.11s\n",
      "Epoch 2218/1000000, train_loss: 35.5541, val_loss: 31.2429, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2219/1000000, train_loss: 35.6406, val_loss: 31.1690, time: 0.11s\n",
      "Epoch 2220/1000000, train_loss: 35.7584, val_loss: 31.1985, time: 0.11s\n",
      "Epoch 2221/1000000, train_loss: 35.6061, val_loss: 31.1722, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2222/1000000, train_loss: 35.7079, val_loss: 31.0982, time: 0.15s\n",
      "Epoch 2223/1000000, train_loss: 35.5196, val_loss: 31.1042, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2224/1000000, train_loss: 35.4791, val_loss: 31.0494, time: 0.11s\n",
      "Epoch 2225/1000000, train_loss: 35.4753, val_loss: 31.0701, time: 0.11s\n",
      "Epoch 2226/1000000, train_loss: 35.4613, val_loss: 31.0565, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2227/1000000, train_loss: 35.4477, val_loss: 30.9778, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2228/1000000, train_loss: 35.4309, val_loss: 30.8900, time: 0.11s\n",
      "Epoch 2229/1000000, train_loss: 35.4096, val_loss: 31.0243, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2230/1000000, train_loss: 35.4059, val_loss: 30.8671, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2231/1000000, train_loss: 35.3900, val_loss: 30.7918, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2232/1000000, train_loss: 35.3825, val_loss: 30.7707, time: 0.11s\n",
      "Epoch 2233/1000000, train_loss: 35.3695, val_loss: 30.8163, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2234/1000000, train_loss: 35.3589, val_loss: 30.7272, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2235/1000000, train_loss: 35.3360, val_loss: 30.6758, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2236/1000000, train_loss: 35.3205, val_loss: 30.6748, time: 0.11s\n",
      "Epoch 2237/1000000, train_loss: 35.4696, val_loss: 30.6819, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2238/1000000, train_loss: 35.3035, val_loss: 30.6251, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2239/1000000, train_loss: 35.2884, val_loss: 30.5200, time: 0.11s\n",
      "Epoch 2240/1000000, train_loss: 35.2851, val_loss: 30.6406, time: 0.11s\n",
      "Epoch 2241/1000000, train_loss: 35.2737, val_loss: 30.5244, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2242/1000000, train_loss: 35.2586, val_loss: 30.4947, time: 0.11s\n",
      "Epoch 2243/1000000, train_loss: 35.2426, val_loss: 30.5112, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2244/1000000, train_loss: 35.2241, val_loss: 30.4235, time: 0.11s\n",
      "Epoch 2245/1000000, train_loss: 35.2107, val_loss: 30.4540, time: 0.11s\n",
      "Epoch 2246/1000000, train_loss: 35.3813, val_loss: 30.4246, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2247/1000000, train_loss: 35.2807, val_loss: 30.3662, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2248/1000000, train_loss: 35.5159, val_loss: 30.3018, time: 0.11s\n",
      "Epoch 2249/1000000, train_loss: 35.2545, val_loss: 30.3217, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2250/1000000, train_loss: 35.1590, val_loss: 30.2980, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2251/1000000, train_loss: 35.1370, val_loss: 30.2907, time: 0.11s\n",
      "Epoch 2252/1000000, train_loss: 35.1389, val_loss: 30.3163, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2253/1000000, train_loss: 35.1190, val_loss: 30.1929, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2254/1000000, train_loss: 35.1091, val_loss: 30.1884, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2255/1000000, train_loss: 35.0943, val_loss: 30.1832, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2256/1000000, train_loss: 35.0721, val_loss: 30.0859, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2257/1000000, train_loss: 35.0652, val_loss: 30.0529, time: 0.11s\n",
      "Epoch 2258/1000000, train_loss: 35.0565, val_loss: 30.0927, time: 0.11s\n",
      "Epoch 2259/1000000, train_loss: 35.0609, val_loss: 30.1154, time: 0.11s\n",
      "Epoch 2260/1000000, train_loss: 35.0397, val_loss: 30.1221, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2261/1000000, train_loss: 35.0170, val_loss: 29.9657, time: 0.11s\n",
      "Epoch 2262/1000000, train_loss: 34.9976, val_loss: 29.9839, time: 0.11s\n",
      "Epoch 2263/1000000, train_loss: 34.9940, val_loss: 29.9755, time: 0.11s\n",
      "Epoch 2264/1000000, train_loss: 34.9712, val_loss: 29.9713, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2265/1000000, train_loss: 34.9666, val_loss: 29.8957, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2266/1000000, train_loss: 34.9740, val_loss: 29.8800, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2267/1000000, train_loss: 35.0562, val_loss: 29.8430, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2268/1000000, train_loss: 35.2255, val_loss: 29.7915, time: 0.11s\n",
      "Epoch 2269/1000000, train_loss: 34.9291, val_loss: 29.8041, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2270/1000000, train_loss: 34.8984, val_loss: 29.6942, time: 0.11s\n",
      "Epoch 2271/1000000, train_loss: 34.8867, val_loss: 29.7529, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2272/1000000, train_loss: 34.8896, val_loss: 29.6836, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2273/1000000, train_loss: 34.8655, val_loss: 29.6443, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2274/1000000, train_loss: 34.8900, val_loss: 29.5831, time: 0.11s\n",
      "Epoch 2275/1000000, train_loss: 34.8425, val_loss: 29.5946, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2276/1000000, train_loss: 34.8301, val_loss: 29.5584, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2277/1000000, train_loss: 34.8253, val_loss: 29.4315, time: 0.11s\n",
      "Epoch 2278/1000000, train_loss: 34.8121, val_loss: 29.5066, time: 0.11s\n",
      "Epoch 2279/1000000, train_loss: 34.7873, val_loss: 29.4849, time: 0.11s\n",
      "Epoch 2280/1000000, train_loss: 34.7892, val_loss: 29.4519, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2281/1000000, train_loss: 34.7674, val_loss: 29.3944, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2282/1000000, train_loss: 34.7698, val_loss: 29.3739, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2283/1000000, train_loss: 34.7477, val_loss: 29.2516, time: 0.11s\n",
      "Epoch 2284/1000000, train_loss: 34.7272, val_loss: 29.3030, time: 0.11s\n",
      "Epoch 2285/1000000, train_loss: 34.7019, val_loss: 29.3211, time: 0.11s\n",
      "Epoch 2286/1000000, train_loss: 34.6953, val_loss: 29.2521, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2287/1000000, train_loss: 34.7080, val_loss: 29.1806, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2288/1000000, train_loss: 34.7214, val_loss: 29.1550, time: 0.11s\n",
      "Epoch 2289/1000000, train_loss: 34.8589, val_loss: 29.2011, time: 0.11s\n",
      "Epoch 2290/1000000, train_loss: 34.6595, val_loss: 29.2249, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2291/1000000, train_loss: 34.8184, val_loss: 29.0480, time: 0.11s\n",
      "Epoch 2292/1000000, train_loss: 34.6926, val_loss: 29.1174, time: 0.11s\n",
      "Epoch 2293/1000000, train_loss: 34.6190, val_loss: 29.1185, time: 0.11s\n",
      "Epoch 2294/1000000, train_loss: 34.5995, val_loss: 29.0683, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2295/1000000, train_loss: 34.5902, val_loss: 28.9970, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2296/1000000, train_loss: 34.6789, val_loss: 28.9744, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2297/1000000, train_loss: 34.5901, val_loss: 28.8882, time: 0.11s\n",
      "Epoch 2298/1000000, train_loss: 34.5645, val_loss: 28.9220, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2299/1000000, train_loss: 34.7724, val_loss: 28.8716, time: 0.11s\n",
      "Epoch 2300/1000000, train_loss: 34.6716, val_loss: 28.8992, time: 0.11s\n",
      "Epoch 2301/1000000, train_loss: 34.8767, val_loss: 28.8993, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2302/1000000, train_loss: 34.6233, val_loss: 28.7452, time: 0.11s\n",
      "Epoch 2303/1000000, train_loss: 34.4819, val_loss: 28.7538, time: 0.11s\n",
      "Epoch 2304/1000000, train_loss: 34.4780, val_loss: 28.7670, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2305/1000000, train_loss: 34.4470, val_loss: 28.7114, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2306/1000000, train_loss: 34.5752, val_loss: 28.6551, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2307/1000000, train_loss: 34.4346, val_loss: 28.6249, time: 0.11s\n",
      "Epoch 2308/1000000, train_loss: 34.6131, val_loss: 28.7349, time: 0.11s\n",
      "Epoch 2309/1000000, train_loss: 34.6849, val_loss: 28.6795, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2310/1000000, train_loss: 36.0065, val_loss: 28.5710, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2311/1000000, train_loss: 35.5155, val_loss: 28.4533, time: 0.11s\n",
      "Epoch 2312/1000000, train_loss: 34.3817, val_loss: 28.5948, time: 0.11s\n",
      "Epoch 2313/1000000, train_loss: 34.3668, val_loss: 28.5236, time: 0.11s\n",
      "Epoch 2314/1000000, train_loss: 34.3450, val_loss: 28.4748, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2315/1000000, train_loss: 34.3344, val_loss: 28.4415, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2316/1000000, train_loss: 34.3294, val_loss: 28.4397, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2317/1000000, train_loss: 34.3243, val_loss: 28.3654, time: 0.13s\n",
      "Epoch 2318/1000000, train_loss: 34.2921, val_loss: 28.3707, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2319/1000000, train_loss: 34.2949, val_loss: 28.3485, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2320/1000000, train_loss: 34.2875, val_loss: 28.3240, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2321/1000000, train_loss: 34.2566, val_loss: 28.2582, time: 0.11s\n",
      "Epoch 2322/1000000, train_loss: 34.2462, val_loss: 28.3025, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2323/1000000, train_loss: 34.2458, val_loss: 28.1882, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2324/1000000, train_loss: 34.2122, val_loss: 28.1495, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2325/1000000, train_loss: 34.2141, val_loss: 28.1233, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2326/1000000, train_loss: 34.2375, val_loss: 28.0544, time: 0.11s\n",
      "Epoch 2327/1000000, train_loss: 34.1886, val_loss: 28.1299, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2328/1000000, train_loss: 34.1786, val_loss: 27.9805, time: 0.11s\n",
      "Epoch 2329/1000000, train_loss: 34.1583, val_loss: 28.1193, time: 0.11s\n",
      "Epoch 2330/1000000, train_loss: 34.1520, val_loss: 28.0563, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2331/1000000, train_loss: 34.1386, val_loss: 27.9304, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2332/1000000, train_loss: 34.1274, val_loss: 27.9168, time: 0.11s\n",
      "Epoch 2333/1000000, train_loss: 34.1193, val_loss: 27.9181, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2334/1000000, train_loss: 34.1033, val_loss: 27.8307, time: 0.11s\n",
      "Epoch 2335/1000000, train_loss: 34.0914, val_loss: 27.8783, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2336/1000000, train_loss: 34.0676, val_loss: 27.7146, time: 0.11s\n",
      "Epoch 2337/1000000, train_loss: 34.0597, val_loss: 27.8379, time: 0.11s\n",
      "Epoch 2338/1000000, train_loss: 34.0422, val_loss: 27.7305, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2339/1000000, train_loss: 34.0438, val_loss: 27.6566, time: 0.11s\n",
      "Epoch 2340/1000000, train_loss: 34.0259, val_loss: 27.7772, time: 0.11s\n",
      "Epoch 2341/1000000, train_loss: 34.0173, val_loss: 27.6778, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2342/1000000, train_loss: 33.9953, val_loss: 27.5789, time: 0.11s\n",
      "Epoch 2343/1000000, train_loss: 33.9835, val_loss: 27.6036, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2344/1000000, train_loss: 33.9741, val_loss: 27.5220, time: 0.11s\n",
      "Epoch 2345/1000000, train_loss: 33.9593, val_loss: 27.6012, time: 0.11s\n",
      "Epoch 2346/1000000, train_loss: 33.9598, val_loss: 27.5733, time: 0.11s\n",
      "Epoch 2347/1000000, train_loss: 33.9261, val_loss: 27.5809, time: 0.11s\n",
      "Epoch 2348/1000000, train_loss: 33.9295, val_loss: 27.5549, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2349/1000000, train_loss: 33.9151, val_loss: 27.4591, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2350/1000000, train_loss: 33.8962, val_loss: 27.4014, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2351/1000000, train_loss: 33.8933, val_loss: 27.3262, time: 0.11s\n",
      "Epoch 2352/1000000, train_loss: 33.8937, val_loss: 27.3689, time: 0.11s\n",
      "Epoch 2353/1000000, train_loss: 33.9357, val_loss: 27.4173, time: 0.11s\n",
      "Epoch 2354/1000000, train_loss: 33.8460, val_loss: 27.3977, time: 0.10s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2355/1000000, train_loss: 33.8236, val_loss: 27.1953, time: 0.11s\n",
      "Epoch 2356/1000000, train_loss: 33.8328, val_loss: 27.2473, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2357/1000000, train_loss: 33.8131, val_loss: 27.1738, time: 0.11s\n",
      "Epoch 2358/1000000, train_loss: 33.8018, val_loss: 27.2555, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2359/1000000, train_loss: 33.7812, val_loss: 27.1186, time: 0.11s\n",
      "Epoch 2360/1000000, train_loss: 33.7719, val_loss: 27.1279, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2361/1000000, train_loss: 33.7532, val_loss: 27.0859, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2362/1000000, train_loss: 33.7516, val_loss: 27.0171, time: 0.11s\n",
      "Epoch 2363/1000000, train_loss: 33.7837, val_loss: 27.1721, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2364/1000000, train_loss: 33.9943, val_loss: 26.9997, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2365/1000000, train_loss: 33.7097, val_loss: 26.9316, time: 0.11s\n",
      "Epoch 2366/1000000, train_loss: 33.9402, val_loss: 26.9604, time: 0.11s\n",
      "Epoch 2367/1000000, train_loss: 34.0281, val_loss: 26.9460, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2368/1000000, train_loss: 33.6849, val_loss: 26.9215, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2369/1000000, train_loss: 33.6561, val_loss: 26.8568, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2370/1000000, train_loss: 33.6713, val_loss: 26.8341, time: 0.11s\n",
      "Epoch 2371/1000000, train_loss: 33.8912, val_loss: 26.8677, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2372/1000000, train_loss: 33.6936, val_loss: 26.7689, time: 0.11s\n",
      "Epoch 2373/1000000, train_loss: 33.5966, val_loss: 26.7795, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2374/1000000, train_loss: 33.6063, val_loss: 26.7200, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2375/1000000, train_loss: 33.5909, val_loss: 26.6401, time: 0.11s\n",
      "Epoch 2376/1000000, train_loss: 33.5802, val_loss: 26.7313, time: 0.11s\n",
      "Epoch 2377/1000000, train_loss: 33.6733, val_loss: 26.7709, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2378/1000000, train_loss: 33.8462, val_loss: 26.5865, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2379/1000000, train_loss: 33.5438, val_loss: 26.5789, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2380/1000000, train_loss: 33.5106, val_loss: 26.4959, time: 0.11s\n",
      "Epoch 2381/1000000, train_loss: 33.6426, val_loss: 26.5323, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2382/1000000, train_loss: 33.7939, val_loss: 26.4693, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2383/1000000, train_loss: 33.4876, val_loss: 26.4663, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2384/1000000, train_loss: 33.4710, val_loss: 26.4574, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2385/1000000, train_loss: 33.4700, val_loss: 26.3953, time: 0.11s\n",
      "Epoch 2386/1000000, train_loss: 33.4787, val_loss: 26.4481, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2387/1000000, train_loss: 33.5207, val_loss: 26.3499, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2388/1000000, train_loss: 33.4448, val_loss: 26.3195, time: 0.11s\n",
      "Epoch 2389/1000000, train_loss: 33.4027, val_loss: 26.4153, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2390/1000000, train_loss: 33.3978, val_loss: 26.2155, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2391/1000000, train_loss: 33.4003, val_loss: 26.1672, time: 0.11s\n",
      "Epoch 2392/1000000, train_loss: 33.3754, val_loss: 26.2555, time: 0.11s\n",
      "Epoch 2393/1000000, train_loss: 33.3575, val_loss: 26.1966, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2394/1000000, train_loss: 33.3413, val_loss: 26.1609, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2395/1000000, train_loss: 33.3258, val_loss: 26.0676, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2396/1000000, train_loss: 33.3239, val_loss: 25.9997, time: 0.11s\n",
      "Epoch 2397/1000000, train_loss: 33.3115, val_loss: 26.1432, time: 0.11s\n",
      "Epoch 2398/1000000, train_loss: 33.2892, val_loss: 26.0687, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2399/1000000, train_loss: 33.2831, val_loss: 25.9503, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2400/1000000, train_loss: 33.2876, val_loss: 25.9064, time: 0.11s\n",
      "Epoch 2401/1000000, train_loss: 33.2673, val_loss: 25.9619, time: 0.11s\n",
      "Epoch 2402/1000000, train_loss: 33.2510, val_loss: 25.9839, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2403/1000000, train_loss: 33.2353, val_loss: 25.8305, time: 0.11s\n",
      "Epoch 2404/1000000, train_loss: 33.2205, val_loss: 25.9467, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2405/1000000, train_loss: 33.2045, val_loss: 25.7520, time: 0.11s\n",
      "Epoch 2406/1000000, train_loss: 33.1777, val_loss: 25.9174, time: 0.11s\n",
      "Epoch 2407/1000000, train_loss: 33.1898, val_loss: 25.8165, time: 0.11s\n",
      "Epoch 2408/1000000, train_loss: 33.1678, val_loss: 25.8011, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2409/1000000, train_loss: 33.1618, val_loss: 25.7443, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2410/1000000, train_loss: 33.1557, val_loss: 25.6921, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2411/1000000, train_loss: 33.1295, val_loss: 25.6375, time: 0.11s\n",
      "Epoch 2412/1000000, train_loss: 33.1410, val_loss: 25.6486, time: 0.11s\n",
      "Epoch 2413/1000000, train_loss: 33.1324, val_loss: 25.7056, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2414/1000000, train_loss: 33.1021, val_loss: 25.5468, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2415/1000000, train_loss: 33.0871, val_loss: 25.4778, time: 0.13s\n",
      "Epoch 2416/1000000, train_loss: 33.0623, val_loss: 25.5730, time: 0.11s\n",
      "Epoch 2417/1000000, train_loss: 33.0680, val_loss: 25.5442, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2418/1000000, train_loss: 33.0400, val_loss: 25.3800, time: 0.11s\n",
      "Epoch 2419/1000000, train_loss: 33.0321, val_loss: 25.5097, time: 0.11s\n",
      "Epoch 2420/1000000, train_loss: 33.0212, val_loss: 25.5030, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2421/1000000, train_loss: 33.0245, val_loss: 25.3517, time: 0.11s\n",
      "Epoch 2422/1000000, train_loss: 32.9897, val_loss: 25.3674, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2423/1000000, train_loss: 32.9844, val_loss: 25.3404, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2424/1000000, train_loss: 32.9678, val_loss: 25.3339, time: 0.14s\n",
      "Epoch 2425/1000000, train_loss: 33.5275, val_loss: 25.3412, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2426/1000000, train_loss: 32.9536, val_loss: 25.2133, time: 0.11s\n",
      "Epoch 2427/1000000, train_loss: 32.9324, val_loss: 25.2473, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2428/1000000, train_loss: 32.9276, val_loss: 25.0826, time: 0.11s\n",
      "Epoch 2429/1000000, train_loss: 32.9085, val_loss: 25.1404, time: 0.11s\n",
      "Epoch 2430/1000000, train_loss: 32.9013, val_loss: 25.1388, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2431/1000000, train_loss: 32.8882, val_loss: 25.0004, time: 0.11s\n",
      "Epoch 2432/1000000, train_loss: 32.8705, val_loss: 25.0584, time: 0.11s\n",
      "Epoch 2433/1000000, train_loss: 32.8507, val_loss: 25.1061, time: 0.11s\n",
      "Epoch 2434/1000000, train_loss: 32.9467, val_loss: 25.1446, time: 0.11s\n",
      "Epoch 2435/1000000, train_loss: 33.0239, val_loss: 25.0072, time: 0.11s\n",
      "Epoch 2436/1000000, train_loss: 33.1994, val_loss: 28.7578, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2437/1000000, train_loss: 32.9740, val_loss: 24.8374, time: 0.11s\n",
      "Epoch 2438/1000000, train_loss: 32.7997, val_loss: 24.9245, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2439/1000000, train_loss: 32.8232, val_loss: 24.8111, time: 0.11s\n",
      "Epoch 2440/1000000, train_loss: 32.7247, val_loss: 24.8669, time: 0.11s\n",
      "Epoch 2441/1000000, train_loss: 32.7173, val_loss: 24.9068, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2442/1000000, train_loss: 32.7382, val_loss: 24.7256, time: 0.11s\n",
      "Epoch 2443/1000000, train_loss: 32.7692, val_loss: 24.7501, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2444/1000000, train_loss: 32.6845, val_loss: 24.6010, time: 0.11s\n",
      "Epoch 2445/1000000, train_loss: 32.6520, val_loss: 24.7982, time: 0.11s\n",
      "Epoch 2446/1000000, train_loss: 32.6566, val_loss: 24.6543, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2447/1000000, train_loss: 32.6342, val_loss: 24.5182, time: 0.11s\n",
      "Epoch 2448/1000000, train_loss: 32.6531, val_loss: 24.6179, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2449/1000000, train_loss: 33.0310, val_loss: 24.5124, time: 0.11s\n",
      "Epoch 2450/1000000, train_loss: 32.8530, val_loss: 24.5927, time: 0.11s\n",
      "Epoch 2451/1000000, train_loss: 32.6087, val_loss: 24.5485, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2452/1000000, train_loss: 32.5729, val_loss: 24.4949, time: 0.11s\n",
      "Epoch 2453/1000000, train_loss: 32.5666, val_loss: 24.4976, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2454/1000000, train_loss: 32.5464, val_loss: 24.3761, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2455/1000000, train_loss: 32.5320, val_loss: 24.2488, time: 0.11s\n",
      "Epoch 2456/1000000, train_loss: 32.5198, val_loss: 24.3781, time: 0.12s\n",
      "Epoch 2457/1000000, train_loss: 32.5095, val_loss: 24.3741, time: 0.14s\n",
      "Epoch 2458/1000000, train_loss: 32.4928, val_loss: 24.3539, time: 0.11s\n",
      "Epoch 2459/1000000, train_loss: 32.4839, val_loss: 24.3850, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2460/1000000, train_loss: 32.4703, val_loss: 24.1632, time: 0.11s\n",
      "Epoch 2461/1000000, train_loss: 32.8502, val_loss: 25.1324, time: 0.11s\n",
      "Epoch 2462/1000000, train_loss: 33.1794, val_loss: 24.6440, time: 0.11s\n",
      "Epoch 2463/1000000, train_loss: 33.0645, val_loss: 24.3078, time: 0.11s\n",
      "Epoch 2464/1000000, train_loss: 33.0103, val_loss: 24.3023, time: 0.11s\n",
      "Epoch 2465/1000000, train_loss: 32.7439, val_loss: 24.1947, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2466/1000000, train_loss: 32.6258, val_loss: 24.0880, time: 0.11s\n",
      "Epoch 2467/1000000, train_loss: 32.6222, val_loss: 24.1852, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2468/1000000, train_loss: 32.5921, val_loss: 24.0396, time: 0.11s\n",
      "Epoch 2469/1000000, train_loss: 32.5833, val_loss: 24.1235, time: 0.11s\n",
      "Epoch 2470/1000000, train_loss: 32.5647, val_loss: 24.0942, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2471/1000000, train_loss: 32.5352, val_loss: 23.9584, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2472/1000000, train_loss: 32.5338, val_loss: 23.8898, time: 0.11s\n",
      "Epoch 2473/1000000, train_loss: 32.5191, val_loss: 23.9447, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2474/1000000, train_loss: 32.4948, val_loss: 23.8828, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2475/1000000, train_loss: 32.4124, val_loss: 23.8242, time: 0.11s\n",
      "Epoch 2476/1000000, train_loss: 32.3499, val_loss: 23.8269, time: 0.11s\n",
      "Epoch 2477/1000000, train_loss: 32.3354, val_loss: 23.8247, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2478/1000000, train_loss: 32.3137, val_loss: 23.7063, time: 0.12s\n",
      "Epoch 2479/1000000, train_loss: 32.3024, val_loss: 23.7168, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2480/1000000, train_loss: 32.2880, val_loss: 23.6588, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2481/1000000, train_loss: 32.2780, val_loss: 23.6159, time: 0.11s\n",
      "Epoch 2482/1000000, train_loss: 32.2642, val_loss: 23.6700, time: 0.11s\n",
      "Epoch 2483/1000000, train_loss: 32.2430, val_loss: 23.6663, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2484/1000000, train_loss: 32.2523, val_loss: 23.5323, time: 0.12s\n",
      "Epoch 2485/1000000, train_loss: 32.1822, val_loss: 23.5509, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2486/1000000, train_loss: 32.1514, val_loss: 23.4274, time: 0.11s\n",
      "Epoch 2487/1000000, train_loss: 32.1550, val_loss: 23.5218, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2488/1000000, train_loss: 32.1482, val_loss: 23.4269, time: 0.11s\n",
      "Epoch 2489/1000000, train_loss: 32.1209, val_loss: 23.5244, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2490/1000000, train_loss: 32.1066, val_loss: 23.3337, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2491/1000000, train_loss: 32.0975, val_loss: 23.3311, time: 0.11s\n",
      "Epoch 2492/1000000, train_loss: 32.0918, val_loss: 23.3441, time: 0.11s\n",
      "Epoch 2493/1000000, train_loss: 32.0659, val_loss: 23.3481, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2494/1000000, train_loss: 32.0671, val_loss: 23.3271, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2495/1000000, train_loss: 32.0453, val_loss: 23.1992, time: 0.12s\n",
      "Epoch 2496/1000000, train_loss: 32.0445, val_loss: 23.2300, time: 0.13s\n",
      "Epoch 2497/1000000, train_loss: 32.0298, val_loss: 23.2269, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2498/1000000, train_loss: 32.0187, val_loss: 23.0958, time: 0.13s\n",
      "Epoch 2499/1000000, train_loss: 32.0007, val_loss: 23.1829, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2500/1000000, train_loss: 31.9830, val_loss: 23.0884, time: 0.12s\n",
      "Epoch 2501/1000000, train_loss: 31.9698, val_loss: 23.1833, time: 0.11s\n",
      "Epoch 2502/1000000, train_loss: 31.9560, val_loss: 23.1767, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2503/1000000, train_loss: 31.9343, val_loss: 23.0435, time: 0.12s\n",
      "Epoch 2504/1000000, train_loss: 31.9300, val_loss: 23.0816, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2505/1000000, train_loss: 31.9071, val_loss: 22.9527, time: 0.27s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2506/1000000, train_loss: 31.9063, val_loss: 22.9475, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2507/1000000, train_loss: 31.8938, val_loss: 22.9253, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2508/1000000, train_loss: 31.8722, val_loss: 22.8493, time: 0.12s\n",
      "Epoch 2509/1000000, train_loss: 31.8738, val_loss: 22.8995, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2510/1000000, train_loss: 34.0144, val_loss: 22.7259, time: 0.12s\n",
      "Epoch 2511/1000000, train_loss: 33.2209, val_loss: 22.8586, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2512/1000000, train_loss: 31.8480, val_loss: 22.7222, time: 0.12s\n",
      "Epoch 2513/1000000, train_loss: 31.8095, val_loss: 22.7567, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2514/1000000, train_loss: 31.8037, val_loss: 22.6258, time: 0.12s\n",
      "Epoch 2515/1000000, train_loss: 31.7953, val_loss: 22.6382, time: 0.12s\n",
      "Epoch 2516/1000000, train_loss: 31.7820, val_loss: 22.7275, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2517/1000000, train_loss: 31.7636, val_loss: 22.5826, time: 0.12s\n",
      "Epoch 2518/1000000, train_loss: 31.7363, val_loss: 22.6396, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2519/1000000, train_loss: 31.7481, val_loss: 22.5397, time: 0.11s\n",
      "Epoch 2520/1000000, train_loss: 31.7271, val_loss: 22.5721, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2521/1000000, train_loss: 31.7208, val_loss: 22.4355, time: 0.11s\n",
      "Epoch 2522/1000000, train_loss: 31.7027, val_loss: 22.5024, time: 0.11s\n",
      "Epoch 2523/1000000, train_loss: 31.6858, val_loss: 22.5367, time: 0.11s\n",
      "Epoch 2524/1000000, train_loss: 31.6742, val_loss: 22.5099, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2525/1000000, train_loss: 31.6544, val_loss: 22.4134, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2526/1000000, train_loss: 31.6670, val_loss: 22.3736, time: 0.12s\n",
      "Epoch 2527/1000000, train_loss: 31.6391, val_loss: 22.4123, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2528/1000000, train_loss: 31.6338, val_loss: 22.2924, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2529/1000000, train_loss: 31.6224, val_loss: 22.2356, time: 0.12s\n",
      "Epoch 2530/1000000, train_loss: 31.5953, val_loss: 22.3267, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2531/1000000, train_loss: 31.5956, val_loss: 22.1021, time: 0.12s\n",
      "Epoch 2532/1000000, train_loss: 31.5698, val_loss: 22.1287, time: 0.11s\n",
      "Epoch 2533/1000000, train_loss: 31.5589, val_loss: 22.1243, time: 0.12s\n",
      "Epoch 2534/1000000, train_loss: 31.5458, val_loss: 22.2225, time: 0.19s\n",
      "Epoch 2535/1000000, train_loss: 31.5373, val_loss: 22.1630, time: 0.13s\n",
      "Epoch 2536/1000000, train_loss: 31.5306, val_loss: 22.1291, time: 0.11s\n",
      "Epoch 2537/1000000, train_loss: 31.5170, val_loss: 22.1545, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2538/1000000, train_loss: 31.5052, val_loss: 22.0026, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2539/1000000, train_loss: 31.4870, val_loss: 21.9377, time: 0.11s\n",
      "Epoch 2540/1000000, train_loss: 31.4748, val_loss: 21.9502, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2541/1000000, train_loss: 31.4547, val_loss: 21.8161, time: 0.12s\n",
      "Epoch 2542/1000000, train_loss: 31.4404, val_loss: 21.9915, time: 0.12s\n",
      "Epoch 2543/1000000, train_loss: 31.4257, val_loss: 21.9253, time: 0.12s\n",
      "Epoch 2544/1000000, train_loss: 31.4233, val_loss: 21.9127, time: 0.11s\n",
      "Epoch 2545/1000000, train_loss: 31.4222, val_loss: 21.8794, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2546/1000000, train_loss: 31.3922, val_loss: 21.7729, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2547/1000000, train_loss: 31.3740, val_loss: 21.7486, time: 0.11s\n",
      "Epoch 2548/1000000, train_loss: 31.3820, val_loss: 21.8309, time: 0.12s\n",
      "Epoch 2549/1000000, train_loss: 31.3671, val_loss: 21.7550, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2550/1000000, train_loss: 31.3491, val_loss: 21.6697, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2551/1000000, train_loss: 31.3387, val_loss: 21.6592, time: 0.12s\n",
      "Epoch 2552/1000000, train_loss: 31.3269, val_loss: 21.6622, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2553/1000000, train_loss: 31.3016, val_loss: 21.4860, time: 0.12s\n",
      "Epoch 2554/1000000, train_loss: 31.3000, val_loss: 21.5808, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2555/1000000, train_loss: 31.2927, val_loss: 21.4432, time: 0.12s\n",
      "Epoch 2556/1000000, train_loss: 31.2775, val_loss: 21.5414, time: 0.12s\n",
      "Epoch 2557/1000000, train_loss: 31.2648, val_loss: 21.4700, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2558/1000000, train_loss: 31.2599, val_loss: 21.3715, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2559/1000000, train_loss: 31.2507, val_loss: 21.3340, time: 0.11s\n",
      "Epoch 2560/1000000, train_loss: 31.2209, val_loss: 21.3724, time: 0.12s\n",
      "Epoch 2561/1000000, train_loss: 31.2194, val_loss: 21.3621, time: 0.12s\n",
      "Epoch 2562/1000000, train_loss: 31.2027, val_loss: 21.3606, time: 0.12s\n",
      "Epoch 2563/1000000, train_loss: 31.1737, val_loss: 21.4296, time: 0.11s\n",
      "Epoch 2564/1000000, train_loss: 31.1722, val_loss: 21.3759, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2565/1000000, train_loss: 31.1599, val_loss: 21.2986, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2566/1000000, train_loss: 31.1393, val_loss: 21.2261, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2567/1000000, train_loss: 31.1317, val_loss: 21.2017, time: 0.12s\n",
      "Epoch 2568/1000000, train_loss: 31.1151, val_loss: 21.3170, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2569/1000000, train_loss: 31.1154, val_loss: 21.1672, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2570/1000000, train_loss: 31.0874, val_loss: 21.1477, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2571/1000000, train_loss: 31.0948, val_loss: 21.1317, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2572/1000000, train_loss: 31.0747, val_loss: 21.0117, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2573/1000000, train_loss: 31.0590, val_loss: 20.9500, time: 0.12s\n",
      "Epoch 2574/1000000, train_loss: 31.0564, val_loss: 21.0336, time: 0.12s\n",
      "Epoch 2575/1000000, train_loss: 31.0380, val_loss: 20.9605, time: 0.11s\n",
      "Epoch 2576/1000000, train_loss: 31.0279, val_loss: 20.9840, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2577/1000000, train_loss: 31.0067, val_loss: 20.8292, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2578/1000000, train_loss: 30.9876, val_loss: 20.7757, time: 0.13s\n",
      "Epoch 2579/1000000, train_loss: 30.9913, val_loss: 20.9470, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2580/1000000, train_loss: 30.9569, val_loss: 20.7631, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2581/1000000, train_loss: 30.9598, val_loss: 20.7402, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2582/1000000, train_loss: 30.9575, val_loss: 20.7361, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2583/1000000, train_loss: 30.9366, val_loss: 20.6393, time: 0.13s\n",
      "Epoch 2584/1000000, train_loss: 30.9103, val_loss: 20.7486, time: 0.12s\n",
      "Epoch 2585/1000000, train_loss: 30.9151, val_loss: 20.7246, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2586/1000000, train_loss: 30.9010, val_loss: 20.6188, time: 0.12s\n",
      "Epoch 2587/1000000, train_loss: 30.9653, val_loss: 20.6378, time: 0.12s\n",
      "Epoch 2588/1000000, train_loss: 30.8606, val_loss: 20.7052, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2589/1000000, train_loss: 31.1367, val_loss: 20.6161, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2590/1000000, train_loss: 30.8394, val_loss: 20.5649, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2591/1000000, train_loss: 30.8438, val_loss: 20.5546, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2592/1000000, train_loss: 30.8094, val_loss: 20.3289, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2593/1000000, train_loss: 30.7952, val_loss: 20.2975, time: 0.11s\n",
      "Epoch 2594/1000000, train_loss: 30.7869, val_loss: 20.3861, time: 0.12s\n",
      "Epoch 2595/1000000, train_loss: 30.7743, val_loss: 20.3892, time: 0.12s\n",
      "Epoch 2596/1000000, train_loss: 30.7712, val_loss: 20.4052, time: 0.12s\n",
      "Epoch 2597/1000000, train_loss: 30.8730, val_loss: 20.3540, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2598/1000000, train_loss: 30.8460, val_loss: 20.2571, time: 0.12s\n",
      "Epoch 2599/1000000, train_loss: 31.0206, val_loss: 20.2577, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2600/1000000, train_loss: 30.7699, val_loss: 20.2121, time: 0.12s\n",
      "Epoch 2601/1000000, train_loss: 30.9412, val_loss: 20.2277, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2602/1000000, train_loss: 30.8144, val_loss: 20.1690, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2603/1000000, train_loss: 30.9003, val_loss: 20.1321, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2604/1000000, train_loss: 30.7997, val_loss: 20.0952, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2605/1000000, train_loss: 30.9203, val_loss: 20.0016, time: 0.12s\n",
      "Epoch 2606/1000000, train_loss: 30.6530, val_loss: 20.1218, time: 0.11s\n",
      "Epoch 2607/1000000, train_loss: 30.6779, val_loss: 20.0381, time: 0.22s\n",
      "Epoch 2608/1000000, train_loss: 31.0522, val_loss: 20.0284, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2609/1000000, train_loss: 30.7752, val_loss: 19.8861, time: 0.13s\n",
      "Epoch 2610/1000000, train_loss: 30.5782, val_loss: 19.9713, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2611/1000000, train_loss: 30.8214, val_loss: 19.8459, time: 0.12s\n",
      "Epoch 2612/1000000, train_loss: 30.5734, val_loss: 19.9724, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2613/1000000, train_loss: 30.6100, val_loss: 19.7510, time: 0.15s\n",
      "Epoch 2614/1000000, train_loss: 30.7464, val_loss: 19.9188, time: 0.12s\n",
      "Epoch 2615/1000000, train_loss: 30.5775, val_loss: 19.8014, time: 0.12s\n",
      "Epoch 2616/1000000, train_loss: 30.5233, val_loss: 19.8126, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2617/1000000, train_loss: 30.5024, val_loss: 19.7201, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2618/1000000, train_loss: 30.5024, val_loss: 19.6318, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2619/1000000, train_loss: 30.4778, val_loss: 19.6050, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2620/1000000, train_loss: 30.4695, val_loss: 19.5505, time: 0.11s\n",
      "Epoch 2621/1000000, train_loss: 30.4665, val_loss: 19.6635, time: 0.13s\n",
      "Epoch 2622/1000000, train_loss: 30.4595, val_loss: 19.6095, time: 0.12s\n",
      "Epoch 2623/1000000, train_loss: 30.4337, val_loss: 19.6955, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2624/1000000, train_loss: 30.4088, val_loss: 19.4896, time: 0.12s\n",
      "Epoch 2625/1000000, train_loss: 30.4043, val_loss: 19.4916, time: 0.11s\n",
      "Epoch 2626/1000000, train_loss: 30.8032, val_loss: 20.5178, time: 0.12s\n",
      "Epoch 2627/1000000, train_loss: 31.0700, val_loss: 20.1235, time: 0.12s\n",
      "Epoch 2628/1000000, train_loss: 31.0793, val_loss: 19.7565, time: 0.11s\n",
      "Epoch 2629/1000000, train_loss: 31.0343, val_loss: 19.9276, time: 0.12s\n",
      "Epoch 2630/1000000, train_loss: 31.0169, val_loss: 19.5344, time: 0.12s\n",
      "Epoch 2631/1000000, train_loss: 30.9797, val_loss: 19.7208, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2632/1000000, train_loss: 30.9175, val_loss: 19.3808, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2633/1000000, train_loss: 30.6571, val_loss: 19.3332, time: 0.12s\n",
      "Epoch 2634/1000000, train_loss: 30.5412, val_loss: 19.3673, time: 0.11s\n",
      "Epoch 2635/1000000, train_loss: 30.5187, val_loss: 19.4876, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2636/1000000, train_loss: 30.5202, val_loss: 19.2873, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2637/1000000, train_loss: 30.4909, val_loss: 19.1048, time: 0.12s\n",
      "Epoch 2638/1000000, train_loss: 30.4808, val_loss: 19.1720, time: 0.12s\n",
      "Epoch 2639/1000000, train_loss: 30.4596, val_loss: 19.2718, time: 0.12s\n",
      "Epoch 2640/1000000, train_loss: 30.4245, val_loss: 19.1766, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2641/1000000, train_loss: 30.4111, val_loss: 18.9991, time: 0.12s\n",
      "Epoch 2642/1000000, train_loss: 30.2738, val_loss: 19.0754, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2643/1000000, train_loss: 30.2223, val_loss: 18.9677, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2644/1000000, train_loss: 30.1964, val_loss: 18.9190, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2645/1000000, train_loss: 30.1899, val_loss: 18.8383, time: 0.12s\n",
      "Epoch 2646/1000000, train_loss: 30.1804, val_loss: 18.9890, time: 0.11s\n",
      "Epoch 2647/1000000, train_loss: 30.1525, val_loss: 18.9942, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2648/1000000, train_loss: 30.1395, val_loss: 18.7285, time: 0.12s\n",
      "Epoch 2649/1000000, train_loss: 30.1420, val_loss: 18.7942, time: 0.12s\n",
      "Epoch 2650/1000000, train_loss: 30.1084, val_loss: 18.8070, time: 0.12s\n",
      "Epoch 2651/1000000, train_loss: 30.0846, val_loss: 18.7636, time: 0.11s\n",
      "Epoch 2652/1000000, train_loss: 30.0872, val_loss: 18.7736, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2653/1000000, train_loss: 30.0638, val_loss: 18.6959, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2654/1000000, train_loss: 30.0606, val_loss: 18.6851, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2655/1000000, train_loss: 30.0477, val_loss: 18.6792, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2656/1000000, train_loss: 30.0306, val_loss: 18.5316, time: 0.19s\n",
      "Epoch 2657/1000000, train_loss: 30.0158, val_loss: 18.5851, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2658/1000000, train_loss: 30.0041, val_loss: 18.4777, time: 0.14s\n",
      "Epoch 2659/1000000, train_loss: 29.9929, val_loss: 18.6324, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2660/1000000, train_loss: 29.9873, val_loss: 18.4662, time: 0.12s\n",
      "Epoch 2661/1000000, train_loss: 29.9677, val_loss: 18.4840, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2662/1000000, train_loss: 29.9443, val_loss: 18.4149, time: 0.12s\n",
      "Epoch 2663/1000000, train_loss: 29.9427, val_loss: 18.4941, time: 0.12s\n",
      "Epoch 2664/1000000, train_loss: 29.9321, val_loss: 18.4910, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2665/1000000, train_loss: 29.9211, val_loss: 18.2788, time: 0.12s\n",
      "Epoch 2666/1000000, train_loss: 29.9077, val_loss: 18.4015, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2667/1000000, train_loss: 29.9013, val_loss: 18.2409, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2668/1000000, train_loss: 29.8963, val_loss: 18.2151, time: 0.13s\n",
      "Epoch 2669/1000000, train_loss: 29.8610, val_loss: 18.3677, time: 0.12s\n",
      "Epoch 2670/1000000, train_loss: 29.8654, val_loss: 18.3753, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2671/1000000, train_loss: 29.8424, val_loss: 18.0834, time: 0.11s\n",
      "Epoch 2672/1000000, train_loss: 29.8267, val_loss: 18.1550, time: 0.12s\n",
      "Epoch 2673/1000000, train_loss: 29.8312, val_loss: 18.1867, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2674/1000000, train_loss: 29.8543, val_loss: 18.0419, time: 0.12s\n",
      "Epoch 2675/1000000, train_loss: 29.7910, val_loss: 18.0757, time: 0.12s\n",
      "Epoch 2676/1000000, train_loss: 29.7930, val_loss: 18.0938, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2677/1000000, train_loss: 29.7592, val_loss: 18.0301, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2678/1000000, train_loss: 29.7476, val_loss: 17.9226, time: 0.12s\n",
      "Epoch 2679/1000000, train_loss: 29.7391, val_loss: 18.0488, time: 0.12s\n",
      "Epoch 2680/1000000, train_loss: 29.7241, val_loss: 17.9554, time: 0.12s\n",
      "Epoch 2681/1000000, train_loss: 29.7253, val_loss: 17.9488, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2682/1000000, train_loss: 29.7103, val_loss: 17.9050, time: 0.12s\n",
      "Epoch 2683/1000000, train_loss: 29.6990, val_loss: 17.9460, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2684/1000000, train_loss: 29.6839, val_loss: 17.7881, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2685/1000000, train_loss: 29.6522, val_loss: 17.7436, time: 0.12s\n",
      "Epoch 2686/1000000, train_loss: 29.6573, val_loss: 17.7825, time: 0.13s\n",
      "Epoch 2687/1000000, train_loss: 29.6399, val_loss: 17.7974, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2688/1000000, train_loss: 29.6273, val_loss: 17.7003, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2689/1000000, train_loss: 29.6077, val_loss: 17.6321, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2690/1000000, train_loss: 29.6085, val_loss: 17.5407, time: 0.12s\n",
      "Epoch 2691/1000000, train_loss: 29.5875, val_loss: 17.6062, time: 0.12s\n",
      "Epoch 2692/1000000, train_loss: 29.5765, val_loss: 17.5815, time: 0.11s\n",
      "Epoch 2693/1000000, train_loss: 29.5532, val_loss: 17.5682, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2694/1000000, train_loss: 29.5556, val_loss: 17.4675, time: 0.11s\n",
      "Epoch 2695/1000000, train_loss: 29.5418, val_loss: 17.5402, time: 0.11s\n",
      "Epoch 2696/1000000, train_loss: 29.5157, val_loss: 17.5603, time: 0.11s\n",
      "Epoch 2697/1000000, train_loss: 29.5076, val_loss: 17.5007, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2698/1000000, train_loss: 29.4965, val_loss: 17.3317, time: 0.11s\n",
      "Epoch 2699/1000000, train_loss: 29.4891, val_loss: 17.3678, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2700/1000000, train_loss: 29.4851, val_loss: 17.3283, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2701/1000000, train_loss: 29.4555, val_loss: 17.2643, time: 0.11s\n",
      "Epoch 2702/1000000, train_loss: 29.4609, val_loss: 17.3683, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2703/1000000, train_loss: 29.4572, val_loss: 17.2419, time: 0.11s\n",
      "Epoch 2704/1000000, train_loss: 29.4327, val_loss: 17.3754, time: 0.12s\n",
      "Epoch 2705/1000000, train_loss: 29.4044, val_loss: 17.2675, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2706/1000000, train_loss: 29.4011, val_loss: 17.2405, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2707/1000000, train_loss: 29.3806, val_loss: 17.0572, time: 0.11s\n",
      "Epoch 2708/1000000, train_loss: 29.3717, val_loss: 17.0973, time: 0.11s\n",
      "Epoch 2709/1000000, train_loss: 29.3540, val_loss: 17.1474, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2710/1000000, train_loss: 29.3318, val_loss: 17.0406, time: 0.11s\n",
      "Epoch 2711/1000000, train_loss: 29.3337, val_loss: 17.0507, time: 0.12s\n",
      "Epoch 2712/1000000, train_loss: 29.3346, val_loss: 17.0529, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2713/1000000, train_loss: 29.3077, val_loss: 17.0200, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2714/1000000, train_loss: 29.3042, val_loss: 16.9775, time: 0.12s\n",
      "Epoch 2715/1000000, train_loss: 29.2911, val_loss: 17.0018, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2716/1000000, train_loss: 29.2713, val_loss: 16.9465, time: 0.12s\n",
      "Epoch 2717/1000000, train_loss: 29.2581, val_loss: 16.9732, time: 0.12s\n",
      "Epoch 2718/1000000, train_loss: 29.2559, val_loss: 16.9712, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2719/1000000, train_loss: 29.2342, val_loss: 16.7648, time: 0.12s\n",
      "Epoch 2720/1000000, train_loss: 29.2105, val_loss: 16.8100, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2721/1000000, train_loss: 29.2013, val_loss: 16.7590, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2722/1000000, train_loss: 29.2045, val_loss: 16.7077, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2723/1000000, train_loss: 29.1875, val_loss: 16.6854, time: 0.11s\n",
      "Epoch 2724/1000000, train_loss: 29.1743, val_loss: 16.6971, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2725/1000000, train_loss: 29.1620, val_loss: 16.6394, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2726/1000000, train_loss: 29.1550, val_loss: 16.6131, time: 0.12s\n",
      "Epoch 2727/1000000, train_loss: 29.1344, val_loss: 16.6269, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2728/1000000, train_loss: 29.1025, val_loss: 16.6040, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2729/1000000, train_loss: 29.1173, val_loss: 16.4617, time: 0.12s\n",
      "Epoch 2730/1000000, train_loss: 29.0970, val_loss: 16.6392, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2731/1000000, train_loss: 29.0769, val_loss: 16.4470, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2732/1000000, train_loss: 29.1054, val_loss: 16.4264, time: 0.12s\n",
      "Epoch 2733/1000000, train_loss: 29.0631, val_loss: 16.4675, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2734/1000000, train_loss: 29.0341, val_loss: 16.1889, time: 0.11s\n",
      "Epoch 2735/1000000, train_loss: 29.0325, val_loss: 16.2524, time: 0.11s\n",
      "Epoch 2736/1000000, train_loss: 29.0919, val_loss: 16.4513, time: 0.11s\n",
      "Epoch 2737/1000000, train_loss: 29.0067, val_loss: 16.2737, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2738/1000000, train_loss: 28.9929, val_loss: 16.1784, time: 0.12s\n",
      "Epoch 2739/1000000, train_loss: 28.9815, val_loss: 16.1834, time: 0.12s\n",
      "Epoch 2740/1000000, train_loss: 28.9545, val_loss: 16.2218, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2741/1000000, train_loss: 28.9465, val_loss: 16.0938, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2742/1000000, train_loss: 28.9427, val_loss: 15.9612, time: 0.11s\n",
      "Epoch 2743/1000000, train_loss: 28.9321, val_loss: 16.1522, time: 0.11s\n",
      "Epoch 2744/1000000, train_loss: 28.9323, val_loss: 16.0420, time: 0.12s\n",
      "Epoch 2745/1000000, train_loss: 28.9060, val_loss: 16.0503, time: 0.12s\n",
      "Epoch 2746/1000000, train_loss: 28.8944, val_loss: 16.1369, time: 0.12s\n",
      "Epoch 2747/1000000, train_loss: 28.8770, val_loss: 15.9953, time: 0.12s\n",
      "Epoch 2748/1000000, train_loss: 28.8747, val_loss: 15.9721, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2749/1000000, train_loss: 28.8567, val_loss: 15.8857, time: 0.12s\n",
      "Epoch 2750/1000000, train_loss: 28.8412, val_loss: 15.9857, time: 0.12s\n",
      "Epoch 2751/1000000, train_loss: 28.8261, val_loss: 15.9642, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2752/1000000, train_loss: 28.8128, val_loss: 15.8372, time: 0.12s\n",
      "Epoch 2753/1000000, train_loss: 28.8045, val_loss: 15.8747, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2754/1000000, train_loss: 28.7972, val_loss: 15.8178, time: 0.12s\n",
      "Epoch 2755/1000000, train_loss: 28.7927, val_loss: 15.8403, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2756/1000000, train_loss: 28.8290, val_loss: 15.7977, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2757/1000000, train_loss: 28.7720, val_loss: 15.6198, time: 0.12s\n",
      "Epoch 2758/1000000, train_loss: 28.7393, val_loss: 15.6961, time: 0.12s\n",
      "Epoch 2759/1000000, train_loss: 28.7349, val_loss: 15.7055, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2760/1000000, train_loss: 28.7328, val_loss: 15.5953, time: 0.12s\n",
      "Epoch 2761/1000000, train_loss: 28.7037, val_loss: 15.7810, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2762/1000000, train_loss: 28.6934, val_loss: 15.4644, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2763/1000000, train_loss: 28.6940, val_loss: 15.4198, time: 0.12s\n",
      "Epoch 2764/1000000, train_loss: 28.6635, val_loss: 15.5412, time: 0.12s\n",
      "Epoch 2765/1000000, train_loss: 28.6561, val_loss: 15.6727, time: 0.12s\n",
      "Epoch 2766/1000000, train_loss: 28.7578, val_loss: 15.4485, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2767/1000000, train_loss: 28.6135, val_loss: 15.4171, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2768/1000000, train_loss: 28.6686, val_loss: 15.3809, time: 0.13s\n",
      "Epoch 2769/1000000, train_loss: 28.6216, val_loss: 15.4317, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2770/1000000, train_loss: 28.6011, val_loss: 15.3609, time: 0.12s\n",
      "Epoch 2771/1000000, train_loss: 28.5709, val_loss: 15.4022, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2772/1000000, train_loss: 28.5704, val_loss: 15.1480, time: 0.12s\n",
      "Epoch 2773/1000000, train_loss: 28.5648, val_loss: 15.2466, time: 0.12s\n",
      "Epoch 2774/1000000, train_loss: 28.5448, val_loss: 15.1545, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2775/1000000, train_loss: 28.5337, val_loss: 15.0680, time: 0.12s\n",
      "Epoch 2776/1000000, train_loss: 28.5092, val_loss: 15.2286, time: 0.12s\n",
      "Epoch 2777/1000000, train_loss: 28.5203, val_loss: 15.1920, time: 0.12s\n",
      "Epoch 2778/1000000, train_loss: 28.5036, val_loss: 15.1906, time: 0.12s\n",
      "Epoch 2779/1000000, train_loss: 28.4792, val_loss: 15.1892, time: 0.12s\n",
      "Epoch 2780/1000000, train_loss: 28.4614, val_loss: 15.1316, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2781/1000000, train_loss: 28.4476, val_loss: 15.0218, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2782/1000000, train_loss: 28.4419, val_loss: 15.0133, time: 0.17s\n",
      "Epoch 2783/1000000, train_loss: 28.4267, val_loss: 15.0973, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2784/1000000, train_loss: 28.4259, val_loss: 14.9906, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2785/1000000, train_loss: 28.4064, val_loss: 14.9350, time: 0.11s\n",
      "Epoch 2786/1000000, train_loss: 28.4045, val_loss: 14.9833, time: 0.11s\n",
      "Epoch 2787/1000000, train_loss: 28.3758, val_loss: 14.9479, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2788/1000000, train_loss: 28.3832, val_loss: 14.7275, time: 0.12s\n",
      "Epoch 2789/1000000, train_loss: 28.3413, val_loss: 14.8296, time: 0.12s\n",
      "Epoch 2790/1000000, train_loss: 28.3564, val_loss: 14.8107, time: 0.12s\n",
      "Epoch 2791/1000000, train_loss: 28.3221, val_loss: 14.9323, time: 0.12s\n",
      "Epoch 2792/1000000, train_loss: 28.3263, val_loss: 14.8049, time: 0.12s\n",
      "Epoch 2793/1000000, train_loss: 28.3195, val_loss: 14.7320, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2794/1000000, train_loss: 28.2926, val_loss: 14.6575, time: 0.20s\n",
      "Epoch 2795/1000000, train_loss: 28.2751, val_loss: 14.7850, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2796/1000000, train_loss: 28.2611, val_loss: 14.5312, time: 0.11s\n",
      "Epoch 2797/1000000, train_loss: 28.3617, val_loss: 14.6838, time: 0.11s\n",
      "Epoch 2798/1000000, train_loss: 28.6093, val_loss: 14.6626, time: 0.11s\n",
      "Epoch 2799/1000000, train_loss: 28.3425, val_loss: 14.6459, time: 0.11s\n",
      "Epoch 2800/1000000, train_loss: 28.3684, val_loss: 14.5650, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2801/1000000, train_loss: 28.2042, val_loss: 14.5197, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2802/1000000, train_loss: 28.1819, val_loss: 14.3871, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2803/1000000, train_loss: 28.1871, val_loss: 14.3810, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2804/1000000, train_loss: 28.1531, val_loss: 14.2975, time: 0.11s\n",
      "Epoch 2805/1000000, train_loss: 28.1809, val_loss: 14.3481, time: 0.12s\n",
      "Epoch 2806/1000000, train_loss: 28.1444, val_loss: 14.4135, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2807/1000000, train_loss: 28.5556, val_loss: 14.2636, time: 0.11s\n",
      "Epoch 2808/1000000, train_loss: 28.1049, val_loss: 14.3133, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2809/1000000, train_loss: 28.2205, val_loss: 14.1841, time: 0.11s\n",
      "Epoch 2810/1000000, train_loss: 28.0942, val_loss: 14.2698, time: 0.11s\n",
      "Epoch 2811/1000000, train_loss: 28.4358, val_loss: 14.2043, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2812/1000000, train_loss: 28.1626, val_loss: 14.0588, time: 0.11s\n",
      "Epoch 2813/1000000, train_loss: 28.1021, val_loss: 14.1837, time: 0.11s\n",
      "Epoch 2814/1000000, train_loss: 28.5079, val_loss: 14.0819, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2815/1000000, train_loss: 28.4353, val_loss: 13.9501, time: 0.12s\n",
      "Epoch 2816/1000000, train_loss: 28.4828, val_loss: 13.9553, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2817/1000000, train_loss: 28.3626, val_loss: 13.8558, time: 0.12s\n",
      "Epoch 2818/1000000, train_loss: 28.4598, val_loss: 14.1288, time: 0.11s\n",
      "Epoch 2819/1000000, train_loss: 28.3718, val_loss: 13.9676, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2820/1000000, train_loss: 28.4314, val_loss: 13.7310, time: 0.11s\n",
      "Epoch 2821/1000000, train_loss: 28.2398, val_loss: 13.9707, time: 0.11s\n",
      "Epoch 2822/1000000, train_loss: 28.1502, val_loss: 13.8478, time: 0.11s\n",
      "Epoch 2823/1000000, train_loss: 27.9461, val_loss: 13.7526, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2824/1000000, train_loss: 27.9295, val_loss: 13.6363, time: 0.11s\n",
      "Epoch 2825/1000000, train_loss: 27.9233, val_loss: 13.6943, time: 0.11s\n",
      "Epoch 2826/1000000, train_loss: 27.8991, val_loss: 13.7951, time: 0.11s\n",
      "Epoch 2827/1000000, train_loss: 27.8713, val_loss: 13.6949, time: 0.11s\n",
      "Epoch 2828/1000000, train_loss: 27.8720, val_loss: 13.6706, time: 0.11s\n",
      "Epoch 2829/1000000, train_loss: 27.8492, val_loss: 13.7773, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2830/1000000, train_loss: 27.8353, val_loss: 13.6128, time: 0.11s\n",
      "Epoch 2831/1000000, train_loss: 27.8371, val_loss: 13.6606, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2832/1000000, train_loss: 27.8155, val_loss: 13.5025, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2833/1000000, train_loss: 27.7900, val_loss: 13.4385, time: 0.12s\n",
      "Epoch 2834/1000000, train_loss: 27.7833, val_loss: 13.5884, time: 0.11s\n",
      "Epoch 2835/1000000, train_loss: 27.7678, val_loss: 13.5742, time: 0.11s\n",
      "Epoch 2836/1000000, train_loss: 27.7727, val_loss: 13.5151, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2837/1000000, train_loss: 27.7486, val_loss: 13.4226, time: 0.11s\n",
      "Epoch 2838/1000000, train_loss: 27.7371, val_loss: 13.4803, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2839/1000000, train_loss: 27.7845, val_loss: 13.2947, time: 0.12s\n",
      "Epoch 2840/1000000, train_loss: 27.7186, val_loss: 13.4550, time: 0.11s\n",
      "Epoch 2841/1000000, train_loss: 27.7966, val_loss: 13.3060, time: 0.12s\n",
      "Epoch 2842/1000000, train_loss: 27.6838, val_loss: 13.4575, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2843/1000000, train_loss: 27.6826, val_loss: 13.1856, time: 0.12s\n",
      "Epoch 2844/1000000, train_loss: 27.6607, val_loss: 13.2691, time: 0.11s\n",
      "Epoch 2845/1000000, train_loss: 27.6586, val_loss: 13.2473, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2846/1000000, train_loss: 27.6290, val_loss: 13.0928, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2847/1000000, train_loss: 27.6453, val_loss: 13.0850, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2848/1000000, train_loss: 27.6139, val_loss: 13.0755, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2849/1000000, train_loss: 27.6084, val_loss: 12.9853, time: 0.11s\n",
      "Epoch 2850/1000000, train_loss: 27.6012, val_loss: 13.0178, time: 0.11s\n",
      "Epoch 2851/1000000, train_loss: 27.5798, val_loss: 13.0835, time: 0.12s\n",
      "Epoch 2852/1000000, train_loss: 27.5893, val_loss: 13.0710, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2853/1000000, train_loss: 27.5742, val_loss: 12.9726, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2854/1000000, train_loss: 27.5409, val_loss: 12.9093, time: 0.13s\n",
      "Epoch 2855/1000000, train_loss: 27.5302, val_loss: 12.9829, time: 0.12s\n",
      "Epoch 2856/1000000, train_loss: 27.5251, val_loss: 13.0709, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2857/1000000, train_loss: 27.5150, val_loss: 12.8739, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2858/1000000, train_loss: 27.4936, val_loss: 12.6992, time: 0.13s\n",
      "Epoch 2859/1000000, train_loss: 27.4729, val_loss: 12.8676, time: 0.13s\n",
      "Epoch 2860/1000000, train_loss: 27.4780, val_loss: 12.8254, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2861/1000000, train_loss: 27.4460, val_loss: 12.6485, time: 0.12s\n",
      "Epoch 2862/1000000, train_loss: 27.4321, val_loss: 12.6996, time: 0.12s\n",
      "Epoch 2863/1000000, train_loss: 27.4251, val_loss: 12.6558, time: 0.12s\n",
      "Epoch 2864/1000000, train_loss: 27.3992, val_loss: 12.6654, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2865/1000000, train_loss: 27.3885, val_loss: 12.6284, time: 0.12s\n",
      "Epoch 2866/1000000, train_loss: 27.3823, val_loss: 12.6419, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2867/1000000, train_loss: 27.4159, val_loss: 12.5165, time: 0.12s\n",
      "Epoch 2868/1000000, train_loss: 27.3632, val_loss: 12.5205, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2869/1000000, train_loss: 27.3460, val_loss: 12.4834, time: 0.12s\n",
      "Epoch 2870/1000000, train_loss: 27.3487, val_loss: 12.6534, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2871/1000000, train_loss: 27.3579, val_loss: 12.4523, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2872/1000000, train_loss: 27.7034, val_loss: 12.3581, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2873/1000000, train_loss: 27.4025, val_loss: 12.3569, time: 0.18s\n",
      "Epoch 2874/1000000, train_loss: 27.3123, val_loss: 12.3784, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2875/1000000, train_loss: 27.2717, val_loss: 12.2725, time: 0.11s\n",
      "Epoch 2876/1000000, train_loss: 27.2712, val_loss: 12.3808, time: 0.13s\n",
      "Epoch 2877/1000000, train_loss: 27.2368, val_loss: 12.3767, time: 0.11s\n",
      "Epoch 2878/1000000, train_loss: 27.2362, val_loss: 12.3149, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2879/1000000, train_loss: 27.2266, val_loss: 12.2689, time: 0.12s\n",
      "Epoch 2880/1000000, train_loss: 27.2260, val_loss: 12.2736, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2881/1000000, train_loss: 27.2160, val_loss: 12.1907, time: 0.11s\n",
      "Epoch 2882/1000000, train_loss: 27.1902, val_loss: 12.2875, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2883/1000000, train_loss: 27.1858, val_loss: 12.1469, time: 0.11s\n",
      "Epoch 2884/1000000, train_loss: 27.1604, val_loss: 12.1558, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2885/1000000, train_loss: 27.1525, val_loss: 12.0069, time: 0.11s\n",
      "Epoch 2886/1000000, train_loss: 27.1319, val_loss: 12.0324, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2887/1000000, train_loss: 27.1080, val_loss: 11.8725, time: 0.11s\n",
      "Epoch 2888/1000000, train_loss: 27.0986, val_loss: 11.9565, time: 0.11s\n",
      "Epoch 2889/1000000, train_loss: 27.1063, val_loss: 11.9977, time: 0.11s\n",
      "Epoch 2890/1000000, train_loss: 27.0762, val_loss: 11.9614, time: 0.11s\n",
      "Epoch 2891/1000000, train_loss: 27.0863, val_loss: 11.9753, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2892/1000000, train_loss: 27.0512, val_loss: 11.8630, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2893/1000000, train_loss: 27.0499, val_loss: 11.6359, time: 0.12s\n",
      "Epoch 2894/1000000, train_loss: 27.0351, val_loss: 11.7267, time: 0.11s\n",
      "Epoch 2895/1000000, train_loss: 27.0343, val_loss: 11.8503, time: 0.11s\n",
      "Epoch 2896/1000000, train_loss: 27.0134, val_loss: 11.7281, time: 0.11s\n",
      "Epoch 2897/1000000, train_loss: 26.9862, val_loss: 11.6922, time: 0.11s\n",
      "Epoch 2898/1000000, train_loss: 27.1043, val_loss: 11.8507, time: 0.11s\n",
      "Epoch 2899/1000000, train_loss: 27.3278, val_loss: 11.6882, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2900/1000000, train_loss: 26.9550, val_loss: 11.4952, time: 0.12s\n",
      "Epoch 2901/1000000, train_loss: 27.1046, val_loss: 11.5484, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2902/1000000, train_loss: 26.9682, val_loss: 11.4841, time: 0.12s\n",
      "Epoch 2903/1000000, train_loss: 26.9370, val_loss: 11.6238, time: 0.11s\n",
      "Epoch 2904/1000000, train_loss: 26.9000, val_loss: 11.5523, time: 0.11s\n",
      "Epoch 2905/1000000, train_loss: 26.8953, val_loss: 11.5214, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2906/1000000, train_loss: 26.8921, val_loss: 11.4074, time: 0.11s\n",
      "Epoch 2907/1000000, train_loss: 26.8733, val_loss: 11.4267, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2908/1000000, train_loss: 26.8620, val_loss: 11.3362, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2909/1000000, train_loss: 26.8536, val_loss: 11.2816, time: 0.11s\n",
      "Epoch 2910/1000000, train_loss: 26.8320, val_loss: 11.3996, time: 0.11s\n",
      "Epoch 2911/1000000, train_loss: 26.8298, val_loss: 11.4599, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2912/1000000, train_loss: 26.8192, val_loss: 11.1830, time: 0.12s\n",
      "Epoch 2913/1000000, train_loss: 26.8051, val_loss: 11.2556, time: 0.11s\n",
      "Epoch 2914/1000000, train_loss: 26.7608, val_loss: 11.2403, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2915/1000000, train_loss: 26.7746, val_loss: 11.1682, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2916/1000000, train_loss: 26.7498, val_loss: 11.1230, time: 0.12s\n",
      "Epoch 2917/1000000, train_loss: 26.7347, val_loss: 11.2110, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2918/1000000, train_loss: 26.7314, val_loss: 10.9253, time: 0.14s\n",
      "Epoch 2919/1000000, train_loss: 26.7210, val_loss: 11.1859, time: 0.13s\n",
      "Epoch 2920/1000000, train_loss: 26.7012, val_loss: 11.0096, time: 0.12s\n",
      "Epoch 2921/1000000, train_loss: 26.6925, val_loss: 11.0826, time: 0.12s\n",
      "Epoch 2922/1000000, train_loss: 26.6872, val_loss: 10.9776, time: 0.12s\n",
      "Epoch 2923/1000000, train_loss: 26.6660, val_loss: 11.0125, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2924/1000000, train_loss: 26.6587, val_loss: 10.6969, time: 0.12s\n",
      "Epoch 2925/1000000, train_loss: 26.6301, val_loss: 10.9241, time: 0.12s\n",
      "Epoch 2926/1000000, train_loss: 26.6316, val_loss: 10.8325, time: 0.12s\n",
      "Epoch 2927/1000000, train_loss: 26.6060, val_loss: 10.8314, time: 0.12s\n",
      "Epoch 2928/1000000, train_loss: 26.5971, val_loss: 10.7603, time: 0.12s\n",
      "Epoch 2929/1000000, train_loss: 26.7195, val_loss: 10.9066, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2930/1000000, train_loss: 26.6089, val_loss: 10.6812, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2931/1000000, train_loss: 26.5868, val_loss: 10.6705, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2932/1000000, train_loss: 26.5401, val_loss: 10.6417, time: 0.11s\n",
      "Epoch 2933/1000000, train_loss: 26.5459, val_loss: 10.7585, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2934/1000000, train_loss: 26.5387, val_loss: 10.5428, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2935/1000000, train_loss: 26.5250, val_loss: 10.5085, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2936/1000000, train_loss: 26.5008, val_loss: 10.4519, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2937/1000000, train_loss: 26.5130, val_loss: 10.3543, time: 0.12s\n",
      "Epoch 2938/1000000, train_loss: 26.4887, val_loss: 10.5584, time: 0.11s\n",
      "Epoch 2939/1000000, train_loss: 26.4642, val_loss: 10.5181, time: 0.11s\n",
      "Epoch 2940/1000000, train_loss: 26.4794, val_loss: 10.4757, time: 0.11s\n",
      "Epoch 2941/1000000, train_loss: 26.4536, val_loss: 10.4960, time: 0.14s\n",
      "Epoch 2942/1000000, train_loss: 26.4297, val_loss: 10.4220, time: 0.14s\n",
      "Epoch 2943/1000000, train_loss: 26.4175, val_loss: 10.3706, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2944/1000000, train_loss: 26.3973, val_loss: 10.1333, time: 0.17s\n",
      "Epoch 2945/1000000, train_loss: 26.4108, val_loss: 10.4358, time: 0.20s\n",
      "Epoch 2946/1000000, train_loss: 26.3770, val_loss: 10.2637, time: 0.13s\n",
      "Epoch 2947/1000000, train_loss: 26.3918, val_loss: 10.2596, time: 0.12s\n",
      "Epoch 2948/1000000, train_loss: 26.3582, val_loss: 10.3157, time: 0.12s\n",
      "Epoch 2949/1000000, train_loss: 26.3439, val_loss: 10.3106, time: 0.12s\n",
      "Epoch 2950/1000000, train_loss: 26.3190, val_loss: 10.2190, time: 0.12s\n",
      "Epoch 2951/1000000, train_loss: 26.3238, val_loss: 10.2473, time: 0.12s\n",
      "Epoch 2952/1000000, train_loss: 26.3161, val_loss: 10.1713, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2953/1000000, train_loss: 26.2996, val_loss: 10.1151, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2954/1000000, train_loss: 26.2788, val_loss: 9.9872, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2955/1000000, train_loss: 26.2706, val_loss: 9.8113, time: 0.12s\n",
      "Epoch 2956/1000000, train_loss: 26.2465, val_loss: 9.8995, time: 0.12s\n",
      "Epoch 2957/1000000, train_loss: 26.2459, val_loss: 10.1295, time: 0.11s\n",
      "Epoch 2958/1000000, train_loss: 26.2263, val_loss: 9.9295, time: 0.11s\n",
      "Epoch 2959/1000000, train_loss: 26.2165, val_loss: 9.9207, time: 0.12s\n",
      "Epoch 2960/1000000, train_loss: 26.1980, val_loss: 9.8190, time: 0.12s\n",
      "Epoch 2961/1000000, train_loss: 26.2020, val_loss: 9.8342, time: 0.12s\n",
      "Epoch 2962/1000000, train_loss: 26.2810, val_loss: 9.9151, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2963/1000000, train_loss: 26.1520, val_loss: 9.7433, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2964/1000000, train_loss: 26.1676, val_loss: 9.6702, time: 0.12s\n",
      "Epoch 2965/1000000, train_loss: 26.1401, val_loss: 9.6780, time: 0.25s\n",
      "Epoch 2966/1000000, train_loss: 26.1441, val_loss: 9.7798, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2967/1000000, train_loss: 26.1269, val_loss: 9.5399, time: 0.14s\n",
      "Epoch 2968/1000000, train_loss: 26.1051, val_loss: 9.6829, time: 0.11s\n",
      "Epoch 2969/1000000, train_loss: 26.3319, val_loss: 9.6530, time: 0.11s\n",
      "Epoch 2970/1000000, train_loss: 26.0824, val_loss: 9.6464, time: 0.12s\n",
      "Epoch 2971/1000000, train_loss: 26.0792, val_loss: 9.5992, time: 0.13s\n",
      "Epoch 2972/1000000, train_loss: 26.0638, val_loss: 9.5587, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2973/1000000, train_loss: 26.0472, val_loss: 9.4213, time: 0.12s\n",
      "Epoch 2974/1000000, train_loss: 26.0386, val_loss: 9.4320, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2975/1000000, train_loss: 26.2513, val_loss: 9.3994, time: 0.12s\n",
      "Epoch 2976/1000000, train_loss: 26.0095, val_loss: 9.5177, time: 0.12s\n",
      "Epoch 2977/1000000, train_loss: 26.2253, val_loss: 9.6221, time: 0.11s\n",
      "Epoch 2978/1000000, train_loss: 26.3814, val_loss: 9.4593, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2979/1000000, train_loss: 26.0207, val_loss: 9.3327, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2980/1000000, train_loss: 26.1634, val_loss: 9.3160, time: 0.11s\n",
      "Epoch 2981/1000000, train_loss: 25.9423, val_loss: 9.4948, time: 0.12s\n",
      "Epoch 2982/1000000, train_loss: 26.1067, val_loss: 9.4057, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2983/1000000, train_loss: 26.3824, val_loss: 9.2614, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2984/1000000, train_loss: 26.3798, val_loss: 9.1844, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2985/1000000, train_loss: 26.3163, val_loss: 9.1828, time: 0.12s\n",
      "Epoch 2986/1000000, train_loss: 26.3653, val_loss: 9.2061, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2987/1000000, train_loss: 26.3625, val_loss: 9.0676, time: 0.11s\n",
      "Epoch 2988/1000000, train_loss: 26.3407, val_loss: 9.0924, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2989/1000000, train_loss: 26.3310, val_loss: 9.0116, time: 0.11s\n",
      "Epoch 2990/1000000, train_loss: 26.3153, val_loss: 9.0515, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2991/1000000, train_loss: 26.2890, val_loss: 8.9816, time: 0.12s\n",
      "Epoch 2992/1000000, train_loss: 26.3006, val_loss: 9.0157, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2993/1000000, train_loss: 26.2845, val_loss: 8.8358, time: 0.12s\n",
      "Epoch 2994/1000000, train_loss: 26.2583, val_loss: 8.9817, time: 0.11s\n",
      "Epoch 2995/1000000, train_loss: 26.2407, val_loss: 8.8714, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2996/1000000, train_loss: 26.2426, val_loss: 8.7014, time: 0.12s\n",
      "Epoch 2997/1000000, train_loss: 26.2215, val_loss: 8.7688, time: 0.12s\n",
      "Epoch 2998/1000000, train_loss: 26.2097, val_loss: 8.8401, time: 0.20s\n",
      "Epoch 2999/1000000, train_loss: 26.2029, val_loss: 8.7306, time: 0.12s\n",
      "Epoch 3000/1000000, train_loss: 26.1980, val_loss: 8.8685, time: 0.12s\n",
      "Epoch 3001/1000000, train_loss: 26.1807, val_loss: 8.7274, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3002/1000000, train_loss: 26.1652, val_loss: 8.6131, time: 0.11s\n",
      "Epoch 3003/1000000, train_loss: 26.1471, val_loss: 8.8224, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3004/1000000, train_loss: 26.1364, val_loss: 8.5798, time: 0.12s\n",
      "Epoch 3005/1000000, train_loss: 26.1194, val_loss: 8.6264, time: 0.11s\n",
      "Epoch 3006/1000000, train_loss: 26.1260, val_loss: 8.6643, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3007/1000000, train_loss: 26.1215, val_loss: 8.2976, time: 0.11s\n",
      "Epoch 3008/1000000, train_loss: 26.1340, val_loss: 8.5407, time: 0.11s\n",
      "Epoch 3009/1000000, train_loss: 26.0731, val_loss: 8.4405, time: 0.11s\n",
      "Epoch 3010/1000000, train_loss: 26.0829, val_loss: 8.4892, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3011/1000000, train_loss: 26.0287, val_loss: 8.2817, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3012/1000000, train_loss: 26.0360, val_loss: 8.2345, time: 0.11s\n",
      "Epoch 3013/1000000, train_loss: 26.0232, val_loss: 8.4811, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3014/1000000, train_loss: 26.0244, val_loss: 8.2088, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3015/1000000, train_loss: 26.0050, val_loss: 8.1791, time: 0.11s\n",
      "Epoch 3016/1000000, train_loss: 25.9818, val_loss: 8.3533, time: 0.12s\n",
      "Epoch 3017/1000000, train_loss: 25.9846, val_loss: 8.2042, time: 0.12s\n",
      "Epoch 3018/1000000, train_loss: 25.9773, val_loss: 8.2602, time: 0.12s\n",
      "Epoch 3019/1000000, train_loss: 25.9586, val_loss: 8.2355, time: 0.11s\n",
      "Epoch 3020/1000000, train_loss: 25.9614, val_loss: 8.2919, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3021/1000000, train_loss: 25.9329, val_loss: 8.0748, time: 0.11s\n",
      "Epoch 3022/1000000, train_loss: 25.9160, val_loss: 8.0795, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3023/1000000, train_loss: 25.8986, val_loss: 8.0353, time: 0.12s\n",
      "Epoch 3024/1000000, train_loss: 25.8770, val_loss: 8.1272, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3025/1000000, train_loss: 25.8602, val_loss: 7.8899, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3026/1000000, train_loss: 25.8488, val_loss: 7.8877, time: 0.12s\n",
      "Epoch 3027/1000000, train_loss: 25.8474, val_loss: 7.9550, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3028/1000000, train_loss: 25.8245, val_loss: 7.8706, time: 0.12s\n",
      "Epoch 3029/1000000, train_loss: 25.8082, val_loss: 7.9046, time: 0.12s\n",
      "Epoch 3030/1000000, train_loss: 25.8191, val_loss: 7.9156, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3031/1000000, train_loss: 25.7929, val_loss: 7.6729, time: 0.12s\n",
      "Epoch 3032/1000000, train_loss: 25.7709, val_loss: 7.9347, time: 0.13s\n",
      "Epoch 3033/1000000, train_loss: 25.7679, val_loss: 8.0331, time: 0.16s\n",
      "Epoch 3034/1000000, train_loss: 25.7582, val_loss: 7.8136, time: 0.13s\n",
      "Epoch 3035/1000000, train_loss: 25.7434, val_loss: 7.7633, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3036/1000000, train_loss: 25.7174, val_loss: 7.6060, time: 0.12s\n",
      "Epoch 3037/1000000, train_loss: 25.7029, val_loss: 7.7380, time: 0.12s\n",
      "Epoch 3038/1000000, train_loss: 25.6913, val_loss: 7.7768, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3039/1000000, train_loss: 25.6954, val_loss: 7.4639, time: 0.12s\n",
      "Epoch 3040/1000000, train_loss: 25.6683, val_loss: 7.6928, time: 0.12s\n",
      "Epoch 3041/1000000, train_loss: 25.6611, val_loss: 7.5389, time: 0.12s\n",
      "Epoch 3042/1000000, train_loss: 25.6520, val_loss: 7.6108, time: 0.12s\n",
      "Epoch 3043/1000000, train_loss: 25.6217, val_loss: 7.7001, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3044/1000000, train_loss: 25.6362, val_loss: 7.4111, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3045/1000000, train_loss: 25.6239, val_loss: 7.3647, time: 0.12s\n",
      "Epoch 3046/1000000, train_loss: 25.6005, val_loss: 7.3691, time: 0.12s\n",
      "Epoch 3047/1000000, train_loss: 25.6091, val_loss: 7.4701, time: 0.12s\n",
      "Epoch 3048/1000000, train_loss: 25.5721, val_loss: 7.4067, time: 0.22s\n",
      "Epoch 3049/1000000, train_loss: 25.5775, val_loss: 7.4147, time: 0.23s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3050/1000000, train_loss: 25.5519, val_loss: 7.2886, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3051/1000000, train_loss: 25.5512, val_loss: 7.2106, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3052/1000000, train_loss: 25.5226, val_loss: 7.1196, time: 0.12s\n",
      "Epoch 3053/1000000, train_loss: 25.5210, val_loss: 7.1978, time: 0.11s\n",
      "Epoch 3054/1000000, train_loss: 25.5070, val_loss: 7.1987, time: 0.13s\n",
      "Epoch 3055/1000000, train_loss: 25.5100, val_loss: 7.1725, time: 0.12s\n",
      "Epoch 3056/1000000, train_loss: 25.4718, val_loss: 7.1806, time: 0.11s\n",
      "Epoch 3057/1000000, train_loss: 25.4311, val_loss: 7.1230, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3058/1000000, train_loss: 25.4462, val_loss: 6.8867, time: 0.11s\n",
      "Epoch 3059/1000000, train_loss: 25.4388, val_loss: 7.0631, time: 0.11s\n",
      "Epoch 3060/1000000, train_loss: 25.4197, val_loss: 7.0858, time: 0.11s\n",
      "Epoch 3061/1000000, train_loss: 25.4156, val_loss: 6.9771, time: 0.12s\n",
      "Epoch 3062/1000000, train_loss: 25.3978, val_loss: 7.1021, time: 0.11s\n",
      "Epoch 3063/1000000, train_loss: 25.3947, val_loss: 7.0056, time: 0.12s\n",
      "Epoch 3064/1000000, train_loss: 25.3837, val_loss: 6.9165, time: 0.12s\n",
      "Epoch 3065/1000000, train_loss: 25.3692, val_loss: 6.9940, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3066/1000000, train_loss: 25.3500, val_loss: 6.7305, time: 0.12s\n",
      "Epoch 3067/1000000, train_loss: 25.3504, val_loss: 6.8297, time: 0.11s\n",
      "Epoch 3068/1000000, train_loss: 25.3147, val_loss: 7.0203, time: 0.12s\n",
      "Epoch 3069/1000000, train_loss: 25.3225, val_loss: 6.7707, time: 0.12s\n",
      "Epoch 3070/1000000, train_loss: 25.3108, val_loss: 6.8000, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3071/1000000, train_loss: 25.2763, val_loss: 6.6036, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3072/1000000, train_loss: 25.2716, val_loss: 6.5733, time: 0.12s\n",
      "Epoch 3073/1000000, train_loss: 25.2727, val_loss: 6.7045, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3074/1000000, train_loss: 25.2527, val_loss: 6.4575, time: 0.11s\n",
      "Epoch 3075/1000000, train_loss: 25.2500, val_loss: 6.6144, time: 0.11s\n",
      "Epoch 3076/1000000, train_loss: 25.2209, val_loss: 6.6714, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3077/1000000, train_loss: 25.2138, val_loss: 6.3886, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3078/1000000, train_loss: 25.1978, val_loss: 6.3188, time: 0.11s\n",
      "Epoch 3079/1000000, train_loss: 25.1840, val_loss: 6.5745, time: 0.11s\n",
      "Epoch 3080/1000000, train_loss: 25.1777, val_loss: 6.4613, time: 0.11s\n",
      "Epoch 3081/1000000, train_loss: 25.1535, val_loss: 6.4187, time: 0.11s\n",
      "Epoch 3082/1000000, train_loss: 25.1639, val_loss: 6.4133, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3083/1000000, train_loss: 25.1469, val_loss: 6.2183, time: 0.12s\n",
      "Epoch 3084/1000000, train_loss: 25.1344, val_loss: 6.3131, time: 0.11s\n",
      "Epoch 3085/1000000, train_loss: 25.1067, val_loss: 6.3868, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3086/1000000, train_loss: 25.1097, val_loss: 6.2172, time: 0.15s\n",
      "Epoch 3087/1000000, train_loss: 25.0769, val_loss: 6.2786, time: 0.13s\n",
      "Epoch 3088/1000000, train_loss: 25.0646, val_loss: 6.2595, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3089/1000000, train_loss: 25.0601, val_loss: 6.1725, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3090/1000000, train_loss: 25.0565, val_loss: 6.1352, time: 0.12s\n",
      "Epoch 3091/1000000, train_loss: 25.0454, val_loss: 6.3428, time: 0.12s\n",
      "Epoch 3092/1000000, train_loss: 25.0484, val_loss: 6.1579, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3093/1000000, train_loss: 25.0289, val_loss: 5.9915, time: 0.12s\n",
      "Epoch 3094/1000000, train_loss: 25.0162, val_loss: 6.1294, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3095/1000000, train_loss: 24.9974, val_loss: 5.9225, time: 0.12s\n",
      "Epoch 3096/1000000, train_loss: 24.9884, val_loss: 6.0640, time: 0.13s\n",
      "Epoch 3097/1000000, train_loss: 25.0014, val_loss: 6.0187, time: 0.11s\n",
      "Epoch 3098/1000000, train_loss: 24.9690, val_loss: 6.0481, time: 0.23s\n",
      "Epoch 3099/1000000, train_loss: 24.9530, val_loss: 5.9417, time: 0.11s\n",
      "Epoch 3100/1000000, train_loss: 24.9339, val_loss: 5.9328, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3101/1000000, train_loss: 24.9314, val_loss: 5.8912, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3102/1000000, train_loss: 24.9005, val_loss: 5.8369, time: 0.12s\n",
      "Epoch 3103/1000000, train_loss: 24.9211, val_loss: 5.9134, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3104/1000000, train_loss: 24.9101, val_loss: 5.7228, time: 0.12s\n",
      "Epoch 3105/1000000, train_loss: 24.8740, val_loss: 5.8643, time: 0.11s\n",
      "Epoch 3106/1000000, train_loss: 24.8729, val_loss: 5.8176, time: 0.11s\n",
      "Epoch 3107/1000000, train_loss: 24.8634, val_loss: 5.9772, time: 0.11s\n",
      "Epoch 3108/1000000, train_loss: 24.8504, val_loss: 5.7742, time: 0.11s\n",
      "Epoch 3109/1000000, train_loss: 24.8568, val_loss: 5.8843, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3110/1000000, train_loss: 24.8425, val_loss: 5.6643, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3111/1000000, train_loss: 24.8270, val_loss: 5.5784, time: 0.12s\n",
      "Epoch 3112/1000000, train_loss: 24.8195, val_loss: 5.6207, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3113/1000000, train_loss: 24.8226, val_loss: 5.4523, time: 0.13s\n",
      "Epoch 3114/1000000, train_loss: 24.8079, val_loss: 5.5759, time: 0.11s\n",
      "Epoch 3115/1000000, train_loss: 24.7953, val_loss: 5.5057, time: 0.11s\n",
      "Epoch 3116/1000000, train_loss: 24.7805, val_loss: 5.5482, time: 0.11s\n",
      "Epoch 3117/1000000, train_loss: 24.7708, val_loss: 5.4924, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3118/1000000, train_loss: 24.7663, val_loss: 5.3274, time: 0.14s\n",
      "Epoch 3119/1000000, train_loss: 24.7645, val_loss: 5.5194, time: 0.17s\n",
      "Epoch 3120/1000000, train_loss: 24.7472, val_loss: 5.3288, time: 0.14s\n",
      "Epoch 3121/1000000, train_loss: 24.7274, val_loss: 5.4010, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3122/1000000, train_loss: 24.7375, val_loss: 5.2259, time: 0.13s\n",
      "Epoch 3123/1000000, train_loss: 24.7306, val_loss: 5.3963, time: 0.12s\n",
      "Epoch 3124/1000000, train_loss: 24.7123, val_loss: 5.3490, time: 0.12s\n",
      "Epoch 3125/1000000, train_loss: 24.7151, val_loss: 5.3537, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3126/1000000, train_loss: 24.7031, val_loss: 5.1549, time: 0.12s\n",
      "Epoch 3127/1000000, train_loss: 24.7053, val_loss: 5.4522, time: 0.11s\n",
      "Epoch 3128/1000000, train_loss: 24.6888, val_loss: 5.2580, time: 0.12s\n",
      "Epoch 3129/1000000, train_loss: 24.6817, val_loss: 5.2744, time: 0.11s\n",
      "Epoch 3130/1000000, train_loss: 24.6772, val_loss: 5.2109, time: 0.11s\n",
      "Epoch 3131/1000000, train_loss: 24.6691, val_loss: 5.2103, time: 0.11s\n",
      "Epoch 3132/1000000, train_loss: 24.6526, val_loss: 5.2910, time: 0.12s\n",
      "Epoch 3133/1000000, train_loss: 24.6415, val_loss: 5.2011, time: 0.22s\n",
      "Epoch 3134/1000000, train_loss: 24.6395, val_loss: 5.3056, time: 0.13s\n",
      "Epoch 3135/1000000, train_loss: 24.6495, val_loss: 5.2064, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3136/1000000, train_loss: 24.6289, val_loss: 5.1469, time: 0.12s\n",
      "Epoch 3137/1000000, train_loss: 24.6406, val_loss: 5.2668, time: 0.12s\n",
      "Epoch 3138/1000000, train_loss: 24.6262, val_loss: 5.3448, time: 0.11s\n",
      "Epoch 3139/1000000, train_loss: 24.6254, val_loss: 5.2092, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3140/1000000, train_loss: 24.6137, val_loss: 5.1096, time: 0.12s\n",
      "Epoch 3141/1000000, train_loss: 24.6053, val_loss: 5.1839, time: 0.12s\n",
      "Epoch 3142/1000000, train_loss: 24.6217, val_loss: 5.2118, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3143/1000000, train_loss: 24.5802, val_loss: 5.0668, time: 0.11s\n",
      "Epoch 3144/1000000, train_loss: 24.5924, val_loss: 5.1068, time: 0.11s\n",
      "Epoch 3145/1000000, train_loss: 24.5877, val_loss: 5.3114, time: 0.12s\n",
      "Epoch 3146/1000000, train_loss: 24.6452, val_loss: 5.0984, time: 0.12s\n",
      "Epoch 3147/1000000, train_loss: 24.6388, val_loss: 5.1202, time: 0.12s\n",
      "Epoch 3148/1000000, train_loss: 24.5960, val_loss: 5.0886, time: 0.11s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3149/1000000, train_loss: 24.5625, val_loss: 5.0313, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3150/1000000, train_loss: 24.5595, val_loss: 4.9151, time: 0.12s\n",
      "Epoch 3151/1000000, train_loss: 24.5610, val_loss: 4.9728, time: 0.12s\n",
      "Epoch 3152/1000000, train_loss: 24.5606, val_loss: 5.2760, time: 0.12s\n",
      "Epoch 3153/1000000, train_loss: 24.5876, val_loss: 5.0228, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3154/1000000, train_loss: 24.5718, val_loss: 4.8767, time: 0.12s\n",
      "Epoch 3155/1000000, train_loss: 24.5462, val_loss: 5.1297, time: 0.12s\n",
      "Epoch 3156/1000000, train_loss: 24.5673, val_loss: 5.0717, time: 0.12s\n",
      "Epoch 3157/1000000, train_loss: 24.5430, val_loss: 4.9803, time: 0.13s\n",
      "Epoch 3158/1000000, train_loss: 24.5451, val_loss: 5.0938, time: 0.12s\n",
      "Epoch 3159/1000000, train_loss: 24.5472, val_loss: 5.1843, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3160/1000000, train_loss: 24.5453, val_loss: 4.8634, time: 0.12s\n",
      "Epoch 3161/1000000, train_loss: 24.5440, val_loss: 4.8810, time: 0.11s\n",
      "Epoch 3162/1000000, train_loss: 24.5348, val_loss: 4.9777, time: 0.12s\n",
      "Epoch 3163/1000000, train_loss: 24.5313, val_loss: 4.8919, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3164/1000000, train_loss: 24.5179, val_loss: 4.8050, time: 0.12s\n",
      "Epoch 3165/1000000, train_loss: 24.5214, val_loss: 5.0444, time: 0.12s\n",
      "Epoch 3166/1000000, train_loss: 24.5182, val_loss: 4.9071, time: 0.12s\n",
      "Epoch 3167/1000000, train_loss: 24.5275, val_loss: 5.0430, time: 0.12s\n",
      "Epoch 3168/1000000, train_loss: 24.5218, val_loss: 4.8444, time: 0.11s\n",
      "Epoch 3169/1000000, train_loss: 24.5135, val_loss: 5.1220, time: 0.12s\n",
      "Epoch 3170/1000000, train_loss: 24.5330, val_loss: 5.0464, time: 0.12s\n",
      "Epoch 3171/1000000, train_loss: 24.5078, val_loss: 5.1191, time: 0.11s\n",
      "Epoch 3172/1000000, train_loss: 24.5122, val_loss: 4.8576, time: 0.11s\n",
      "Epoch 3173/1000000, train_loss: 24.5264, val_loss: 5.0786, time: 0.11s\n",
      "Epoch 3174/1000000, train_loss: 24.5223, val_loss: 4.9288, time: 0.11s\n",
      "Epoch 3175/1000000, train_loss: 24.5115, val_loss: 5.0428, time: 0.11s\n",
      "Epoch 3176/1000000, train_loss: 24.4904, val_loss: 4.9497, time: 0.11s\n",
      "Epoch 3177/1000000, train_loss: 24.5047, val_loss: 5.0903, time: 0.11s\n",
      "Epoch 3178/1000000, train_loss: 24.5133, val_loss: 4.8640, time: 0.12s\n",
      "Epoch 3179/1000000, train_loss: 24.5139, val_loss: 4.9757, time: 0.11s\n",
      "Epoch 3180/1000000, train_loss: 24.5069, val_loss: 4.9046, time: 0.11s\n",
      "Epoch 3181/1000000, train_loss: 24.5225, val_loss: 4.8535, time: 0.12s\n",
      "Epoch 3182/1000000, train_loss: 24.5215, val_loss: 5.0461, time: 0.12s\n",
      "Epoch 3183/1000000, train_loss: 24.4994, val_loss: 4.8207, time: 0.13s\n",
      "Early stopping on epoch 3184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'RNN', 'Type': 'multi2multi', 'MAE': 26.633978162493026}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_multi2uni = RNN(input_size = multi2uni_loader.in_variable, hidden_size = hidden_size, output_size = multi2uni_loader.out_variable, ahead = label_size, num_layers=num_layers)\n",
    "RNN_multi2uni = ModelManager(model=RNN_multi2uni, train_loader=multi2uni_loader.train_loader, val_loader=multi2uni_loader.val_loader, lr=learning_rate, patience=patience)\n",
    "RNN_multi2uni.train(num_epochs=num_epochs, save_dir=os.path.join(weight_dir, sub_dir))\n",
    "results.append({\n",
    "    \"Name\": RNN_multi2uni.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": RNN_multi2uni.evaluate(loader=multi2uni_loader.test_loader),\n",
    "})\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1/1000000, train_loss: 28.0154, val_loss: 31.4907, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2/1000000, train_loss: 27.9980, val_loss: 31.4725, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3/1000000, train_loss: 27.9787, val_loss: 31.4405, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 4/1000000, train_loss: 27.9658, val_loss: 31.4092, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 5/1000000, train_loss: 27.9376, val_loss: 31.3888, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 6/1000000, train_loss: 27.9106, val_loss: 31.3490, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 7/1000000, train_loss: 27.8725, val_loss: 31.3124, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 8/1000000, train_loss: 27.8392, val_loss: 31.2718, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 9/1000000, train_loss: 27.8006, val_loss: 31.2350, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 10/1000000, train_loss: 27.7614, val_loss: 31.1949, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 11/1000000, train_loss: 27.7221, val_loss: 31.1506, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 12/1000000, train_loss: 27.6840, val_loss: 31.1071, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 13/1000000, train_loss: 27.6438, val_loss: 31.0651, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 14/1000000, train_loss: 27.6081, val_loss: 31.0277, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 15/1000000, train_loss: 27.5672, val_loss: 30.9927, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 16/1000000, train_loss: 27.5296, val_loss: 30.9413, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 17/1000000, train_loss: 27.4957, val_loss: 30.9077, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 18/1000000, train_loss: 27.4577, val_loss: 30.8661, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 19/1000000, train_loss: 27.4212, val_loss: 30.8332, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 20/1000000, train_loss: 27.3891, val_loss: 30.7924, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 21/1000000, train_loss: 27.3579, val_loss: 30.7660, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 22/1000000, train_loss: 27.3245, val_loss: 30.7192, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 23/1000000, train_loss: 27.2873, val_loss: 30.6889, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 24/1000000, train_loss: 27.2580, val_loss: 30.6517, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 25/1000000, train_loss: 27.2266, val_loss: 30.6099, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 26/1000000, train_loss: 27.1953, val_loss: 30.5862, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 27/1000000, train_loss: 27.1606, val_loss: 30.5598, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 28/1000000, train_loss: 27.1323, val_loss: 30.5214, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 29/1000000, train_loss: 27.1043, val_loss: 30.4896, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 30/1000000, train_loss: 27.0738, val_loss: 30.4566, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 31/1000000, train_loss: 27.0419, val_loss: 30.4233, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 32/1000000, train_loss: 27.0149, val_loss: 30.3850, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 33/1000000, train_loss: 26.9836, val_loss: 30.3640, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 34/1000000, train_loss: 26.9544, val_loss: 30.3318, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 35/1000000, train_loss: 26.9247, val_loss: 30.2955, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 36/1000000, train_loss: 26.8977, val_loss: 30.2657, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 37/1000000, train_loss: 26.8687, val_loss: 30.2443, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 38/1000000, train_loss: 26.8393, val_loss: 30.1966, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 39/1000000, train_loss: 26.8122, val_loss: 30.1753, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 40/1000000, train_loss: 26.7821, val_loss: 30.1391, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 41/1000000, train_loss: 26.7555, val_loss: 30.1068, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 42/1000000, train_loss: 26.7271, val_loss: 30.0911, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 43/1000000, train_loss: 26.6991, val_loss: 30.0602, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 44/1000000, train_loss: 26.6724, val_loss: 30.0144, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 45/1000000, train_loss: 26.6437, val_loss: 29.9945, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 46/1000000, train_loss: 26.6166, val_loss: 29.9599, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 47/1000000, train_loss: 26.5865, val_loss: 29.9232, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 48/1000000, train_loss: 26.5609, val_loss: 29.8991, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 49/1000000, train_loss: 26.5353, val_loss: 29.8724, time: 0.23s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 50/1000000, train_loss: 26.5064, val_loss: 29.8422, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 51/1000000, train_loss: 26.4778, val_loss: 29.8124, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 52/1000000, train_loss: 26.4495, val_loss: 29.7841, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 53/1000000, train_loss: 26.4233, val_loss: 29.7461, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 54/1000000, train_loss: 26.3957, val_loss: 29.7267, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 55/1000000, train_loss: 26.3690, val_loss: 29.6968, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 56/1000000, train_loss: 26.3407, val_loss: 29.6608, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 57/1000000, train_loss: 26.3086, val_loss: 29.6356, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 58/1000000, train_loss: 26.2891, val_loss: 29.5981, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 59/1000000, train_loss: 26.2608, val_loss: 29.5716, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 60/1000000, train_loss: 26.2325, val_loss: 29.5538, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 61/1000000, train_loss: 26.2055, val_loss: 29.5213, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 62/1000000, train_loss: 26.1812, val_loss: 29.4951, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 63/1000000, train_loss: 26.1539, val_loss: 29.4676, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 64/1000000, train_loss: 26.1283, val_loss: 29.4318, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 65/1000000, train_loss: 26.0972, val_loss: 29.3997, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 66/1000000, train_loss: 26.0726, val_loss: 29.3741, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 67/1000000, train_loss: 26.0493, val_loss: 29.3442, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 68/1000000, train_loss: 26.0159, val_loss: 29.3187, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 69/1000000, train_loss: 25.9913, val_loss: 29.2836, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 70/1000000, train_loss: 25.9682, val_loss: 29.2650, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 71/1000000, train_loss: 25.9390, val_loss: 29.2229, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 72/1000000, train_loss: 25.9100, val_loss: 29.1965, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 73/1000000, train_loss: 25.8889, val_loss: 29.1827, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 74/1000000, train_loss: 25.8618, val_loss: 29.1452, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 75/1000000, train_loss: 25.8322, val_loss: 29.1257, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 76/1000000, train_loss: 25.8080, val_loss: 29.0875, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 77/1000000, train_loss: 25.7777, val_loss: 29.0589, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 78/1000000, train_loss: 25.7509, val_loss: 29.0321, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 79/1000000, train_loss: 25.7270, val_loss: 28.9995, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 80/1000000, train_loss: 25.7030, val_loss: 28.9757, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 81/1000000, train_loss: 25.6747, val_loss: 28.9348, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 82/1000000, train_loss: 25.6449, val_loss: 28.9157, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 83/1000000, train_loss: 25.6218, val_loss: 28.8829, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 84/1000000, train_loss: 25.5945, val_loss: 28.8480, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 85/1000000, train_loss: 25.5646, val_loss: 28.8194, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 86/1000000, train_loss: 25.5403, val_loss: 28.8110, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 87/1000000, train_loss: 25.5126, val_loss: 28.7593, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 88/1000000, train_loss: 25.4880, val_loss: 28.7383, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 89/1000000, train_loss: 25.4628, val_loss: 28.7154, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 90/1000000, train_loss: 25.4349, val_loss: 28.6846, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 91/1000000, train_loss: 25.4066, val_loss: 28.6674, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 92/1000000, train_loss: 25.3844, val_loss: 28.6239, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 93/1000000, train_loss: 25.3561, val_loss: 28.5973, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 94/1000000, train_loss: 25.3308, val_loss: 28.5748, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 95/1000000, train_loss: 25.3032, val_loss: 28.5354, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 96/1000000, train_loss: 25.2763, val_loss: 28.5121, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 97/1000000, train_loss: 25.2515, val_loss: 28.4827, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 98/1000000, train_loss: 25.2234, val_loss: 28.4589, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 99/1000000, train_loss: 25.1983, val_loss: 28.4371, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 100/1000000, train_loss: 25.1731, val_loss: 28.4026, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 101/1000000, train_loss: 25.1486, val_loss: 28.3739, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 102/1000000, train_loss: 25.1246, val_loss: 28.3473, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 103/1000000, train_loss: 25.0951, val_loss: 28.3230, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 104/1000000, train_loss: 25.0673, val_loss: 28.2807, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 105/1000000, train_loss: 25.0411, val_loss: 28.2642, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 106/1000000, train_loss: 25.0168, val_loss: 28.2234, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 107/1000000, train_loss: 24.9865, val_loss: 28.1980, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 108/1000000, train_loss: 24.9642, val_loss: 28.1692, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 109/1000000, train_loss: 24.9390, val_loss: 28.1308, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 110/1000000, train_loss: 24.9120, val_loss: 28.1298, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 111/1000000, train_loss: 24.8846, val_loss: 28.0826, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 112/1000000, train_loss: 24.8617, val_loss: 28.0596, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 113/1000000, train_loss: 24.8338, val_loss: 28.0377, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 114/1000000, train_loss: 24.8068, val_loss: 28.0050, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 115/1000000, train_loss: 24.7809, val_loss: 27.9804, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 116/1000000, train_loss: 24.7554, val_loss: 27.9409, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 117/1000000, train_loss: 24.7308, val_loss: 27.9262, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 118/1000000, train_loss: 24.7034, val_loss: 27.8889, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 119/1000000, train_loss: 24.6798, val_loss: 27.8770, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 120/1000000, train_loss: 24.6505, val_loss: 27.8377, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 121/1000000, train_loss: 24.6305, val_loss: 27.8173, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 122/1000000, train_loss: 24.6016, val_loss: 27.8020, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 123/1000000, train_loss: 24.5766, val_loss: 27.7627, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 124/1000000, train_loss: 24.5540, val_loss: 27.7385, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 125/1000000, train_loss: 24.5233, val_loss: 27.7019, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 126/1000000, train_loss: 24.4983, val_loss: 27.6809, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 127/1000000, train_loss: 24.4756, val_loss: 27.6586, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 128/1000000, train_loss: 24.4484, val_loss: 27.6204, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 129/1000000, train_loss: 24.4240, val_loss: 27.5961, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 130/1000000, train_loss: 24.4024, val_loss: 27.5587, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 131/1000000, train_loss: 24.3748, val_loss: 27.5371, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 132/1000000, train_loss: 24.3476, val_loss: 27.5142, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 133/1000000, train_loss: 24.3239, val_loss: 27.4927, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 134/1000000, train_loss: 24.2965, val_loss: 27.4610, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 135/1000000, train_loss: 24.2710, val_loss: 27.4327, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 136/1000000, train_loss: 24.2453, val_loss: 27.4053, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 137/1000000, train_loss: 24.2201, val_loss: 27.3616, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 138/1000000, train_loss: 24.1955, val_loss: 27.3556, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 139/1000000, train_loss: 24.1693, val_loss: 27.3247, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 140/1000000, train_loss: 24.1440, val_loss: 27.3017, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 141/1000000, train_loss: 24.1187, val_loss: 27.2817, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 142/1000000, train_loss: 24.0931, val_loss: 27.2507, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 143/1000000, train_loss: 24.0715, val_loss: 27.2257, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 144/1000000, train_loss: 24.0420, val_loss: 27.2034, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 145/1000000, train_loss: 24.0176, val_loss: 27.1648, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 146/1000000, train_loss: 23.9953, val_loss: 27.1435, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 147/1000000, train_loss: 23.9674, val_loss: 27.1181, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 148/1000000, train_loss: 23.9462, val_loss: 27.0896, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 149/1000000, train_loss: 23.9168, val_loss: 27.0627, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 150/1000000, train_loss: 23.8929, val_loss: 27.0320, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 151/1000000, train_loss: 23.8676, val_loss: 27.0041, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 152/1000000, train_loss: 23.8452, val_loss: 26.9974, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 153/1000000, train_loss: 23.8168, val_loss: 26.9617, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 154/1000000, train_loss: 23.7969, val_loss: 26.9300, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 155/1000000, train_loss: 23.7694, val_loss: 26.9173, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 156/1000000, train_loss: 23.7462, val_loss: 26.8790, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 157/1000000, train_loss: 23.7206, val_loss: 26.8524, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 158/1000000, train_loss: 23.6938, val_loss: 26.8354, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 159/1000000, train_loss: 23.6666, val_loss: 26.8085, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 160/1000000, train_loss: 23.6455, val_loss: 26.7736, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 161/1000000, train_loss: 23.6205, val_loss: 26.7522, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 162/1000000, train_loss: 23.5976, val_loss: 26.7329, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 163/1000000, train_loss: 23.5727, val_loss: 26.7059, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 164/1000000, train_loss: 23.5458, val_loss: 26.6920, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 165/1000000, train_loss: 23.5197, val_loss: 26.6530, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 166/1000000, train_loss: 23.4967, val_loss: 26.6381, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 167/1000000, train_loss: 23.4699, val_loss: 26.5961, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 168/1000000, train_loss: 23.4480, val_loss: 26.5754, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 169/1000000, train_loss: 23.4226, val_loss: 26.5551, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 170/1000000, train_loss: 23.3994, val_loss: 26.5235, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 171/1000000, train_loss: 23.3739, val_loss: 26.5138, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 172/1000000, train_loss: 23.3484, val_loss: 26.4609, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 173/1000000, train_loss: 23.3247, val_loss: 26.4486, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 174/1000000, train_loss: 23.3006, val_loss: 26.4217, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 175/1000000, train_loss: 23.2732, val_loss: 26.4016, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 176/1000000, train_loss: 23.2515, val_loss: 26.3715, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 177/1000000, train_loss: 23.2259, val_loss: 26.3362, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 178/1000000, train_loss: 23.2015, val_loss: 26.3097, time: 0.12s\n",
      "Epoch 179/1000000, train_loss: 23.1780, val_loss: 26.3117, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 180/1000000, train_loss: 23.1542, val_loss: 26.2724, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 181/1000000, train_loss: 23.1307, val_loss: 26.2573, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 182/1000000, train_loss: 23.1044, val_loss: 26.2230, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 183/1000000, train_loss: 23.0801, val_loss: 26.1827, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 184/1000000, train_loss: 23.0557, val_loss: 26.1730, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 185/1000000, train_loss: 23.0317, val_loss: 26.1386, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 186/1000000, train_loss: 23.0089, val_loss: 26.1165, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 187/1000000, train_loss: 22.9800, val_loss: 26.1059, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 188/1000000, train_loss: 22.9585, val_loss: 26.0638, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 189/1000000, train_loss: 22.9342, val_loss: 26.0492, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 190/1000000, train_loss: 22.9069, val_loss: 26.0119, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 191/1000000, train_loss: 22.8840, val_loss: 25.9885, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 192/1000000, train_loss: 22.8595, val_loss: 25.9719, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 193/1000000, train_loss: 22.8351, val_loss: 25.9421, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 194/1000000, train_loss: 22.8121, val_loss: 25.9290, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 195/1000000, train_loss: 22.7878, val_loss: 25.9076, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 196/1000000, train_loss: 22.7642, val_loss: 25.8686, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 197/1000000, train_loss: 22.7385, val_loss: 25.8362, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 198/1000000, train_loss: 22.7168, val_loss: 25.8168, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 199/1000000, train_loss: 22.6915, val_loss: 25.7970, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 200/1000000, train_loss: 22.6687, val_loss: 25.7719, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 201/1000000, train_loss: 22.6438, val_loss: 25.7443, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 202/1000000, train_loss: 22.6178, val_loss: 25.7202, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 203/1000000, train_loss: 22.5955, val_loss: 25.7035, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 204/1000000, train_loss: 22.5709, val_loss: 25.6745, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 205/1000000, train_loss: 22.5462, val_loss: 25.6456, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 206/1000000, train_loss: 22.5223, val_loss: 25.6234, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 207/1000000, train_loss: 22.4995, val_loss: 25.6074, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 208/1000000, train_loss: 22.4744, val_loss: 25.5830, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 209/1000000, train_loss: 22.4526, val_loss: 25.5506, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 210/1000000, train_loss: 22.4288, val_loss: 25.5313, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 211/1000000, train_loss: 22.4032, val_loss: 25.4997, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 212/1000000, train_loss: 22.3795, val_loss: 25.4656, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 213/1000000, train_loss: 22.3544, val_loss: 25.4500, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 214/1000000, train_loss: 22.3323, val_loss: 25.4293, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 215/1000000, train_loss: 22.3059, val_loss: 25.3953, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 216/1000000, train_loss: 22.2823, val_loss: 25.3784, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 217/1000000, train_loss: 22.2611, val_loss: 25.3449, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 218/1000000, train_loss: 22.2353, val_loss: 25.3298, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 219/1000000, train_loss: 22.2103, val_loss: 25.3059, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 220/1000000, train_loss: 22.1858, val_loss: 25.2687, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 221/1000000, train_loss: 22.1609, val_loss: 25.2491, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 222/1000000, train_loss: 22.1417, val_loss: 25.2213, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 223/1000000, train_loss: 22.1135, val_loss: 25.2044, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 224/1000000, train_loss: 22.0888, val_loss: 25.1789, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 225/1000000, train_loss: 22.0690, val_loss: 25.1568, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 226/1000000, train_loss: 22.0446, val_loss: 25.1211, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 227/1000000, train_loss: 22.0212, val_loss: 25.1060, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 228/1000000, train_loss: 21.9986, val_loss: 25.0764, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 229/1000000, train_loss: 21.9714, val_loss: 25.0580, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 230/1000000, train_loss: 21.9496, val_loss: 25.0336, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 231/1000000, train_loss: 21.9268, val_loss: 25.0006, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 232/1000000, train_loss: 21.9003, val_loss: 24.9704, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 233/1000000, train_loss: 21.8805, val_loss: 24.9607, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 234/1000000, train_loss: 21.8541, val_loss: 24.9303, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 235/1000000, train_loss: 21.8327, val_loss: 24.9010, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 236/1000000, train_loss: 21.8059, val_loss: 24.8797, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 237/1000000, train_loss: 21.7835, val_loss: 24.8509, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 238/1000000, train_loss: 21.7636, val_loss: 24.8260, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 239/1000000, train_loss: 21.7389, val_loss: 24.8031, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 240/1000000, train_loss: 21.7106, val_loss: 24.7878, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 241/1000000, train_loss: 21.6889, val_loss: 24.7560, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 242/1000000, train_loss: 21.6640, val_loss: 24.7419, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 243/1000000, train_loss: 21.6436, val_loss: 24.7201, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 244/1000000, train_loss: 21.6187, val_loss: 24.6903, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 245/1000000, train_loss: 21.5957, val_loss: 24.6593, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 246/1000000, train_loss: 21.5737, val_loss: 24.6293, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 247/1000000, train_loss: 21.5496, val_loss: 24.6041, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 248/1000000, train_loss: 21.5284, val_loss: 24.5834, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 249/1000000, train_loss: 21.5020, val_loss: 24.5662, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 250/1000000, train_loss: 21.4827, val_loss: 24.5438, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 251/1000000, train_loss: 21.4561, val_loss: 24.5204, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 252/1000000, train_loss: 21.4349, val_loss: 24.4925, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 253/1000000, train_loss: 21.4103, val_loss: 24.4541, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 254/1000000, train_loss: 21.3861, val_loss: 24.4499, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 255/1000000, train_loss: 21.3627, val_loss: 24.4137, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 256/1000000, train_loss: 21.3379, val_loss: 24.3932, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 257/1000000, train_loss: 21.3159, val_loss: 24.3686, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 258/1000000, train_loss: 21.2953, val_loss: 24.3379, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 259/1000000, train_loss: 21.2716, val_loss: 24.3152, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 260/1000000, train_loss: 21.2500, val_loss: 24.2953, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 261/1000000, train_loss: 21.2266, val_loss: 24.2660, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 262/1000000, train_loss: 21.2020, val_loss: 24.2320, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 263/1000000, train_loss: 21.1824, val_loss: 24.2245, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 264/1000000, train_loss: 21.1584, val_loss: 24.1929, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 265/1000000, train_loss: 21.1336, val_loss: 24.1726, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 266/1000000, train_loss: 21.1113, val_loss: 24.1481, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 267/1000000, train_loss: 21.0874, val_loss: 24.1282, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 268/1000000, train_loss: 21.0671, val_loss: 24.0985, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 269/1000000, train_loss: 21.0440, val_loss: 24.0830, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 270/1000000, train_loss: 21.0205, val_loss: 24.0580, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 271/1000000, train_loss: 20.9985, val_loss: 24.0258, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 272/1000000, train_loss: 20.9762, val_loss: 24.0052, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 273/1000000, train_loss: 20.9506, val_loss: 23.9829, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 274/1000000, train_loss: 20.9271, val_loss: 23.9618, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 275/1000000, train_loss: 20.9084, val_loss: 23.9346, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 276/1000000, train_loss: 20.8838, val_loss: 23.9039, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 277/1000000, train_loss: 20.8627, val_loss: 23.8798, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 278/1000000, train_loss: 20.8408, val_loss: 23.8568, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 279/1000000, train_loss: 20.8177, val_loss: 23.8350, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 280/1000000, train_loss: 20.7967, val_loss: 23.8199, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 281/1000000, train_loss: 20.7729, val_loss: 23.8018, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 282/1000000, train_loss: 20.7491, val_loss: 23.7624, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 283/1000000, train_loss: 20.7297, val_loss: 23.7386, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 284/1000000, train_loss: 20.7049, val_loss: 23.7161, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 285/1000000, train_loss: 20.6806, val_loss: 23.7087, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 286/1000000, train_loss: 20.6624, val_loss: 23.6798, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 287/1000000, train_loss: 20.6412, val_loss: 23.6469, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 288/1000000, train_loss: 20.6164, val_loss: 23.6177, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 289/1000000, train_loss: 20.5964, val_loss: 23.5954, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 290/1000000, train_loss: 20.5747, val_loss: 23.5818, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 291/1000000, train_loss: 20.5487, val_loss: 23.5507, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 292/1000000, train_loss: 20.5273, val_loss: 23.5307, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 293/1000000, train_loss: 20.5084, val_loss: 23.5105, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 294/1000000, train_loss: 20.4860, val_loss: 23.4819, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 295/1000000, train_loss: 20.4605, val_loss: 23.4678, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 296/1000000, train_loss: 20.4420, val_loss: 23.4422, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 297/1000000, train_loss: 20.4220, val_loss: 23.4218, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 298/1000000, train_loss: 20.3971, val_loss: 23.3942, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 299/1000000, train_loss: 20.3761, val_loss: 23.3690, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 300/1000000, train_loss: 20.3541, val_loss: 23.3494, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 301/1000000, train_loss: 20.3309, val_loss: 23.3225, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 302/1000000, train_loss: 20.3107, val_loss: 23.3085, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 303/1000000, train_loss: 20.2895, val_loss: 23.2757, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 304/1000000, train_loss: 20.2631, val_loss: 23.2471, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 305/1000000, train_loss: 20.2439, val_loss: 23.2326, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 306/1000000, train_loss: 20.2218, val_loss: 23.2141, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 307/1000000, train_loss: 20.2004, val_loss: 23.1890, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 308/1000000, train_loss: 20.1805, val_loss: 23.1679, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 309/1000000, train_loss: 20.1598, val_loss: 23.1492, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 310/1000000, train_loss: 20.1358, val_loss: 23.1126, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 311/1000000, train_loss: 20.1126, val_loss: 23.0957, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 312/1000000, train_loss: 20.0957, val_loss: 23.0661, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 313/1000000, train_loss: 20.0742, val_loss: 23.0520, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 314/1000000, train_loss: 20.0525, val_loss: 23.0216, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 315/1000000, train_loss: 20.0294, val_loss: 23.0095, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 316/1000000, train_loss: 20.0055, val_loss: 22.9809, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 317/1000000, train_loss: 19.9844, val_loss: 22.9661, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 318/1000000, train_loss: 19.9626, val_loss: 22.9285, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 319/1000000, train_loss: 19.9399, val_loss: 22.9074, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 320/1000000, train_loss: 19.9210, val_loss: 22.8834, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 321/1000000, train_loss: 19.9011, val_loss: 22.8710, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 322/1000000, train_loss: 19.8780, val_loss: 22.8457, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 323/1000000, train_loss: 19.8587, val_loss: 22.8244, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 324/1000000, train_loss: 19.8364, val_loss: 22.8008, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 325/1000000, train_loss: 19.8145, val_loss: 22.7822, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 326/1000000, train_loss: 19.7924, val_loss: 22.7568, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 327/1000000, train_loss: 19.7728, val_loss: 22.7424, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 328/1000000, train_loss: 19.7488, val_loss: 22.6991, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 329/1000000, train_loss: 19.7301, val_loss: 22.6976, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 330/1000000, train_loss: 19.7095, val_loss: 22.6611, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 331/1000000, train_loss: 19.6888, val_loss: 22.6449, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 332/1000000, train_loss: 19.6669, val_loss: 22.6241, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 333/1000000, train_loss: 19.6464, val_loss: 22.6059, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 334/1000000, train_loss: 19.6219, val_loss: 22.5775, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 335/1000000, train_loss: 19.6008, val_loss: 22.5588, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 336/1000000, train_loss: 19.5825, val_loss: 22.5326, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 337/1000000, train_loss: 19.5574, val_loss: 22.5190, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 338/1000000, train_loss: 19.5400, val_loss: 22.4910, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 339/1000000, train_loss: 19.5177, val_loss: 22.4591, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 340/1000000, train_loss: 19.4949, val_loss: 22.4483, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 341/1000000, train_loss: 19.4755, val_loss: 22.4304, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 342/1000000, train_loss: 19.4499, val_loss: 22.4007, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 343/1000000, train_loss: 19.4317, val_loss: 22.3837, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 344/1000000, train_loss: 19.4110, val_loss: 22.3495, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 345/1000000, train_loss: 19.3896, val_loss: 22.3295, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 346/1000000, train_loss: 19.3690, val_loss: 22.3090, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 347/1000000, train_loss: 19.3493, val_loss: 22.2920, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 348/1000000, train_loss: 19.3276, val_loss: 22.2620, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 349/1000000, train_loss: 19.3064, val_loss: 22.2457, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 350/1000000, train_loss: 19.2854, val_loss: 22.2259, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 351/1000000, train_loss: 19.2614, val_loss: 22.2021, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 352/1000000, train_loss: 19.2425, val_loss: 22.1806, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 353/1000000, train_loss: 19.2207, val_loss: 22.1543, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 354/1000000, train_loss: 19.1992, val_loss: 22.1259, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 355/1000000, train_loss: 19.1790, val_loss: 22.1202, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 356/1000000, train_loss: 19.1578, val_loss: 22.0938, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 357/1000000, train_loss: 19.1391, val_loss: 22.0684, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 358/1000000, train_loss: 19.1156, val_loss: 22.0400, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 359/1000000, train_loss: 19.0960, val_loss: 22.0290, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 360/1000000, train_loss: 19.0767, val_loss: 22.0026, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 361/1000000, train_loss: 19.0550, val_loss: 21.9678, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 362/1000000, train_loss: 19.0333, val_loss: 21.9517, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 363/1000000, train_loss: 19.0143, val_loss: 21.9431, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 364/1000000, train_loss: 18.9918, val_loss: 21.9243, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 365/1000000, train_loss: 18.9712, val_loss: 21.8996, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 366/1000000, train_loss: 18.9488, val_loss: 21.8732, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 367/1000000, train_loss: 18.9273, val_loss: 21.8555, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 368/1000000, train_loss: 18.9074, val_loss: 21.8217, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 369/1000000, train_loss: 18.8871, val_loss: 21.8168, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 370/1000000, train_loss: 18.8663, val_loss: 21.7791, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 371/1000000, train_loss: 18.8462, val_loss: 21.7702, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 372/1000000, train_loss: 18.8208, val_loss: 21.7458, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 373/1000000, train_loss: 18.8031, val_loss: 21.7203, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 374/1000000, train_loss: 18.7822, val_loss: 21.7010, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 375/1000000, train_loss: 18.7608, val_loss: 21.6707, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 376/1000000, train_loss: 18.7407, val_loss: 21.6448, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 377/1000000, train_loss: 18.7216, val_loss: 21.6364, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 378/1000000, train_loss: 18.7004, val_loss: 21.6000, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 379/1000000, train_loss: 18.6770, val_loss: 21.5865, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 380/1000000, train_loss: 18.6623, val_loss: 21.5659, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 381/1000000, train_loss: 18.6393, val_loss: 21.5412, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 382/1000000, train_loss: 18.6201, val_loss: 21.5156, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 383/1000000, train_loss: 18.5990, val_loss: 21.5022, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 384/1000000, train_loss: 18.5769, val_loss: 21.4745, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 385/1000000, train_loss: 18.5565, val_loss: 21.4543, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 386/1000000, train_loss: 18.5360, val_loss: 21.4396, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 387/1000000, train_loss: 18.5160, val_loss: 21.4053, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 388/1000000, train_loss: 18.4951, val_loss: 21.3899, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 389/1000000, train_loss: 18.4746, val_loss: 21.3666, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 390/1000000, train_loss: 18.4535, val_loss: 21.3537, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 391/1000000, train_loss: 18.4322, val_loss: 21.3250, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 392/1000000, train_loss: 18.4142, val_loss: 21.3078, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 393/1000000, train_loss: 18.3910, val_loss: 21.2706, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 394/1000000, train_loss: 18.3734, val_loss: 21.2541, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 395/1000000, train_loss: 18.3501, val_loss: 21.2397, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 396/1000000, train_loss: 18.3326, val_loss: 21.2134, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 397/1000000, train_loss: 18.3110, val_loss: 21.1893, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 398/1000000, train_loss: 18.2897, val_loss: 21.1812, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 399/1000000, train_loss: 18.2666, val_loss: 21.1529, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 400/1000000, train_loss: 18.2463, val_loss: 21.1315, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 401/1000000, train_loss: 18.2287, val_loss: 21.1114, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 402/1000000, train_loss: 18.2098, val_loss: 21.0870, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 403/1000000, train_loss: 18.1898, val_loss: 21.0620, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 404/1000000, train_loss: 18.1664, val_loss: 21.0458, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 405/1000000, train_loss: 18.1427, val_loss: 21.0232, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 406/1000000, train_loss: 18.1305, val_loss: 20.9996, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 407/1000000, train_loss: 18.1070, val_loss: 20.9677, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 408/1000000, train_loss: 18.0853, val_loss: 20.9566, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 409/1000000, train_loss: 18.0667, val_loss: 20.9466, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 410/1000000, train_loss: 18.0501, val_loss: 20.9117, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 411/1000000, train_loss: 18.0256, val_loss: 20.8991, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 412/1000000, train_loss: 18.0049, val_loss: 20.8692, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 413/1000000, train_loss: 17.9878, val_loss: 20.8585, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 414/1000000, train_loss: 17.9645, val_loss: 20.8383, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 415/1000000, train_loss: 17.9449, val_loss: 20.8107, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 416/1000000, train_loss: 17.9255, val_loss: 20.7907, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 417/1000000, train_loss: 17.9048, val_loss: 20.7644, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 418/1000000, train_loss: 17.8849, val_loss: 20.7493, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 419/1000000, train_loss: 17.8645, val_loss: 20.7325, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 420/1000000, train_loss: 17.8446, val_loss: 20.7054, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 421/1000000, train_loss: 17.8252, val_loss: 20.6843, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 422/1000000, train_loss: 17.8060, val_loss: 20.6600, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 423/1000000, train_loss: 17.7833, val_loss: 20.6419, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 424/1000000, train_loss: 17.7636, val_loss: 20.6204, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 425/1000000, train_loss: 17.7463, val_loss: 20.6026, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 426/1000000, train_loss: 17.7244, val_loss: 20.5754, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 427/1000000, train_loss: 17.7021, val_loss: 20.5610, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 428/1000000, train_loss: 17.6853, val_loss: 20.5379, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 429/1000000, train_loss: 17.6621, val_loss: 20.5088, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 430/1000000, train_loss: 17.6435, val_loss: 20.4982, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 431/1000000, train_loss: 17.6261, val_loss: 20.4760, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 432/1000000, train_loss: 17.6061, val_loss: 20.4587, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 433/1000000, train_loss: 17.5853, val_loss: 20.4378, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 434/1000000, train_loss: 17.5620, val_loss: 20.4072, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 435/1000000, train_loss: 17.5443, val_loss: 20.3944, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 436/1000000, train_loss: 17.5249, val_loss: 20.3712, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 437/1000000, train_loss: 17.5056, val_loss: 20.3437, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 438/1000000, train_loss: 17.4864, val_loss: 20.3228, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 439/1000000, train_loss: 17.4655, val_loss: 20.3055, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 440/1000000, train_loss: 17.4446, val_loss: 20.2912, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 441/1000000, train_loss: 17.4238, val_loss: 20.2737, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 442/1000000, train_loss: 17.4065, val_loss: 20.2513, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 443/1000000, train_loss: 17.3847, val_loss: 20.2222, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 444/1000000, train_loss: 17.3664, val_loss: 20.2039, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 445/1000000, train_loss: 17.3464, val_loss: 20.1814, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 446/1000000, train_loss: 17.3295, val_loss: 20.1669, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 447/1000000, train_loss: 17.3074, val_loss: 20.1390, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 448/1000000, train_loss: 17.2872, val_loss: 20.1214, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 449/1000000, train_loss: 17.2668, val_loss: 20.0904, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 450/1000000, train_loss: 17.2473, val_loss: 20.0769, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 451/1000000, train_loss: 17.2274, val_loss: 20.0553, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 452/1000000, train_loss: 17.2078, val_loss: 20.0359, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 453/1000000, train_loss: 17.1873, val_loss: 20.0159, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 454/1000000, train_loss: 17.1713, val_loss: 19.9945, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 455/1000000, train_loss: 17.1505, val_loss: 19.9619, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 456/1000000, train_loss: 17.1311, val_loss: 19.9451, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 457/1000000, train_loss: 17.1102, val_loss: 19.9320, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 458/1000000, train_loss: 17.0915, val_loss: 19.9132, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 459/1000000, train_loss: 17.0728, val_loss: 19.8989, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 460/1000000, train_loss: 17.0507, val_loss: 19.8642, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 461/1000000, train_loss: 17.0309, val_loss: 19.8529, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 462/1000000, train_loss: 17.0138, val_loss: 19.8287, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 463/1000000, train_loss: 16.9951, val_loss: 19.8131, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 464/1000000, train_loss: 16.9749, val_loss: 19.7850, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 465/1000000, train_loss: 16.9568, val_loss: 19.7673, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 466/1000000, train_loss: 16.9368, val_loss: 19.7504, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 467/1000000, train_loss: 16.9145, val_loss: 19.7271, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 468/1000000, train_loss: 16.8944, val_loss: 19.7059, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 469/1000000, train_loss: 16.8763, val_loss: 19.6866, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 470/1000000, train_loss: 16.8580, val_loss: 19.6692, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 471/1000000, train_loss: 16.8423, val_loss: 19.6503, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 472/1000000, train_loss: 16.8226, val_loss: 19.6262, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 473/1000000, train_loss: 16.8015, val_loss: 19.6079, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 474/1000000, train_loss: 16.7806, val_loss: 19.5933, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 475/1000000, train_loss: 16.7615, val_loss: 19.5662, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 476/1000000, train_loss: 16.7434, val_loss: 19.5421, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 477/1000000, train_loss: 16.7247, val_loss: 19.5322, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 478/1000000, train_loss: 16.7027, val_loss: 19.5057, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 479/1000000, train_loss: 16.6833, val_loss: 19.4812, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 480/1000000, train_loss: 16.6672, val_loss: 19.4765, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 481/1000000, train_loss: 16.6478, val_loss: 19.4461, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 482/1000000, train_loss: 16.6307, val_loss: 19.4155, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 483/1000000, train_loss: 16.6098, val_loss: 19.3986, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 484/1000000, train_loss: 16.5870, val_loss: 19.3892, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 485/1000000, train_loss: 16.5707, val_loss: 19.3698, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 486/1000000, train_loss: 16.5481, val_loss: 19.3420, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 487/1000000, train_loss: 16.5332, val_loss: 19.3107, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 488/1000000, train_loss: 16.5143, val_loss: 19.3085, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 489/1000000, train_loss: 16.4939, val_loss: 19.2901, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 490/1000000, train_loss: 16.4740, val_loss: 19.2652, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 491/1000000, train_loss: 16.4548, val_loss: 19.2374, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 492/1000000, train_loss: 16.4380, val_loss: 19.2246, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 493/1000000, train_loss: 16.4172, val_loss: 19.2135, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 494/1000000, train_loss: 16.3974, val_loss: 19.1767, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 495/1000000, train_loss: 16.3783, val_loss: 19.1730, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 496/1000000, train_loss: 16.3597, val_loss: 19.1462, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 497/1000000, train_loss: 16.3409, val_loss: 19.1228, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 498/1000000, train_loss: 16.3207, val_loss: 19.1156, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 499/1000000, train_loss: 16.3053, val_loss: 19.0865, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 500/1000000, train_loss: 16.2842, val_loss: 19.0599, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 501/1000000, train_loss: 16.2615, val_loss: 19.0448, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 502/1000000, train_loss: 16.2430, val_loss: 19.0207, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 503/1000000, train_loss: 16.2288, val_loss: 19.0044, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 504/1000000, train_loss: 16.2079, val_loss: 18.9919, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 505/1000000, train_loss: 16.1913, val_loss: 18.9660, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 506/1000000, train_loss: 16.1716, val_loss: 18.9413, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 507/1000000, train_loss: 16.1503, val_loss: 18.9162, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 508/1000000, train_loss: 16.1297, val_loss: 18.9110, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 509/1000000, train_loss: 16.1145, val_loss: 18.8878, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 510/1000000, train_loss: 16.0944, val_loss: 18.8652, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 511/1000000, train_loss: 16.0749, val_loss: 18.8375, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 512/1000000, train_loss: 16.0601, val_loss: 18.8258, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 513/1000000, train_loss: 16.0414, val_loss: 18.7978, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 514/1000000, train_loss: 16.0205, val_loss: 18.7920, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 515/1000000, train_loss: 16.0023, val_loss: 18.7629, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 516/1000000, train_loss: 15.9825, val_loss: 18.7470, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 517/1000000, train_loss: 15.9629, val_loss: 18.7289, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 518/1000000, train_loss: 15.9461, val_loss: 18.7064, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 519/1000000, train_loss: 15.9288, val_loss: 18.6812, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 520/1000000, train_loss: 15.9083, val_loss: 18.6716, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 521/1000000, train_loss: 15.8935, val_loss: 18.6459, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 522/1000000, train_loss: 15.8691, val_loss: 18.6276, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 523/1000000, train_loss: 15.8525, val_loss: 18.6062, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 524/1000000, train_loss: 15.8343, val_loss: 18.5939, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 525/1000000, train_loss: 15.8160, val_loss: 18.5642, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 526/1000000, train_loss: 15.7965, val_loss: 18.5459, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 527/1000000, train_loss: 15.7802, val_loss: 18.5304, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 528/1000000, train_loss: 15.7616, val_loss: 18.5189, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 529/1000000, train_loss: 15.7430, val_loss: 18.4889, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 530/1000000, train_loss: 15.7242, val_loss: 18.4624, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 531/1000000, train_loss: 15.7024, val_loss: 18.4496, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 532/1000000, train_loss: 15.6869, val_loss: 18.4310, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 533/1000000, train_loss: 15.6684, val_loss: 18.4071, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 534/1000000, train_loss: 15.6480, val_loss: 18.3916, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 535/1000000, train_loss: 15.6310, val_loss: 18.3801, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 536/1000000, train_loss: 15.6141, val_loss: 18.3470, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 537/1000000, train_loss: 15.5958, val_loss: 18.3345, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 538/1000000, train_loss: 15.5754, val_loss: 18.3163, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 539/1000000, train_loss: 15.5573, val_loss: 18.2931, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 540/1000000, train_loss: 15.5402, val_loss: 18.2768, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 541/1000000, train_loss: 15.5196, val_loss: 18.2536, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 542/1000000, train_loss: 15.5047, val_loss: 18.2387, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 543/1000000, train_loss: 15.4835, val_loss: 18.2128, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 544/1000000, train_loss: 15.4667, val_loss: 18.1964, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 545/1000000, train_loss: 15.4469, val_loss: 18.1669, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 546/1000000, train_loss: 15.4338, val_loss: 18.1500, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 547/1000000, train_loss: 15.4113, val_loss: 18.1248, time: 0.12s\n",
      "Epoch 548/1000000, train_loss: 15.3940, val_loss: 18.1262, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 549/1000000, train_loss: 15.3738, val_loss: 18.1005, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 550/1000000, train_loss: 15.3618, val_loss: 18.0875, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 551/1000000, train_loss: 15.3386, val_loss: 18.0624, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 552/1000000, train_loss: 15.3183, val_loss: 18.0400, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 553/1000000, train_loss: 15.3038, val_loss: 18.0248, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 554/1000000, train_loss: 15.2846, val_loss: 18.0043, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 555/1000000, train_loss: 15.2661, val_loss: 17.9807, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 556/1000000, train_loss: 15.2480, val_loss: 17.9563, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 557/1000000, train_loss: 15.2348, val_loss: 17.9522, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 558/1000000, train_loss: 15.2147, val_loss: 17.9274, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 559/1000000, train_loss: 15.1983, val_loss: 17.9032, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 560/1000000, train_loss: 15.1771, val_loss: 17.8710, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 561/1000000, train_loss: 15.1588, val_loss: 17.8674, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 562/1000000, train_loss: 15.1379, val_loss: 17.8566, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 563/1000000, train_loss: 15.1205, val_loss: 17.8210, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 564/1000000, train_loss: 15.1008, val_loss: 17.8069, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 565/1000000, train_loss: 15.0878, val_loss: 17.7859, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 566/1000000, train_loss: 15.0691, val_loss: 17.7737, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 567/1000000, train_loss: 15.0500, val_loss: 17.7369, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 568/1000000, train_loss: 15.0334, val_loss: 17.7255, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 569/1000000, train_loss: 15.0154, val_loss: 17.7078, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 570/1000000, train_loss: 14.9982, val_loss: 17.6884, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 571/1000000, train_loss: 14.9794, val_loss: 17.6584, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 572/1000000, train_loss: 14.9625, val_loss: 17.6504, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 573/1000000, train_loss: 14.9428, val_loss: 17.6360, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 574/1000000, train_loss: 14.9255, val_loss: 17.6206, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 575/1000000, train_loss: 14.9061, val_loss: 17.5961, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 576/1000000, train_loss: 14.8869, val_loss: 17.5801, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 577/1000000, train_loss: 14.8703, val_loss: 17.5584, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 578/1000000, train_loss: 14.8556, val_loss: 17.5394, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 579/1000000, train_loss: 14.8352, val_loss: 17.5253, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 580/1000000, train_loss: 14.8172, val_loss: 17.4943, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 581/1000000, train_loss: 14.8017, val_loss: 17.4891, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 582/1000000, train_loss: 14.7848, val_loss: 17.4667, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 583/1000000, train_loss: 14.7666, val_loss: 17.4407, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 584/1000000, train_loss: 14.7468, val_loss: 17.4146, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 585/1000000, train_loss: 14.7298, val_loss: 17.3978, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 586/1000000, train_loss: 14.7109, val_loss: 17.3879, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 587/1000000, train_loss: 14.6961, val_loss: 17.3681, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 588/1000000, train_loss: 14.6756, val_loss: 17.3384, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 589/1000000, train_loss: 14.6598, val_loss: 17.3237, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 590/1000000, train_loss: 14.6419, val_loss: 17.3030, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 591/1000000, train_loss: 14.6240, val_loss: 17.2877, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 592/1000000, train_loss: 14.6042, val_loss: 17.2723, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 593/1000000, train_loss: 14.5897, val_loss: 17.2476, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 594/1000000, train_loss: 14.5703, val_loss: 17.2256, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 595/1000000, train_loss: 14.5546, val_loss: 17.2102, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 596/1000000, train_loss: 14.5353, val_loss: 17.1942, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 597/1000000, train_loss: 14.5171, val_loss: 17.1705, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 598/1000000, train_loss: 14.4998, val_loss: 17.1563, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 599/1000000, train_loss: 14.4843, val_loss: 17.1375, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 600/1000000, train_loss: 14.4651, val_loss: 17.1156, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 601/1000000, train_loss: 14.4511, val_loss: 17.0920, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 602/1000000, train_loss: 14.4310, val_loss: 17.0753, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 603/1000000, train_loss: 14.4116, val_loss: 17.0555, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 604/1000000, train_loss: 14.3955, val_loss: 17.0458, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 605/1000000, train_loss: 14.3805, val_loss: 17.0138, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 606/1000000, train_loss: 14.3608, val_loss: 17.0053, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 607/1000000, train_loss: 14.3414, val_loss: 16.9799, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 608/1000000, train_loss: 14.3267, val_loss: 16.9663, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 609/1000000, train_loss: 14.3116, val_loss: 16.9460, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 610/1000000, train_loss: 14.2917, val_loss: 16.9222, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 611/1000000, train_loss: 14.2762, val_loss: 16.9121, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 612/1000000, train_loss: 14.2593, val_loss: 16.8923, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 613/1000000, train_loss: 14.2397, val_loss: 16.8643, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 614/1000000, train_loss: 14.2218, val_loss: 16.8474, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 615/1000000, train_loss: 14.2054, val_loss: 16.8321, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 616/1000000, train_loss: 14.1891, val_loss: 16.8169, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 617/1000000, train_loss: 14.1722, val_loss: 16.7951, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 618/1000000, train_loss: 14.1534, val_loss: 16.7748, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 619/1000000, train_loss: 14.1394, val_loss: 16.7481, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 620/1000000, train_loss: 14.1214, val_loss: 16.7440, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 621/1000000, train_loss: 14.1054, val_loss: 16.7149, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 622/1000000, train_loss: 14.0880, val_loss: 16.7010, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 623/1000000, train_loss: 14.0705, val_loss: 16.6811, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 624/1000000, train_loss: 14.0530, val_loss: 16.6634, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 625/1000000, train_loss: 14.0341, val_loss: 16.6411, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 626/1000000, train_loss: 14.0196, val_loss: 16.6243, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 627/1000000, train_loss: 14.0036, val_loss: 16.6020, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 628/1000000, train_loss: 13.9836, val_loss: 16.5727, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 629/1000000, train_loss: 13.9653, val_loss: 16.5639, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 630/1000000, train_loss: 13.9493, val_loss: 16.5482, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 631/1000000, train_loss: 13.9341, val_loss: 16.5242, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 632/1000000, train_loss: 13.9171, val_loss: 16.5089, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 633/1000000, train_loss: 13.9017, val_loss: 16.4946, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 634/1000000, train_loss: 13.8843, val_loss: 16.4765, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 635/1000000, train_loss: 13.8660, val_loss: 16.4570, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 636/1000000, train_loss: 13.8501, val_loss: 16.4316, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 637/1000000, train_loss: 13.8344, val_loss: 16.4123, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 638/1000000, train_loss: 13.8154, val_loss: 16.3925, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 639/1000000, train_loss: 13.8018, val_loss: 16.3776, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 640/1000000, train_loss: 13.7861, val_loss: 16.3596, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 641/1000000, train_loss: 13.7688, val_loss: 16.3345, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 642/1000000, train_loss: 13.7500, val_loss: 16.3231, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 643/1000000, train_loss: 13.7332, val_loss: 16.3000, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 644/1000000, train_loss: 13.7159, val_loss: 16.2864, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 645/1000000, train_loss: 13.6984, val_loss: 16.2630, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 646/1000000, train_loss: 13.6837, val_loss: 16.2436, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 647/1000000, train_loss: 13.6649, val_loss: 16.2332, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 648/1000000, train_loss: 13.6483, val_loss: 16.1991, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 649/1000000, train_loss: 13.6356, val_loss: 16.1889, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 650/1000000, train_loss: 13.6179, val_loss: 16.1737, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 651/1000000, train_loss: 13.5998, val_loss: 16.1579, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 652/1000000, train_loss: 13.5824, val_loss: 16.1361, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 653/1000000, train_loss: 13.5661, val_loss: 16.1160, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 654/1000000, train_loss: 13.5489, val_loss: 16.0940, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 655/1000000, train_loss: 13.5328, val_loss: 16.0729, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 656/1000000, train_loss: 13.5165, val_loss: 16.0523, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 657/1000000, train_loss: 13.4994, val_loss: 16.0348, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 658/1000000, train_loss: 13.4878, val_loss: 16.0188, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 659/1000000, train_loss: 13.4695, val_loss: 15.9967, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 660/1000000, train_loss: 13.4528, val_loss: 15.9866, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 661/1000000, train_loss: 13.4367, val_loss: 15.9623, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 662/1000000, train_loss: 13.4208, val_loss: 15.9447, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 663/1000000, train_loss: 13.4043, val_loss: 15.9325, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 664/1000000, train_loss: 13.3883, val_loss: 15.9064, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 665/1000000, train_loss: 13.3713, val_loss: 15.8938, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 666/1000000, train_loss: 13.3551, val_loss: 15.8654, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 667/1000000, train_loss: 13.3374, val_loss: 15.8581, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 668/1000000, train_loss: 13.3261, val_loss: 15.8339, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 669/1000000, train_loss: 13.3090, val_loss: 15.8144, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 670/1000000, train_loss: 13.2914, val_loss: 15.7973, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 671/1000000, train_loss: 13.2763, val_loss: 15.7847, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 672/1000000, train_loss: 13.2611, val_loss: 15.7594, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 673/1000000, train_loss: 13.2450, val_loss: 15.7430, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 674/1000000, train_loss: 13.2273, val_loss: 15.7274, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 675/1000000, train_loss: 13.2140, val_loss: 15.7157, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 676/1000000, train_loss: 13.2002, val_loss: 15.6885, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 677/1000000, train_loss: 13.1821, val_loss: 15.6755, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 678/1000000, train_loss: 13.1664, val_loss: 15.6585, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 679/1000000, train_loss: 13.1507, val_loss: 15.6352, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 680/1000000, train_loss: 13.1364, val_loss: 15.6219, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 681/1000000, train_loss: 13.1183, val_loss: 15.5958, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 682/1000000, train_loss: 13.1030, val_loss: 15.5855, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 683/1000000, train_loss: 13.0888, val_loss: 15.5625, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 684/1000000, train_loss: 13.0737, val_loss: 15.5440, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 685/1000000, train_loss: 13.0581, val_loss: 15.5262, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 686/1000000, train_loss: 13.0422, val_loss: 15.5046, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 687/1000000, train_loss: 13.0270, val_loss: 15.4895, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 688/1000000, train_loss: 13.0124, val_loss: 15.4699, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 689/1000000, train_loss: 12.9959, val_loss: 15.4543, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 690/1000000, train_loss: 12.9833, val_loss: 15.4352, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 691/1000000, train_loss: 12.9683, val_loss: 15.4168, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 692/1000000, train_loss: 12.9520, val_loss: 15.3930, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 693/1000000, train_loss: 12.9370, val_loss: 15.3807, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 694/1000000, train_loss: 12.9227, val_loss: 15.3648, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 695/1000000, train_loss: 12.9068, val_loss: 15.3429, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 696/1000000, train_loss: 12.8930, val_loss: 15.3163, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 697/1000000, train_loss: 12.8766, val_loss: 15.3133, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 698/1000000, train_loss: 12.8629, val_loss: 15.2925, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 699/1000000, train_loss: 12.8489, val_loss: 15.2807, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 700/1000000, train_loss: 12.8336, val_loss: 15.2601, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 701/1000000, train_loss: 12.8203, val_loss: 15.2420, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 702/1000000, train_loss: 12.8027, val_loss: 15.2207, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 703/1000000, train_loss: 12.7910, val_loss: 15.2022, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 704/1000000, train_loss: 12.7797, val_loss: 15.1870, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 705/1000000, train_loss: 12.7636, val_loss: 15.1838, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 706/1000000, train_loss: 12.7455, val_loss: 15.1529, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 707/1000000, train_loss: 12.7334, val_loss: 15.1438, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 708/1000000, train_loss: 12.7175, val_loss: 15.1194, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 709/1000000, train_loss: 12.7045, val_loss: 15.1094, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 710/1000000, train_loss: 12.6898, val_loss: 15.0832, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 711/1000000, train_loss: 12.6778, val_loss: 15.0721, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 712/1000000, train_loss: 12.6667, val_loss: 15.0563, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 713/1000000, train_loss: 12.6511, val_loss: 15.0411, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 714/1000000, train_loss: 12.6356, val_loss: 15.0132, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 715/1000000, train_loss: 12.6192, val_loss: 15.0032, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 716/1000000, train_loss: 12.6081, val_loss: 14.9847, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 717/1000000, train_loss: 12.5939, val_loss: 14.9756, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 718/1000000, train_loss: 12.5790, val_loss: 14.9527, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 719/1000000, train_loss: 12.5680, val_loss: 14.9361, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 720/1000000, train_loss: 12.5535, val_loss: 14.9203, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 721/1000000, train_loss: 12.5404, val_loss: 14.9093, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 722/1000000, train_loss: 12.5246, val_loss: 14.8800, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 723/1000000, train_loss: 12.5135, val_loss: 14.8664, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 724/1000000, train_loss: 12.4973, val_loss: 14.8484, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 725/1000000, train_loss: 12.4863, val_loss: 14.8367, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 726/1000000, train_loss: 12.4759, val_loss: 14.8292, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 727/1000000, train_loss: 12.4548, val_loss: 14.8041, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 728/1000000, train_loss: 12.4448, val_loss: 14.7905, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 729/1000000, train_loss: 12.4316, val_loss: 14.7744, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 730/1000000, train_loss: 12.4188, val_loss: 14.7596, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 731/1000000, train_loss: 12.4059, val_loss: 14.7456, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 732/1000000, train_loss: 12.3946, val_loss: 14.7246, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 733/1000000, train_loss: 12.3823, val_loss: 14.7118, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 734/1000000, train_loss: 12.3695, val_loss: 14.6946, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 735/1000000, train_loss: 12.3550, val_loss: 14.6826, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 736/1000000, train_loss: 12.3414, val_loss: 14.6652, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 737/1000000, train_loss: 12.3295, val_loss: 14.6461, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 738/1000000, train_loss: 12.3181, val_loss: 14.6388, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 739/1000000, train_loss: 12.3054, val_loss: 14.6225, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 740/1000000, train_loss: 12.2924, val_loss: 14.5984, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 741/1000000, train_loss: 12.2833, val_loss: 14.5917, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 742/1000000, train_loss: 12.2653, val_loss: 14.5678, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 743/1000000, train_loss: 12.2570, val_loss: 14.5531, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 744/1000000, train_loss: 12.2441, val_loss: 14.5489, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 745/1000000, train_loss: 12.2335, val_loss: 14.5263, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 746/1000000, train_loss: 12.2173, val_loss: 14.5211, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 747/1000000, train_loss: 12.2053, val_loss: 14.5091, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 748/1000000, train_loss: 12.1928, val_loss: 14.4879, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 749/1000000, train_loss: 12.1823, val_loss: 14.4764, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 750/1000000, train_loss: 12.1696, val_loss: 14.4641, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 751/1000000, train_loss: 12.1602, val_loss: 14.4393, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 752/1000000, train_loss: 12.1458, val_loss: 14.4294, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 753/1000000, train_loss: 12.1342, val_loss: 14.4178, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 754/1000000, train_loss: 12.1213, val_loss: 14.3951, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 755/1000000, train_loss: 12.1112, val_loss: 14.3790, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 756/1000000, train_loss: 12.0991, val_loss: 14.3700, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 757/1000000, train_loss: 12.0857, val_loss: 14.3550, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 758/1000000, train_loss: 12.0723, val_loss: 14.3468, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 759/1000000, train_loss: 12.0624, val_loss: 14.3316, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 760/1000000, train_loss: 12.0493, val_loss: 14.3131, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 761/1000000, train_loss: 12.0396, val_loss: 14.3086, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 762/1000000, train_loss: 12.0266, val_loss: 14.3010, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 763/1000000, train_loss: 12.0136, val_loss: 14.2713, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 764/1000000, train_loss: 12.0037, val_loss: 14.2559, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 765/1000000, train_loss: 11.9897, val_loss: 14.2450, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 766/1000000, train_loss: 11.9814, val_loss: 14.2313, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 767/1000000, train_loss: 11.9699, val_loss: 14.2198, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 768/1000000, train_loss: 11.9570, val_loss: 14.2033, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 769/1000000, train_loss: 11.9457, val_loss: 14.1955, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 770/1000000, train_loss: 11.9326, val_loss: 14.1742, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 771/1000000, train_loss: 11.9208, val_loss: 14.1640, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 772/1000000, train_loss: 11.9106, val_loss: 14.1492, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 773/1000000, train_loss: 11.8980, val_loss: 14.1368, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 774/1000000, train_loss: 11.8890, val_loss: 14.1207, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 775/1000000, train_loss: 11.8766, val_loss: 14.1148, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 776/1000000, train_loss: 11.8641, val_loss: 14.0924, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 777/1000000, train_loss: 11.8512, val_loss: 14.0781, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 778/1000000, train_loss: 11.8417, val_loss: 14.0595, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 779/1000000, train_loss: 11.8306, val_loss: 14.0506, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 780/1000000, train_loss: 11.8184, val_loss: 14.0405, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 781/1000000, train_loss: 11.8079, val_loss: 14.0306, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 782/1000000, train_loss: 11.7952, val_loss: 14.0123, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 783/1000000, train_loss: 11.7855, val_loss: 13.9975, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 784/1000000, train_loss: 11.7709, val_loss: 13.9879, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 785/1000000, train_loss: 11.7609, val_loss: 13.9630, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 786/1000000, train_loss: 11.7508, val_loss: 13.9565, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 787/1000000, train_loss: 11.7384, val_loss: 13.9468, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 788/1000000, train_loss: 11.7296, val_loss: 13.9321, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 789/1000000, train_loss: 11.7155, val_loss: 13.9191, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 790/1000000, train_loss: 11.7061, val_loss: 13.9066, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 791/1000000, train_loss: 11.6960, val_loss: 13.8849, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 792/1000000, train_loss: 11.6841, val_loss: 13.8787, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 793/1000000, train_loss: 11.6724, val_loss: 13.8701, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 794/1000000, train_loss: 11.6620, val_loss: 13.8552, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 795/1000000, train_loss: 11.6516, val_loss: 13.8340, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 796/1000000, train_loss: 11.6402, val_loss: 13.8236, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 797/1000000, train_loss: 11.6283, val_loss: 13.8137, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 798/1000000, train_loss: 11.6176, val_loss: 13.7953, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 799/1000000, train_loss: 11.6068, val_loss: 13.7716, time: 0.12s\n",
      "Epoch 800/1000000, train_loss: 11.5967, val_loss: 13.7773, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 801/1000000, train_loss: 11.5851, val_loss: 13.7572, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 802/1000000, train_loss: 11.5737, val_loss: 13.7506, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 803/1000000, train_loss: 11.5642, val_loss: 13.7341, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 804/1000000, train_loss: 11.5537, val_loss: 13.7088, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 805/1000000, train_loss: 11.5422, val_loss: 13.6987, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 806/1000000, train_loss: 11.5313, val_loss: 13.6930, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 807/1000000, train_loss: 11.5209, val_loss: 13.6725, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 808/1000000, train_loss: 11.5091, val_loss: 13.6651, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 809/1000000, train_loss: 11.5002, val_loss: 13.6454, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 810/1000000, train_loss: 11.4909, val_loss: 13.6420, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 811/1000000, train_loss: 11.4781, val_loss: 13.6281, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 812/1000000, train_loss: 11.4664, val_loss: 13.6203, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 813/1000000, train_loss: 11.4590, val_loss: 13.6034, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 814/1000000, train_loss: 11.4505, val_loss: 13.5948, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 815/1000000, train_loss: 11.4376, val_loss: 13.5864, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 816/1000000, train_loss: 11.4260, val_loss: 13.5635, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 817/1000000, train_loss: 11.4180, val_loss: 13.5536, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 818/1000000, train_loss: 11.4067, val_loss: 13.5458, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 819/1000000, train_loss: 11.3943, val_loss: 13.5344, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 820/1000000, train_loss: 11.3860, val_loss: 13.5079, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 821/1000000, train_loss: 11.3780, val_loss: 13.5038, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 822/1000000, train_loss: 11.3660, val_loss: 13.4922, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 823/1000000, train_loss: 11.3554, val_loss: 13.4771, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 824/1000000, train_loss: 11.3454, val_loss: 13.4637, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 825/1000000, train_loss: 11.3338, val_loss: 13.4576, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 826/1000000, train_loss: 11.3244, val_loss: 13.4366, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 827/1000000, train_loss: 11.3138, val_loss: 13.4263, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 828/1000000, train_loss: 11.3052, val_loss: 13.4158, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 829/1000000, train_loss: 11.2928, val_loss: 13.4029, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 830/1000000, train_loss: 11.2842, val_loss: 13.3859, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 831/1000000, train_loss: 11.2735, val_loss: 13.3796, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 832/1000000, train_loss: 11.2648, val_loss: 13.3713, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 833/1000000, train_loss: 11.2549, val_loss: 13.3572, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 834/1000000, train_loss: 11.2469, val_loss: 13.3477, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 835/1000000, train_loss: 11.2368, val_loss: 13.3371, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 836/1000000, train_loss: 11.2242, val_loss: 13.3181, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 837/1000000, train_loss: 11.2168, val_loss: 13.3067, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 838/1000000, train_loss: 11.2070, val_loss: 13.2985, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 839/1000000, train_loss: 11.1960, val_loss: 13.2851, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 840/1000000, train_loss: 11.1881, val_loss: 13.2649, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 841/1000000, train_loss: 11.1777, val_loss: 13.2622, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 842/1000000, train_loss: 11.1693, val_loss: 13.2442, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 843/1000000, train_loss: 11.1595, val_loss: 13.2350, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 844/1000000, train_loss: 11.1474, val_loss: 13.2242, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 845/1000000, train_loss: 11.1400, val_loss: 13.2116, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 846/1000000, train_loss: 11.1291, val_loss: 13.2005, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 847/1000000, train_loss: 11.1213, val_loss: 13.1880, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 848/1000000, train_loss: 11.1121, val_loss: 13.1797, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 849/1000000, train_loss: 11.1021, val_loss: 13.1685, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 850/1000000, train_loss: 11.0914, val_loss: 13.1499, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 851/1000000, train_loss: 11.0852, val_loss: 13.1408, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 852/1000000, train_loss: 11.0745, val_loss: 13.1318, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 853/1000000, train_loss: 11.0639, val_loss: 13.1143, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 854/1000000, train_loss: 11.0564, val_loss: 13.1086, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 855/1000000, train_loss: 11.0487, val_loss: 13.0956, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 856/1000000, train_loss: 11.0373, val_loss: 13.0890, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 857/1000000, train_loss: 11.0287, val_loss: 13.0778, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 858/1000000, train_loss: 11.0191, val_loss: 13.0635, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 859/1000000, train_loss: 11.0116, val_loss: 13.0511, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 860/1000000, train_loss: 10.9992, val_loss: 13.0465, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 861/1000000, train_loss: 10.9919, val_loss: 13.0257, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 862/1000000, train_loss: 10.9837, val_loss: 13.0200, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 863/1000000, train_loss: 10.9732, val_loss: 13.0126, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 864/1000000, train_loss: 10.9652, val_loss: 12.9977, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 865/1000000, train_loss: 10.9555, val_loss: 12.9904, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 866/1000000, train_loss: 10.9481, val_loss: 12.9641, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 867/1000000, train_loss: 10.9385, val_loss: 12.9624, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 868/1000000, train_loss: 10.9289, val_loss: 12.9520, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 869/1000000, train_loss: 10.9198, val_loss: 12.9443, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 870/1000000, train_loss: 10.9143, val_loss: 12.9344, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 871/1000000, train_loss: 10.9028, val_loss: 12.9178, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 872/1000000, train_loss: 10.8924, val_loss: 12.9113, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 873/1000000, train_loss: 10.8852, val_loss: 12.8989, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 874/1000000, train_loss: 10.8788, val_loss: 12.8903, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 875/1000000, train_loss: 10.8693, val_loss: 12.8726, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 876/1000000, train_loss: 10.8610, val_loss: 12.8619, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 877/1000000, train_loss: 10.8507, val_loss: 12.8478, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 878/1000000, train_loss: 10.8448, val_loss: 12.8406, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 879/1000000, train_loss: 10.8336, val_loss: 12.8310, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 880/1000000, train_loss: 10.8244, val_loss: 12.8177, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 881/1000000, train_loss: 10.8158, val_loss: 12.8066, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 882/1000000, train_loss: 10.8095, val_loss: 12.8017, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 883/1000000, train_loss: 10.8002, val_loss: 12.7880, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 884/1000000, train_loss: 10.7899, val_loss: 12.7785, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 885/1000000, train_loss: 10.7856, val_loss: 12.7701, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 886/1000000, train_loss: 10.7745, val_loss: 12.7513, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 887/1000000, train_loss: 10.7666, val_loss: 12.7453, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 888/1000000, train_loss: 10.7590, val_loss: 12.7397, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 889/1000000, train_loss: 10.7493, val_loss: 12.7285, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 890/1000000, train_loss: 10.7402, val_loss: 12.7069, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 891/1000000, train_loss: 10.7325, val_loss: 12.7037, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 892/1000000, train_loss: 10.7250, val_loss: 12.7008, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 893/1000000, train_loss: 10.7141, val_loss: 12.6823, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 894/1000000, train_loss: 10.7080, val_loss: 12.6751, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 895/1000000, train_loss: 10.7030, val_loss: 12.6607, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 896/1000000, train_loss: 10.6907, val_loss: 12.6472, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 897/1000000, train_loss: 10.6821, val_loss: 12.6429, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 898/1000000, train_loss: 10.6747, val_loss: 12.6347, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 899/1000000, train_loss: 10.6669, val_loss: 12.6107, time: 0.14s\n",
      "Epoch 900/1000000, train_loss: 10.6590, val_loss: 12.6128, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 901/1000000, train_loss: 10.6524, val_loss: 12.6037, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 902/1000000, train_loss: 10.6436, val_loss: 12.5904, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 903/1000000, train_loss: 10.6345, val_loss: 12.5774, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 904/1000000, train_loss: 10.6278, val_loss: 12.5595, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 905/1000000, train_loss: 10.6189, val_loss: 12.5551, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 906/1000000, train_loss: 10.6102, val_loss: 12.5495, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 907/1000000, train_loss: 10.6030, val_loss: 12.5353, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 908/1000000, train_loss: 10.5937, val_loss: 12.5284, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 909/1000000, train_loss: 10.5856, val_loss: 12.5121, time: 0.12s\n",
      "Epoch 910/1000000, train_loss: 10.5806, val_loss: 12.5127, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 911/1000000, train_loss: 10.5719, val_loss: 12.4995, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 912/1000000, train_loss: 10.5637, val_loss: 12.4945, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 913/1000000, train_loss: 10.5551, val_loss: 12.4818, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 914/1000000, train_loss: 10.5472, val_loss: 12.4739, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 915/1000000, train_loss: 10.5422, val_loss: 12.4614, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 916/1000000, train_loss: 10.5330, val_loss: 12.4495, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 917/1000000, train_loss: 10.5265, val_loss: 12.4478, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 918/1000000, train_loss: 10.5151, val_loss: 12.4394, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 919/1000000, train_loss: 10.5085, val_loss: 12.4191, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 920/1000000, train_loss: 10.5024, val_loss: 12.4123, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 921/1000000, train_loss: 10.4940, val_loss: 12.3997, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 922/1000000, train_loss: 10.4858, val_loss: 12.3965, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 923/1000000, train_loss: 10.4777, val_loss: 12.3807, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 924/1000000, train_loss: 10.4721, val_loss: 12.3739, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 925/1000000, train_loss: 10.4622, val_loss: 12.3662, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 926/1000000, train_loss: 10.4581, val_loss: 12.3557, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 927/1000000, train_loss: 10.4493, val_loss: 12.3545, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 928/1000000, train_loss: 10.4409, val_loss: 12.3394, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 929/1000000, train_loss: 10.4339, val_loss: 12.3282, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 930/1000000, train_loss: 10.4253, val_loss: 12.3209, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 931/1000000, train_loss: 10.4188, val_loss: 12.3126, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 932/1000000, train_loss: 10.4132, val_loss: 12.3013, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 933/1000000, train_loss: 10.4063, val_loss: 12.2905, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 934/1000000, train_loss: 10.3976, val_loss: 12.2845, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 935/1000000, train_loss: 10.3920, val_loss: 12.2749, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 936/1000000, train_loss: 10.3828, val_loss: 12.2577, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 937/1000000, train_loss: 10.3743, val_loss: 12.2555, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 938/1000000, train_loss: 10.3691, val_loss: 12.2458, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 939/1000000, train_loss: 10.3604, val_loss: 12.2306, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 940/1000000, train_loss: 10.3537, val_loss: 12.2287, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 941/1000000, train_loss: 10.3491, val_loss: 12.2231, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 942/1000000, train_loss: 10.3384, val_loss: 12.2025, time: 0.12s\n",
      "Epoch 943/1000000, train_loss: 10.3319, val_loss: 12.2070, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 944/1000000, train_loss: 10.3266, val_loss: 12.1857, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 945/1000000, train_loss: 10.3185, val_loss: 12.1853, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 946/1000000, train_loss: 10.3136, val_loss: 12.1770, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 947/1000000, train_loss: 10.3043, val_loss: 12.1702, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 948/1000000, train_loss: 10.2991, val_loss: 12.1558, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 949/1000000, train_loss: 10.2915, val_loss: 12.1453, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 950/1000000, train_loss: 10.2857, val_loss: 12.1390, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 951/1000000, train_loss: 10.2779, val_loss: 12.1247, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 952/1000000, train_loss: 10.2696, val_loss: 12.1184, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 953/1000000, train_loss: 10.2624, val_loss: 12.1093, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 954/1000000, train_loss: 10.2582, val_loss: 12.1015, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 955/1000000, train_loss: 10.2513, val_loss: 12.0916, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 956/1000000, train_loss: 10.2443, val_loss: 12.0905, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 957/1000000, train_loss: 10.2356, val_loss: 12.0787, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 958/1000000, train_loss: 10.2300, val_loss: 12.0600, time: 0.12s\n",
      "Epoch 959/1000000, train_loss: 10.2231, val_loss: 12.0604, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 960/1000000, train_loss: 10.2170, val_loss: 12.0522, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 961/1000000, train_loss: 10.2102, val_loss: 12.0423, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 962/1000000, train_loss: 10.2027, val_loss: 12.0315, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 963/1000000, train_loss: 10.1981, val_loss: 12.0268, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 964/1000000, train_loss: 10.1915, val_loss: 12.0138, time: 0.12s\n",
      "Epoch 965/1000000, train_loss: 10.1831, val_loss: 12.0140, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 966/1000000, train_loss: 10.1761, val_loss: 11.9988, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 967/1000000, train_loss: 10.1702, val_loss: 11.9954, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 968/1000000, train_loss: 10.1651, val_loss: 11.9817, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 969/1000000, train_loss: 10.1579, val_loss: 11.9789, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 970/1000000, train_loss: 10.1518, val_loss: 11.9748, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 971/1000000, train_loss: 10.1427, val_loss: 11.9496, time: 0.12s\n",
      "Epoch 972/1000000, train_loss: 10.1376, val_loss: 11.9517, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 973/1000000, train_loss: 10.1348, val_loss: 11.9418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 974/1000000, train_loss: 10.1265, val_loss: 11.9335, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 975/1000000, train_loss: 10.1188, val_loss: 11.9331, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 976/1000000, train_loss: 10.1142, val_loss: 11.9249, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 977/1000000, train_loss: 10.1073, val_loss: 11.9056, time: 0.12s\n",
      "Epoch 978/1000000, train_loss: 10.1016, val_loss: 11.9071, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 979/1000000, train_loss: 10.0935, val_loss: 11.8940, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 980/1000000, train_loss: 10.0880, val_loss: 11.8923, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 981/1000000, train_loss: 10.0833, val_loss: 11.8800, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 982/1000000, train_loss: 10.0771, val_loss: 11.8753, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 983/1000000, train_loss: 10.0718, val_loss: 11.8634, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 984/1000000, train_loss: 10.0653, val_loss: 11.8500, time: 0.12s\n",
      "Epoch 985/1000000, train_loss: 10.0588, val_loss: 11.8540, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 986/1000000, train_loss: 10.0535, val_loss: 11.8419, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 987/1000000, train_loss: 10.0462, val_loss: 11.8293, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 988/1000000, train_loss: 10.0409, val_loss: 11.8266, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 989/1000000, train_loss: 10.0343, val_loss: 11.8253, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 990/1000000, train_loss: 10.0281, val_loss: 11.8087, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 991/1000000, train_loss: 10.0232, val_loss: 11.8018, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 992/1000000, train_loss: 10.0174, val_loss: 11.7938, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 993/1000000, train_loss: 10.0102, val_loss: 11.7802, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 994/1000000, train_loss: 10.0025, val_loss: 11.7741, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 995/1000000, train_loss: 9.9988, val_loss: 11.7728, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 996/1000000, train_loss: 9.9910, val_loss: 11.7584, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 997/1000000, train_loss: 9.9847, val_loss: 11.7485, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 998/1000000, train_loss: 9.9800, val_loss: 11.7483, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 999/1000000, train_loss: 9.9730, val_loss: 11.7400, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1000/1000000, train_loss: 9.9670, val_loss: 11.7389, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1001/1000000, train_loss: 9.9624, val_loss: 11.7297, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1002/1000000, train_loss: 9.9555, val_loss: 11.7170, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1003/1000000, train_loss: 9.9497, val_loss: 11.7133, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1004/1000000, train_loss: 9.9461, val_loss: 11.7098, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1005/1000000, train_loss: 9.9385, val_loss: 11.6999, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1006/1000000, train_loss: 9.9326, val_loss: 11.6881, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1007/1000000, train_loss: 9.9294, val_loss: 11.6821, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1008/1000000, train_loss: 9.9224, val_loss: 11.6702, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1009/1000000, train_loss: 9.9171, val_loss: 11.6666, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1010/1000000, train_loss: 9.9096, val_loss: 11.6607, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1011/1000000, train_loss: 9.9051, val_loss: 11.6523, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1012/1000000, train_loss: 9.8991, val_loss: 11.6421, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1013/1000000, train_loss: 9.8923, val_loss: 11.6419, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1014/1000000, train_loss: 9.8869, val_loss: 11.6253, time: 0.12s\n",
      "Epoch 1015/1000000, train_loss: 9.8822, val_loss: 11.6265, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1016/1000000, train_loss: 9.8770, val_loss: 11.6122, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1017/1000000, train_loss: 9.8702, val_loss: 11.5987, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1018/1000000, train_loss: 9.8659, val_loss: 11.5938, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1019/1000000, train_loss: 9.8590, val_loss: 11.5904, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1020/1000000, train_loss: 9.8525, val_loss: 11.5829, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1021/1000000, train_loss: 9.8481, val_loss: 11.5770, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1022/1000000, train_loss: 9.8439, val_loss: 11.5687, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1023/1000000, train_loss: 9.8357, val_loss: 11.5673, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1024/1000000, train_loss: 9.8306, val_loss: 11.5553, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1025/1000000, train_loss: 9.8245, val_loss: 11.5447, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1026/1000000, train_loss: 9.8209, val_loss: 11.5366, time: 0.12s\n",
      "Epoch 1027/1000000, train_loss: 9.8135, val_loss: 11.5414, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1028/1000000, train_loss: 9.8103, val_loss: 11.5305, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1029/1000000, train_loss: 9.8035, val_loss: 11.5187, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1030/1000000, train_loss: 9.7972, val_loss: 11.5119, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1031/1000000, train_loss: 9.7925, val_loss: 11.4969, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1032/1000000, train_loss: 9.7870, val_loss: 11.4964, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1033/1000000, train_loss: 9.7829, val_loss: 11.4892, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1034/1000000, train_loss: 9.7747, val_loss: 11.4745, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1035/1000000, train_loss: 9.7702, val_loss: 11.4743, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1036/1000000, train_loss: 9.7634, val_loss: 11.4665, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1037/1000000, train_loss: 9.7613, val_loss: 11.4613, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1038/1000000, train_loss: 9.7535, val_loss: 11.4508, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1039/1000000, train_loss: 9.7489, val_loss: 11.4487, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1040/1000000, train_loss: 9.7440, val_loss: 11.4418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1041/1000000, train_loss: 9.7365, val_loss: 11.4262, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1042/1000000, train_loss: 9.7328, val_loss: 11.4169, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1043/1000000, train_loss: 9.7277, val_loss: 11.4163, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1044/1000000, train_loss: 9.7212, val_loss: 11.4075, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1045/1000000, train_loss: 9.7168, val_loss: 11.4009, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1046/1000000, train_loss: 9.7100, val_loss: 11.3951, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1047/1000000, train_loss: 9.7075, val_loss: 11.3949, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1048/1000000, train_loss: 9.7008, val_loss: 11.3758, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1049/1000000, train_loss: 9.6941, val_loss: 11.3672, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1050/1000000, train_loss: 9.6896, val_loss: 11.3598, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1051/1000000, train_loss: 9.6856, val_loss: 11.3503, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1052/1000000, train_loss: 9.6804, val_loss: 11.3384, time: 0.14s\n",
      "Epoch 1053/1000000, train_loss: 9.6741, val_loss: 11.3435, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1054/1000000, train_loss: 9.6698, val_loss: 11.3287, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1055/1000000, train_loss: 9.6640, val_loss: 11.3286, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1056/1000000, train_loss: 9.6596, val_loss: 11.3220, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1057/1000000, train_loss: 9.6538, val_loss: 11.3127, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1058/1000000, train_loss: 9.6478, val_loss: 11.3000, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1059/1000000, train_loss: 9.6419, val_loss: 11.2989, time: 0.12s\n",
      "Epoch 1060/1000000, train_loss: 9.6371, val_loss: 11.3002, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1061/1000000, train_loss: 9.6342, val_loss: 11.2899, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1062/1000000, train_loss: 9.6295, val_loss: 11.2791, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1063/1000000, train_loss: 9.6221, val_loss: 11.2679, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1064/1000000, train_loss: 9.6177, val_loss: 11.2601, time: 0.12s\n",
      "Epoch 1065/1000000, train_loss: 9.6129, val_loss: 11.2644, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1066/1000000, train_loss: 9.6078, val_loss: 11.2506, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1067/1000000, train_loss: 9.6015, val_loss: 11.2457, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1068/1000000, train_loss: 9.5973, val_loss: 11.2329, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1069/1000000, train_loss: 9.5925, val_loss: 11.2263, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1070/1000000, train_loss: 9.5869, val_loss: 11.2248, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1071/1000000, train_loss: 9.5850, val_loss: 11.2151, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1072/1000000, train_loss: 9.5776, val_loss: 11.2089, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1073/1000000, train_loss: 9.5721, val_loss: 11.2006, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1074/1000000, train_loss: 9.5689, val_loss: 11.1913, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1075/1000000, train_loss: 9.5611, val_loss: 11.1841, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1076/1000000, train_loss: 9.5579, val_loss: 11.1705, time: 0.12s\n",
      "Epoch 1077/1000000, train_loss: 9.5530, val_loss: 11.1727, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1078/1000000, train_loss: 9.5483, val_loss: 11.1701, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1079/1000000, train_loss: 9.5442, val_loss: 11.1536, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1080/1000000, train_loss: 9.5394, val_loss: 11.1523, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1081/1000000, train_loss: 9.5330, val_loss: 11.1437, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1082/1000000, train_loss: 9.5296, val_loss: 11.1287, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1083/1000000, train_loss: 9.5229, val_loss: 11.1277, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1084/1000000, train_loss: 9.5192, val_loss: 11.1220, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1085/1000000, train_loss: 9.5124, val_loss: 11.1157, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1086/1000000, train_loss: 9.5102, val_loss: 11.1091, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1087/1000000, train_loss: 9.5035, val_loss: 11.0990, time: 0.12s\n",
      "Epoch 1088/1000000, train_loss: 9.4984, val_loss: 11.1001, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1089/1000000, train_loss: 9.4941, val_loss: 11.0874, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1090/1000000, train_loss: 9.4896, val_loss: 11.0768, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1091/1000000, train_loss: 9.4847, val_loss: 11.0745, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1092/1000000, train_loss: 9.4800, val_loss: 11.0561, time: 0.12s\n",
      "Epoch 1093/1000000, train_loss: 9.4750, val_loss: 11.0563, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1094/1000000, train_loss: 9.4715, val_loss: 11.0485, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1095/1000000, train_loss: 9.4645, val_loss: 11.0408, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1096/1000000, train_loss: 9.4619, val_loss: 11.0405, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1097/1000000, train_loss: 9.4558, val_loss: 11.0282, time: 0.12s\n",
      "Epoch 1098/1000000, train_loss: 9.4540, val_loss: 11.0388, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1099/1000000, train_loss: 9.4465, val_loss: 11.0178, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1100/1000000, train_loss: 9.4418, val_loss: 11.0128, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1101/1000000, train_loss: 9.4384, val_loss: 11.0076, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1102/1000000, train_loss: 9.4315, val_loss: 10.9973, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1103/1000000, train_loss: 9.4283, val_loss: 10.9858, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1104/1000000, train_loss: 9.4240, val_loss: 10.9804, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1105/1000000, train_loss: 9.4191, val_loss: 10.9698, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1106/1000000, train_loss: 9.4164, val_loss: 10.9673, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1107/1000000, train_loss: 9.4099, val_loss: 10.9604, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1108/1000000, train_loss: 9.4044, val_loss: 10.9587, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1109/1000000, train_loss: 9.4023, val_loss: 10.9457, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1110/1000000, train_loss: 9.3959, val_loss: 10.9401, time: 0.12s\n",
      "Epoch 1111/1000000, train_loss: 9.3934, val_loss: 10.9433, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1112/1000000, train_loss: 9.3872, val_loss: 10.9258, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1113/1000000, train_loss: 9.3832, val_loss: 10.9231, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1114/1000000, train_loss: 9.3773, val_loss: 10.9220, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1115/1000000, train_loss: 9.3757, val_loss: 10.9133, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1116/1000000, train_loss: 9.3684, val_loss: 10.9047, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1117/1000000, train_loss: 9.3636, val_loss: 10.8932, time: 0.12s\n",
      "Epoch 1118/1000000, train_loss: 9.3591, val_loss: 10.8945, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1119/1000000, train_loss: 9.3557, val_loss: 10.8787, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1120/1000000, train_loss: 9.3506, val_loss: 10.8702, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1121/1000000, train_loss: 9.3456, val_loss: 10.8690, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1122/1000000, train_loss: 9.3450, val_loss: 10.8515, time: 0.15s\n",
      "Epoch 1123/1000000, train_loss: 9.3382, val_loss: 10.8538, time: 0.19s\n",
      "Epoch 1124/1000000, train_loss: 9.3324, val_loss: 10.8549, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1125/1000000, train_loss: 9.3289, val_loss: 10.8489, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1126/1000000, train_loss: 9.3242, val_loss: 10.8357, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1127/1000000, train_loss: 9.3218, val_loss: 10.8213, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1128/1000000, train_loss: 9.3179, val_loss: 10.8203, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1129/1000000, train_loss: 9.3124, val_loss: 10.8056, time: 0.13s\n",
      "Epoch 1130/1000000, train_loss: 9.3073, val_loss: 10.8070, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1131/1000000, train_loss: 9.3027, val_loss: 10.7964, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1132/1000000, train_loss: 9.2998, val_loss: 10.7915, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1133/1000000, train_loss: 9.2947, val_loss: 10.7880, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1134/1000000, train_loss: 9.2915, val_loss: 10.7790, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1135/1000000, train_loss: 9.2871, val_loss: 10.7785, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1136/1000000, train_loss: 9.2804, val_loss: 10.7657, time: 0.12s\n",
      "Epoch 1137/1000000, train_loss: 9.2789, val_loss: 10.7661, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1138/1000000, train_loss: 9.2749, val_loss: 10.7555, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1139/1000000, train_loss: 9.2706, val_loss: 10.7509, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1140/1000000, train_loss: 9.2666, val_loss: 10.7393, time: 0.12s\n",
      "Epoch 1141/1000000, train_loss: 9.2600, val_loss: 10.7397, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1142/1000000, train_loss: 9.2584, val_loss: 10.7273, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1143/1000000, train_loss: 9.2531, val_loss: 10.7262, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1144/1000000, train_loss: 9.2491, val_loss: 10.7207, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1145/1000000, train_loss: 9.2470, val_loss: 10.7035, time: 0.12s\n",
      "Epoch 1146/1000000, train_loss: 9.2405, val_loss: 10.7078, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1147/1000000, train_loss: 9.2358, val_loss: 10.6952, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1148/1000000, train_loss: 9.2322, val_loss: 10.6918, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1149/1000000, train_loss: 9.2284, val_loss: 10.6794, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1150/1000000, train_loss: 9.2248, val_loss: 10.6761, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1151/1000000, train_loss: 9.2205, val_loss: 10.6719, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1152/1000000, train_loss: 9.2141, val_loss: 10.6570, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1153/1000000, train_loss: 9.2098, val_loss: 10.6527, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1154/1000000, train_loss: 9.2057, val_loss: 10.6505, time: 0.12s\n",
      "Epoch 1155/1000000, train_loss: 9.2048, val_loss: 10.6514, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1156/1000000, train_loss: 9.1990, val_loss: 10.6419, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1157/1000000, train_loss: 9.1945, val_loss: 10.6418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1158/1000000, train_loss: 9.1901, val_loss: 10.6215, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1159/1000000, train_loss: 9.1872, val_loss: 10.6152, time: 0.12s\n",
      "Epoch 1160/1000000, train_loss: 9.1845, val_loss: 10.6168, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1161/1000000, train_loss: 9.1797, val_loss: 10.6101, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1162/1000000, train_loss: 9.1761, val_loss: 10.5996, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1163/1000000, train_loss: 9.1702, val_loss: 10.5987, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1164/1000000, train_loss: 9.1655, val_loss: 10.5909, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1165/1000000, train_loss: 9.1628, val_loss: 10.5816, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1166/1000000, train_loss: 9.1595, val_loss: 10.5804, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1167/1000000, train_loss: 9.1563, val_loss: 10.5694, time: 0.12s\n",
      "Epoch 1168/1000000, train_loss: 9.1512, val_loss: 10.5736, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1169/1000000, train_loss: 9.1490, val_loss: 10.5542, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1170/1000000, train_loss: 9.1417, val_loss: 10.5510, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1171/1000000, train_loss: 9.1386, val_loss: 10.5509, time: 0.12s\n",
      "Epoch 1172/1000000, train_loss: 9.1367, val_loss: 10.5523, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1173/1000000, train_loss: 9.1305, val_loss: 10.5300, time: 0.12s\n",
      "Epoch 1174/1000000, train_loss: 9.1281, val_loss: 10.5358, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1175/1000000, train_loss: 9.1252, val_loss: 10.5197, time: 0.12s\n",
      "Epoch 1176/1000000, train_loss: 9.1197, val_loss: 10.5228, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1177/1000000, train_loss: 9.1156, val_loss: 10.5124, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1178/1000000, train_loss: 9.1136, val_loss: 10.5116, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1179/1000000, train_loss: 9.1059, val_loss: 10.4951, time: 0.12s\n",
      "Epoch 1180/1000000, train_loss: 9.1032, val_loss: 10.5043, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1181/1000000, train_loss: 9.0999, val_loss: 10.4920, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1182/1000000, train_loss: 9.0968, val_loss: 10.4809, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1183/1000000, train_loss: 9.0935, val_loss: 10.4727, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1184/1000000, train_loss: 9.0876, val_loss: 10.4652, time: 0.12s\n",
      "Epoch 1185/1000000, train_loss: 9.0844, val_loss: 10.4726, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1186/1000000, train_loss: 9.0790, val_loss: 10.4598, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1187/1000000, train_loss: 9.0761, val_loss: 10.4449, time: 0.14s\n",
      "Epoch 1188/1000000, train_loss: 9.0714, val_loss: 10.4571, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1189/1000000, train_loss: 9.0676, val_loss: 10.4424, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1190/1000000, train_loss: 9.0644, val_loss: 10.4368, time: 0.12s\n",
      "Epoch 1191/1000000, train_loss: 9.0595, val_loss: 10.4411, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1192/1000000, train_loss: 9.0568, val_loss: 10.4277, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1193/1000000, train_loss: 9.0511, val_loss: 10.4219, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1194/1000000, train_loss: 9.0488, val_loss: 10.4211, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1195/1000000, train_loss: 9.0457, val_loss: 10.4079, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1196/1000000, train_loss: 9.0404, val_loss: 10.4058, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1197/1000000, train_loss: 9.0391, val_loss: 10.3968, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1198/1000000, train_loss: 9.0323, val_loss: 10.3825, time: 0.13s\n",
      "Epoch 1199/1000000, train_loss: 9.0293, val_loss: 10.3837, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1200/1000000, train_loss: 9.0257, val_loss: 10.3806, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1201/1000000, train_loss: 9.0219, val_loss: 10.3712, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1202/1000000, train_loss: 9.0186, val_loss: 10.3646, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1203/1000000, train_loss: 9.0133, val_loss: 10.3590, time: 0.13s\n",
      "Epoch 1204/1000000, train_loss: 9.0111, val_loss: 10.3611, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1205/1000000, train_loss: 9.0044, val_loss: 10.3491, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1206/1000000, train_loss: 9.0014, val_loss: 10.3395, time: 0.12s\n",
      "Epoch 1207/1000000, train_loss: 8.9972, val_loss: 10.3412, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1208/1000000, train_loss: 8.9954, val_loss: 10.3337, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1209/1000000, train_loss: 8.9915, val_loss: 10.3281, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1210/1000000, train_loss: 8.9871, val_loss: 10.3169, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1211/1000000, train_loss: 8.9835, val_loss: 10.3164, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1212/1000000, train_loss: 8.9792, val_loss: 10.3083, time: 0.13s\n",
      "Epoch 1213/1000000, train_loss: 8.9754, val_loss: 10.3106, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1214/1000000, train_loss: 8.9728, val_loss: 10.3062, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1215/1000000, train_loss: 8.9689, val_loss: 10.2922, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1216/1000000, train_loss: 8.9657, val_loss: 10.2861, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1217/1000000, train_loss: 8.9616, val_loss: 10.2776, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1218/1000000, train_loss: 8.9570, val_loss: 10.2769, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1219/1000000, train_loss: 8.9523, val_loss: 10.2627, time: 0.12s\n",
      "Epoch 1220/1000000, train_loss: 8.9484, val_loss: 10.2707, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1221/1000000, train_loss: 8.9460, val_loss: 10.2613, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1222/1000000, train_loss: 8.9387, val_loss: 10.2516, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1223/1000000, train_loss: 8.9378, val_loss: 10.2502, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1224/1000000, train_loss: 8.9327, val_loss: 10.2392, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1225/1000000, train_loss: 8.9306, val_loss: 10.2319, time: 0.12s\n",
      "Epoch 1226/1000000, train_loss: 8.9249, val_loss: 10.2391, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1227/1000000, train_loss: 8.9226, val_loss: 10.2317, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1228/1000000, train_loss: 8.9179, val_loss: 10.2192, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1229/1000000, train_loss: 8.9158, val_loss: 10.2105, time: 0.12s\n",
      "Epoch 1230/1000000, train_loss: 8.9097, val_loss: 10.2205, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1231/1000000, train_loss: 8.9085, val_loss: 10.2052, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1232/1000000, train_loss: 8.9036, val_loss: 10.1973, time: 0.12s\n",
      "Epoch 1233/1000000, train_loss: 8.9002, val_loss: 10.2043, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1234/1000000, train_loss: 8.8944, val_loss: 10.1853, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1235/1000000, train_loss: 8.8925, val_loss: 10.1849, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1236/1000000, train_loss: 8.8873, val_loss: 10.1780, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1237/1000000, train_loss: 8.8832, val_loss: 10.1745, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1238/1000000, train_loss: 8.8789, val_loss: 10.1625, time: 0.12s\n",
      "Epoch 1239/1000000, train_loss: 8.8776, val_loss: 10.1650, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1240/1000000, train_loss: 8.8730, val_loss: 10.1526, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1241/1000000, train_loss: 8.8696, val_loss: 10.1511, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1242/1000000, train_loss: 8.8671, val_loss: 10.1487, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1243/1000000, train_loss: 8.8619, val_loss: 10.1414, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1244/1000000, train_loss: 8.8571, val_loss: 10.1397, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1245/1000000, train_loss: 8.8552, val_loss: 10.1288, time: 0.15s\n",
      "Epoch 1246/1000000, train_loss: 8.8520, val_loss: 10.1292, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1247/1000000, train_loss: 8.8460, val_loss: 10.1186, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1248/1000000, train_loss: 8.8443, val_loss: 10.1085, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1249/1000000, train_loss: 8.8394, val_loss: 10.1083, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1250/1000000, train_loss: 8.8348, val_loss: 10.0991, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1251/1000000, train_loss: 8.8330, val_loss: 10.0954, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1252/1000000, train_loss: 8.8307, val_loss: 10.0856, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1253/1000000, train_loss: 8.8258, val_loss: 10.0835, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1254/1000000, train_loss: 8.8219, val_loss: 10.0803, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1255/1000000, train_loss: 8.8167, val_loss: 10.0712, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1256/1000000, train_loss: 8.8152, val_loss: 10.0682, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1257/1000000, train_loss: 8.8106, val_loss: 10.0658, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1258/1000000, train_loss: 8.8062, val_loss: 10.0621, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1259/1000000, train_loss: 8.8017, val_loss: 10.0525, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1260/1000000, train_loss: 8.7987, val_loss: 10.0428, time: 0.13s\n",
      "Epoch 1261/1000000, train_loss: 8.7959, val_loss: 10.0434, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1262/1000000, train_loss: 8.7907, val_loss: 10.0357, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1263/1000000, train_loss: 8.7863, val_loss: 10.0277, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1264/1000000, train_loss: 8.7856, val_loss: 10.0257, time: 0.13s\n",
      "Epoch 1265/1000000, train_loss: 8.7812, val_loss: 10.0291, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1266/1000000, train_loss: 8.7773, val_loss: 10.0199, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1267/1000000, train_loss: 8.7727, val_loss: 10.0155, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1268/1000000, train_loss: 8.7685, val_loss: 9.9962, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1269/1000000, train_loss: 8.7670, val_loss: 9.9936, time: 0.12s\n",
      "Epoch 1270/1000000, train_loss: 8.7622, val_loss: 9.9964, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1271/1000000, train_loss: 8.7589, val_loss: 9.9875, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1272/1000000, train_loss: 8.7533, val_loss: 9.9838, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1273/1000000, train_loss: 8.7515, val_loss: 9.9755, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1274/1000000, train_loss: 8.7463, val_loss: 9.9710, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1275/1000000, train_loss: 8.7446, val_loss: 9.9662, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1276/1000000, train_loss: 8.7404, val_loss: 9.9638, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1277/1000000, train_loss: 8.7359, val_loss: 9.9515, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1278/1000000, train_loss: 8.7314, val_loss: 9.9453, time: 0.13s\n",
      "Epoch 1279/1000000, train_loss: 8.7288, val_loss: 9.9510, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1280/1000000, train_loss: 8.7249, val_loss: 9.9440, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1281/1000000, train_loss: 8.7235, val_loss: 9.9354, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1282/1000000, train_loss: 8.7170, val_loss: 9.9206, time: 0.14s\n",
      "Epoch 1283/1000000, train_loss: 8.7147, val_loss: 9.9239, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1284/1000000, train_loss: 8.7105, val_loss: 9.9176, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1285/1000000, train_loss: 8.7079, val_loss: 9.9099, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1286/1000000, train_loss: 8.7032, val_loss: 9.9070, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1287/1000000, train_loss: 8.6997, val_loss: 9.9056, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1288/1000000, train_loss: 8.6975, val_loss: 9.8983, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1289/1000000, train_loss: 8.6928, val_loss: 9.8892, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1290/1000000, train_loss: 8.6880, val_loss: 9.8863, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1291/1000000, train_loss: 8.6858, val_loss: 9.8761, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1292/1000000, train_loss: 8.6822, val_loss: 9.8745, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1293/1000000, train_loss: 8.6798, val_loss: 9.8655, time: 0.14s\n",
      "Epoch 1294/1000000, train_loss: 8.6759, val_loss: 9.8657, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1295/1000000, train_loss: 8.6708, val_loss: 9.8571, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1296/1000000, train_loss: 8.6668, val_loss: 9.8488, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1297/1000000, train_loss: 8.6633, val_loss: 9.8447, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1298/1000000, train_loss: 8.6615, val_loss: 9.8386, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1299/1000000, train_loss: 8.6571, val_loss: 9.8338, time: 0.12s\n",
      "Epoch 1300/1000000, train_loss: 8.6531, val_loss: 9.8346, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1301/1000000, train_loss: 8.6494, val_loss: 9.8329, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1302/1000000, train_loss: 8.6458, val_loss: 9.8161, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1303/1000000, train_loss: 8.6425, val_loss: 9.8137, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1304/1000000, train_loss: 8.6412, val_loss: 9.8119, time: 0.13s\n",
      "Epoch 1305/1000000, train_loss: 8.6358, val_loss: 9.8123, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1306/1000000, train_loss: 8.6317, val_loss: 9.7978, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1307/1000000, train_loss: 8.6261, val_loss: 9.7882, time: 0.12s\n",
      "Epoch 1308/1000000, train_loss: 8.6248, val_loss: 9.7911, time: 0.12s\n",
      "Epoch 1309/1000000, train_loss: 8.6207, val_loss: 9.7912, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1310/1000000, train_loss: 8.6173, val_loss: 9.7724, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1311/1000000, train_loss: 8.6138, val_loss: 9.7670, time: 0.12s\n",
      "Epoch 1312/1000000, train_loss: 8.6095, val_loss: 9.7683, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1313/1000000, train_loss: 8.6075, val_loss: 9.7597, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1314/1000000, train_loss: 8.6026, val_loss: 9.7519, time: 0.12s\n",
      "Epoch 1315/1000000, train_loss: 8.5997, val_loss: 9.7536, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1316/1000000, train_loss: 8.5954, val_loss: 9.7516, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1317/1000000, train_loss: 8.5918, val_loss: 9.7385, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1318/1000000, train_loss: 8.5865, val_loss: 9.7367, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1319/1000000, train_loss: 8.5848, val_loss: 9.7284, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1320/1000000, train_loss: 8.5810, val_loss: 9.7284, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1321/1000000, train_loss: 8.5782, val_loss: 9.7142, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1322/1000000, train_loss: 8.5746, val_loss: 9.7135, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1323/1000000, train_loss: 8.5708, val_loss: 9.7093, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1324/1000000, train_loss: 8.5680, val_loss: 9.7066, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1325/1000000, train_loss: 8.5639, val_loss: 9.6925, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1326/1000000, train_loss: 8.5598, val_loss: 9.6908, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1327/1000000, train_loss: 8.5572, val_loss: 9.6869, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1328/1000000, train_loss: 8.5521, val_loss: 9.6832, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1329/1000000, train_loss: 8.5503, val_loss: 9.6743, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1330/1000000, train_loss: 8.5463, val_loss: 9.6656, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1331/1000000, train_loss: 8.5430, val_loss: 9.6620, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1332/1000000, train_loss: 8.5381, val_loss: 9.6578, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1333/1000000, train_loss: 8.5368, val_loss: 9.6556, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1334/1000000, train_loss: 8.5334, val_loss: 9.6457, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1335/1000000, train_loss: 8.5302, val_loss: 9.6408, time: 0.12s\n",
      "Epoch 1336/1000000, train_loss: 8.5241, val_loss: 9.6411, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1337/1000000, train_loss: 8.5209, val_loss: 9.6294, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1338/1000000, train_loss: 8.5169, val_loss: 9.6234, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1339/1000000, train_loss: 8.5153, val_loss: 9.6163, time: 0.12s\n",
      "Epoch 1340/1000000, train_loss: 8.5110, val_loss: 9.6195, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1341/1000000, train_loss: 8.5083, val_loss: 9.6120, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1342/1000000, train_loss: 8.5044, val_loss: 9.6114, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1343/1000000, train_loss: 8.5012, val_loss: 9.6018, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1344/1000000, train_loss: 8.4956, val_loss: 9.5842, time: 0.12s\n",
      "Epoch 1345/1000000, train_loss: 8.4927, val_loss: 9.5847, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1346/1000000, train_loss: 8.4890, val_loss: 9.5832, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1347/1000000, train_loss: 8.4874, val_loss: 9.5775, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1348/1000000, train_loss: 8.4824, val_loss: 9.5655, time: 0.12s\n",
      "Epoch 1349/1000000, train_loss: 8.4797, val_loss: 9.5667, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1350/1000000, train_loss: 8.4759, val_loss: 9.5618, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1351/1000000, train_loss: 8.4724, val_loss: 9.5532, time: 0.12s\n",
      "Epoch 1352/1000000, train_loss: 8.4692, val_loss: 9.5541, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1353/1000000, train_loss: 8.4657, val_loss: 9.5428, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1354/1000000, train_loss: 8.4632, val_loss: 9.5329, time: 0.12s\n",
      "Epoch 1355/1000000, train_loss: 8.4578, val_loss: 9.5330, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1356/1000000, train_loss: 8.4557, val_loss: 9.5298, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1357/1000000, train_loss: 8.4499, val_loss: 9.5258, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1358/1000000, train_loss: 8.4485, val_loss: 9.5146, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1359/1000000, train_loss: 8.4438, val_loss: 9.5131, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1360/1000000, train_loss: 8.4422, val_loss: 9.5081, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1361/1000000, train_loss: 8.4381, val_loss: 9.4987, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1362/1000000, train_loss: 8.4349, val_loss: 9.4972, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1363/1000000, train_loss: 8.4311, val_loss: 9.4940, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1364/1000000, train_loss: 8.4265, val_loss: 9.4828, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1365/1000000, train_loss: 8.4246, val_loss: 9.4804, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1366/1000000, train_loss: 8.4209, val_loss: 9.4716, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1367/1000000, train_loss: 8.4166, val_loss: 9.4689, time: 0.12s\n",
      "Epoch 1368/1000000, train_loss: 8.4137, val_loss: 9.4708, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1369/1000000, train_loss: 8.4109, val_loss: 9.4606, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1370/1000000, train_loss: 8.4087, val_loss: 9.4577, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1371/1000000, train_loss: 8.4021, val_loss: 9.4508, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1372/1000000, train_loss: 8.4001, val_loss: 9.4456, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1373/1000000, train_loss: 8.3958, val_loss: 9.4377, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1374/1000000, train_loss: 8.3936, val_loss: 9.4362, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1375/1000000, train_loss: 8.3901, val_loss: 9.4300, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1376/1000000, train_loss: 8.3867, val_loss: 9.4211, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1377/1000000, train_loss: 8.3827, val_loss: 9.4174, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1378/1000000, train_loss: 8.3795, val_loss: 9.4121, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1379/1000000, train_loss: 8.3761, val_loss: 9.4044, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1380/1000000, train_loss: 8.3719, val_loss: 9.4040, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1381/1000000, train_loss: 8.3696, val_loss: 9.3997, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1382/1000000, train_loss: 8.3658, val_loss: 9.3826, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1383/1000000, train_loss: 8.3636, val_loss: 9.3797, time: 0.12s\n",
      "Epoch 1384/1000000, train_loss: 8.3592, val_loss: 9.3803, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1385/1000000, train_loss: 8.3558, val_loss: 9.3672, time: 0.12s\n",
      "Epoch 1386/1000000, train_loss: 8.3532, val_loss: 9.3712, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1387/1000000, train_loss: 8.3497, val_loss: 9.3659, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1388/1000000, train_loss: 8.3466, val_loss: 9.3596, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1389/1000000, train_loss: 8.3417, val_loss: 9.3531, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1390/1000000, train_loss: 8.3409, val_loss: 9.3498, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1391/1000000, train_loss: 8.3370, val_loss: 9.3413, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1392/1000000, train_loss: 8.3326, val_loss: 9.3372, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1393/1000000, train_loss: 8.3295, val_loss: 9.3318, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1394/1000000, train_loss: 8.3265, val_loss: 9.3287, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1395/1000000, train_loss: 8.3242, val_loss: 9.3250, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1396/1000000, train_loss: 8.3187, val_loss: 9.3119, time: 0.12s\n",
      "Epoch 1397/1000000, train_loss: 8.3168, val_loss: 9.3133, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1398/1000000, train_loss: 8.3115, val_loss: 9.3003, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1399/1000000, train_loss: 8.3088, val_loss: 9.2990, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1400/1000000, train_loss: 8.3066, val_loss: 9.2975, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1401/1000000, train_loss: 8.3027, val_loss: 9.2937, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1402/1000000, train_loss: 8.2990, val_loss: 9.2878, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1403/1000000, train_loss: 8.2953, val_loss: 9.2856, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1404/1000000, train_loss: 8.2920, val_loss: 9.2803, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1405/1000000, train_loss: 8.2889, val_loss: 9.2733, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1406/1000000, train_loss: 8.2858, val_loss: 9.2606, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1407/1000000, train_loss: 8.2847, val_loss: 9.2593, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1408/1000000, train_loss: 8.2802, val_loss: 9.2556, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1409/1000000, train_loss: 8.2763, val_loss: 9.2502, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1410/1000000, train_loss: 8.2722, val_loss: 9.2466, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1411/1000000, train_loss: 8.2704, val_loss: 9.2407, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1412/1000000, train_loss: 8.2660, val_loss: 9.2282, time: 0.24s\n",
      "Epoch 1413/1000000, train_loss: 8.2634, val_loss: 9.2286, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1414/1000000, train_loss: 8.2582, val_loss: 9.2226, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1415/1000000, train_loss: 8.2570, val_loss: 9.2196, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1416/1000000, train_loss: 8.2540, val_loss: 9.2139, time: 0.13s\n",
      "Epoch 1417/1000000, train_loss: 8.2495, val_loss: 9.2149, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1418/1000000, train_loss: 8.2466, val_loss: 9.1971, time: 0.13s\n",
      "Epoch 1419/1000000, train_loss: 8.2438, val_loss: 9.1982, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1420/1000000, train_loss: 8.2394, val_loss: 9.1853, time: 0.14s\n",
      "Epoch 1421/1000000, train_loss: 8.2363, val_loss: 9.1892, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1422/1000000, train_loss: 8.2337, val_loss: 9.1812, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1423/1000000, train_loss: 8.2305, val_loss: 9.1723, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1424/1000000, train_loss: 8.2275, val_loss: 9.1721, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1425/1000000, train_loss: 8.2227, val_loss: 9.1637, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1426/1000000, train_loss: 8.2198, val_loss: 9.1568, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1427/1000000, train_loss: 8.2171, val_loss: 9.1500, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1428/1000000, train_loss: 8.2146, val_loss: 9.1472, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1429/1000000, train_loss: 8.2134, val_loss: 9.1415, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1430/1000000, train_loss: 8.2074, val_loss: 9.1396, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1431/1000000, train_loss: 8.2048, val_loss: 9.1313, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1432/1000000, train_loss: 8.2019, val_loss: 9.1304, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1433/1000000, train_loss: 8.1972, val_loss: 9.1271, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1434/1000000, train_loss: 8.1935, val_loss: 9.1185, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1435/1000000, train_loss: 8.1913, val_loss: 9.1136, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1436/1000000, train_loss: 8.1868, val_loss: 9.1078, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1437/1000000, train_loss: 8.1853, val_loss: 9.1064, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1438/1000000, train_loss: 8.1819, val_loss: 9.0933, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1439/1000000, train_loss: 8.1786, val_loss: 9.0892, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1440/1000000, train_loss: 8.1750, val_loss: 9.0888, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1441/1000000, train_loss: 8.1723, val_loss: 9.0802, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1442/1000000, train_loss: 8.1675, val_loss: 9.0764, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1443/1000000, train_loss: 8.1659, val_loss: 9.0695, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1444/1000000, train_loss: 8.1610, val_loss: 9.0587, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1445/1000000, train_loss: 8.1597, val_loss: 9.0573, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1446/1000000, train_loss: 8.1564, val_loss: 9.0510, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1447/1000000, train_loss: 8.1515, val_loss: 9.0450, time: 0.13s\n",
      "Epoch 1448/1000000, train_loss: 8.1498, val_loss: 9.0451, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1449/1000000, train_loss: 8.1463, val_loss: 9.0330, time: 0.12s\n",
      "Epoch 1450/1000000, train_loss: 8.1437, val_loss: 9.0334, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1451/1000000, train_loss: 8.1415, val_loss: 9.0281, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1452/1000000, train_loss: 8.1378, val_loss: 9.0232, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1453/1000000, train_loss: 8.1338, val_loss: 9.0140, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1454/1000000, train_loss: 8.1309, val_loss: 9.0109, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1455/1000000, train_loss: 8.1276, val_loss: 9.0102, time: 0.24s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1456/1000000, train_loss: 8.1254, val_loss: 9.0043, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1457/1000000, train_loss: 8.1199, val_loss: 8.9976, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1458/1000000, train_loss: 8.1200, val_loss: 8.9923, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1459/1000000, train_loss: 8.1147, val_loss: 8.9825, time: 0.14s\n",
      "Epoch 1460/1000000, train_loss: 8.1105, val_loss: 8.9838, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1461/1000000, train_loss: 8.1081, val_loss: 8.9775, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1462/1000000, train_loss: 8.1047, val_loss: 8.9631, time: 0.13s\n",
      "Epoch 1463/1000000, train_loss: 8.1023, val_loss: 8.9664, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1464/1000000, train_loss: 8.0995, val_loss: 8.9623, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1465/1000000, train_loss: 8.0947, val_loss: 8.9515, time: 0.13s\n",
      "Epoch 1466/1000000, train_loss: 8.0921, val_loss: 8.9533, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1467/1000000, train_loss: 8.0880, val_loss: 8.9495, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1468/1000000, train_loss: 8.0862, val_loss: 8.9439, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1469/1000000, train_loss: 8.0828, val_loss: 8.9342, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1470/1000000, train_loss: 8.0794, val_loss: 8.9271, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1471/1000000, train_loss: 8.0770, val_loss: 8.9220, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1472/1000000, train_loss: 8.0739, val_loss: 8.9209, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1473/1000000, train_loss: 8.0708, val_loss: 8.9146, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1474/1000000, train_loss: 8.0672, val_loss: 8.9065, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1475/1000000, train_loss: 8.0638, val_loss: 8.9035, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1476/1000000, train_loss: 8.0604, val_loss: 8.9028, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1477/1000000, train_loss: 8.0590, val_loss: 8.8889, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1478/1000000, train_loss: 8.0550, val_loss: 8.8879, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1479/1000000, train_loss: 8.0533, val_loss: 8.8830, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1480/1000000, train_loss: 8.0478, val_loss: 8.8829, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1481/1000000, train_loss: 8.0449, val_loss: 8.8698, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1482/1000000, train_loss: 8.0423, val_loss: 8.8663, time: 0.13s\n",
      "Epoch 1483/1000000, train_loss: 8.0397, val_loss: 8.8674, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1484/1000000, train_loss: 8.0353, val_loss: 8.8601, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1485/1000000, train_loss: 8.0334, val_loss: 8.8585, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1486/1000000, train_loss: 8.0319, val_loss: 8.8442, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1487/1000000, train_loss: 8.0261, val_loss: 8.8425, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1488/1000000, train_loss: 8.0254, val_loss: 8.8402, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1489/1000000, train_loss: 8.0204, val_loss: 8.8367, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1490/1000000, train_loss: 8.0186, val_loss: 8.8303, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1491/1000000, train_loss: 8.0150, val_loss: 8.8201, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1492/1000000, train_loss: 8.0127, val_loss: 8.8183, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1493/1000000, train_loss: 8.0088, val_loss: 8.8126, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1494/1000000, train_loss: 8.0056, val_loss: 8.8106, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1495/1000000, train_loss: 8.0026, val_loss: 8.8002, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1496/1000000, train_loss: 7.9997, val_loss: 8.7996, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1497/1000000, train_loss: 7.9970, val_loss: 8.7939, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1498/1000000, train_loss: 7.9946, val_loss: 8.7917, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1499/1000000, train_loss: 7.9903, val_loss: 8.7805, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1500/1000000, train_loss: 7.9861, val_loss: 8.7763, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1501/1000000, train_loss: 7.9829, val_loss: 8.7706, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1502/1000000, train_loss: 7.9826, val_loss: 8.7660, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1503/1000000, train_loss: 7.9788, val_loss: 8.7624, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1504/1000000, train_loss: 7.9754, val_loss: 8.7566, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1505/1000000, train_loss: 7.9713, val_loss: 8.7504, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1506/1000000, train_loss: 7.9699, val_loss: 8.7466, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1507/1000000, train_loss: 7.9642, val_loss: 8.7389, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1508/1000000, train_loss: 7.9625, val_loss: 8.7355, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1509/1000000, train_loss: 7.9604, val_loss: 8.7342, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1510/1000000, train_loss: 7.9575, val_loss: 8.7305, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1511/1000000, train_loss: 7.9553, val_loss: 8.7200, time: 0.12s\n",
      "Epoch 1512/1000000, train_loss: 7.9513, val_loss: 8.7230, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1513/1000000, train_loss: 7.9483, val_loss: 8.7154, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1514/1000000, train_loss: 7.9443, val_loss: 8.7115, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1515/1000000, train_loss: 7.9418, val_loss: 8.7029, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1516/1000000, train_loss: 7.9400, val_loss: 8.6912, time: 0.12s\n",
      "Epoch 1517/1000000, train_loss: 7.9363, val_loss: 8.6918, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1518/1000000, train_loss: 7.9336, val_loss: 8.6823, time: 0.13s\n",
      "Epoch 1519/1000000, train_loss: 7.9305, val_loss: 8.6838, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1520/1000000, train_loss: 7.9277, val_loss: 8.6749, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1521/1000000, train_loss: 7.9239, val_loss: 8.6706, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1522/1000000, train_loss: 7.9229, val_loss: 8.6656, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1523/1000000, train_loss: 7.9177, val_loss: 8.6592, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1524/1000000, train_loss: 7.9145, val_loss: 8.6588, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1525/1000000, train_loss: 7.9123, val_loss: 8.6499, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1526/1000000, train_loss: 7.9093, val_loss: 8.6455, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1527/1000000, train_loss: 7.9081, val_loss: 8.6415, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1528/1000000, train_loss: 7.9051, val_loss: 8.6359, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1529/1000000, train_loss: 7.9011, val_loss: 8.6270, time: 0.13s\n",
      "Epoch 1530/1000000, train_loss: 7.8966, val_loss: 8.6281, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1531/1000000, train_loss: 7.8943, val_loss: 8.6190, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1532/1000000, train_loss: 7.8932, val_loss: 8.6176, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1533/1000000, train_loss: 7.8890, val_loss: 8.6134, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1534/1000000, train_loss: 7.8871, val_loss: 8.6049, time: 0.12s\n",
      "Epoch 1535/1000000, train_loss: 7.8821, val_loss: 8.6052, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1536/1000000, train_loss: 7.8813, val_loss: 8.5937, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1537/1000000, train_loss: 7.8785, val_loss: 8.5936, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1538/1000000, train_loss: 7.8748, val_loss: 8.5902, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1539/1000000, train_loss: 7.8715, val_loss: 8.5829, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1540/1000000, train_loss: 7.8693, val_loss: 8.5826, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1541/1000000, train_loss: 7.8660, val_loss: 8.5768, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1542/1000000, train_loss: 7.8627, val_loss: 8.5718, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1543/1000000, train_loss: 7.8603, val_loss: 8.5687, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1544/1000000, train_loss: 7.8573, val_loss: 8.5613, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1545/1000000, train_loss: 7.8542, val_loss: 8.5576, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1546/1000000, train_loss: 7.8514, val_loss: 8.5491, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1547/1000000, train_loss: 7.8496, val_loss: 8.5426, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1548/1000000, train_loss: 7.8454, val_loss: 8.5409, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1549/1000000, train_loss: 7.8426, val_loss: 8.5330, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1550/1000000, train_loss: 7.8400, val_loss: 8.5263, time: 0.13s\n",
      "Epoch 1551/1000000, train_loss: 7.8370, val_loss: 8.5271, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1552/1000000, train_loss: 7.8326, val_loss: 8.5199, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1553/1000000, train_loss: 7.8320, val_loss: 8.5141, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1554/1000000, train_loss: 7.8280, val_loss: 8.5129, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1555/1000000, train_loss: 7.8258, val_loss: 8.5081, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1556/1000000, train_loss: 7.8234, val_loss: 8.4995, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1557/1000000, train_loss: 7.8203, val_loss: 8.4993, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1558/1000000, train_loss: 7.8177, val_loss: 8.4944, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1559/1000000, train_loss: 7.8149, val_loss: 8.4929, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1560/1000000, train_loss: 7.8124, val_loss: 8.4842, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1561/1000000, train_loss: 7.8097, val_loss: 8.4776, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1562/1000000, train_loss: 7.8065, val_loss: 8.4748, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1563/1000000, train_loss: 7.8031, val_loss: 8.4677, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1564/1000000, train_loss: 7.8016, val_loss: 8.4634, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1565/1000000, train_loss: 7.7981, val_loss: 8.4615, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1566/1000000, train_loss: 7.7954, val_loss: 8.4558, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1567/1000000, train_loss: 7.7929, val_loss: 8.4462, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1568/1000000, train_loss: 7.7891, val_loss: 8.4379, time: 0.12s\n",
      "Epoch 1569/1000000, train_loss: 7.7868, val_loss: 8.4427, time: 0.12s\n",
      "Epoch 1570/1000000, train_loss: 7.7850, val_loss: 8.4423, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1571/1000000, train_loss: 7.7811, val_loss: 8.4294, time: 0.12s\n",
      "Epoch 1572/1000000, train_loss: 7.7795, val_loss: 8.4331, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1573/1000000, train_loss: 7.7752, val_loss: 8.4204, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1574/1000000, train_loss: 7.7742, val_loss: 8.4202, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1575/1000000, train_loss: 7.7695, val_loss: 8.4076, time: 0.12s\n",
      "Epoch 1576/1000000, train_loss: 7.7683, val_loss: 8.4113, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1577/1000000, train_loss: 7.7648, val_loss: 8.4028, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1578/1000000, train_loss: 7.7607, val_loss: 8.3966, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1579/1000000, train_loss: 7.7603, val_loss: 8.3953, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1580/1000000, train_loss: 7.7559, val_loss: 8.3864, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1581/1000000, train_loss: 7.7531, val_loss: 8.3835, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1582/1000000, train_loss: 7.7515, val_loss: 8.3793, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1583/1000000, train_loss: 7.7499, val_loss: 8.3769, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1584/1000000, train_loss: 7.7447, val_loss: 8.3696, time: 0.13s\n",
      "Epoch 1585/1000000, train_loss: 7.7425, val_loss: 8.3697, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1586/1000000, train_loss: 7.7403, val_loss: 8.3601, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1587/1000000, train_loss: 7.7357, val_loss: 8.3565, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1588/1000000, train_loss: 7.7343, val_loss: 8.3497, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1589/1000000, train_loss: 7.7321, val_loss: 8.3437, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1590/1000000, train_loss: 7.7288, val_loss: 8.3409, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1591/1000000, train_loss: 7.7260, val_loss: 8.3368, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1592/1000000, train_loss: 7.7229, val_loss: 8.3343, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1593/1000000, train_loss: 7.7205, val_loss: 8.3322, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1594/1000000, train_loss: 7.7180, val_loss: 8.3258, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1595/1000000, train_loss: 7.7155, val_loss: 8.3234, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1596/1000000, train_loss: 7.7128, val_loss: 8.3206, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1597/1000000, train_loss: 7.7096, val_loss: 8.3124, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1598/1000000, train_loss: 7.7084, val_loss: 8.3099, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1599/1000000, train_loss: 7.7051, val_loss: 8.2982, time: 0.12s\n",
      "Epoch 1600/1000000, train_loss: 7.7018, val_loss: 8.3002, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1601/1000000, train_loss: 7.6988, val_loss: 8.2946, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1602/1000000, train_loss: 7.6973, val_loss: 8.2879, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1603/1000000, train_loss: 7.6943, val_loss: 8.2760, time: 0.12s\n",
      "Epoch 1604/1000000, train_loss: 7.6918, val_loss: 8.2822, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1605/1000000, train_loss: 7.6879, val_loss: 8.2718, time: 0.13s\n",
      "Epoch 1606/1000000, train_loss: 7.6860, val_loss: 8.2726, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1607/1000000, train_loss: 7.6835, val_loss: 8.2684, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1608/1000000, train_loss: 7.6820, val_loss: 8.2621, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1609/1000000, train_loss: 7.6772, val_loss: 8.2544, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1610/1000000, train_loss: 7.6751, val_loss: 8.2510, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1611/1000000, train_loss: 7.6723, val_loss: 8.2467, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1612/1000000, train_loss: 7.6692, val_loss: 8.2424, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1613/1000000, train_loss: 7.6674, val_loss: 8.2392, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1614/1000000, train_loss: 7.6653, val_loss: 8.2316, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1615/1000000, train_loss: 7.6622, val_loss: 8.2295, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1616/1000000, train_loss: 7.6594, val_loss: 8.2248, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1617/1000000, train_loss: 7.6580, val_loss: 8.2184, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1618/1000000, train_loss: 7.6545, val_loss: 8.2122, time: 0.12s\n",
      "Epoch 1619/1000000, train_loss: 7.6520, val_loss: 8.2163, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1620/1000000, train_loss: 7.6486, val_loss: 8.2092, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1621/1000000, train_loss: 7.6467, val_loss: 8.2016, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1622/1000000, train_loss: 7.6434, val_loss: 8.2001, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1623/1000000, train_loss: 7.6407, val_loss: 8.1969, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1624/1000000, train_loss: 7.6390, val_loss: 8.1892, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1625/1000000, train_loss: 7.6381, val_loss: 8.1849, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1626/1000000, train_loss: 7.6341, val_loss: 8.1841, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1627/1000000, train_loss: 7.6320, val_loss: 8.1763, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1628/1000000, train_loss: 7.6283, val_loss: 8.1733, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1629/1000000, train_loss: 7.6256, val_loss: 8.1718, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1630/1000000, train_loss: 7.6238, val_loss: 8.1652, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1631/1000000, train_loss: 7.6220, val_loss: 8.1624, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1632/1000000, train_loss: 7.6185, val_loss: 8.1501, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1633/1000000, train_loss: 7.6143, val_loss: 8.1498, time: 0.12s\n",
      "Epoch 1634/1000000, train_loss: 7.6120, val_loss: 8.1498, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1635/1000000, train_loss: 7.6104, val_loss: 8.1418, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1636/1000000, train_loss: 7.6087, val_loss: 8.1356, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1637/1000000, train_loss: 7.6052, val_loss: 8.1332, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1638/1000000, train_loss: 7.6028, val_loss: 8.1239, time: 0.12s\n",
      "Epoch 1639/1000000, train_loss: 7.5998, val_loss: 8.1253, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1640/1000000, train_loss: 7.5990, val_loss: 8.1202, time: 0.12s\n",
      "Epoch 1641/1000000, train_loss: 7.5951, val_loss: 8.1208, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1642/1000000, train_loss: 7.5936, val_loss: 8.1120, time: 0.12s\n",
      "Epoch 1643/1000000, train_loss: 7.5895, val_loss: 8.1121, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1644/1000000, train_loss: 7.5863, val_loss: 8.1019, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1645/1000000, train_loss: 7.5848, val_loss: 8.0996, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1646/1000000, train_loss: 7.5824, val_loss: 8.0922, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1647/1000000, train_loss: 7.5802, val_loss: 8.0916, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1648/1000000, train_loss: 7.5784, val_loss: 8.0836, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1649/1000000, train_loss: 7.5746, val_loss: 8.0831, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1650/1000000, train_loss: 7.5727, val_loss: 8.0720, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1651/1000000, train_loss: 7.5686, val_loss: 8.0703, time: 0.12s\n",
      "Epoch 1652/1000000, train_loss: 7.5661, val_loss: 8.0705, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1653/1000000, train_loss: 7.5652, val_loss: 8.0644, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1654/1000000, train_loss: 7.5623, val_loss: 8.0603, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1655/1000000, train_loss: 7.5599, val_loss: 8.0564, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1656/1000000, train_loss: 7.5569, val_loss: 8.0544, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1657/1000000, train_loss: 7.5545, val_loss: 8.0457, time: 0.12s\n",
      "Epoch 1658/1000000, train_loss: 7.5517, val_loss: 8.0479, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1659/1000000, train_loss: 7.5497, val_loss: 8.0392, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1660/1000000, train_loss: 7.5486, val_loss: 8.0345, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1661/1000000, train_loss: 7.5453, val_loss: 8.0325, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1662/1000000, train_loss: 7.5421, val_loss: 8.0238, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1663/1000000, train_loss: 7.5404, val_loss: 8.0203, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1664/1000000, train_loss: 7.5372, val_loss: 8.0182, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1665/1000000, train_loss: 7.5338, val_loss: 8.0126, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1666/1000000, train_loss: 7.5321, val_loss: 8.0107, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1667/1000000, train_loss: 7.5299, val_loss: 8.0103, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1668/1000000, train_loss: 7.5275, val_loss: 7.9989, time: 0.12s\n",
      "Epoch 1669/1000000, train_loss: 7.5248, val_loss: 7.9989, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1670/1000000, train_loss: 7.5227, val_loss: 7.9913, time: 0.12s\n",
      "Epoch 1671/1000000, train_loss: 7.5205, val_loss: 7.9954, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1672/1000000, train_loss: 7.5180, val_loss: 7.9809, time: 0.23s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1673/1000000, train_loss: 7.5144, val_loss: 7.9804, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1674/1000000, train_loss: 7.5136, val_loss: 7.9756, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1675/1000000, train_loss: 7.5104, val_loss: 7.9747, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1676/1000000, train_loss: 7.5085, val_loss: 7.9714, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1677/1000000, train_loss: 7.5055, val_loss: 7.9649, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1678/1000000, train_loss: 7.5042, val_loss: 7.9632, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1679/1000000, train_loss: 7.5011, val_loss: 7.9566, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1680/1000000, train_loss: 7.4983, val_loss: 7.9552, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1681/1000000, train_loss: 7.4960, val_loss: 7.9479, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1682/1000000, train_loss: 7.4941, val_loss: 7.9428, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1683/1000000, train_loss: 7.4916, val_loss: 7.9418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1684/1000000, train_loss: 7.4884, val_loss: 7.9350, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1685/1000000, train_loss: 7.4854, val_loss: 7.9320, time: 0.12s\n",
      "Epoch 1686/1000000, train_loss: 7.4843, val_loss: 7.9346, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1687/1000000, train_loss: 7.4808, val_loss: 7.9265, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1688/1000000, train_loss: 7.4781, val_loss: 7.9234, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1689/1000000, train_loss: 7.4755, val_loss: 7.9137, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1690/1000000, train_loss: 7.4741, val_loss: 7.9092, time: 0.13s\n",
      "Epoch 1691/1000000, train_loss: 7.4716, val_loss: 7.9107, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1692/1000000, train_loss: 7.4695, val_loss: 7.8995, time: 0.12s\n",
      "Epoch 1693/1000000, train_loss: 7.4673, val_loss: 7.9011, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1694/1000000, train_loss: 7.4649, val_loss: 7.8977, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1695/1000000, train_loss: 7.4618, val_loss: 7.8942, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1696/1000000, train_loss: 7.4611, val_loss: 7.8821, time: 0.12s\n",
      "Epoch 1697/1000000, train_loss: 7.4579, val_loss: 7.8850, time: 0.24s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1698/1000000, train_loss: 7.4558, val_loss: 7.8789, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1699/1000000, train_loss: 7.4523, val_loss: 7.8774, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1700/1000000, train_loss: 7.4499, val_loss: 7.8728, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1701/1000000, train_loss: 7.4467, val_loss: 7.8641, time: 0.12s\n",
      "Epoch 1702/1000000, train_loss: 7.4445, val_loss: 7.8662, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1703/1000000, train_loss: 7.4443, val_loss: 7.8609, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1704/1000000, train_loss: 7.4411, val_loss: 7.8560, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1705/1000000, train_loss: 7.4388, val_loss: 7.8540, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1706/1000000, train_loss: 7.4357, val_loss: 7.8449, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1707/1000000, train_loss: 7.4344, val_loss: 7.8409, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1708/1000000, train_loss: 7.4312, val_loss: 7.8409, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1709/1000000, train_loss: 7.4276, val_loss: 7.8361, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1710/1000000, train_loss: 7.4264, val_loss: 7.8343, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1711/1000000, train_loss: 7.4246, val_loss: 7.8270, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1712/1000000, train_loss: 7.4216, val_loss: 7.8242, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1713/1000000, train_loss: 7.4197, val_loss: 7.8239, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1714/1000000, train_loss: 7.4166, val_loss: 7.8111, time: 0.15s\n",
      "Epoch 1715/1000000, train_loss: 7.4148, val_loss: 7.8112, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1716/1000000, train_loss: 7.4123, val_loss: 7.8072, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1717/1000000, train_loss: 7.4094, val_loss: 7.8021, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1718/1000000, train_loss: 7.4097, val_loss: 7.7992, time: 0.12s\n",
      "Epoch 1719/1000000, train_loss: 7.4057, val_loss: 7.7998, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1720/1000000, train_loss: 7.4022, val_loss: 7.7917, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1721/1000000, train_loss: 7.4006, val_loss: 7.7875, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1722/1000000, train_loss: 7.3983, val_loss: 7.7801, time: 0.23s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1723/1000000, train_loss: 7.3954, val_loss: 7.7800, time: 0.12s\n",
      "Epoch 1724/1000000, train_loss: 7.3937, val_loss: 7.7821, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1725/1000000, train_loss: 7.3915, val_loss: 7.7727, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1726/1000000, train_loss: 7.3887, val_loss: 7.7708, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1727/1000000, train_loss: 7.3867, val_loss: 7.7635, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1728/1000000, train_loss: 7.3847, val_loss: 7.7626, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1729/1000000, train_loss: 7.3836, val_loss: 7.7543, time: 0.12s\n",
      "Epoch 1730/1000000, train_loss: 7.3790, val_loss: 7.7571, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1731/1000000, train_loss: 7.3770, val_loss: 7.7503, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1732/1000000, train_loss: 7.3752, val_loss: 7.7459, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1733/1000000, train_loss: 7.3735, val_loss: 7.7393, time: 0.12s\n",
      "Epoch 1734/1000000, train_loss: 7.3697, val_loss: 7.7432, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1735/1000000, train_loss: 7.3681, val_loss: 7.7390, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1736/1000000, train_loss: 7.3659, val_loss: 7.7252, time: 0.13s\n",
      "Epoch 1737/1000000, train_loss: 7.3641, val_loss: 7.7274, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1738/1000000, train_loss: 7.3615, val_loss: 7.7206, time: 0.12s\n",
      "Epoch 1739/1000000, train_loss: 7.3578, val_loss: 7.7214, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1740/1000000, train_loss: 7.3573, val_loss: 7.7133, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1741/1000000, train_loss: 7.3550, val_loss: 7.7133, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1742/1000000, train_loss: 7.3520, val_loss: 7.7131, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1743/1000000, train_loss: 7.3494, val_loss: 7.7079, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1744/1000000, train_loss: 7.3481, val_loss: 7.7031, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1745/1000000, train_loss: 7.3442, val_loss: 7.6977, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1746/1000000, train_loss: 7.3416, val_loss: 7.6926, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1747/1000000, train_loss: 7.3408, val_loss: 7.6913, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1748/1000000, train_loss: 7.3392, val_loss: 7.6899, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1749/1000000, train_loss: 7.3360, val_loss: 7.6826, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1750/1000000, train_loss: 7.3333, val_loss: 7.6803, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1751/1000000, train_loss: 7.3314, val_loss: 7.6766, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1752/1000000, train_loss: 7.3295, val_loss: 7.6735, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1753/1000000, train_loss: 7.3271, val_loss: 7.6709, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1754/1000000, train_loss: 7.3243, val_loss: 7.6646, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1755/1000000, train_loss: 7.3216, val_loss: 7.6576, time: 0.15s\n",
      "Epoch 1756/1000000, train_loss: 7.3194, val_loss: 7.6581, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1757/1000000, train_loss: 7.3190, val_loss: 7.6534, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1758/1000000, train_loss: 7.3153, val_loss: 7.6513, time: 0.13s\n",
      "Epoch 1759/1000000, train_loss: 7.3141, val_loss: 7.6524, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1760/1000000, train_loss: 7.3113, val_loss: 7.6436, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1761/1000000, train_loss: 7.3102, val_loss: 7.6403, time: 0.27s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1762/1000000, train_loss: 7.3057, val_loss: 7.6309, time: 0.15s\n",
      "Epoch 1763/1000000, train_loss: 7.3045, val_loss: 7.6328, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1764/1000000, train_loss: 7.3019, val_loss: 7.6251, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1765/1000000, train_loss: 7.3002, val_loss: 7.6239, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1766/1000000, train_loss: 7.2973, val_loss: 7.6232, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1767/1000000, train_loss: 7.2959, val_loss: 7.6128, time: 0.13s\n",
      "Epoch 1768/1000000, train_loss: 7.2930, val_loss: 7.6166, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1769/1000000, train_loss: 7.2915, val_loss: 7.6095, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1770/1000000, train_loss: 7.2881, val_loss: 7.6048, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1771/1000000, train_loss: 7.2858, val_loss: 7.5996, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1772/1000000, train_loss: 7.2843, val_loss: 7.5961, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1773/1000000, train_loss: 7.2809, val_loss: 7.5923, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1774/1000000, train_loss: 7.2790, val_loss: 7.5909, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1775/1000000, train_loss: 7.2783, val_loss: 7.5884, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1776/1000000, train_loss: 7.2740, val_loss: 7.5793, time: 0.12s\n",
      "Epoch 1777/1000000, train_loss: 7.2734, val_loss: 7.5840, time: 0.15s\n",
      "Epoch 1778/1000000, train_loss: 7.2714, val_loss: 7.5823, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1779/1000000, train_loss: 7.2684, val_loss: 7.5706, time: 0.28s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1780/1000000, train_loss: 7.2656, val_loss: 7.5703, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1781/1000000, train_loss: 7.2638, val_loss: 7.5645, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1782/1000000, train_loss: 7.2626, val_loss: 7.5561, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1783/1000000, train_loss: 7.2595, val_loss: 7.5527, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1784/1000000, train_loss: 7.2566, val_loss: 7.5522, time: 0.12s\n",
      "Epoch 1785/1000000, train_loss: 7.2547, val_loss: 7.5522, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1786/1000000, train_loss: 7.2527, val_loss: 7.5435, time: 0.12s\n",
      "Epoch 1787/1000000, train_loss: 7.2506, val_loss: 7.5435, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1788/1000000, train_loss: 7.2476, val_loss: 7.5419, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1789/1000000, train_loss: 7.2463, val_loss: 7.5319, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1790/1000000, train_loss: 7.2443, val_loss: 7.5297, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1791/1000000, train_loss: 7.2424, val_loss: 7.5239, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1792/1000000, train_loss: 7.2385, val_loss: 7.5236, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1793/1000000, train_loss: 7.2365, val_loss: 7.5225, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1794/1000000, train_loss: 7.2338, val_loss: 7.5216, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1795/1000000, train_loss: 7.2333, val_loss: 7.5180, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1796/1000000, train_loss: 7.2299, val_loss: 7.5097, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1797/1000000, train_loss: 7.2282, val_loss: 7.5072, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1798/1000000, train_loss: 7.2258, val_loss: 7.4976, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1799/1000000, train_loss: 7.2235, val_loss: 7.4949, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1800/1000000, train_loss: 7.2209, val_loss: 7.4940, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1801/1000000, train_loss: 7.2188, val_loss: 7.4875, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1802/1000000, train_loss: 7.2163, val_loss: 7.4871, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1803/1000000, train_loss: 7.2150, val_loss: 7.4845, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1804/1000000, train_loss: 7.2133, val_loss: 7.4760, time: 0.25s\n",
      "Epoch 1805/1000000, train_loss: 7.2109, val_loss: 7.4767, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1806/1000000, train_loss: 7.2077, val_loss: 7.4733, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1807/1000000, train_loss: 7.2070, val_loss: 7.4705, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1808/1000000, train_loss: 7.2032, val_loss: 7.4631, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1809/1000000, train_loss: 7.2011, val_loss: 7.4579, time: 0.13s\n",
      "Epoch 1810/1000000, train_loss: 7.1997, val_loss: 7.4614, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1811/1000000, train_loss: 7.1977, val_loss: 7.4562, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1812/1000000, train_loss: 7.1951, val_loss: 7.4526, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1813/1000000, train_loss: 7.1932, val_loss: 7.4464, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1814/1000000, train_loss: 7.1913, val_loss: 7.4427, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1815/1000000, train_loss: 7.1887, val_loss: 7.4411, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1816/1000000, train_loss: 7.1867, val_loss: 7.4383, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1817/1000000, train_loss: 7.1849, val_loss: 7.4281, time: 0.14s\n",
      "Epoch 1818/1000000, train_loss: 7.1827, val_loss: 7.4313, time: 0.13s\n",
      "Epoch 1819/1000000, train_loss: 7.1812, val_loss: 7.4298, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1820/1000000, train_loss: 7.1770, val_loss: 7.4191, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1821/1000000, train_loss: 7.1760, val_loss: 7.4172, time: 0.13s\n",
      "Epoch 1822/1000000, train_loss: 7.1737, val_loss: 7.4193, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1823/1000000, train_loss: 7.1709, val_loss: 7.4105, time: 0.18s\n",
      "Epoch 1824/1000000, train_loss: 7.1697, val_loss: 7.4126, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1825/1000000, train_loss: 7.1676, val_loss: 7.3981, time: 0.14s\n",
      "Epoch 1826/1000000, train_loss: 7.1651, val_loss: 7.3981, time: 0.13s\n",
      "Epoch 1827/1000000, train_loss: 7.1627, val_loss: 7.4001, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1828/1000000, train_loss: 7.1604, val_loss: 7.3938, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1829/1000000, train_loss: 7.1580, val_loss: 7.3892, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1830/1000000, train_loss: 7.1572, val_loss: 7.3886, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1831/1000000, train_loss: 7.1548, val_loss: 7.3859, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1832/1000000, train_loss: 7.1509, val_loss: 7.3769, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1833/1000000, train_loss: 7.1499, val_loss: 7.3765, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1834/1000000, train_loss: 7.1481, val_loss: 7.3701, time: 0.13s\n",
      "Epoch 1835/1000000, train_loss: 7.1458, val_loss: 7.3721, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1836/1000000, train_loss: 7.1442, val_loss: 7.3669, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1837/1000000, train_loss: 7.1423, val_loss: 7.3620, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1838/1000000, train_loss: 7.1394, val_loss: 7.3613, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1839/1000000, train_loss: 7.1380, val_loss: 7.3543, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1840/1000000, train_loss: 7.1356, val_loss: 7.3495, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1841/1000000, train_loss: 7.1324, val_loss: 7.3458, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1842/1000000, train_loss: 7.1316, val_loss: 7.3447, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1843/1000000, train_loss: 7.1290, val_loss: 7.3428, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1844/1000000, train_loss: 7.1271, val_loss: 7.3415, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1845/1000000, train_loss: 7.1252, val_loss: 7.3336, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1846/1000000, train_loss: 7.1220, val_loss: 7.3243, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1847/1000000, train_loss: 7.1208, val_loss: 7.3198, time: 0.14s\n",
      "Epoch 1848/1000000, train_loss: 7.1186, val_loss: 7.3245, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1849/1000000, train_loss: 7.1159, val_loss: 7.3148, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1850/1000000, train_loss: 7.1138, val_loss: 7.3128, time: 0.13s\n",
      "Epoch 1851/1000000, train_loss: 7.1110, val_loss: 7.3152, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1852/1000000, train_loss: 7.1095, val_loss: 7.3081, time: 0.12s\n",
      "Epoch 1853/1000000, train_loss: 7.1076, val_loss: 7.3093, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1854/1000000, train_loss: 7.1053, val_loss: 7.3031, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1855/1000000, train_loss: 7.1027, val_loss: 7.2960, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1856/1000000, train_loss: 7.1012, val_loss: 7.2930, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1857/1000000, train_loss: 7.0992, val_loss: 7.2905, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1858/1000000, train_loss: 7.0979, val_loss: 7.2842, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1859/1000000, train_loss: 7.0943, val_loss: 7.2822, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1860/1000000, train_loss: 7.0923, val_loss: 7.2809, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1861/1000000, train_loss: 7.0911, val_loss: 7.2769, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1862/1000000, train_loss: 7.0900, val_loss: 7.2728, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1863/1000000, train_loss: 7.0867, val_loss: 7.2684, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1864/1000000, train_loss: 7.0861, val_loss: 7.2655, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1865/1000000, train_loss: 7.0819, val_loss: 7.2624, time: 0.26s\n",
      "Epoch 1866/1000000, train_loss: 7.0805, val_loss: 7.2626, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1867/1000000, train_loss: 7.0789, val_loss: 7.2512, time: 0.15s\n",
      "Epoch 1868/1000000, train_loss: 7.0777, val_loss: 7.2536, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1869/1000000, train_loss: 7.0746, val_loss: 7.2450, time: 0.12s\n",
      "Epoch 1870/1000000, train_loss: 7.0720, val_loss: 7.2451, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1871/1000000, train_loss: 7.0707, val_loss: 7.2435, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1872/1000000, train_loss: 7.0678, val_loss: 7.2378, time: 0.13s\n",
      "Epoch 1873/1000000, train_loss: 7.0660, val_loss: 7.2390, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1874/1000000, train_loss: 7.0647, val_loss: 7.2286, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1875/1000000, train_loss: 7.0624, val_loss: 7.2232, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1876/1000000, train_loss: 7.0600, val_loss: 7.2223, time: 0.12s\n",
      "Epoch 1877/1000000, train_loss: 7.0584, val_loss: 7.2235, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1878/1000000, train_loss: 7.0556, val_loss: 7.2141, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1879/1000000, train_loss: 7.0544, val_loss: 7.2099, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1880/1000000, train_loss: 7.0517, val_loss: 7.2078, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1881/1000000, train_loss: 7.0506, val_loss: 7.2076, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1882/1000000, train_loss: 7.0482, val_loss: 7.2031, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1883/1000000, train_loss: 7.0455, val_loss: 7.2002, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1884/1000000, train_loss: 7.0442, val_loss: 7.1985, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1885/1000000, train_loss: 7.0416, val_loss: 7.1910, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1886/1000000, train_loss: 7.0397, val_loss: 7.1904, time: 0.12s\n",
      "Epoch 1887/1000000, train_loss: 7.0369, val_loss: 7.1908, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1888/1000000, train_loss: 7.0356, val_loss: 7.1807, time: 0.14s\n",
      "Epoch 1889/1000000, train_loss: 7.0336, val_loss: 7.1809, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1890/1000000, train_loss: 7.0312, val_loss: 7.1736, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1891/1000000, train_loss: 7.0288, val_loss: 7.1676, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1892/1000000, train_loss: 7.0280, val_loss: 7.1664, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1893/1000000, train_loss: 7.0259, val_loss: 7.1622, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1894/1000000, train_loss: 7.0228, val_loss: 7.1571, time: 0.13s\n",
      "Epoch 1895/1000000, train_loss: 7.0222, val_loss: 7.1580, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1896/1000000, train_loss: 7.0193, val_loss: 7.1512, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1897/1000000, train_loss: 7.0171, val_loss: 7.1502, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1898/1000000, train_loss: 7.0151, val_loss: 7.1498, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1899/1000000, train_loss: 7.0133, val_loss: 7.1418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1900/1000000, train_loss: 7.0117, val_loss: 7.1379, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1901/1000000, train_loss: 7.0098, val_loss: 7.1327, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1902/1000000, train_loss: 7.0073, val_loss: 7.1307, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1903/1000000, train_loss: 7.0046, val_loss: 7.1263, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1904/1000000, train_loss: 7.0037, val_loss: 7.1209, time: 0.13s\n",
      "Epoch 1905/1000000, train_loss: 7.0018, val_loss: 7.1232, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1906/1000000, train_loss: 7.0002, val_loss: 7.1191, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1907/1000000, train_loss: 6.9965, val_loss: 7.1140, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1908/1000000, train_loss: 6.9964, val_loss: 7.1105, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1909/1000000, train_loss: 6.9933, val_loss: 7.1070, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1910/1000000, train_loss: 6.9915, val_loss: 7.1035, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1911/1000000, train_loss: 6.9903, val_loss: 7.1013, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1912/1000000, train_loss: 6.9875, val_loss: 7.0982, time: 0.25s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1913/1000000, train_loss: 6.9856, val_loss: 7.0933, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1914/1000000, train_loss: 6.9850, val_loss: 7.0854, time: 0.12s\n",
      "Epoch 1915/1000000, train_loss: 6.9817, val_loss: 7.0859, time: 0.13s\n",
      "Epoch 1916/1000000, train_loss: 6.9796, val_loss: 7.0867, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1917/1000000, train_loss: 6.9780, val_loss: 7.0790, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1918/1000000, train_loss: 6.9754, val_loss: 7.0729, time: 0.12s\n",
      "Epoch 1919/1000000, train_loss: 6.9734, val_loss: 7.0731, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1920/1000000, train_loss: 6.9716, val_loss: 7.0708, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1921/1000000, train_loss: 6.9711, val_loss: 7.0633, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1922/1000000, train_loss: 6.9676, val_loss: 7.0626, time: 0.12s\n",
      "Epoch 1923/1000000, train_loss: 6.9659, val_loss: 7.0631, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1924/1000000, train_loss: 6.9643, val_loss: 7.0512, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1925/1000000, train_loss: 6.9624, val_loss: 7.0476, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1926/1000000, train_loss: 6.9608, val_loss: 7.0439, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1927/1000000, train_loss: 6.9585, val_loss: 7.0425, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1928/1000000, train_loss: 6.9570, val_loss: 7.0422, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1929/1000000, train_loss: 6.9546, val_loss: 7.0379, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1930/1000000, train_loss: 6.9521, val_loss: 7.0341, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1931/1000000, train_loss: 6.9511, val_loss: 7.0318, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1932/1000000, train_loss: 6.9494, val_loss: 7.0291, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1933/1000000, train_loss: 6.9468, val_loss: 7.0232, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1934/1000000, train_loss: 6.9437, val_loss: 7.0228, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1935/1000000, train_loss: 6.9433, val_loss: 7.0138, time: 0.20s\n",
      "Epoch 1936/1000000, train_loss: 6.9407, val_loss: 7.0154, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1937/1000000, train_loss: 6.9389, val_loss: 7.0079, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1938/1000000, train_loss: 6.9371, val_loss: 7.0077, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1939/1000000, train_loss: 6.9362, val_loss: 7.0046, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1940/1000000, train_loss: 6.9336, val_loss: 7.0009, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1941/1000000, train_loss: 6.9312, val_loss: 6.9934, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1942/1000000, train_loss: 6.9287, val_loss: 6.9929, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1943/1000000, train_loss: 6.9266, val_loss: 6.9898, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1944/1000000, train_loss: 6.9250, val_loss: 6.9861, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1945/1000000, train_loss: 6.9240, val_loss: 6.9834, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1946/1000000, train_loss: 6.9231, val_loss: 6.9747, time: 0.15s\n",
      "Epoch 1947/1000000, train_loss: 6.9199, val_loss: 6.9754, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1948/1000000, train_loss: 6.9180, val_loss: 6.9706, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1949/1000000, train_loss: 6.9154, val_loss: 6.9657, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1950/1000000, train_loss: 6.9154, val_loss: 6.9583, time: 0.13s\n",
      "Epoch 1951/1000000, train_loss: 6.9126, val_loss: 6.9595, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1952/1000000, train_loss: 6.9117, val_loss: 6.9572, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1953/1000000, train_loss: 6.9089, val_loss: 6.9533, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1954/1000000, train_loss: 6.9062, val_loss: 6.9526, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1955/1000000, train_loss: 6.9053, val_loss: 6.9459, time: 0.13s\n",
      "Epoch 1956/1000000, train_loss: 6.9038, val_loss: 6.9467, time: 0.13s\n",
      "Epoch 1957/1000000, train_loss: 6.9012, val_loss: 6.9474, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1958/1000000, train_loss: 6.8985, val_loss: 6.9350, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1959/1000000, train_loss: 6.8981, val_loss: 6.9311, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1960/1000000, train_loss: 6.8958, val_loss: 6.9251, time: 0.17s\n",
      "Epoch 1961/1000000, train_loss: 6.8936, val_loss: 6.9260, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1962/1000000, train_loss: 6.8913, val_loss: 6.9226, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1963/1000000, train_loss: 6.8895, val_loss: 6.9192, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1964/1000000, train_loss: 6.8876, val_loss: 6.9151, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1965/1000000, train_loss: 6.8860, val_loss: 6.9113, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1966/1000000, train_loss: 6.8845, val_loss: 6.9091, time: 0.12s\n",
      "Epoch 1967/1000000, train_loss: 6.8827, val_loss: 6.9093, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1968/1000000, train_loss: 6.8805, val_loss: 6.9021, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1969/1000000, train_loss: 6.8794, val_loss: 6.8960, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1970/1000000, train_loss: 6.8775, val_loss: 6.8920, time: 0.12s\n",
      "Epoch 1971/1000000, train_loss: 6.8752, val_loss: 6.8922, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1972/1000000, train_loss: 6.8731, val_loss: 6.8827, time: 0.12s\n",
      "Epoch 1973/1000000, train_loss: 6.8717, val_loss: 6.8875, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1974/1000000, train_loss: 6.8692, val_loss: 6.8808, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1975/1000000, train_loss: 6.8685, val_loss: 6.8763, time: 0.12s\n",
      "Epoch 1976/1000000, train_loss: 6.8657, val_loss: 6.8763, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1977/1000000, train_loss: 6.8647, val_loss: 6.8682, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1978/1000000, train_loss: 6.8631, val_loss: 6.8681, time: 0.12s\n",
      "Epoch 1979/1000000, train_loss: 6.8610, val_loss: 6.8683, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1980/1000000, train_loss: 6.8590, val_loss: 6.8619, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1981/1000000, train_loss: 6.8581, val_loss: 6.8517, time: 0.14s\n",
      "Epoch 1982/1000000, train_loss: 6.8551, val_loss: 6.8541, time: 0.21s\n",
      "Epoch 1983/1000000, train_loss: 6.8541, val_loss: 6.8518, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1984/1000000, train_loss: 6.8522, val_loss: 6.8458, time: 0.14s\n",
      "Epoch 1985/1000000, train_loss: 6.8510, val_loss: 6.8459, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1986/1000000, train_loss: 6.8471, val_loss: 6.8386, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1987/1000000, train_loss: 6.8466, val_loss: 6.8361, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1988/1000000, train_loss: 6.8444, val_loss: 6.8346, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1989/1000000, train_loss: 6.8428, val_loss: 6.8251, time: 0.12s\n",
      "Epoch 1990/1000000, train_loss: 6.8408, val_loss: 6.8267, time: 0.12s\n",
      "Epoch 1991/1000000, train_loss: 6.8394, val_loss: 6.8256, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1992/1000000, train_loss: 6.8383, val_loss: 6.8145, time: 0.13s\n",
      "Epoch 1993/1000000, train_loss: 6.8357, val_loss: 6.8177, time: 0.14s\n",
      "Epoch 1994/1000000, train_loss: 6.8340, val_loss: 6.8165, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1995/1000000, train_loss: 6.8320, val_loss: 6.8042, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1996/1000000, train_loss: 6.8310, val_loss: 6.8020, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1997/1000000, train_loss: 6.8293, val_loss: 6.8016, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 1998/1000000, train_loss: 6.8270, val_loss: 6.7915, time: 0.13s\n",
      "Epoch 1999/1000000, train_loss: 6.8255, val_loss: 6.7964, time: 0.20s\n",
      "Epoch 2000/1000000, train_loss: 6.8240, val_loss: 6.7942, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2001/1000000, train_loss: 6.8215, val_loss: 6.7840, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2002/1000000, train_loss: 6.8192, val_loss: 6.7808, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2003/1000000, train_loss: 6.8173, val_loss: 6.7789, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2004/1000000, train_loss: 6.8157, val_loss: 6.7773, time: 0.13s\n",
      "Epoch 2005/1000000, train_loss: 6.8141, val_loss: 6.7782, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2006/1000000, train_loss: 6.8123, val_loss: 6.7688, time: 0.13s\n",
      "Epoch 2007/1000000, train_loss: 6.8109, val_loss: 6.7710, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2008/1000000, train_loss: 6.8086, val_loss: 6.7636, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2009/1000000, train_loss: 6.8075, val_loss: 6.7592, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2010/1000000, train_loss: 6.8055, val_loss: 6.7561, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2011/1000000, train_loss: 6.8036, val_loss: 6.7516, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2012/1000000, train_loss: 6.8022, val_loss: 6.7459, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2013/1000000, train_loss: 6.8003, val_loss: 6.7440, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2014/1000000, train_loss: 6.7988, val_loss: 6.7426, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2015/1000000, train_loss: 6.7971, val_loss: 6.7361, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2016/1000000, train_loss: 6.7951, val_loss: 6.7330, time: 0.14s\n",
      "Epoch 2017/1000000, train_loss: 6.7937, val_loss: 6.7341, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2018/1000000, train_loss: 6.7920, val_loss: 6.7296, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2019/1000000, train_loss: 6.7907, val_loss: 6.7254, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2020/1000000, train_loss: 6.7887, val_loss: 6.7179, time: 0.14s\n",
      "Epoch 2021/1000000, train_loss: 6.7873, val_loss: 6.7195, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2022/1000000, train_loss: 6.7867, val_loss: 6.7124, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2023/1000000, train_loss: 6.7829, val_loss: 6.7113, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2024/1000000, train_loss: 6.7826, val_loss: 6.7101, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2025/1000000, train_loss: 6.7804, val_loss: 6.7019, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2026/1000000, train_loss: 6.7787, val_loss: 6.6974, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2027/1000000, train_loss: 6.7768, val_loss: 6.6954, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2028/1000000, train_loss: 6.7751, val_loss: 6.6906, time: 0.13s\n",
      "Epoch 2029/1000000, train_loss: 6.7733, val_loss: 6.6909, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2030/1000000, train_loss: 6.7725, val_loss: 6.6829, time: 0.12s\n",
      "Epoch 2031/1000000, train_loss: 6.7697, val_loss: 6.6843, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2032/1000000, train_loss: 6.7681, val_loss: 6.6786, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2033/1000000, train_loss: 6.7670, val_loss: 6.6738, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2034/1000000, train_loss: 6.7648, val_loss: 6.6725, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2035/1000000, train_loss: 6.7635, val_loss: 6.6674, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2036/1000000, train_loss: 6.7616, val_loss: 6.6673, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2037/1000000, train_loss: 6.7606, val_loss: 6.6626, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2038/1000000, train_loss: 6.7586, val_loss: 6.6604, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2039/1000000, train_loss: 6.7572, val_loss: 6.6547, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2040/1000000, train_loss: 6.7552, val_loss: 6.6489, time: 0.13s\n",
      "Epoch 2041/1000000, train_loss: 6.7535, val_loss: 6.6520, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2042/1000000, train_loss: 6.7524, val_loss: 6.6462, time: 0.21s\n",
      "Epoch 2043/1000000, train_loss: 6.7507, val_loss: 6.6471, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2044/1000000, train_loss: 6.7493, val_loss: 6.6365, time: 0.13s\n",
      "Epoch 2045/1000000, train_loss: 6.7477, val_loss: 6.6381, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2046/1000000, train_loss: 6.7456, val_loss: 6.6333, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2047/1000000, train_loss: 6.7439, val_loss: 6.6309, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2048/1000000, train_loss: 6.7425, val_loss: 6.6253, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2049/1000000, train_loss: 6.7407, val_loss: 6.6229, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2050/1000000, train_loss: 6.7395, val_loss: 6.6211, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2051/1000000, train_loss: 6.7379, val_loss: 6.6181, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2052/1000000, train_loss: 6.7357, val_loss: 6.6102, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2053/1000000, train_loss: 6.7344, val_loss: 6.6072, time: 0.14s\n",
      "Epoch 2054/1000000, train_loss: 6.7328, val_loss: 6.6087, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2055/1000000, train_loss: 6.7312, val_loss: 6.5972, time: 0.12s\n",
      "Epoch 2056/1000000, train_loss: 6.7304, val_loss: 6.5988, time: 0.14s\n",
      "Epoch 2057/1000000, train_loss: 6.7281, val_loss: 6.6017, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2058/1000000, train_loss: 6.7268, val_loss: 6.5915, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2059/1000000, train_loss: 6.7247, val_loss: 6.5847, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2060/1000000, train_loss: 6.7237, val_loss: 6.5847, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2061/1000000, train_loss: 6.7222, val_loss: 6.5785, time: 0.13s\n",
      "Epoch 2062/1000000, train_loss: 6.7200, val_loss: 6.5840, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2063/1000000, train_loss: 6.7187, val_loss: 6.5781, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2064/1000000, train_loss: 6.7172, val_loss: 6.5671, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2065/1000000, train_loss: 6.7157, val_loss: 6.5635, time: 0.12s\n",
      "Epoch 2066/1000000, train_loss: 6.7136, val_loss: 6.5639, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2067/1000000, train_loss: 6.7131, val_loss: 6.5588, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2068/1000000, train_loss: 6.7115, val_loss: 6.5534, time: 0.13s\n",
      "Epoch 2069/1000000, train_loss: 6.7089, val_loss: 6.5552, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2070/1000000, train_loss: 6.7078, val_loss: 6.5474, time: 0.12s\n",
      "Epoch 2071/1000000, train_loss: 6.7061, val_loss: 6.5490, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2072/1000000, train_loss: 6.7051, val_loss: 6.5460, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2073/1000000, train_loss: 6.7033, val_loss: 6.5447, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2074/1000000, train_loss: 6.7027, val_loss: 6.5378, time: 0.14s\n",
      "Epoch 2075/1000000, train_loss: 6.6995, val_loss: 6.5382, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2076/1000000, train_loss: 6.6982, val_loss: 6.5239, time: 0.13s\n",
      "Epoch 2077/1000000, train_loss: 6.6967, val_loss: 6.5283, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2078/1000000, train_loss: 6.6952, val_loss: 6.5203, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2079/1000000, train_loss: 6.6946, val_loss: 6.5194, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2080/1000000, train_loss: 6.6922, val_loss: 6.5180, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2081/1000000, train_loss: 6.6914, val_loss: 6.5114, time: 0.12s\n",
      "Epoch 2082/1000000, train_loss: 6.6895, val_loss: 6.5153, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2083/1000000, train_loss: 6.6887, val_loss: 6.5048, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2084/1000000, train_loss: 6.6871, val_loss: 6.4982, time: 0.12s\n",
      "Epoch 2085/1000000, train_loss: 6.6842, val_loss: 6.5000, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2086/1000000, train_loss: 6.6844, val_loss: 6.4954, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2087/1000000, train_loss: 6.6812, val_loss: 6.4909, time: 0.14s\n",
      "Epoch 2088/1000000, train_loss: 6.6811, val_loss: 6.4928, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2089/1000000, train_loss: 6.6789, val_loss: 6.4830, time: 0.12s\n",
      "Epoch 2090/1000000, train_loss: 6.6767, val_loss: 6.4863, time: 0.12s\n",
      "Epoch 2091/1000000, train_loss: 6.6761, val_loss: 6.4849, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2092/1000000, train_loss: 6.6746, val_loss: 6.4786, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2093/1000000, train_loss: 6.6741, val_loss: 6.4740, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2094/1000000, train_loss: 6.6717, val_loss: 6.4671, time: 0.13s\n",
      "Epoch 2095/1000000, train_loss: 6.6702, val_loss: 6.4696, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2096/1000000, train_loss: 6.6689, val_loss: 6.4616, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2097/1000000, train_loss: 6.6677, val_loss: 6.4560, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2098/1000000, train_loss: 6.6647, val_loss: 6.4537, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2099/1000000, train_loss: 6.6635, val_loss: 6.4516, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2100/1000000, train_loss: 6.6629, val_loss: 6.4473, time: 0.12s\n",
      "Epoch 2101/1000000, train_loss: 6.6611, val_loss: 6.4515, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2102/1000000, train_loss: 6.6594, val_loss: 6.4389, time: 0.14s\n",
      "Epoch 2103/1000000, train_loss: 6.6584, val_loss: 6.4390, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2104/1000000, train_loss: 6.6578, val_loss: 6.4358, time: 0.13s\n",
      "Epoch 2105/1000000, train_loss: 6.6558, val_loss: 6.4370, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2106/1000000, train_loss: 6.6549, val_loss: 6.4295, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2107/1000000, train_loss: 6.6533, val_loss: 6.4286, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2108/1000000, train_loss: 6.6511, val_loss: 6.4204, time: 0.15s\n",
      "Epoch 2109/1000000, train_loss: 6.6496, val_loss: 6.4240, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2110/1000000, train_loss: 6.6478, val_loss: 6.4088, time: 0.12s\n",
      "Epoch 2111/1000000, train_loss: 6.6467, val_loss: 6.4149, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2112/1000000, train_loss: 6.6452, val_loss: 6.4079, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2113/1000000, train_loss: 6.6439, val_loss: 6.4067, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2114/1000000, train_loss: 6.6428, val_loss: 6.3999, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2115/1000000, train_loss: 6.6405, val_loss: 6.3950, time: 0.12s\n",
      "Epoch 2116/1000000, train_loss: 6.6402, val_loss: 6.3964, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2117/1000000, train_loss: 6.6387, val_loss: 6.3860, time: 0.12s\n",
      "Epoch 2118/1000000, train_loss: 6.6370, val_loss: 6.3873, time: 0.12s\n",
      "Epoch 2119/1000000, train_loss: 6.6362, val_loss: 6.3903, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2120/1000000, train_loss: 6.6343, val_loss: 6.3823, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2121/1000000, train_loss: 6.6329, val_loss: 6.3784, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2122/1000000, train_loss: 6.6310, val_loss: 6.3757, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2123/1000000, train_loss: 6.6307, val_loss: 6.3738, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2124/1000000, train_loss: 6.6287, val_loss: 6.3622, time: 0.12s\n",
      "Epoch 2125/1000000, train_loss: 6.6270, val_loss: 6.3660, time: 0.13s\n",
      "Epoch 2126/1000000, train_loss: 6.6262, val_loss: 6.3632, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2127/1000000, train_loss: 6.6244, val_loss: 6.3561, time: 0.12s\n",
      "Epoch 2128/1000000, train_loss: 6.6225, val_loss: 6.3566, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2129/1000000, train_loss: 6.6209, val_loss: 6.3478, time: 0.13s\n",
      "Epoch 2130/1000000, train_loss: 6.6202, val_loss: 6.3489, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2131/1000000, train_loss: 6.6187, val_loss: 6.3460, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2132/1000000, train_loss: 6.6170, val_loss: 6.3357, time: 0.13s\n",
      "Epoch 2133/1000000, train_loss: 6.6157, val_loss: 6.3431, time: 0.12s\n",
      "Epoch 2134/1000000, train_loss: 6.6149, val_loss: 6.3368, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2135/1000000, train_loss: 6.6137, val_loss: 6.3345, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2136/1000000, train_loss: 6.6112, val_loss: 6.3324, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2137/1000000, train_loss: 6.6105, val_loss: 6.3267, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2138/1000000, train_loss: 6.6087, val_loss: 6.3230, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2139/1000000, train_loss: 6.6076, val_loss: 6.3226, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2140/1000000, train_loss: 6.6068, val_loss: 6.3104, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2141/1000000, train_loss: 6.6057, val_loss: 6.3097, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2142/1000000, train_loss: 6.6046, val_loss: 6.2993, time: 0.12s\n",
      "Epoch 2143/1000000, train_loss: 6.6024, val_loss: 6.3047, time: 0.13s\n",
      "Epoch 2144/1000000, train_loss: 6.6009, val_loss: 6.2996, time: 0.13s\n",
      "Epoch 2145/1000000, train_loss: 6.6007, val_loss: 6.2997, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2146/1000000, train_loss: 6.5980, val_loss: 6.2985, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2147/1000000, train_loss: 6.5964, val_loss: 6.2913, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2148/1000000, train_loss: 6.5962, val_loss: 6.2888, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2149/1000000, train_loss: 6.5944, val_loss: 6.2795, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2150/1000000, train_loss: 6.5944, val_loss: 6.2787, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2151/1000000, train_loss: 6.5919, val_loss: 6.2778, time: 0.14s\n",
      "Epoch 2152/1000000, train_loss: 6.5907, val_loss: 6.2802, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2153/1000000, train_loss: 6.5894, val_loss: 6.2684, time: 0.13s\n",
      "Epoch 2154/1000000, train_loss: 6.5886, val_loss: 6.2698, time: 0.13s\n",
      "Epoch 2155/1000000, train_loss: 6.5876, val_loss: 6.2696, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2156/1000000, train_loss: 6.5849, val_loss: 6.2608, time: 0.12s\n",
      "Epoch 2157/1000000, train_loss: 6.5845, val_loss: 6.2611, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2158/1000000, train_loss: 6.5834, val_loss: 6.2607, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2159/1000000, train_loss: 6.5821, val_loss: 6.2529, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2160/1000000, train_loss: 6.5800, val_loss: 6.2431, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2161/1000000, train_loss: 6.5793, val_loss: 6.2428, time: 0.12s\n",
      "Epoch 2162/1000000, train_loss: 6.5778, val_loss: 6.2438, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2163/1000000, train_loss: 6.5766, val_loss: 6.2411, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2164/1000000, train_loss: 6.5753, val_loss: 6.2282, time: 0.13s\n",
      "Epoch 2165/1000000, train_loss: 6.5744, val_loss: 6.2322, time: 0.12s\n",
      "Epoch 2166/1000000, train_loss: 6.5732, val_loss: 6.2302, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2167/1000000, train_loss: 6.5722, val_loss: 6.2242, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2168/1000000, train_loss: 6.5703, val_loss: 6.2229, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2169/1000000, train_loss: 6.5702, val_loss: 6.2194, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2170/1000000, train_loss: 6.5684, val_loss: 6.2182, time: 0.12s\n",
      "Epoch 2171/1000000, train_loss: 6.5663, val_loss: 6.2219, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2172/1000000, train_loss: 6.5654, val_loss: 6.2156, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2173/1000000, train_loss: 6.5647, val_loss: 6.2060, time: 0.12s\n",
      "Epoch 2174/1000000, train_loss: 6.5642, val_loss: 6.2111, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2175/1000000, train_loss: 6.5623, val_loss: 6.1925, time: 0.12s\n",
      "Epoch 2176/1000000, train_loss: 6.5611, val_loss: 6.1982, time: 0.12s\n",
      "Epoch 2177/1000000, train_loss: 6.5597, val_loss: 6.1977, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2178/1000000, train_loss: 6.5581, val_loss: 6.1925, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2179/1000000, train_loss: 6.5579, val_loss: 6.1905, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2180/1000000, train_loss: 6.5563, val_loss: 6.1804, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2181/1000000, train_loss: 6.5556, val_loss: 6.1774, time: 0.13s\n",
      "Epoch 2182/1000000, train_loss: 6.5533, val_loss: 6.1780, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2183/1000000, train_loss: 6.5527, val_loss: 6.1743, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2184/1000000, train_loss: 6.5518, val_loss: 6.1725, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2185/1000000, train_loss: 6.5506, val_loss: 6.1644, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2186/1000000, train_loss: 6.5488, val_loss: 6.1638, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2187/1000000, train_loss: 6.5480, val_loss: 6.1594, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2188/1000000, train_loss: 6.5462, val_loss: 6.1577, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2189/1000000, train_loss: 6.5454, val_loss: 6.1542, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2190/1000000, train_loss: 6.5444, val_loss: 6.1468, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2191/1000000, train_loss: 6.5431, val_loss: 6.1452, time: 0.12s\n",
      "Epoch 2192/1000000, train_loss: 6.5425, val_loss: 6.1501, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2193/1000000, train_loss: 6.5412, val_loss: 6.1404, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2194/1000000, train_loss: 6.5404, val_loss: 6.1401, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2195/1000000, train_loss: 6.5386, val_loss: 6.1338, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2196/1000000, train_loss: 6.5373, val_loss: 6.1310, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2197/1000000, train_loss: 6.5363, val_loss: 6.1304, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2198/1000000, train_loss: 6.5352, val_loss: 6.1256, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2199/1000000, train_loss: 6.5338, val_loss: 6.1217, time: 0.14s\n",
      "Epoch 2200/1000000, train_loss: 6.5337, val_loss: 6.1220, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2201/1000000, train_loss: 6.5324, val_loss: 6.1187, time: 0.13s\n",
      "Epoch 2202/1000000, train_loss: 6.5306, val_loss: 6.1206, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2203/1000000, train_loss: 6.5296, val_loss: 6.1070, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2204/1000000, train_loss: 6.5290, val_loss: 6.1062, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2205/1000000, train_loss: 6.5273, val_loss: 6.1008, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2206/1000000, train_loss: 6.5266, val_loss: 6.0963, time: 0.12s\n",
      "Epoch 2207/1000000, train_loss: 6.5251, val_loss: 6.1013, time: 0.13s\n",
      "Epoch 2208/1000000, train_loss: 6.5246, val_loss: 6.1040, time: 0.12s\n",
      "Epoch 2209/1000000, train_loss: 6.5228, val_loss: 6.0985, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2210/1000000, train_loss: 6.5218, val_loss: 6.0945, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2211/1000000, train_loss: 6.5206, val_loss: 6.0912, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2212/1000000, train_loss: 6.5192, val_loss: 6.0874, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2213/1000000, train_loss: 6.5185, val_loss: 6.0772, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2214/1000000, train_loss: 6.5170, val_loss: 6.0772, time: 0.13s\n",
      "Epoch 2215/1000000, train_loss: 6.5158, val_loss: 6.0799, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2216/1000000, train_loss: 6.5149, val_loss: 6.0727, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2217/1000000, train_loss: 6.5143, val_loss: 6.0714, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2218/1000000, train_loss: 6.5139, val_loss: 6.0672, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2219/1000000, train_loss: 6.5123, val_loss: 6.0564, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2220/1000000, train_loss: 6.5108, val_loss: 6.0543, time: 0.15s\n",
      "Epoch 2221/1000000, train_loss: 6.5092, val_loss: 6.0553, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2222/1000000, train_loss: 6.5088, val_loss: 6.0510, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2223/1000000, train_loss: 6.5073, val_loss: 6.0468, time: 0.22s\n",
      "Epoch 2224/1000000, train_loss: 6.5073, val_loss: 6.0498, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2225/1000000, train_loss: 6.5060, val_loss: 6.0416, time: 0.12s\n",
      "Epoch 2226/1000000, train_loss: 6.5052, val_loss: 6.0418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2227/1000000, train_loss: 6.5043, val_loss: 6.0386, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2228/1000000, train_loss: 6.5027, val_loss: 6.0326, time: 0.12s\n",
      "Epoch 2229/1000000, train_loss: 6.5022, val_loss: 6.0344, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2230/1000000, train_loss: 6.5004, val_loss: 6.0253, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2231/1000000, train_loss: 6.4997, val_loss: 6.0234, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2232/1000000, train_loss: 6.4987, val_loss: 6.0222, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2233/1000000, train_loss: 6.4984, val_loss: 6.0205, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2234/1000000, train_loss: 6.4969, val_loss: 6.0127, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2235/1000000, train_loss: 6.4962, val_loss: 6.0098, time: 0.13s\n",
      "Epoch 2236/1000000, train_loss: 6.4951, val_loss: 6.0123, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2237/1000000, train_loss: 6.4944, val_loss: 6.0024, time: 0.12s\n",
      "Epoch 2238/1000000, train_loss: 6.4930, val_loss: 6.0063, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2239/1000000, train_loss: 6.4915, val_loss: 5.9996, time: 0.12s\n",
      "Epoch 2240/1000000, train_loss: 6.4904, val_loss: 6.0037, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2241/1000000, train_loss: 6.4897, val_loss: 5.9906, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2242/1000000, train_loss: 6.4888, val_loss: 5.9890, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2243/1000000, train_loss: 6.4874, val_loss: 5.9856, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2244/1000000, train_loss: 6.4875, val_loss: 5.9851, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2245/1000000, train_loss: 6.4866, val_loss: 5.9780, time: 0.12s\n",
      "Epoch 2246/1000000, train_loss: 6.4852, val_loss: 5.9792, time: 0.13s\n",
      "Epoch 2247/1000000, train_loss: 6.4842, val_loss: 5.9835, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2248/1000000, train_loss: 6.4832, val_loss: 5.9711, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2249/1000000, train_loss: 6.4823, val_loss: 5.9698, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2250/1000000, train_loss: 6.4823, val_loss: 5.9676, time: 0.13s\n",
      "Epoch 2251/1000000, train_loss: 6.4805, val_loss: 5.9690, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2252/1000000, train_loss: 6.4798, val_loss: 5.9634, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2253/1000000, train_loss: 6.4784, val_loss: 5.9597, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2254/1000000, train_loss: 6.4777, val_loss: 5.9508, time: 0.12s\n",
      "Epoch 2255/1000000, train_loss: 6.4767, val_loss: 5.9515, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2256/1000000, train_loss: 6.4756, val_loss: 5.9498, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2257/1000000, train_loss: 6.4750, val_loss: 5.9429, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2258/1000000, train_loss: 6.4735, val_loss: 5.9361, time: 0.12s\n",
      "Epoch 2259/1000000, train_loss: 6.4735, val_loss: 5.9436, time: 0.12s\n",
      "Epoch 2260/1000000, train_loss: 6.4724, val_loss: 5.9392, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2261/1000000, train_loss: 6.4713, val_loss: 5.9314, time: 0.12s\n",
      "Epoch 2262/1000000, train_loss: 6.4705, val_loss: 5.9337, time: 0.12s\n",
      "Epoch 2263/1000000, train_loss: 6.4701, val_loss: 5.9318, time: 0.12s\n",
      "Epoch 2264/1000000, train_loss: 6.4688, val_loss: 5.9321, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2265/1000000, train_loss: 6.4682, val_loss: 5.9164, time: 0.12s\n",
      "Epoch 2266/1000000, train_loss: 6.4659, val_loss: 5.9212, time: 0.12s\n",
      "Epoch 2267/1000000, train_loss: 6.4668, val_loss: 5.9171, time: 0.20s\n",
      "Epoch 2268/1000000, train_loss: 6.4660, val_loss: 5.9180, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2269/1000000, train_loss: 6.4634, val_loss: 5.9090, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2270/1000000, train_loss: 6.4632, val_loss: 5.9033, time: 0.12s\n",
      "Epoch 2271/1000000, train_loss: 6.4626, val_loss: 5.9036, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2272/1000000, train_loss: 6.4617, val_loss: 5.8985, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2273/1000000, train_loss: 6.4608, val_loss: 5.8977, time: 0.12s\n",
      "Epoch 2274/1000000, train_loss: 6.4594, val_loss: 5.9014, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2275/1000000, train_loss: 6.4590, val_loss: 5.8896, time: 0.12s\n",
      "Epoch 2276/1000000, train_loss: 6.4586, val_loss: 5.8940, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2277/1000000, train_loss: 6.4569, val_loss: 5.8860, time: 0.12s\n",
      "Epoch 2278/1000000, train_loss: 6.4565, val_loss: 5.8886, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2279/1000000, train_loss: 6.4560, val_loss: 5.8804, time: 0.12s\n",
      "Epoch 2280/1000000, train_loss: 6.4552, val_loss: 5.8836, time: 0.12s\n",
      "Epoch 2281/1000000, train_loss: 6.4544, val_loss: 5.8842, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2282/1000000, train_loss: 6.4532, val_loss: 5.8700, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2283/1000000, train_loss: 6.4527, val_loss: 5.8699, time: 0.12s\n",
      "Epoch 2284/1000000, train_loss: 6.4517, val_loss: 5.8766, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2285/1000000, train_loss: 6.4503, val_loss: 5.8697, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2286/1000000, train_loss: 6.4504, val_loss: 5.8610, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2287/1000000, train_loss: 6.4491, val_loss: 5.8589, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2288/1000000, train_loss: 6.4479, val_loss: 5.8580, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2289/1000000, train_loss: 6.4476, val_loss: 5.8479, time: 0.13s\n",
      "Epoch 2290/1000000, train_loss: 6.4469, val_loss: 5.8505, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2291/1000000, train_loss: 6.4462, val_loss: 5.8430, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2292/1000000, train_loss: 6.4458, val_loss: 5.8403, time: 0.12s\n",
      "Epoch 2293/1000000, train_loss: 6.4447, val_loss: 5.8418, time: 0.12s\n",
      "Epoch 2294/1000000, train_loss: 6.4442, val_loss: 5.8433, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2295/1000000, train_loss: 6.4433, val_loss: 5.8295, time: 0.12s\n",
      "Epoch 2296/1000000, train_loss: 6.4420, val_loss: 5.8347, time: 0.12s\n",
      "Epoch 2297/1000000, train_loss: 6.4412, val_loss: 5.8357, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2298/1000000, train_loss: 6.4406, val_loss: 5.8201, time: 0.12s\n",
      "Epoch 2299/1000000, train_loss: 6.4405, val_loss: 5.8273, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2300/1000000, train_loss: 6.4401, val_loss: 5.8189, time: 0.12s\n",
      "Epoch 2301/1000000, train_loss: 6.4394, val_loss: 5.8223, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2302/1000000, train_loss: 6.4379, val_loss: 5.8146, time: 0.12s\n",
      "Epoch 2303/1000000, train_loss: 6.4366, val_loss: 5.8177, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2304/1000000, train_loss: 6.4370, val_loss: 5.8125, time: 0.12s\n",
      "Epoch 2305/1000000, train_loss: 6.4363, val_loss: 5.8144, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2306/1000000, train_loss: 6.4349, val_loss: 5.8086, time: 0.12s\n",
      "Epoch 2307/1000000, train_loss: 6.4339, val_loss: 5.8116, time: 0.12s\n",
      "Epoch 2308/1000000, train_loss: 6.4335, val_loss: 5.8086, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2309/1000000, train_loss: 6.4326, val_loss: 5.7985, time: 0.12s\n",
      "Epoch 2310/1000000, train_loss: 6.4324, val_loss: 5.8019, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2311/1000000, train_loss: 6.4318, val_loss: 5.7978, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2312/1000000, train_loss: 6.4304, val_loss: 5.7948, time: 0.12s\n",
      "Epoch 2313/1000000, train_loss: 6.4294, val_loss: 5.7957, time: 0.12s\n",
      "Epoch 2314/1000000, train_loss: 6.4294, val_loss: 5.7974, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2315/1000000, train_loss: 6.4294, val_loss: 5.7837, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2316/1000000, train_loss: 6.4281, val_loss: 5.7830, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2317/1000000, train_loss: 6.4282, val_loss: 5.7782, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2318/1000000, train_loss: 6.4277, val_loss: 5.7774, time: 0.12s\n",
      "Epoch 2319/1000000, train_loss: 6.4254, val_loss: 5.7802, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2320/1000000, train_loss: 6.4257, val_loss: 5.7694, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2321/1000000, train_loss: 6.4249, val_loss: 5.7683, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2322/1000000, train_loss: 6.4244, val_loss: 5.7634, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2323/1000000, train_loss: 6.4229, val_loss: 5.7610, time: 0.12s\n",
      "Epoch 2324/1000000, train_loss: 6.4230, val_loss: 5.7643, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2325/1000000, train_loss: 6.4216, val_loss: 5.7556, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2326/1000000, train_loss: 6.4214, val_loss: 5.7543, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2327/1000000, train_loss: 6.4210, val_loss: 5.7539, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2328/1000000, train_loss: 6.4204, val_loss: 5.7423, time: 0.12s\n",
      "Epoch 2329/1000000, train_loss: 6.4191, val_loss: 5.7516, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2330/1000000, train_loss: 6.4193, val_loss: 5.7413, time: 0.12s\n",
      "Epoch 2331/1000000, train_loss: 6.4185, val_loss: 5.7440, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2332/1000000, train_loss: 6.4172, val_loss: 5.7340, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2333/1000000, train_loss: 6.4164, val_loss: 5.7336, time: 0.12s\n",
      "Epoch 2334/1000000, train_loss: 6.4163, val_loss: 5.7382, time: 0.12s\n",
      "Epoch 2335/1000000, train_loss: 6.4155, val_loss: 5.7348, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2336/1000000, train_loss: 6.4150, val_loss: 5.7222, time: 0.13s\n",
      "Epoch 2337/1000000, train_loss: 6.4152, val_loss: 5.7275, time: 0.15s\n",
      "Epoch 2338/1000000, train_loss: 6.4133, val_loss: 5.7259, time: 0.12s\n",
      "Epoch 2339/1000000, train_loss: 6.4134, val_loss: 5.7234, time: 0.12s\n",
      "Epoch 2340/1000000, train_loss: 6.4124, val_loss: 5.7227, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2341/1000000, train_loss: 6.4110, val_loss: 5.7203, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2342/1000000, train_loss: 6.4108, val_loss: 5.7130, time: 0.17s\n",
      "Epoch 2343/1000000, train_loss: 6.4106, val_loss: 5.7165, time: 0.12s\n",
      "Epoch 2344/1000000, train_loss: 6.4105, val_loss: 5.7153, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2345/1000000, train_loss: 6.4093, val_loss: 5.7104, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2346/1000000, train_loss: 6.4084, val_loss: 5.7009, time: 0.24s\n",
      "Epoch 2347/1000000, train_loss: 6.4081, val_loss: 5.7046, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2348/1000000, train_loss: 6.4068, val_loss: 5.6938, time: 0.14s\n",
      "Epoch 2349/1000000, train_loss: 6.4075, val_loss: 5.6961, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2350/1000000, train_loss: 6.4066, val_loss: 5.6913, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2351/1000000, train_loss: 6.4061, val_loss: 5.6862, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2352/1000000, train_loss: 6.4055, val_loss: 5.6793, time: 0.12s\n",
      "Epoch 2353/1000000, train_loss: 6.4045, val_loss: 5.6796, time: 0.14s\n",
      "Epoch 2354/1000000, train_loss: 6.4041, val_loss: 5.6904, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2355/1000000, train_loss: 6.4026, val_loss: 5.6771, time: 0.16s\n",
      "Epoch 2356/1000000, train_loss: 6.4031, val_loss: 5.6875, time: 0.17s\n",
      "Epoch 2357/1000000, train_loss: 6.4025, val_loss: 5.6786, time: 0.13s\n",
      "Epoch 2358/1000000, train_loss: 6.4018, val_loss: 5.6841, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2359/1000000, train_loss: 6.4012, val_loss: 5.6753, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2360/1000000, train_loss: 6.4000, val_loss: 5.6746, time: 0.12s\n",
      "Epoch 2361/1000000, train_loss: 6.4002, val_loss: 5.6755, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2362/1000000, train_loss: 6.3994, val_loss: 5.6644, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2363/1000000, train_loss: 6.3991, val_loss: 5.6609, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2364/1000000, train_loss: 6.3986, val_loss: 5.6586, time: 0.12s\n",
      "Epoch 2365/1000000, train_loss: 6.3985, val_loss: 5.6611, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2366/1000000, train_loss: 6.3971, val_loss: 5.6568, time: 0.12s\n",
      "Epoch 2367/1000000, train_loss: 6.3966, val_loss: 5.6575, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2368/1000000, train_loss: 6.3962, val_loss: 5.6496, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2369/1000000, train_loss: 6.3953, val_loss: 5.6418, time: 0.12s\n",
      "Epoch 2370/1000000, train_loss: 6.3953, val_loss: 5.6472, time: 0.12s\n",
      "Epoch 2371/1000000, train_loss: 6.3953, val_loss: 5.6530, time: 0.14s\n",
      "Epoch 2372/1000000, train_loss: 6.3940, val_loss: 5.6428, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2373/1000000, train_loss: 6.3935, val_loss: 5.6410, time: 0.14s\n",
      "Epoch 2374/1000000, train_loss: 6.3924, val_loss: 5.6422, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2375/1000000, train_loss: 6.3924, val_loss: 5.6377, time: 0.12s\n",
      "Epoch 2376/1000000, train_loss: 6.3917, val_loss: 5.6385, time: 0.12s\n",
      "Epoch 2377/1000000, train_loss: 6.3909, val_loss: 5.6433, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2378/1000000, train_loss: 6.3905, val_loss: 5.6292, time: 0.12s\n",
      "Epoch 2379/1000000, train_loss: 6.3906, val_loss: 5.6335, time: 0.12s\n",
      "Epoch 2380/1000000, train_loss: 6.3894, val_loss: 5.6295, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2381/1000000, train_loss: 6.3889, val_loss: 5.6279, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2382/1000000, train_loss: 6.3886, val_loss: 5.6262, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2383/1000000, train_loss: 6.3879, val_loss: 5.6182, time: 0.12s\n",
      "Epoch 2384/1000000, train_loss: 6.3874, val_loss: 5.6227, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2385/1000000, train_loss: 6.3868, val_loss: 5.6180, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2386/1000000, train_loss: 6.3866, val_loss: 5.6091, time: 0.12s\n",
      "Epoch 2387/1000000, train_loss: 6.3862, val_loss: 5.6122, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2388/1000000, train_loss: 6.3861, val_loss: 5.6081, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2389/1000000, train_loss: 6.3850, val_loss: 5.6044, time: 0.12s\n",
      "Epoch 2390/1000000, train_loss: 6.3849, val_loss: 5.6057, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2391/1000000, train_loss: 6.3843, val_loss: 5.6005, time: 0.12s\n",
      "Epoch 2392/1000000, train_loss: 6.3836, val_loss: 5.6013, time: 0.12s\n",
      "Epoch 2393/1000000, train_loss: 6.3825, val_loss: 5.6010, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2394/1000000, train_loss: 6.3823, val_loss: 5.5980, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2395/1000000, train_loss: 6.3815, val_loss: 5.5909, time: 0.12s\n",
      "Epoch 2396/1000000, train_loss: 6.3819, val_loss: 5.5977, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2397/1000000, train_loss: 6.3813, val_loss: 5.5875, time: 0.12s\n",
      "Epoch 2398/1000000, train_loss: 6.3804, val_loss: 5.5985, time: 0.12s\n",
      "Epoch 2399/1000000, train_loss: 6.3805, val_loss: 5.5942, time: 0.12s\n",
      "Epoch 2400/1000000, train_loss: 6.3793, val_loss: 5.5886, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2401/1000000, train_loss: 6.3796, val_loss: 5.5747, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2402/1000000, train_loss: 6.3784, val_loss: 5.5735, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2403/1000000, train_loss: 6.3782, val_loss: 5.5705, time: 0.12s\n",
      "Epoch 2404/1000000, train_loss: 6.3773, val_loss: 5.5707, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2405/1000000, train_loss: 6.3765, val_loss: 5.5655, time: 0.12s\n",
      "Epoch 2406/1000000, train_loss: 6.3764, val_loss: 5.5726, time: 0.12s\n",
      "Epoch 2407/1000000, train_loss: 6.3766, val_loss: 5.5697, time: 0.12s\n",
      "Epoch 2408/1000000, train_loss: 6.3747, val_loss: 5.5751, time: 0.19s\n",
      "Epoch 2409/1000000, train_loss: 6.3756, val_loss: 5.5681, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2410/1000000, train_loss: 6.3749, val_loss: 5.5611, time: 0.12s\n",
      "Epoch 2411/1000000, train_loss: 6.3746, val_loss: 5.5642, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2412/1000000, train_loss: 6.3729, val_loss: 5.5591, time: 0.12s\n",
      "Epoch 2413/1000000, train_loss: 6.3733, val_loss: 5.5648, time: 0.12s\n",
      "Epoch 2414/1000000, train_loss: 6.3721, val_loss: 5.5629, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2415/1000000, train_loss: 6.3719, val_loss: 5.5524, time: 0.12s\n",
      "Epoch 2416/1000000, train_loss: 6.3723, val_loss: 5.5560, time: 0.12s\n",
      "Epoch 2417/1000000, train_loss: 6.3723, val_loss: 5.5618, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2418/1000000, train_loss: 6.3708, val_loss: 5.5516, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2419/1000000, train_loss: 6.3704, val_loss: 5.5477, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2420/1000000, train_loss: 6.3702, val_loss: 5.5322, time: 0.13s\n",
      "Epoch 2421/1000000, train_loss: 6.3684, val_loss: 5.5508, time: 0.12s\n",
      "Epoch 2422/1000000, train_loss: 6.3682, val_loss: 5.5523, time: 0.12s\n",
      "Epoch 2423/1000000, train_loss: 6.3682, val_loss: 5.5399, time: 0.12s\n",
      "Epoch 2424/1000000, train_loss: 6.3690, val_loss: 5.5441, time: 0.13s\n",
      "Epoch 2425/1000000, train_loss: 6.3673, val_loss: 5.5390, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2426/1000000, train_loss: 6.3670, val_loss: 5.5314, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2427/1000000, train_loss: 6.3657, val_loss: 5.5289, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2428/1000000, train_loss: 6.3658, val_loss: 5.5272, time: 0.12s\n",
      "Epoch 2429/1000000, train_loss: 6.3645, val_loss: 5.5335, time: 0.12s\n",
      "Epoch 2430/1000000, train_loss: 6.3642, val_loss: 5.5313, time: 0.12s\n",
      "Epoch 2431/1000000, train_loss: 6.3645, val_loss: 5.5357, time: 0.12s\n",
      "Epoch 2432/1000000, train_loss: 6.3639, val_loss: 5.5351, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2433/1000000, train_loss: 6.3633, val_loss: 5.5195, time: 0.15s\n",
      "Epoch 2434/1000000, train_loss: 6.3634, val_loss: 5.5254, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2435/1000000, train_loss: 6.3620, val_loss: 5.5158, time: 0.19s\n",
      "Epoch 2436/1000000, train_loss: 6.3612, val_loss: 5.5279, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2437/1000000, train_loss: 6.3610, val_loss: 5.5053, time: 0.12s\n",
      "Epoch 2438/1000000, train_loss: 6.3610, val_loss: 5.5200, time: 0.12s\n",
      "Epoch 2439/1000000, train_loss: 6.3612, val_loss: 5.5148, time: 0.12s\n",
      "Epoch 2440/1000000, train_loss: 6.3607, val_loss: 5.5121, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2441/1000000, train_loss: 6.3605, val_loss: 5.5006, time: 0.12s\n",
      "Epoch 2442/1000000, train_loss: 6.3588, val_loss: 5.5095, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2443/1000000, train_loss: 6.3581, val_loss: 5.5002, time: 0.12s\n",
      "Epoch 2444/1000000, train_loss: 6.3576, val_loss: 5.5148, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2445/1000000, train_loss: 6.3580, val_loss: 5.4968, time: 0.12s\n",
      "Epoch 2446/1000000, train_loss: 6.3579, val_loss: 5.4981, time: 0.12s\n",
      "Epoch 2447/1000000, train_loss: 6.3570, val_loss: 5.4998, time: 0.12s\n",
      "Epoch 2448/1000000, train_loss: 6.3565, val_loss: 5.4988, time: 0.12s\n",
      "Epoch 2449/1000000, train_loss: 6.3552, val_loss: 5.4996, time: 0.12s\n",
      "Epoch 2450/1000000, train_loss: 6.3569, val_loss: 5.5005, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2451/1000000, train_loss: 6.3547, val_loss: 5.4947, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2452/1000000, train_loss: 6.3549, val_loss: 5.4786, time: 0.12s\n",
      "Epoch 2453/1000000, train_loss: 6.3547, val_loss: 5.4818, time: 0.12s\n",
      "Epoch 2454/1000000, train_loss: 6.3543, val_loss: 5.4889, time: 0.12s\n",
      "Epoch 2455/1000000, train_loss: 6.3523, val_loss: 5.4841, time: 0.14s\n",
      "Epoch 2456/1000000, train_loss: 6.3528, val_loss: 5.4810, time: 0.16s\n",
      "Epoch 2457/1000000, train_loss: 6.3517, val_loss: 5.4787, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2458/1000000, train_loss: 6.3512, val_loss: 5.4721, time: 0.12s\n",
      "Epoch 2459/1000000, train_loss: 6.3516, val_loss: 5.4738, time: 0.12s\n",
      "Epoch 2460/1000000, train_loss: 6.3509, val_loss: 5.4799, time: 0.12s\n",
      "Epoch 2461/1000000, train_loss: 6.3506, val_loss: 5.4725, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2462/1000000, train_loss: 6.3493, val_loss: 5.4648, time: 0.13s\n",
      "Epoch 2463/1000000, train_loss: 6.3491, val_loss: 5.4664, time: 0.12s\n",
      "Epoch 2464/1000000, train_loss: 6.3486, val_loss: 5.4723, time: 0.13s\n",
      "Epoch 2465/1000000, train_loss: 6.3477, val_loss: 5.4695, time: 0.12s\n",
      "Epoch 2466/1000000, train_loss: 6.3478, val_loss: 5.4721, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2467/1000000, train_loss: 6.3475, val_loss: 5.4628, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2468/1000000, train_loss: 6.3464, val_loss: 5.4610, time: 0.24s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2469/1000000, train_loss: 6.3467, val_loss: 5.4531, time: 0.13s\n",
      "Epoch 2470/1000000, train_loss: 6.3456, val_loss: 5.4573, time: 0.12s\n",
      "Epoch 2471/1000000, train_loss: 6.3462, val_loss: 5.4610, time: 0.12s\n",
      "Epoch 2472/1000000, train_loss: 6.3447, val_loss: 5.4596, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2473/1000000, train_loss: 6.3447, val_loss: 5.4485, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2474/1000000, train_loss: 6.3437, val_loss: 5.4476, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2475/1000000, train_loss: 6.3429, val_loss: 5.4456, time: 0.12s\n",
      "Epoch 2476/1000000, train_loss: 6.3428, val_loss: 5.4494, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2477/1000000, train_loss: 6.3420, val_loss: 5.4418, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2478/1000000, train_loss: 6.3420, val_loss: 5.4349, time: 0.13s\n",
      "Epoch 2479/1000000, train_loss: 6.3417, val_loss: 5.4405, time: 0.14s\n",
      "Epoch 2480/1000000, train_loss: 6.3407, val_loss: 5.4554, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2481/1000000, train_loss: 6.3409, val_loss: 5.4262, time: 0.14s\n",
      "Epoch 2482/1000000, train_loss: 6.3401, val_loss: 5.4386, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2483/1000000, train_loss: 6.3406, val_loss: 5.4224, time: 0.12s\n",
      "Epoch 2484/1000000, train_loss: 6.3392, val_loss: 5.4252, time: 0.12s\n",
      "Epoch 2485/1000000, train_loss: 6.3388, val_loss: 5.4380, time: 0.12s\n",
      "Epoch 2486/1000000, train_loss: 6.3376, val_loss: 5.4297, time: 0.13s\n",
      "Epoch 2487/1000000, train_loss: 6.3383, val_loss: 5.4338, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2488/1000000, train_loss: 6.3384, val_loss: 5.4198, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2489/1000000, train_loss: 6.3369, val_loss: 5.4198, time: 0.15s\n",
      "Epoch 2490/1000000, train_loss: 6.3362, val_loss: 5.4224, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2491/1000000, train_loss: 6.3354, val_loss: 5.4108, time: 0.12s\n",
      "Epoch 2492/1000000, train_loss: 6.3360, val_loss: 5.4243, time: 0.12s\n",
      "Epoch 2493/1000000, train_loss: 6.3353, val_loss: 5.4266, time: 0.12s\n",
      "Epoch 2494/1000000, train_loss: 6.3349, val_loss: 5.4164, time: 0.12s\n",
      "Epoch 2495/1000000, train_loss: 6.3339, val_loss: 5.4177, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2496/1000000, train_loss: 6.3336, val_loss: 5.4088, time: 0.12s\n",
      "Epoch 2497/1000000, train_loss: 6.3339, val_loss: 5.4176, time: 0.12s\n",
      "Epoch 2498/1000000, train_loss: 6.3340, val_loss: 5.4160, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2499/1000000, train_loss: 6.3331, val_loss: 5.4014, time: 0.12s\n",
      "Epoch 2500/1000000, train_loss: 6.3319, val_loss: 5.4142, time: 0.12s\n",
      "Epoch 2501/1000000, train_loss: 6.3314, val_loss: 5.4072, time: 0.12s\n",
      "Epoch 2502/1000000, train_loss: 6.3306, val_loss: 5.4100, time: 0.12s\n",
      "Epoch 2503/1000000, train_loss: 6.3298, val_loss: 5.4026, time: 0.12s\n",
      "Epoch 2504/1000000, train_loss: 6.3292, val_loss: 5.4016, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2505/1000000, train_loss: 6.3295, val_loss: 5.3919, time: 0.12s\n",
      "Epoch 2506/1000000, train_loss: 6.3286, val_loss: 5.3920, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2507/1000000, train_loss: 6.3284, val_loss: 5.3859, time: 0.12s\n",
      "Epoch 2508/1000000, train_loss: 6.3288, val_loss: 5.3902, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2509/1000000, train_loss: 6.3274, val_loss: 5.3828, time: 0.16s\n",
      "Epoch 2510/1000000, train_loss: 6.3274, val_loss: 5.4021, time: 0.13s\n",
      "Epoch 2511/1000000, train_loss: 6.3274, val_loss: 5.3918, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2512/1000000, train_loss: 6.3267, val_loss: 5.3801, time: 0.12s\n",
      "Epoch 2513/1000000, train_loss: 6.3264, val_loss: 5.3844, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2514/1000000, train_loss: 6.3246, val_loss: 5.3781, time: 0.12s\n",
      "Epoch 2515/1000000, train_loss: 6.3246, val_loss: 5.3796, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2516/1000000, train_loss: 6.3249, val_loss: 5.3765, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2517/1000000, train_loss: 6.3240, val_loss: 5.3634, time: 0.12s\n",
      "Epoch 2518/1000000, train_loss: 6.3234, val_loss: 5.3739, time: 0.12s\n",
      "Epoch 2519/1000000, train_loss: 6.3219, val_loss: 5.3831, time: 0.12s\n",
      "Epoch 2520/1000000, train_loss: 6.3234, val_loss: 5.3794, time: 0.12s\n",
      "Epoch 2521/1000000, train_loss: 6.3214, val_loss: 5.3771, time: 0.12s\n",
      "Epoch 2522/1000000, train_loss: 6.3211, val_loss: 5.3699, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2523/1000000, train_loss: 6.3210, val_loss: 5.3624, time: 0.12s\n",
      "Epoch 2524/1000000, train_loss: 6.3203, val_loss: 5.3631, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2525/1000000, train_loss: 6.3208, val_loss: 5.3589, time: 0.13s\n",
      "Epoch 2526/1000000, train_loss: 6.3196, val_loss: 5.3678, time: 0.12s\n",
      "Epoch 2527/1000000, train_loss: 6.3191, val_loss: 5.3760, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2528/1000000, train_loss: 6.3186, val_loss: 5.3494, time: 0.12s\n",
      "Epoch 2529/1000000, train_loss: 6.3189, val_loss: 5.3677, time: 0.12s\n",
      "Epoch 2530/1000000, train_loss: 6.3182, val_loss: 5.3608, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2531/1000000, train_loss: 6.3176, val_loss: 5.3429, time: 0.12s\n",
      "Epoch 2532/1000000, train_loss: 6.3161, val_loss: 5.3441, time: 0.12s\n",
      "Epoch 2533/1000000, train_loss: 6.3170, val_loss: 5.3470, time: 0.12s\n",
      "Epoch 2534/1000000, train_loss: 6.3152, val_loss: 5.3495, time: 0.12s\n",
      "Epoch 2535/1000000, train_loss: 6.3155, val_loss: 5.3482, time: 0.12s\n",
      "Epoch 2536/1000000, train_loss: 6.3155, val_loss: 5.3476, time: 0.12s\n",
      "Epoch 2537/1000000, train_loss: 6.3139, val_loss: 5.3443, time: 0.12s\n",
      "Epoch 2538/1000000, train_loss: 6.3144, val_loss: 5.3470, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2539/1000000, train_loss: 6.3147, val_loss: 5.3390, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2540/1000000, train_loss: 6.3130, val_loss: 5.3332, time: 0.12s\n",
      "Epoch 2541/1000000, train_loss: 6.3128, val_loss: 5.3463, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2542/1000000, train_loss: 6.3121, val_loss: 5.3310, time: 0.21s\n",
      "Epoch 2543/1000000, train_loss: 6.3106, val_loss: 5.3404, time: 0.12s\n",
      "Epoch 2544/1000000, train_loss: 6.3108, val_loss: 5.3356, time: 0.12s\n",
      "Epoch 2545/1000000, train_loss: 6.3103, val_loss: 5.3334, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2546/1000000, train_loss: 6.3102, val_loss: 5.3212, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2547/1000000, train_loss: 6.3097, val_loss: 5.3185, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2548/1000000, train_loss: 6.3101, val_loss: 5.3166, time: 0.15s\n",
      "Epoch 2549/1000000, train_loss: 6.3092, val_loss: 5.3279, time: 0.13s\n",
      "Epoch 2550/1000000, train_loss: 6.3075, val_loss: 5.3309, time: 0.12s\n",
      "Epoch 2551/1000000, train_loss: 6.3084, val_loss: 5.3224, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2552/1000000, train_loss: 6.3074, val_loss: 5.3150, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2553/1000000, train_loss: 6.3064, val_loss: 5.3129, time: 0.12s\n",
      "Epoch 2554/1000000, train_loss: 6.3061, val_loss: 5.3165, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2555/1000000, train_loss: 6.3065, val_loss: 5.3118, time: 0.12s\n",
      "Epoch 2556/1000000, train_loss: 6.3056, val_loss: 5.3134, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2557/1000000, train_loss: 6.3052, val_loss: 5.3108, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2558/1000000, train_loss: 6.3044, val_loss: 5.3079, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2559/1000000, train_loss: 6.3040, val_loss: 5.2968, time: 0.12s\n",
      "Epoch 2560/1000000, train_loss: 6.3049, val_loss: 5.3098, time: 0.12s\n",
      "Epoch 2561/1000000, train_loss: 6.3037, val_loss: 5.3089, time: 0.12s\n",
      "Epoch 2562/1000000, train_loss: 6.3025, val_loss: 5.3042, time: 0.12s\n",
      "Epoch 2563/1000000, train_loss: 6.3020, val_loss: 5.3081, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2564/1000000, train_loss: 6.3033, val_loss: 5.2939, time: 0.12s\n",
      "Epoch 2565/1000000, train_loss: 6.3012, val_loss: 5.3034, time: 0.12s\n",
      "Epoch 2566/1000000, train_loss: 6.3013, val_loss: 5.2942, time: 0.12s\n",
      "Epoch 2567/1000000, train_loss: 6.3008, val_loss: 5.2994, time: 0.12s\n",
      "Epoch 2568/1000000, train_loss: 6.2997, val_loss: 5.2972, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2569/1000000, train_loss: 6.2991, val_loss: 5.2934, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2570/1000000, train_loss: 6.2992, val_loss: 5.2876, time: 0.13s\n",
      "Epoch 2571/1000000, train_loss: 6.2984, val_loss: 5.2914, time: 0.12s\n",
      "Epoch 2572/1000000, train_loss: 6.2985, val_loss: 5.2928, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2573/1000000, train_loss: 6.2981, val_loss: 5.2835, time: 0.13s\n",
      "Epoch 2574/1000000, train_loss: 6.2976, val_loss: 5.2900, time: 0.12s\n",
      "Epoch 2575/1000000, train_loss: 6.2979, val_loss: 5.2849, time: 0.12s\n",
      "Epoch 2576/1000000, train_loss: 6.2955, val_loss: 5.2904, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2577/1000000, train_loss: 6.2950, val_loss: 5.2791, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2578/1000000, train_loss: 6.2951, val_loss: 5.2712, time: 0.12s\n",
      "Epoch 2579/1000000, train_loss: 6.2953, val_loss: 5.2826, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2580/1000000, train_loss: 6.2935, val_loss: 5.2618, time: 0.12s\n",
      "Epoch 2581/1000000, train_loss: 6.2930, val_loss: 5.2712, time: 0.12s\n",
      "Epoch 2582/1000000, train_loss: 6.2944, val_loss: 5.2676, time: 0.12s\n",
      "Epoch 2583/1000000, train_loss: 6.2935, val_loss: 5.2651, time: 0.13s\n",
      "Epoch 2584/1000000, train_loss: 6.2921, val_loss: 5.2749, time: 0.12s\n",
      "Epoch 2585/1000000, train_loss: 6.2925, val_loss: 5.2649, time: 0.12s\n",
      "Epoch 2586/1000000, train_loss: 6.2923, val_loss: 5.2672, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2587/1000000, train_loss: 6.2918, val_loss: 5.2602, time: 0.12s\n",
      "Epoch 2588/1000000, train_loss: 6.2905, val_loss: 5.2650, time: 0.12s\n",
      "Epoch 2589/1000000, train_loss: 6.2895, val_loss: 5.2616, time: 0.12s\n",
      "Epoch 2590/1000000, train_loss: 6.2897, val_loss: 5.2674, time: 0.12s\n",
      "Epoch 2591/1000000, train_loss: 6.2895, val_loss: 5.2656, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2592/1000000, train_loss: 6.2885, val_loss: 5.2496, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2593/1000000, train_loss: 6.2884, val_loss: 5.2474, time: 0.12s\n",
      "Epoch 2594/1000000, train_loss: 6.2877, val_loss: 5.2542, time: 0.12s\n",
      "Epoch 2595/1000000, train_loss: 6.2871, val_loss: 5.2490, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2596/1000000, train_loss: 6.2871, val_loss: 5.2410, time: 0.12s\n",
      "Epoch 2597/1000000, train_loss: 6.2867, val_loss: 5.2532, time: 0.14s\n",
      "Epoch 2598/1000000, train_loss: 6.2856, val_loss: 5.2413, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2599/1000000, train_loss: 6.2867, val_loss: 5.2298, time: 0.12s\n",
      "Epoch 2600/1000000, train_loss: 6.2846, val_loss: 5.2451, time: 0.12s\n",
      "Epoch 2601/1000000, train_loss: 6.2847, val_loss: 5.2436, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2602/1000000, train_loss: 6.2849, val_loss: 5.2284, time: 0.12s\n",
      "Epoch 2603/1000000, train_loss: 6.2832, val_loss: 5.2311, time: 0.12s\n",
      "Epoch 2604/1000000, train_loss: 6.2832, val_loss: 5.2349, time: 0.12s\n",
      "Epoch 2605/1000000, train_loss: 6.2834, val_loss: 5.2293, time: 0.12s\n",
      "Epoch 2606/1000000, train_loss: 6.2830, val_loss: 5.2318, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2607/1000000, train_loss: 6.2820, val_loss: 5.2256, time: 0.12s\n",
      "Epoch 2608/1000000, train_loss: 6.2805, val_loss: 5.2280, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2609/1000000, train_loss: 6.2811, val_loss: 5.2107, time: 0.12s\n",
      "Epoch 2610/1000000, train_loss: 6.2806, val_loss: 5.2219, time: 0.12s\n",
      "Epoch 2611/1000000, train_loss: 6.2807, val_loss: 5.2308, time: 0.12s\n",
      "Epoch 2612/1000000, train_loss: 6.2798, val_loss: 5.2167, time: 0.12s\n",
      "Epoch 2613/1000000, train_loss: 6.2795, val_loss: 5.2202, time: 0.12s\n",
      "Epoch 2614/1000000, train_loss: 6.2785, val_loss: 5.2138, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2615/1000000, train_loss: 6.2770, val_loss: 5.2064, time: 0.12s\n",
      "Epoch 2616/1000000, train_loss: 6.2785, val_loss: 5.2192, time: 0.12s\n",
      "Epoch 2617/1000000, train_loss: 6.2768, val_loss: 5.2148, time: 0.19s\n",
      "Epoch 2618/1000000, train_loss: 6.2773, val_loss: 5.2138, time: 0.14s\n",
      "Epoch 2619/1000000, train_loss: 6.2752, val_loss: 5.2103, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2620/1000000, train_loss: 6.2755, val_loss: 5.1943, time: 0.12s\n",
      "Epoch 2621/1000000, train_loss: 6.2750, val_loss: 5.2157, time: 0.12s\n",
      "Epoch 2622/1000000, train_loss: 6.2753, val_loss: 5.2080, time: 0.12s\n",
      "Epoch 2623/1000000, train_loss: 6.2746, val_loss: 5.1953, time: 0.12s\n",
      "Epoch 2624/1000000, train_loss: 6.2733, val_loss: 5.1979, time: 0.12s\n",
      "Epoch 2625/1000000, train_loss: 6.2727, val_loss: 5.1948, time: 0.21s\n",
      "Epoch 2626/1000000, train_loss: 6.2717, val_loss: 5.2097, time: 0.13s\n",
      "Epoch 2627/1000000, train_loss: 6.2717, val_loss: 5.2070, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2628/1000000, train_loss: 6.2710, val_loss: 5.1935, time: 0.12s\n",
      "Epoch 2629/1000000, train_loss: 6.2712, val_loss: 5.1935, time: 0.12s\n",
      "Epoch 2630/1000000, train_loss: 6.2709, val_loss: 5.2025, time: 0.12s\n",
      "Epoch 2631/1000000, train_loss: 6.2703, val_loss: 5.1960, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2632/1000000, train_loss: 6.2701, val_loss: 5.1817, time: 0.12s\n",
      "Epoch 2633/1000000, train_loss: 6.2711, val_loss: 5.1864, time: 0.12s\n",
      "Epoch 2634/1000000, train_loss: 6.2691, val_loss: 5.1917, time: 0.12s\n",
      "Epoch 2635/1000000, train_loss: 6.2695, val_loss: 5.1827, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2636/1000000, train_loss: 6.2681, val_loss: 5.1806, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2637/1000000, train_loss: 6.2672, val_loss: 5.1684, time: 0.12s\n",
      "Epoch 2638/1000000, train_loss: 6.2670, val_loss: 5.1776, time: 0.12s\n",
      "Epoch 2639/1000000, train_loss: 6.2676, val_loss: 5.1788, time: 0.12s\n",
      "Epoch 2640/1000000, train_loss: 6.2652, val_loss: 5.1799, time: 0.12s\n",
      "Epoch 2641/1000000, train_loss: 6.2660, val_loss: 5.1850, time: 0.12s\n",
      "Epoch 2642/1000000, train_loss: 6.2650, val_loss: 5.1740, time: 0.12s\n",
      "Epoch 2643/1000000, train_loss: 6.2650, val_loss: 5.1685, time: 0.12s\n",
      "Epoch 2644/1000000, train_loss: 6.2645, val_loss: 5.1726, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2645/1000000, train_loss: 6.2640, val_loss: 5.1643, time: 0.13s\n",
      "Epoch 2646/1000000, train_loss: 6.2634, val_loss: 5.1666, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2647/1000000, train_loss: 6.2620, val_loss: 5.1518, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2648/1000000, train_loss: 6.2628, val_loss: 5.1422, time: 0.12s\n",
      "Epoch 2649/1000000, train_loss: 6.2632, val_loss: 5.1656, time: 0.12s\n",
      "Epoch 2650/1000000, train_loss: 6.2612, val_loss: 5.1616, time: 0.12s\n",
      "Epoch 2651/1000000, train_loss: 6.2617, val_loss: 5.1558, time: 0.12s\n",
      "Epoch 2652/1000000, train_loss: 6.2618, val_loss: 5.1634, time: 0.12s\n",
      "Epoch 2653/1000000, train_loss: 6.2599, val_loss: 5.1574, time: 0.12s\n",
      "Epoch 2654/1000000, train_loss: 6.2591, val_loss: 5.1576, time: 0.12s\n",
      "Epoch 2655/1000000, train_loss: 6.2588, val_loss: 5.1489, time: 0.12s\n",
      "Epoch 2656/1000000, train_loss: 6.2591, val_loss: 5.1544, time: 0.12s\n",
      "Epoch 2657/1000000, train_loss: 6.2591, val_loss: 5.1518, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2658/1000000, train_loss: 6.2578, val_loss: 5.1332, time: 0.12s\n",
      "Epoch 2659/1000000, train_loss: 6.2581, val_loss: 5.1420, time: 0.12s\n",
      "Epoch 2660/1000000, train_loss: 6.2575, val_loss: 5.1473, time: 0.12s\n",
      "Epoch 2661/1000000, train_loss: 6.2559, val_loss: 5.1421, time: 0.12s\n",
      "Epoch 2662/1000000, train_loss: 6.2563, val_loss: 5.1461, time: 0.12s\n",
      "Epoch 2663/1000000, train_loss: 6.2562, val_loss: 5.1423, time: 0.12s\n",
      "Epoch 2664/1000000, train_loss: 6.2556, val_loss: 5.1463, time: 0.12s\n",
      "Epoch 2665/1000000, train_loss: 6.2540, val_loss: 5.1521, time: 0.12s\n",
      "Epoch 2666/1000000, train_loss: 6.2549, val_loss: 5.1334, time: 0.12s\n",
      "Epoch 2667/1000000, train_loss: 6.2537, val_loss: 5.1379, time: 0.12s\n",
      "Epoch 2668/1000000, train_loss: 6.2529, val_loss: 5.1430, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2669/1000000, train_loss: 6.2515, val_loss: 5.1329, time: 0.26s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2670/1000000, train_loss: 6.2522, val_loss: 5.1311, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2671/1000000, train_loss: 6.2523, val_loss: 5.1259, time: 0.12s\n",
      "Epoch 2672/1000000, train_loss: 6.2525, val_loss: 5.1267, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2673/1000000, train_loss: 6.2511, val_loss: 5.1170, time: 0.13s\n",
      "Epoch 2674/1000000, train_loss: 6.2504, val_loss: 5.1276, time: 0.12s\n",
      "Epoch 2675/1000000, train_loss: 6.2494, val_loss: 5.1173, time: 0.13s\n",
      "Epoch 2676/1000000, train_loss: 6.2489, val_loss: 5.1205, time: 0.12s\n",
      "Epoch 2677/1000000, train_loss: 6.2495, val_loss: 5.1228, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2678/1000000, train_loss: 6.2483, val_loss: 5.1078, time: 0.12s\n",
      "Epoch 2679/1000000, train_loss: 6.2477, val_loss: 5.1115, time: 0.13s\n",
      "Epoch 2680/1000000, train_loss: 6.2472, val_loss: 5.1127, time: 0.13s\n",
      "Epoch 2681/1000000, train_loss: 6.2468, val_loss: 5.1186, time: 0.12s\n",
      "Epoch 2682/1000000, train_loss: 6.2470, val_loss: 5.1106, time: 0.12s\n",
      "Epoch 2683/1000000, train_loss: 6.2465, val_loss: 5.1090, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2684/1000000, train_loss: 6.2453, val_loss: 5.1033, time: 0.12s\n",
      "Epoch 2685/1000000, train_loss: 6.2454, val_loss: 5.1087, time: 0.12s\n",
      "Epoch 2686/1000000, train_loss: 6.2450, val_loss: 5.1090, time: 0.12s\n",
      "Epoch 2687/1000000, train_loss: 6.2439, val_loss: 5.1065, time: 0.12s\n",
      "Epoch 2688/1000000, train_loss: 6.2439, val_loss: 5.1057, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2689/1000000, train_loss: 6.2436, val_loss: 5.0862, time: 0.12s\n",
      "Epoch 2690/1000000, train_loss: 6.2432, val_loss: 5.0956, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2691/1000000, train_loss: 6.2421, val_loss: 5.0790, time: 0.12s\n",
      "Epoch 2692/1000000, train_loss: 6.2419, val_loss: 5.0916, time: 0.13s\n",
      "Epoch 2693/1000000, train_loss: 6.2418, val_loss: 5.0895, time: 0.12s\n",
      "Epoch 2694/1000000, train_loss: 6.2404, val_loss: 5.0971, time: 0.12s\n",
      "Epoch 2695/1000000, train_loss: 6.2407, val_loss: 5.0824, time: 0.12s\n",
      "Epoch 2696/1000000, train_loss: 6.2412, val_loss: 5.0850, time: 0.12s\n",
      "Epoch 2697/1000000, train_loss: 6.2399, val_loss: 5.0944, time: 0.12s\n",
      "Epoch 2698/1000000, train_loss: 6.2384, val_loss: 5.0905, time: 0.13s\n",
      "Epoch 2699/1000000, train_loss: 6.2379, val_loss: 5.0846, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2700/1000000, train_loss: 6.2388, val_loss: 5.0764, time: 0.13s\n",
      "Epoch 2701/1000000, train_loss: 6.2367, val_loss: 5.0804, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2702/1000000, train_loss: 6.2366, val_loss: 5.0739, time: 0.12s\n",
      "Epoch 2703/1000000, train_loss: 6.2378, val_loss: 5.0853, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2704/1000000, train_loss: 6.2360, val_loss: 5.0601, time: 0.13s\n",
      "Epoch 2705/1000000, train_loss: 6.2361, val_loss: 5.0702, time: 0.12s\n",
      "Epoch 2706/1000000, train_loss: 6.2362, val_loss: 5.0683, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2707/1000000, train_loss: 6.2345, val_loss: 5.0597, time: 0.12s\n",
      "Epoch 2708/1000000, train_loss: 6.2357, val_loss: 5.0706, time: 0.12s\n",
      "Epoch 2709/1000000, train_loss: 6.2335, val_loss: 5.0633, time: 0.12s\n",
      "Epoch 2710/1000000, train_loss: 6.2335, val_loss: 5.0669, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2711/1000000, train_loss: 6.2326, val_loss: 5.0523, time: 0.12s\n",
      "Epoch 2712/1000000, train_loss: 6.2327, val_loss: 5.0638, time: 0.12s\n",
      "Epoch 2713/1000000, train_loss: 6.2324, val_loss: 5.0613, time: 0.12s\n",
      "Epoch 2714/1000000, train_loss: 6.2321, val_loss: 5.0531, time: 0.12s\n",
      "Epoch 2715/1000000, train_loss: 6.2320, val_loss: 5.0653, time: 0.12s\n",
      "Epoch 2716/1000000, train_loss: 6.2311, val_loss: 5.0660, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2717/1000000, train_loss: 6.2300, val_loss: 5.0468, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2718/1000000, train_loss: 6.2302, val_loss: 5.0464, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2719/1000000, train_loss: 6.2298, val_loss: 5.0429, time: 0.17s\n",
      "Epoch 2720/1000000, train_loss: 6.2288, val_loss: 5.0520, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2721/1000000, train_loss: 6.2276, val_loss: 5.0380, time: 0.12s\n",
      "Epoch 2722/1000000, train_loss: 6.2286, val_loss: 5.0436, time: 0.13s\n",
      "Epoch 2723/1000000, train_loss: 6.2266, val_loss: 5.0401, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2724/1000000, train_loss: 6.2267, val_loss: 5.0321, time: 0.12s\n",
      "Epoch 2725/1000000, train_loss: 6.2266, val_loss: 5.0381, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2726/1000000, train_loss: 6.2269, val_loss: 5.0270, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2727/1000000, train_loss: 6.2262, val_loss: 5.0265, time: 0.13s\n",
      "Epoch 2728/1000000, train_loss: 6.2258, val_loss: 5.0374, time: 0.18s\n",
      "Epoch 2729/1000000, train_loss: 6.2240, val_loss: 5.0374, time: 0.16s\n",
      "Epoch 2730/1000000, train_loss: 6.2239, val_loss: 5.0391, time: 0.12s\n",
      "Epoch 2731/1000000, train_loss: 6.2250, val_loss: 5.0376, time: 0.12s\n",
      "Epoch 2732/1000000, train_loss: 6.2245, val_loss: 5.0427, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2733/1000000, train_loss: 6.2220, val_loss: 5.0255, time: 0.13s\n",
      "Epoch 2734/1000000, train_loss: 6.2231, val_loss: 5.0260, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2735/1000000, train_loss: 6.2217, val_loss: 5.0199, time: 0.13s\n",
      "Epoch 2736/1000000, train_loss: 6.2216, val_loss: 5.0272, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2737/1000000, train_loss: 6.2211, val_loss: 5.0181, time: 0.12s\n",
      "Epoch 2738/1000000, train_loss: 6.2199, val_loss: 5.0194, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2739/1000000, train_loss: 6.2198, val_loss: 5.0134, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2740/1000000, train_loss: 6.2200, val_loss: 5.0063, time: 0.13s\n",
      "Epoch 2741/1000000, train_loss: 6.2194, val_loss: 5.0223, time: 0.12s\n",
      "Epoch 2742/1000000, train_loss: 6.2186, val_loss: 5.0149, time: 0.13s\n",
      "Epoch 2743/1000000, train_loss: 6.2167, val_loss: 5.0101, time: 0.13s\n",
      "Epoch 2744/1000000, train_loss: 6.2177, val_loss: 5.0087, time: 0.12s\n",
      "Epoch 2745/1000000, train_loss: 6.2184, val_loss: 5.0134, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2746/1000000, train_loss: 6.2151, val_loss: 5.0044, time: 0.25s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2747/1000000, train_loss: 6.2164, val_loss: 4.9936, time: 0.12s\n",
      "Epoch 2748/1000000, train_loss: 6.2167, val_loss: 5.0014, time: 0.12s\n",
      "Epoch 2749/1000000, train_loss: 6.2154, val_loss: 5.0013, time: 0.13s\n",
      "Epoch 2750/1000000, train_loss: 6.2151, val_loss: 5.0008, time: 0.13s\n",
      "Epoch 2751/1000000, train_loss: 6.2150, val_loss: 4.9998, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2752/1000000, train_loss: 6.2124, val_loss: 4.9905, time: 0.13s\n",
      "Epoch 2753/1000000, train_loss: 6.2139, val_loss: 5.0014, time: 0.13s\n",
      "Epoch 2754/1000000, train_loss: 6.2125, val_loss: 5.0041, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2755/1000000, train_loss: 6.2118, val_loss: 4.9831, time: 0.13s\n",
      "Epoch 2756/1000000, train_loss: 6.2130, val_loss: 4.9946, time: 0.12s\n",
      "Epoch 2757/1000000, train_loss: 6.2115, val_loss: 4.9903, time: 0.12s\n",
      "Epoch 2758/1000000, train_loss: 6.2110, val_loss: 4.9977, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2759/1000000, train_loss: 6.2109, val_loss: 4.9812, time: 0.12s\n",
      "Epoch 2760/1000000, train_loss: 6.2094, val_loss: 4.9819, time: 0.18s\n",
      "Epoch 2761/1000000, train_loss: 6.2090, val_loss: 4.9829, time: 0.13s\n",
      "Epoch 2762/1000000, train_loss: 6.2088, val_loss: 4.9816, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2763/1000000, train_loss: 6.2085, val_loss: 4.9797, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2764/1000000, train_loss: 6.2085, val_loss: 4.9667, time: 0.12s\n",
      "Epoch 2765/1000000, train_loss: 6.2070, val_loss: 4.9823, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2766/1000000, train_loss: 6.2072, val_loss: 4.9657, time: 0.18s\n",
      "Epoch 2767/1000000, train_loss: 6.2063, val_loss: 4.9707, time: 0.15s\n",
      "Epoch 2768/1000000, train_loss: 6.2058, val_loss: 4.9694, time: 0.12s\n",
      "Epoch 2769/1000000, train_loss: 6.2050, val_loss: 4.9671, time: 0.12s\n",
      "Epoch 2770/1000000, train_loss: 6.2050, val_loss: 4.9669, time: 0.13s\n",
      "Epoch 2771/1000000, train_loss: 6.2055, val_loss: 4.9787, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2772/1000000, train_loss: 6.2031, val_loss: 4.9576, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2773/1000000, train_loss: 6.2040, val_loss: 4.9567, time: 0.12s\n",
      "Epoch 2774/1000000, train_loss: 6.2028, val_loss: 4.9592, time: 0.13s\n",
      "Epoch 2775/1000000, train_loss: 6.2036, val_loss: 4.9572, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2776/1000000, train_loss: 6.2026, val_loss: 4.9410, time: 0.13s\n",
      "Epoch 2777/1000000, train_loss: 6.2015, val_loss: 4.9632, time: 0.13s\n",
      "Epoch 2778/1000000, train_loss: 6.2019, val_loss: 4.9493, time: 0.12s\n",
      "Epoch 2779/1000000, train_loss: 6.2011, val_loss: 4.9552, time: 0.12s\n",
      "Epoch 2780/1000000, train_loss: 6.2012, val_loss: 4.9417, time: 0.12s\n",
      "Epoch 2781/1000000, train_loss: 6.2012, val_loss: 4.9673, time: 0.12s\n",
      "Epoch 2782/1000000, train_loss: 6.1999, val_loss: 4.9455, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2783/1000000, train_loss: 6.1992, val_loss: 4.9360, time: 0.12s\n",
      "Epoch 2784/1000000, train_loss: 6.1991, val_loss: 4.9412, time: 0.12s\n",
      "Epoch 2785/1000000, train_loss: 6.1974, val_loss: 4.9387, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2786/1000000, train_loss: 6.1984, val_loss: 4.9292, time: 0.13s\n",
      "Epoch 2787/1000000, train_loss: 6.1973, val_loss: 4.9529, time: 0.12s\n",
      "Epoch 2788/1000000, train_loss: 6.1971, val_loss: 4.9485, time: 0.12s\n",
      "Epoch 2789/1000000, train_loss: 6.1946, val_loss: 4.9375, time: 0.12s\n",
      "Epoch 2790/1000000, train_loss: 6.1958, val_loss: 4.9410, time: 0.12s\n",
      "Epoch 2791/1000000, train_loss: 6.1955, val_loss: 4.9424, time: 0.12s\n",
      "Epoch 2792/1000000, train_loss: 6.1959, val_loss: 4.9394, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2793/1000000, train_loss: 6.1939, val_loss: 4.9186, time: 0.22s\n",
      "Epoch 2794/1000000, train_loss: 6.1947, val_loss: 4.9188, time: 0.14s\n",
      "Epoch 2795/1000000, train_loss: 6.1950, val_loss: 4.9201, time: 0.12s\n",
      "Epoch 2796/1000000, train_loss: 6.1926, val_loss: 4.9342, time: 0.12s\n",
      "Epoch 2797/1000000, train_loss: 6.1928, val_loss: 4.9229, time: 0.12s\n",
      "Epoch 2798/1000000, train_loss: 6.1936, val_loss: 4.9204, time: 0.14s\n",
      "Epoch 2799/1000000, train_loss: 6.1921, val_loss: 4.9192, time: 0.12s\n",
      "Epoch 2800/1000000, train_loss: 6.1896, val_loss: 4.9344, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2801/1000000, train_loss: 6.1905, val_loss: 4.9183, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2802/1000000, train_loss: 6.1908, val_loss: 4.9174, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2803/1000000, train_loss: 6.1916, val_loss: 4.9019, time: 0.13s\n",
      "Epoch 2804/1000000, train_loss: 6.1895, val_loss: 4.9164, time: 0.13s\n",
      "Epoch 2805/1000000, train_loss: 6.1900, val_loss: 4.9182, time: 0.13s\n",
      "Epoch 2806/1000000, train_loss: 6.1887, val_loss: 4.9105, time: 0.13s\n",
      "Epoch 2807/1000000, train_loss: 6.1887, val_loss: 4.9087, time: 0.12s\n",
      "Epoch 2808/1000000, train_loss: 6.1878, val_loss: 4.9132, time: 0.12s\n",
      "Epoch 2809/1000000, train_loss: 6.1878, val_loss: 4.9151, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2810/1000000, train_loss: 6.1868, val_loss: 4.8910, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2811/1000000, train_loss: 6.1866, val_loss: 4.8843, time: 0.13s\n",
      "Epoch 2812/1000000, train_loss: 6.1875, val_loss: 4.9096, time: 0.12s\n",
      "Epoch 2813/1000000, train_loss: 6.1852, val_loss: 4.8940, time: 0.19s\n",
      "Epoch 2814/1000000, train_loss: 6.1860, val_loss: 4.8857, time: 0.16s\n",
      "Epoch 2815/1000000, train_loss: 6.1844, val_loss: 4.8861, time: 0.12s\n",
      "Epoch 2816/1000000, train_loss: 6.1842, val_loss: 4.8859, time: 0.12s\n",
      "Epoch 2817/1000000, train_loss: 6.1847, val_loss: 4.8884, time: 0.12s\n",
      "Epoch 2818/1000000, train_loss: 6.1827, val_loss: 4.9028, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2819/1000000, train_loss: 6.1828, val_loss: 4.8815, time: 0.12s\n",
      "Epoch 2820/1000000, train_loss: 6.1807, val_loss: 4.8901, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2821/1000000, train_loss: 6.1810, val_loss: 4.8719, time: 0.12s\n",
      "Epoch 2822/1000000, train_loss: 6.1810, val_loss: 4.8859, time: 0.12s\n",
      "Epoch 2823/1000000, train_loss: 6.1802, val_loss: 4.8845, time: 0.12s\n",
      "Epoch 2824/1000000, train_loss: 6.1796, val_loss: 4.8834, time: 0.12s\n",
      "Epoch 2825/1000000, train_loss: 6.1797, val_loss: 4.8844, time: 0.12s\n",
      "Epoch 2826/1000000, train_loss: 6.1803, val_loss: 4.8728, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2827/1000000, train_loss: 6.1786, val_loss: 4.8669, time: 0.12s\n",
      "Epoch 2828/1000000, train_loss: 6.1780, val_loss: 4.8746, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2829/1000000, train_loss: 6.1776, val_loss: 4.8665, time: 0.12s\n",
      "Epoch 2830/1000000, train_loss: 6.1778, val_loss: 4.8777, time: 0.13s\n",
      "Epoch 2831/1000000, train_loss: 6.1776, val_loss: 4.8716, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2832/1000000, train_loss: 6.1763, val_loss: 4.8648, time: 0.12s\n",
      "Epoch 2833/1000000, train_loss: 6.1760, val_loss: 4.8711, time: 0.15s\n",
      "Epoch 2834/1000000, train_loss: 6.1758, val_loss: 4.8752, time: 0.13s\n",
      "Epoch 2835/1000000, train_loss: 6.1755, val_loss: 4.8698, time: 0.12s\n",
      "Epoch 2836/1000000, train_loss: 6.1740, val_loss: 4.8712, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2837/1000000, train_loss: 6.1738, val_loss: 4.8625, time: 0.13s\n",
      "Epoch 2838/1000000, train_loss: 6.1731, val_loss: 4.8694, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2839/1000000, train_loss: 6.1731, val_loss: 4.8576, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2840/1000000, train_loss: 6.1733, val_loss: 4.8564, time: 0.12s\n",
      "Epoch 2841/1000000, train_loss: 6.1724, val_loss: 4.8640, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2842/1000000, train_loss: 6.1704, val_loss: 4.8478, time: 0.12s\n",
      "Epoch 2843/1000000, train_loss: 6.1707, val_loss: 4.8494, time: 0.12s\n",
      "Epoch 2844/1000000, train_loss: 6.1718, val_loss: 4.8548, time: 0.12s\n",
      "Epoch 2845/1000000, train_loss: 6.1712, val_loss: 4.8563, time: 0.12s\n",
      "Epoch 2846/1000000, train_loss: 6.1702, val_loss: 4.8496, time: 0.12s\n",
      "Epoch 2847/1000000, train_loss: 6.1689, val_loss: 4.8504, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2848/1000000, train_loss: 6.1692, val_loss: 4.8389, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2849/1000000, train_loss: 6.1684, val_loss: 4.8230, time: 0.12s\n",
      "Epoch 2850/1000000, train_loss: 6.1678, val_loss: 4.8363, time: 0.12s\n",
      "Epoch 2851/1000000, train_loss: 6.1683, val_loss: 4.8445, time: 0.12s\n",
      "Epoch 2852/1000000, train_loss: 6.1661, val_loss: 4.8418, time: 0.12s\n",
      "Epoch 2853/1000000, train_loss: 6.1661, val_loss: 4.8435, time: 0.12s\n",
      "Epoch 2854/1000000, train_loss: 6.1660, val_loss: 4.8423, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2855/1000000, train_loss: 6.1660, val_loss: 4.8157, time: 0.12s\n",
      "Epoch 2856/1000000, train_loss: 6.1651, val_loss: 4.8304, time: 0.12s\n",
      "Epoch 2857/1000000, train_loss: 6.1651, val_loss: 4.8392, time: 0.12s\n",
      "Epoch 2858/1000000, train_loss: 6.1649, val_loss: 4.8378, time: 0.12s\n",
      "Epoch 2859/1000000, train_loss: 6.1632, val_loss: 4.8325, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2860/1000000, train_loss: 6.1637, val_loss: 4.8114, time: 0.12s\n",
      "Epoch 2861/1000000, train_loss: 6.1627, val_loss: 4.8277, time: 0.12s\n",
      "Epoch 2862/1000000, train_loss: 6.1619, val_loss: 4.8188, time: 0.12s\n",
      "Epoch 2863/1000000, train_loss: 6.1621, val_loss: 4.8207, time: 0.12s\n",
      "Epoch 2864/1000000, train_loss: 6.1613, val_loss: 4.8239, time: 0.12s\n",
      "Epoch 2865/1000000, train_loss: 6.1611, val_loss: 4.8228, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2866/1000000, train_loss: 6.1600, val_loss: 4.8088, time: 0.12s\n",
      "Epoch 2867/1000000, train_loss: 6.1593, val_loss: 4.8123, time: 0.12s\n",
      "Epoch 2868/1000000, train_loss: 6.1595, val_loss: 4.8197, time: 0.12s\n",
      "Epoch 2869/1000000, train_loss: 6.1593, val_loss: 4.8143, time: 0.20s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2870/1000000, train_loss: 6.1572, val_loss: 4.7901, time: 0.13s\n",
      "Epoch 2871/1000000, train_loss: 6.1575, val_loss: 4.8076, time: 0.13s\n",
      "Epoch 2872/1000000, train_loss: 6.1585, val_loss: 4.8002, time: 0.12s\n",
      "Epoch 2873/1000000, train_loss: 6.1561, val_loss: 4.7975, time: 0.12s\n",
      "Epoch 2874/1000000, train_loss: 6.1559, val_loss: 4.8001, time: 0.12s\n",
      "Epoch 2875/1000000, train_loss: 6.1563, val_loss: 4.8053, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2876/1000000, train_loss: 6.1557, val_loss: 4.7878, time: 0.12s\n",
      "Epoch 2877/1000000, train_loss: 6.1558, val_loss: 4.8053, time: 0.12s\n",
      "Epoch 2878/1000000, train_loss: 6.1556, val_loss: 4.7886, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2879/1000000, train_loss: 6.1542, val_loss: 4.7863, time: 0.12s\n",
      "Epoch 2880/1000000, train_loss: 6.1536, val_loss: 4.7942, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2881/1000000, train_loss: 6.1539, val_loss: 4.7804, time: 0.12s\n",
      "Epoch 2882/1000000, train_loss: 6.1522, val_loss: 4.7978, time: 0.12s\n",
      "Epoch 2883/1000000, train_loss: 6.1516, val_loss: 4.7872, time: 0.12s\n",
      "Epoch 2884/1000000, train_loss: 6.1515, val_loss: 4.7837, time: 0.12s\n",
      "Epoch 2885/1000000, train_loss: 6.1513, val_loss: 4.7893, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2886/1000000, train_loss: 6.1510, val_loss: 4.7695, time: 0.12s\n",
      "Epoch 2887/1000000, train_loss: 6.1508, val_loss: 4.7744, time: 0.12s\n",
      "Epoch 2888/1000000, train_loss: 6.1497, val_loss: 4.7838, time: 0.12s\n",
      "Epoch 2889/1000000, train_loss: 6.1508, val_loss: 4.7825, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2890/1000000, train_loss: 6.1494, val_loss: 4.7661, time: 0.12s\n",
      "Epoch 2891/1000000, train_loss: 6.1498, val_loss: 4.7724, time: 0.12s\n",
      "Epoch 2892/1000000, train_loss: 6.1478, val_loss: 4.7765, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2893/1000000, train_loss: 6.1483, val_loss: 4.7646, time: 0.12s\n",
      "Epoch 2894/1000000, train_loss: 6.1476, val_loss: 4.7667, time: 0.12s\n",
      "Epoch 2895/1000000, train_loss: 6.1476, val_loss: 4.7749, time: 0.12s\n",
      "Epoch 2896/1000000, train_loss: 6.1458, val_loss: 4.7731, time: 0.12s\n",
      "Epoch 2897/1000000, train_loss: 6.1457, val_loss: 4.7701, time: 0.12s\n",
      "Epoch 2898/1000000, train_loss: 6.1453, val_loss: 4.7697, time: 0.12s\n",
      "Epoch 2899/1000000, train_loss: 6.1448, val_loss: 4.7696, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2900/1000000, train_loss: 6.1453, val_loss: 4.7642, time: 0.12s\n",
      "Epoch 2901/1000000, train_loss: 6.1446, val_loss: 4.7689, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2902/1000000, train_loss: 6.1450, val_loss: 4.7526, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2903/1000000, train_loss: 6.1431, val_loss: 4.7520, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2904/1000000, train_loss: 6.1441, val_loss: 4.7492, time: 0.14s\n",
      "Epoch 2905/1000000, train_loss: 6.1424, val_loss: 4.7571, time: 0.14s\n",
      "Epoch 2906/1000000, train_loss: 6.1421, val_loss: 4.7567, time: 0.12s\n",
      "Epoch 2907/1000000, train_loss: 6.1411, val_loss: 4.7507, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2908/1000000, train_loss: 6.1403, val_loss: 4.7459, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2909/1000000, train_loss: 6.1407, val_loss: 4.7446, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2910/1000000, train_loss: 6.1400, val_loss: 4.7397, time: 0.12s\n",
      "Epoch 2911/1000000, train_loss: 6.1396, val_loss: 4.7439, time: 0.12s\n",
      "Epoch 2912/1000000, train_loss: 6.1389, val_loss: 4.7540, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2913/1000000, train_loss: 6.1381, val_loss: 4.7334, time: 0.13s\n",
      "Epoch 2914/1000000, train_loss: 6.1390, val_loss: 4.7441, time: 0.13s\n",
      "Epoch 2915/1000000, train_loss: 6.1366, val_loss: 4.7347, time: 0.12s\n",
      "Epoch 2916/1000000, train_loss: 6.1373, val_loss: 4.7343, time: 0.12s\n",
      "Epoch 2917/1000000, train_loss: 6.1361, val_loss: 4.7362, time: 0.12s\n",
      "Epoch 2918/1000000, train_loss: 6.1354, val_loss: 4.7339, time: 0.12s\n",
      "Epoch 2919/1000000, train_loss: 6.1372, val_loss: 4.7343, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2920/1000000, train_loss: 6.1353, val_loss: 4.7285, time: 0.29s\n",
      "Epoch 2921/1000000, train_loss: 6.1350, val_loss: 4.7327, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2922/1000000, train_loss: 6.1352, val_loss: 4.7141, time: 0.13s\n",
      "Epoch 2923/1000000, train_loss: 6.1346, val_loss: 4.7349, time: 0.12s\n",
      "Epoch 2924/1000000, train_loss: 6.1326, val_loss: 4.7232, time: 0.12s\n",
      "Epoch 2925/1000000, train_loss: 6.1332, val_loss: 4.7319, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2926/1000000, train_loss: 6.1329, val_loss: 4.7037, time: 0.12s\n",
      "Epoch 2927/1000000, train_loss: 6.1320, val_loss: 4.7134, time: 0.12s\n",
      "Epoch 2928/1000000, train_loss: 6.1318, val_loss: 4.7121, time: 0.12s\n",
      "Epoch 2929/1000000, train_loss: 6.1308, val_loss: 4.7114, time: 0.12s\n",
      "Epoch 2930/1000000, train_loss: 6.1301, val_loss: 4.7093, time: 0.12s\n",
      "Epoch 2931/1000000, train_loss: 6.1293, val_loss: 4.7054, time: 0.12s\n",
      "Epoch 2932/1000000, train_loss: 6.1306, val_loss: 4.7057, time: 0.12s\n",
      "Epoch 2933/1000000, train_loss: 6.1301, val_loss: 4.7061, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2934/1000000, train_loss: 6.1286, val_loss: 4.7015, time: 0.12s\n",
      "Epoch 2935/1000000, train_loss: 6.1275, val_loss: 4.7082, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2936/1000000, train_loss: 6.1288, val_loss: 4.6974, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2937/1000000, train_loss: 6.1265, val_loss: 4.6788, time: 0.12s\n",
      "Epoch 2938/1000000, train_loss: 6.1273, val_loss: 4.7027, time: 0.12s\n",
      "Epoch 2939/1000000, train_loss: 6.1259, val_loss: 4.7054, time: 0.12s\n",
      "Epoch 2940/1000000, train_loss: 6.1258, val_loss: 4.7007, time: 0.12s\n",
      "Epoch 2941/1000000, train_loss: 6.1247, val_loss: 4.6989, time: 0.12s\n",
      "Epoch 2942/1000000, train_loss: 6.1259, val_loss: 4.6849, time: 0.12s\n",
      "Epoch 2943/1000000, train_loss: 6.1238, val_loss: 4.6814, time: 0.12s\n",
      "Epoch 2944/1000000, train_loss: 6.1244, val_loss: 4.6985, time: 0.12s\n",
      "Epoch 2945/1000000, train_loss: 6.1248, val_loss: 4.6932, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2946/1000000, train_loss: 6.1231, val_loss: 4.6763, time: 0.13s\n",
      "Epoch 2947/1000000, train_loss: 6.1224, val_loss: 4.6892, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2948/1000000, train_loss: 6.1221, val_loss: 4.6735, time: 0.12s\n",
      "Epoch 2949/1000000, train_loss: 6.1213, val_loss: 4.6841, time: 0.12s\n",
      "Epoch 2950/1000000, train_loss: 6.1213, val_loss: 4.6768, time: 0.12s\n",
      "Epoch 2951/1000000, train_loss: 6.1202, val_loss: 4.6844, time: 0.14s\n",
      "Epoch 2952/1000000, train_loss: 6.1208, val_loss: 4.6774, time: 0.12s\n",
      "Epoch 2953/1000000, train_loss: 6.1214, val_loss: 4.6800, time: 0.12s\n",
      "Epoch 2954/1000000, train_loss: 6.1191, val_loss: 4.6813, time: 0.12s\n",
      "Epoch 2955/1000000, train_loss: 6.1184, val_loss: 4.6781, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2956/1000000, train_loss: 6.1184, val_loss: 4.6715, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2957/1000000, train_loss: 6.1185, val_loss: 4.6713, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2958/1000000, train_loss: 6.1172, val_loss: 4.6511, time: 0.12s\n",
      "Epoch 2959/1000000, train_loss: 6.1166, val_loss: 4.6606, time: 0.12s\n",
      "Epoch 2960/1000000, train_loss: 6.1154, val_loss: 4.6717, time: 0.12s\n",
      "Epoch 2961/1000000, train_loss: 6.1158, val_loss: 4.6552, time: 0.12s\n",
      "Epoch 2962/1000000, train_loss: 6.1164, val_loss: 4.6536, time: 0.12s\n",
      "Epoch 2963/1000000, train_loss: 6.1152, val_loss: 4.6511, time: 0.12s\n",
      "Epoch 2964/1000000, train_loss: 6.1145, val_loss: 4.6622, time: 0.12s\n",
      "Epoch 2965/1000000, train_loss: 6.1136, val_loss: 4.6652, time: 0.12s\n",
      "Epoch 2966/1000000, train_loss: 6.1124, val_loss: 4.6597, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2967/1000000, train_loss: 6.1135, val_loss: 4.6483, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2968/1000000, train_loss: 6.1128, val_loss: 4.6412, time: 0.12s\n",
      "Epoch 2969/1000000, train_loss: 6.1135, val_loss: 4.6523, time: 0.12s\n",
      "Epoch 2970/1000000, train_loss: 6.1121, val_loss: 4.6514, time: 0.12s\n",
      "Epoch 2971/1000000, train_loss: 6.1112, val_loss: 4.6503, time: 0.12s\n",
      "Epoch 2972/1000000, train_loss: 6.1107, val_loss: 4.6417, time: 0.14s\n",
      "Epoch 2973/1000000, train_loss: 6.1117, val_loss: 4.6501, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2974/1000000, train_loss: 6.1095, val_loss: 4.6394, time: 0.12s\n",
      "Epoch 2975/1000000, train_loss: 6.1106, val_loss: 4.6521, time: 0.12s\n",
      "Epoch 2976/1000000, train_loss: 6.1091, val_loss: 4.6452, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2977/1000000, train_loss: 6.1088, val_loss: 4.6311, time: 0.14s\n",
      "Epoch 2978/1000000, train_loss: 6.1079, val_loss: 4.6437, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2979/1000000, train_loss: 6.1076, val_loss: 4.6203, time: 0.13s\n",
      "Epoch 2980/1000000, train_loss: 6.1084, val_loss: 4.6310, time: 0.12s\n",
      "Epoch 2981/1000000, train_loss: 6.1076, val_loss: 4.6384, time: 0.12s\n",
      "Epoch 2982/1000000, train_loss: 6.1060, val_loss: 4.6442, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2983/1000000, train_loss: 6.1048, val_loss: 4.6137, time: 0.12s\n",
      "Epoch 2984/1000000, train_loss: 6.1063, val_loss: 4.6149, time: 0.14s\n",
      "Epoch 2985/1000000, train_loss: 6.1054, val_loss: 4.6313, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2986/1000000, train_loss: 6.1049, val_loss: 4.6082, time: 0.21s\n",
      "Epoch 2987/1000000, train_loss: 6.1040, val_loss: 4.6093, time: 0.21s\n",
      "Epoch 2988/1000000, train_loss: 6.1037, val_loss: 4.6083, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2989/1000000, train_loss: 6.1019, val_loss: 4.6038, time: 0.12s\n",
      "Epoch 2990/1000000, train_loss: 6.1031, val_loss: 4.6161, time: 0.12s\n",
      "Epoch 2991/1000000, train_loss: 6.1016, val_loss: 4.6159, time: 0.12s\n",
      "Epoch 2992/1000000, train_loss: 6.0998, val_loss: 4.6088, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2993/1000000, train_loss: 6.1008, val_loss: 4.5958, time: 0.12s\n",
      "Epoch 2994/1000000, train_loss: 6.1006, val_loss: 4.6012, time: 0.12s\n",
      "Epoch 2995/1000000, train_loss: 6.0993, val_loss: 4.6058, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 2996/1000000, train_loss: 6.0994, val_loss: 4.5896, time: 0.12s\n",
      "Epoch 2997/1000000, train_loss: 6.0988, val_loss: 4.6089, time: 0.12s\n",
      "Epoch 2998/1000000, train_loss: 6.0989, val_loss: 4.6160, time: 0.12s\n",
      "Epoch 2999/1000000, train_loss: 6.0976, val_loss: 4.6088, time: 0.12s\n",
      "Epoch 3000/1000000, train_loss: 6.0985, val_loss: 4.6043, time: 0.14s\n",
      "Epoch 3001/1000000, train_loss: 6.0971, val_loss: 4.5997, time: 0.12s\n",
      "Epoch 3002/1000000, train_loss: 6.0972, val_loss: 4.5963, time: 0.14s\n",
      "Epoch 3003/1000000, train_loss: 6.0956, val_loss: 4.5912, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3004/1000000, train_loss: 6.0946, val_loss: 4.5894, time: 0.12s\n",
      "Epoch 3005/1000000, train_loss: 6.0977, val_loss: 4.5998, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3006/1000000, train_loss: 6.0950, val_loss: 4.5793, time: 0.13s\n",
      "Epoch 3007/1000000, train_loss: 6.0935, val_loss: 4.5876, time: 0.12s\n",
      "Epoch 3008/1000000, train_loss: 6.0940, val_loss: 4.5857, time: 0.12s\n",
      "Epoch 3009/1000000, train_loss: 6.0932, val_loss: 4.5974, time: 0.12s\n",
      "Epoch 3010/1000000, train_loss: 6.0920, val_loss: 4.5821, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3011/1000000, train_loss: 6.0934, val_loss: 4.5725, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3012/1000000, train_loss: 6.0909, val_loss: 4.5663, time: 0.12s\n",
      "Epoch 3013/1000000, train_loss: 6.0923, val_loss: 4.5859, time: 0.12s\n",
      "Epoch 3014/1000000, train_loss: 6.0915, val_loss: 4.5795, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3015/1000000, train_loss: 6.0914, val_loss: 4.5576, time: 0.13s\n",
      "Epoch 3016/1000000, train_loss: 6.0894, val_loss: 4.5778, time: 0.14s\n",
      "Epoch 3017/1000000, train_loss: 6.0893, val_loss: 4.5652, time: 0.16s\n",
      "Epoch 3018/1000000, train_loss: 6.0888, val_loss: 4.5603, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3019/1000000, train_loss: 6.0898, val_loss: 4.5531, time: 0.15s\n",
      "Epoch 3020/1000000, train_loss: 6.0890, val_loss: 4.5657, time: 0.12s\n",
      "Epoch 3021/1000000, train_loss: 6.0876, val_loss: 4.5649, time: 0.12s\n",
      "Epoch 3022/1000000, train_loss: 6.0878, val_loss: 4.5647, time: 0.24s\n",
      "Epoch 3023/1000000, train_loss: 6.0859, val_loss: 4.5672, time: 0.13s\n",
      "Epoch 3024/1000000, train_loss: 6.0855, val_loss: 4.5588, time: 0.12s\n",
      "Epoch 3025/1000000, train_loss: 6.0853, val_loss: 4.5708, time: 0.12s\n",
      "Epoch 3026/1000000, train_loss: 6.0853, val_loss: 4.5668, time: 0.14s\n",
      "Epoch 3027/1000000, train_loss: 6.0860, val_loss: 4.5662, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3028/1000000, train_loss: 6.0849, val_loss: 4.5450, time: 0.13s\n",
      "Epoch 3029/1000000, train_loss: 6.0847, val_loss: 4.5546, time: 0.12s\n",
      "Epoch 3030/1000000, train_loss: 6.0843, val_loss: 4.5514, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3031/1000000, train_loss: 6.0845, val_loss: 4.5449, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3032/1000000, train_loss: 6.0833, val_loss: 4.5338, time: 0.12s\n",
      "Epoch 3033/1000000, train_loss: 6.0817, val_loss: 4.5445, time: 0.12s\n",
      "Epoch 3034/1000000, train_loss: 6.0816, val_loss: 4.5525, time: 0.12s\n",
      "Epoch 3035/1000000, train_loss: 6.0810, val_loss: 4.5492, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3036/1000000, train_loss: 6.0803, val_loss: 4.5274, time: 0.12s\n",
      "Epoch 3037/1000000, train_loss: 6.0822, val_loss: 4.5396, time: 0.12s\n",
      "Epoch 3038/1000000, train_loss: 6.0805, val_loss: 4.5367, time: 0.12s\n",
      "Epoch 3039/1000000, train_loss: 6.0798, val_loss: 4.5403, time: 0.12s\n",
      "Epoch 3040/1000000, train_loss: 6.0803, val_loss: 4.5275, time: 0.12s\n",
      "Epoch 3041/1000000, train_loss: 6.0792, val_loss: 4.5475, time: 0.12s\n",
      "Epoch 3042/1000000, train_loss: 6.0784, val_loss: 4.5376, time: 0.12s\n",
      "Epoch 3043/1000000, train_loss: 6.0775, val_loss: 4.5339, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3044/1000000, train_loss: 6.0769, val_loss: 4.5271, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3045/1000000, train_loss: 6.0766, val_loss: 4.5212, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3046/1000000, train_loss: 6.0757, val_loss: 4.5173, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3047/1000000, train_loss: 6.0767, val_loss: 4.5143, time: 0.13s\n",
      "Epoch 3048/1000000, train_loss: 6.0756, val_loss: 4.5157, time: 0.12s\n",
      "Epoch 3049/1000000, train_loss: 6.0744, val_loss: 4.5286, time: 0.12s\n",
      "Epoch 3050/1000000, train_loss: 6.0740, val_loss: 4.5159, time: 0.12s\n",
      "Epoch 3051/1000000, train_loss: 6.0744, val_loss: 4.5226, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3052/1000000, train_loss: 6.0734, val_loss: 4.5069, time: 0.12s\n",
      "Epoch 3053/1000000, train_loss: 6.0738, val_loss: 4.5154, time: 0.12s\n",
      "Epoch 3054/1000000, train_loss: 6.0731, val_loss: 4.5124, time: 0.12s\n",
      "Epoch 3055/1000000, train_loss: 6.0728, val_loss: 4.5169, time: 0.12s\n",
      "Epoch 3056/1000000, train_loss: 6.0716, val_loss: 4.5079, time: 0.13s\n",
      "Epoch 3057/1000000, train_loss: 6.0716, val_loss: 4.5126, time: 0.21s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3058/1000000, train_loss: 6.0721, val_loss: 4.5017, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3059/1000000, train_loss: 6.0710, val_loss: 4.4906, time: 0.12s\n",
      "Epoch 3060/1000000, train_loss: 6.0686, val_loss: 4.5190, time: 0.12s\n",
      "Epoch 3061/1000000, train_loss: 6.0697, val_loss: 4.5013, time: 0.13s\n",
      "Epoch 3062/1000000, train_loss: 6.0680, val_loss: 4.4951, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3063/1000000, train_loss: 6.0679, val_loss: 4.4881, time: 0.12s\n",
      "Epoch 3064/1000000, train_loss: 6.0675, val_loss: 4.4947, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3065/1000000, train_loss: 6.0679, val_loss: 4.4871, time: 0.12s\n",
      "Epoch 3066/1000000, train_loss: 6.0667, val_loss: 4.4970, time: 0.12s\n",
      "Epoch 3067/1000000, train_loss: 6.0663, val_loss: 4.5121, time: 0.12s\n",
      "Epoch 3068/1000000, train_loss: 6.0669, val_loss: 4.4893, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3069/1000000, train_loss: 6.0662, val_loss: 4.4735, time: 0.12s\n",
      "Epoch 3070/1000000, train_loss: 6.0653, val_loss: 4.4955, time: 0.12s\n",
      "Epoch 3071/1000000, train_loss: 6.0640, val_loss: 4.4869, time: 0.12s\n",
      "Epoch 3072/1000000, train_loss: 6.0633, val_loss: 4.4854, time: 0.12s\n",
      "Epoch 3073/1000000, train_loss: 6.0619, val_loss: 4.4794, time: 0.12s\n",
      "Epoch 3074/1000000, train_loss: 6.0643, val_loss: 4.4769, time: 0.12s\n",
      "Epoch 3075/1000000, train_loss: 6.0636, val_loss: 4.4747, time: 0.12s\n",
      "Epoch 3076/1000000, train_loss: 6.0621, val_loss: 4.4783, time: 0.12s\n",
      "Epoch 3077/1000000, train_loss: 6.0622, val_loss: 4.4874, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3078/1000000, train_loss: 6.0600, val_loss: 4.4692, time: 0.12s\n",
      "Epoch 3079/1000000, train_loss: 6.0608, val_loss: 4.4872, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3080/1000000, train_loss: 6.0609, val_loss: 4.4660, time: 0.12s\n",
      "Epoch 3081/1000000, train_loss: 6.0585, val_loss: 4.4660, time: 0.12s\n",
      "Epoch 3082/1000000, train_loss: 6.0595, val_loss: 4.4750, time: 0.12s\n",
      "Epoch 3083/1000000, train_loss: 6.0601, val_loss: 4.4817, time: 0.12s\n",
      "Epoch 3084/1000000, train_loss: 6.0595, val_loss: 4.4670, time: 0.12s\n",
      "Epoch 3085/1000000, train_loss: 6.0583, val_loss: 4.4759, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3086/1000000, train_loss: 6.0587, val_loss: 4.4590, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3087/1000000, train_loss: 6.0574, val_loss: 4.4566, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3088/1000000, train_loss: 6.0569, val_loss: 4.4544, time: 0.12s\n",
      "Epoch 3089/1000000, train_loss: 6.0556, val_loss: 4.4597, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3090/1000000, train_loss: 6.0560, val_loss: 4.4524, time: 0.12s\n",
      "Epoch 3091/1000000, train_loss: 6.0558, val_loss: 4.4574, time: 0.12s\n",
      "Epoch 3092/1000000, train_loss: 6.0560, val_loss: 4.4533, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3093/1000000, train_loss: 6.0550, val_loss: 4.4449, time: 0.12s\n",
      "Epoch 3094/1000000, train_loss: 6.0537, val_loss: 4.4519, time: 0.12s\n",
      "Epoch 3095/1000000, train_loss: 6.0535, val_loss: 4.4468, time: 0.12s\n",
      "Epoch 3096/1000000, train_loss: 6.0538, val_loss: 4.4505, time: 0.12s\n",
      "Epoch 3097/1000000, train_loss: 6.0527, val_loss: 4.4629, time: 0.12s\n",
      "Epoch 3098/1000000, train_loss: 6.0513, val_loss: 4.4509, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3099/1000000, train_loss: 6.0521, val_loss: 4.4389, time: 0.12s\n",
      "Epoch 3100/1000000, train_loss: 6.0505, val_loss: 4.4512, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3101/1000000, train_loss: 6.0505, val_loss: 4.4380, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3102/1000000, train_loss: 6.0493, val_loss: 4.4233, time: 0.12s\n",
      "Epoch 3103/1000000, train_loss: 6.0486, val_loss: 4.4278, time: 0.12s\n",
      "Epoch 3104/1000000, train_loss: 6.0492, val_loss: 4.4296, time: 0.12s\n",
      "Epoch 3105/1000000, train_loss: 6.0480, val_loss: 4.4236, time: 0.12s\n",
      "Epoch 3106/1000000, train_loss: 6.0482, val_loss: 4.4273, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3107/1000000, train_loss: 6.0466, val_loss: 4.4180, time: 0.12s\n",
      "Epoch 3108/1000000, train_loss: 6.0487, val_loss: 4.4268, time: 0.12s\n",
      "Epoch 3109/1000000, train_loss: 6.0478, val_loss: 4.4230, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3110/1000000, train_loss: 6.0458, val_loss: 4.4172, time: 0.12s\n",
      "Epoch 3111/1000000, train_loss: 6.0470, val_loss: 4.4215, time: 0.12s\n",
      "Epoch 3112/1000000, train_loss: 6.0454, val_loss: 4.4292, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3113/1000000, train_loss: 6.0456, val_loss: 4.4077, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3114/1000000, train_loss: 6.0435, val_loss: 4.4056, time: 0.12s\n",
      "Epoch 3115/1000000, train_loss: 6.0445, val_loss: 4.4073, time: 0.12s\n",
      "Epoch 3116/1000000, train_loss: 6.0447, val_loss: 4.4130, time: 0.12s\n",
      "Epoch 3117/1000000, train_loss: 6.0420, val_loss: 4.4132, time: 0.19s\n",
      "Epoch 3118/1000000, train_loss: 6.0415, val_loss: 4.4125, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3119/1000000, train_loss: 6.0428, val_loss: 4.4054, time: 0.12s\n",
      "Epoch 3120/1000000, train_loss: 6.0413, val_loss: 4.4093, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3121/1000000, train_loss: 6.0407, val_loss: 4.3846, time: 0.12s\n",
      "Epoch 3122/1000000, train_loss: 6.0413, val_loss: 4.4048, time: 0.13s\n",
      "Epoch 3123/1000000, train_loss: 6.0415, val_loss: 4.3966, time: 0.12s\n",
      "Epoch 3124/1000000, train_loss: 6.0397, val_loss: 4.3978, time: 0.17s\n",
      "Epoch 3125/1000000, train_loss: 6.0396, val_loss: 4.3898, time: 0.12s\n",
      "Epoch 3126/1000000, train_loss: 6.0394, val_loss: 4.3891, time: 0.12s\n",
      "Epoch 3127/1000000, train_loss: 6.0386, val_loss: 4.4135, time: 0.12s\n",
      "Epoch 3128/1000000, train_loss: 6.0366, val_loss: 4.3924, time: 0.12s\n",
      "Epoch 3129/1000000, train_loss: 6.0370, val_loss: 4.4094, time: 0.13s\n",
      "Epoch 3130/1000000, train_loss: 6.0377, val_loss: 4.3881, time: 0.15s\n",
      "Epoch 3131/1000000, train_loss: 6.0376, val_loss: 4.3868, time: 0.12s\n",
      "Epoch 3132/1000000, train_loss: 6.0377, val_loss: 4.3978, time: 0.12s\n",
      "Epoch 3133/1000000, train_loss: 6.0359, val_loss: 4.3923, time: 0.12s\n",
      "Epoch 3134/1000000, train_loss: 6.0349, val_loss: 4.3893, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3135/1000000, train_loss: 6.0352, val_loss: 4.3799, time: 0.16s\n",
      "Epoch 3136/1000000, train_loss: 6.0344, val_loss: 4.3923, time: 0.12s\n",
      "Epoch 3137/1000000, train_loss: 6.0337, val_loss: 4.3802, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3138/1000000, train_loss: 6.0340, val_loss: 4.3630, time: 0.12s\n",
      "Epoch 3139/1000000, train_loss: 6.0338, val_loss: 4.3658, time: 0.12s\n",
      "Epoch 3140/1000000, train_loss: 6.0332, val_loss: 4.3677, time: 0.12s\n",
      "Epoch 3141/1000000, train_loss: 6.0322, val_loss: 4.3758, time: 0.12s\n",
      "Epoch 3142/1000000, train_loss: 6.0309, val_loss: 4.3731, time: 0.12s\n",
      "Epoch 3143/1000000, train_loss: 6.0314, val_loss: 4.3642, time: 0.12s\n",
      "Epoch 3144/1000000, train_loss: 6.0298, val_loss: 4.3686, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3145/1000000, train_loss: 6.0299, val_loss: 4.3544, time: 0.12s\n",
      "Epoch 3146/1000000, train_loss: 6.0297, val_loss: 4.3564, time: 0.12s\n",
      "Epoch 3147/1000000, train_loss: 6.0301, val_loss: 4.3562, time: 0.12s\n",
      "Epoch 3148/1000000, train_loss: 6.0286, val_loss: 4.3604, time: 0.12s\n",
      "Epoch 3149/1000000, train_loss: 6.0283, val_loss: 4.3574, time: 0.12s\n",
      "Epoch 3150/1000000, train_loss: 6.0281, val_loss: 4.3565, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3151/1000000, train_loss: 6.0270, val_loss: 4.3464, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3152/1000000, train_loss: 6.0273, val_loss: 4.3424, time: 0.12s\n",
      "Epoch 3153/1000000, train_loss: 6.0259, val_loss: 4.3536, time: 0.12s\n",
      "Epoch 3154/1000000, train_loss: 6.0262, val_loss: 4.3690, time: 0.12s\n",
      "Epoch 3155/1000000, train_loss: 6.0252, val_loss: 4.3670, time: 0.12s\n",
      "Epoch 3156/1000000, train_loss: 6.0231, val_loss: 4.3434, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3157/1000000, train_loss: 6.0241, val_loss: 4.3405, time: 0.13s\n",
      "Epoch 3158/1000000, train_loss: 6.0230, val_loss: 4.3606, time: 0.12s\n",
      "Epoch 3159/1000000, train_loss: 6.0232, val_loss: 4.3606, time: 0.12s\n",
      "Epoch 3160/1000000, train_loss: 6.0232, val_loss: 4.3442, time: 0.12s\n",
      "Epoch 3161/1000000, train_loss: 6.0213, val_loss: 4.3516, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3162/1000000, train_loss: 6.0218, val_loss: 4.3376, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3163/1000000, train_loss: 6.0206, val_loss: 4.3182, time: 0.12s\n",
      "Epoch 3164/1000000, train_loss: 6.0215, val_loss: 4.3487, time: 0.12s\n",
      "Epoch 3165/1000000, train_loss: 6.0195, val_loss: 4.3287, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3166/1000000, train_loss: 6.0203, val_loss: 4.3145, time: 0.15s\n",
      "Epoch 3167/1000000, train_loss: 6.0209, val_loss: 4.3272, time: 0.14s\n",
      "Epoch 3168/1000000, train_loss: 6.0186, val_loss: 4.3211, time: 0.12s\n",
      "Epoch 3169/1000000, train_loss: 6.0178, val_loss: 4.3331, time: 0.12s\n",
      "Epoch 3170/1000000, train_loss: 6.0187, val_loss: 4.3178, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3171/1000000, train_loss: 6.0174, val_loss: 4.3031, time: 0.14s\n",
      "Epoch 3172/1000000, train_loss: 6.0173, val_loss: 4.3125, time: 0.12s\n",
      "Epoch 3173/1000000, train_loss: 6.0177, val_loss: 4.3218, time: 0.12s\n",
      "Epoch 3174/1000000, train_loss: 6.0168, val_loss: 4.3236, time: 0.12s\n",
      "Epoch 3175/1000000, train_loss: 6.0153, val_loss: 4.3174, time: 0.12s\n",
      "Epoch 3176/1000000, train_loss: 6.0150, val_loss: 4.3147, time: 0.14s\n",
      "Epoch 3177/1000000, train_loss: 6.0145, val_loss: 4.3086, time: 0.13s\n",
      "Epoch 3178/1000000, train_loss: 6.0148, val_loss: 4.3116, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3179/1000000, train_loss: 6.0155, val_loss: 4.2973, time: 0.12s\n",
      "Epoch 3180/1000000, train_loss: 6.0147, val_loss: 4.3268, time: 0.12s\n",
      "Epoch 3181/1000000, train_loss: 6.0142, val_loss: 4.3067, time: 0.12s\n",
      "Epoch 3182/1000000, train_loss: 6.0119, val_loss: 4.2994, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3183/1000000, train_loss: 6.0126, val_loss: 4.2958, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3184/1000000, train_loss: 6.0115, val_loss: 4.2951, time: 0.12s\n",
      "Epoch 3185/1000000, train_loss: 6.0126, val_loss: 4.3000, time: 0.12s\n",
      "Epoch 3186/1000000, train_loss: 6.0098, val_loss: 4.2955, time: 0.12s\n",
      "Epoch 3187/1000000, train_loss: 6.0116, val_loss: 4.2995, time: 0.12s\n",
      "Epoch 3188/1000000, train_loss: 6.0098, val_loss: 4.3008, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3189/1000000, train_loss: 6.0090, val_loss: 4.2905, time: 0.12s\n",
      "Epoch 3190/1000000, train_loss: 6.0079, val_loss: 4.2915, time: 0.12s\n",
      "Epoch 3191/1000000, train_loss: 6.0102, val_loss: 4.2923, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3192/1000000, train_loss: 6.0070, val_loss: 4.2849, time: 0.12s\n",
      "Epoch 3193/1000000, train_loss: 6.0074, val_loss: 4.2909, time: 0.12s\n",
      "Epoch 3194/1000000, train_loss: 6.0064, val_loss: 4.3089, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3195/1000000, train_loss: 6.0073, val_loss: 4.2807, time: 0.22s\n",
      "Epoch 3196/1000000, train_loss: 6.0049, val_loss: 4.2965, time: 0.14s\n",
      "Epoch 3197/1000000, train_loss: 6.0053, val_loss: 4.2810, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3198/1000000, train_loss: 6.0055, val_loss: 4.2758, time: 0.12s\n",
      "Epoch 3199/1000000, train_loss: 6.0055, val_loss: 4.2761, time: 0.14s\n",
      "Epoch 3200/1000000, train_loss: 6.0048, val_loss: 4.2790, time: 0.12s\n",
      "Epoch 3201/1000000, train_loss: 6.0035, val_loss: 4.2891, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3202/1000000, train_loss: 6.0031, val_loss: 4.2663, time: 0.12s\n",
      "Epoch 3203/1000000, train_loss: 6.0036, val_loss: 4.2742, time: 0.12s\n",
      "Epoch 3204/1000000, train_loss: 6.0022, val_loss: 4.2817, time: 0.13s\n",
      "Epoch 3205/1000000, train_loss: 6.0017, val_loss: 4.2788, time: 0.13s\n",
      "Epoch 3206/1000000, train_loss: 6.0026, val_loss: 4.2758, time: 0.12s\n",
      "Epoch 3207/1000000, train_loss: 6.0010, val_loss: 4.2683, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3208/1000000, train_loss: 6.0002, val_loss: 4.2537, time: 0.12s\n",
      "Epoch 3209/1000000, train_loss: 6.0004, val_loss: 4.2553, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3210/1000000, train_loss: 5.9999, val_loss: 4.2486, time: 0.12s\n",
      "Epoch 3211/1000000, train_loss: 5.9993, val_loss: 4.2656, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3212/1000000, train_loss: 5.9988, val_loss: 4.2422, time: 0.12s\n",
      "Epoch 3213/1000000, train_loss: 5.9987, val_loss: 4.2503, time: 0.12s\n",
      "Epoch 3214/1000000, train_loss: 5.9962, val_loss: 4.2541, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3215/1000000, train_loss: 5.9973, val_loss: 4.2411, time: 0.12s\n",
      "Epoch 3216/1000000, train_loss: 5.9959, val_loss: 4.2586, time: 0.12s\n",
      "Epoch 3217/1000000, train_loss: 5.9958, val_loss: 4.2600, time: 0.12s\n",
      "Epoch 3218/1000000, train_loss: 5.9964, val_loss: 4.2471, time: 0.12s\n",
      "Epoch 3219/1000000, train_loss: 5.9954, val_loss: 4.2457, time: 0.12s\n",
      "Epoch 3220/1000000, train_loss: 5.9947, val_loss: 4.2524, time: 0.16s\n",
      "Epoch 3221/1000000, train_loss: 5.9945, val_loss: 4.2569, time: 0.19s\n",
      "Epoch 3222/1000000, train_loss: 5.9942, val_loss: 4.2533, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3223/1000000, train_loss: 5.9936, val_loss: 4.2367, time: 0.13s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3224/1000000, train_loss: 5.9931, val_loss: 4.2365, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3225/1000000, train_loss: 5.9916, val_loss: 4.2348, time: 0.12s\n",
      "Epoch 3226/1000000, train_loss: 5.9919, val_loss: 4.2382, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3227/1000000, train_loss: 5.9914, val_loss: 4.2339, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3228/1000000, train_loss: 5.9907, val_loss: 4.2235, time: 0.12s\n",
      "Epoch 3229/1000000, train_loss: 5.9910, val_loss: 4.2261, time: 0.12s\n",
      "Epoch 3230/1000000, train_loss: 5.9896, val_loss: 4.2247, time: 0.12s\n",
      "Epoch 3231/1000000, train_loss: 5.9894, val_loss: 4.2304, time: 0.12s\n",
      "Epoch 3232/1000000, train_loss: 5.9913, val_loss: 4.2327, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3233/1000000, train_loss: 5.9891, val_loss: 4.2200, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3234/1000000, train_loss: 5.9898, val_loss: 4.2117, time: 0.12s\n",
      "Epoch 3235/1000000, train_loss: 5.9867, val_loss: 4.2242, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3236/1000000, train_loss: 5.9873, val_loss: 4.2071, time: 0.12s\n",
      "Epoch 3237/1000000, train_loss: 5.9877, val_loss: 4.2290, time: 0.12s\n",
      "Epoch 3238/1000000, train_loss: 5.9862, val_loss: 4.2146, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3239/1000000, train_loss: 5.9857, val_loss: 4.2062, time: 0.21s\n",
      "Epoch 3240/1000000, train_loss: 5.9851, val_loss: 4.2370, time: 0.18s\n",
      "Epoch 3241/1000000, train_loss: 5.9847, val_loss: 4.2209, time: 0.13s\n",
      "Epoch 3242/1000000, train_loss: 5.9843, val_loss: 4.2156, time: 0.12s\n",
      "Epoch 3243/1000000, train_loss: 5.9845, val_loss: 4.2107, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3244/1000000, train_loss: 5.9839, val_loss: 4.2046, time: 0.12s\n",
      "Epoch 3245/1000000, train_loss: 5.9835, val_loss: 4.2074, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3246/1000000, train_loss: 5.9822, val_loss: 4.1961, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3247/1000000, train_loss: 5.9822, val_loss: 4.1950, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3248/1000000, train_loss: 5.9813, val_loss: 4.1896, time: 0.12s\n",
      "Epoch 3249/1000000, train_loss: 5.9814, val_loss: 4.2002, time: 0.12s\n",
      "Epoch 3250/1000000, train_loss: 5.9796, val_loss: 4.1982, time: 0.12s\n",
      "Epoch 3251/1000000, train_loss: 5.9790, val_loss: 4.1982, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3252/1000000, train_loss: 5.9796, val_loss: 4.1869, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3253/1000000, train_loss: 5.9783, val_loss: 4.1865, time: 0.12s\n",
      "Epoch 3254/1000000, train_loss: 5.9787, val_loss: 4.1896, time: 0.12s\n",
      "Epoch 3255/1000000, train_loss: 5.9790, val_loss: 4.1869, time: 0.12s\n",
      "Epoch 3256/1000000, train_loss: 5.9763, val_loss: 4.1905, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3257/1000000, train_loss: 5.9776, val_loss: 4.1724, time: 0.12s\n",
      "Epoch 3258/1000000, train_loss: 5.9774, val_loss: 4.1860, time: 0.12s\n",
      "Epoch 3259/1000000, train_loss: 5.9750, val_loss: 4.1945, time: 0.12s\n",
      "Epoch 3260/1000000, train_loss: 5.9757, val_loss: 4.1899, time: 0.12s\n",
      "Epoch 3261/1000000, train_loss: 5.9762, val_loss: 4.1795, time: 0.12s\n",
      "Epoch 3262/1000000, train_loss: 5.9752, val_loss: 4.1917, time: 0.12s\n",
      "Epoch 3263/1000000, train_loss: 5.9737, val_loss: 4.1727, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3264/1000000, train_loss: 5.9746, val_loss: 4.1707, time: 0.12s\n",
      "Epoch 3265/1000000, train_loss: 5.9722, val_loss: 4.1870, time: 0.12s\n",
      "Epoch 3266/1000000, train_loss: 5.9734, val_loss: 4.1724, time: 0.12s\n",
      "Epoch 3267/1000000, train_loss: 5.9733, val_loss: 4.1785, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3268/1000000, train_loss: 5.9717, val_loss: 4.1505, time: 0.12s\n",
      "Epoch 3269/1000000, train_loss: 5.9737, val_loss: 4.1679, time: 0.12s\n",
      "Epoch 3270/1000000, train_loss: 5.9710, val_loss: 4.1647, time: 0.15s\n",
      "Epoch 3271/1000000, train_loss: 5.9721, val_loss: 4.1644, time: 0.16s\n",
      "Epoch 3272/1000000, train_loss: 5.9722, val_loss: 4.1696, time: 0.14s\n",
      "Epoch 3273/1000000, train_loss: 5.9700, val_loss: 4.1576, time: 0.15s\n",
      "Epoch 3274/1000000, train_loss: 5.9688, val_loss: 4.1669, time: 0.12s\n",
      "Epoch 3275/1000000, train_loss: 5.9685, val_loss: 4.1571, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3276/1000000, train_loss: 5.9684, val_loss: 4.1446, time: 0.12s\n",
      "Epoch 3277/1000000, train_loss: 5.9690, val_loss: 4.1658, time: 0.12s\n",
      "Epoch 3278/1000000, train_loss: 5.9684, val_loss: 4.1530, time: 0.13s\n",
      "Epoch 3279/1000000, train_loss: 5.9684, val_loss: 4.1562, time: 0.12s\n",
      "Epoch 3280/1000000, train_loss: 5.9683, val_loss: 4.1586, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3281/1000000, train_loss: 5.9675, val_loss: 4.1430, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3282/1000000, train_loss: 5.9657, val_loss: 4.1364, time: 0.12s\n",
      "Epoch 3283/1000000, train_loss: 5.9674, val_loss: 4.1457, time: 0.12s\n",
      "Epoch 3284/1000000, train_loss: 5.9648, val_loss: 4.1558, time: 0.12s\n",
      "Epoch 3285/1000000, train_loss: 5.9639, val_loss: 4.1497, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3286/1000000, train_loss: 5.9659, val_loss: 4.1335, time: 0.12s\n",
      "Epoch 3287/1000000, train_loss: 5.9643, val_loss: 4.1509, time: 0.19s\n",
      "Epoch 3288/1000000, train_loss: 5.9650, val_loss: 4.1449, time: 0.14s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3289/1000000, train_loss: 5.9637, val_loss: 4.1270, time: 0.13s\n",
      "Epoch 3290/1000000, train_loss: 5.9643, val_loss: 4.1405, time: 0.15s\n",
      "Epoch 3291/1000000, train_loss: 5.9652, val_loss: 4.1284, time: 0.18s\n",
      "Epoch 3292/1000000, train_loss: 5.9615, val_loss: 4.1413, time: 0.13s\n",
      "Epoch 3293/1000000, train_loss: 5.9624, val_loss: 4.1311, time: 0.12s\n",
      "Epoch 3294/1000000, train_loss: 5.9630, val_loss: 4.1383, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3295/1000000, train_loss: 5.9607, val_loss: 4.1219, time: 0.12s\n",
      "Epoch 3296/1000000, train_loss: 5.9618, val_loss: 4.1280, time: 0.12s\n",
      "Epoch 3297/1000000, train_loss: 5.9611, val_loss: 4.1350, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3298/1000000, train_loss: 5.9608, val_loss: 4.1195, time: 0.12s\n",
      "Epoch 3299/1000000, train_loss: 5.9586, val_loss: 4.1291, time: 0.15s\n",
      "Epoch 3300/1000000, train_loss: 5.9592, val_loss: 4.1266, time: 0.13s\n",
      "Epoch 3301/1000000, train_loss: 5.9600, val_loss: 4.1198, time: 0.14s\n",
      "Epoch 3302/1000000, train_loss: 5.9582, val_loss: 4.1217, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3303/1000000, train_loss: 5.9596, val_loss: 4.1187, time: 0.12s\n",
      "Epoch 3304/1000000, train_loss: 5.9594, val_loss: 4.1224, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3305/1000000, train_loss: 5.9572, val_loss: 4.1077, time: 0.12s\n",
      "Epoch 3306/1000000, train_loss: 5.9581, val_loss: 4.1203, time: 0.12s\n",
      "Epoch 3307/1000000, train_loss: 5.9587, val_loss: 4.1190, time: 0.12s\n",
      "Epoch 3308/1000000, train_loss: 5.9587, val_loss: 4.1145, time: 0.18s\n",
      "Epoch 3309/1000000, train_loss: 5.9578, val_loss: 4.1178, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3310/1000000, train_loss: 5.9576, val_loss: 4.0989, time: 0.12s\n",
      "Epoch 3311/1000000, train_loss: 5.9577, val_loss: 4.1155, time: 0.21s\n",
      "Epoch 3312/1000000, train_loss: 5.9571, val_loss: 4.1197, time: 0.12s\n",
      "Epoch 3313/1000000, train_loss: 5.9553, val_loss: 4.1210, time: 0.12s\n",
      "Epoch 3314/1000000, train_loss: 5.9567, val_loss: 4.1138, time: 0.12s\n",
      "Epoch 3315/1000000, train_loss: 5.9556, val_loss: 4.1141, time: 0.12s\n",
      "Epoch 3316/1000000, train_loss: 5.9557, val_loss: 4.1085, time: 0.12s\n",
      "Epoch 3317/1000000, train_loss: 5.9564, val_loss: 4.1153, time: 0.12s\n",
      "Model saved to weights/multi2multi/best-RNN.pth\n",
      "Epoch 3318/1000000, train_loss: 5.9575, val_loss: 4.0799, time: 0.12s\n",
      "Epoch 3319/1000000, train_loss: 5.9552, val_loss: 4.1135, time: 0.12s\n",
      "Epoch 3320/1000000, train_loss: 5.9550, val_loss: 4.1029, time: 0.12s\n",
      "Epoch 3321/1000000, train_loss: 5.9551, val_loss: 4.1121, time: 0.12s\n",
      "Epoch 3322/1000000, train_loss: 5.9542, val_loss: 4.1040, time: 0.12s\n",
      "Epoch 3323/1000000, train_loss: 5.9540, val_loss: 4.1120, time: 0.12s\n",
      "Epoch 3324/1000000, train_loss: 5.9552, val_loss: 4.0999, time: 0.13s\n",
      "Epoch 3325/1000000, train_loss: 5.9531, val_loss: 4.1092, time: 0.13s\n",
      "Epoch 3326/1000000, train_loss: 5.9553, val_loss: 4.0961, time: 0.12s\n",
      "Epoch 3327/1000000, train_loss: 5.9539, val_loss: 4.1220, time: 0.12s\n",
      "Epoch 3328/1000000, train_loss: 5.9518, val_loss: 4.1091, time: 0.12s\n",
      "Epoch 3329/1000000, train_loss: 5.9536, val_loss: 4.1009, time: 0.12s\n",
      "Epoch 3330/1000000, train_loss: 5.9548, val_loss: 4.1216, time: 0.12s\n",
      "Epoch 3331/1000000, train_loss: 5.9535, val_loss: 4.1004, time: 0.12s\n",
      "Epoch 3332/1000000, train_loss: 5.9530, val_loss: 4.1064, time: 0.13s\n",
      "Epoch 3333/1000000, train_loss: 5.9537, val_loss: 4.0947, time: 0.12s\n",
      "Epoch 3334/1000000, train_loss: 5.9524, val_loss: 4.1091, time: 0.12s\n",
      "Epoch 3335/1000000, train_loss: 5.9515, val_loss: 4.0917, time: 0.12s\n",
      "Epoch 3336/1000000, train_loss: 5.9516, val_loss: 4.0983, time: 0.12s\n",
      "Epoch 3337/1000000, train_loss: 5.9525, val_loss: 4.0972, time: 0.12s\n",
      "Early stopping on epoch 3338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'RNN', 'Type': 'multi2multi', 'MAE': 4.871362004961286}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_multi2multi = RNN(input_size=multi2multi_loader.in_variable, hidden_size=hidden_size,output_size = multi2multi_loader.out_variable,ahead=label_size,num_layers=num_layers)\n",
    "RNN_multi2multi_manager = ModelManager(model=RNN_multi2multi,train_loader=multi2multi_loader.train_loader,val_loader=multi2multi_loader.val_loader,lr=learning_rate,patience=patience)\n",
    "RNN_multi2multi_manager.train(num_epochs=num_epochs,save_dir=os.path.join(weight_dir,sub_dir))\n",
    "results.append({\n",
    "    \"Name\": RNN_multi2multi_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": RNN_multi2multi_manager.evaluate(loader=multi2multi_loader.test_loader),\n",
    "})\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, ahead):\n",
    "        super(BiLSTM, self).__init__()  \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.ahead = ahead\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size * ahead)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out).view(-1, self.ahead, self.output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1/1000000, train_loss: 28.0771, val_loss: 28.5293, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 2/1000000, train_loss: 28.1725, val_loss: 28.4454, time: 0.16s\n",
      "Epoch 3/1000000, train_loss: 28.1697, val_loss: 28.4727, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 4/1000000, train_loss: 28.1379, val_loss: 28.4028, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 5/1000000, train_loss: 28.0767, val_loss: 28.3754, time: 0.15s\n",
      "Epoch 6/1000000, train_loss: 28.0432, val_loss: 28.4054, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 7/1000000, train_loss: 27.9546, val_loss: 28.2997, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 8/1000000, train_loss: 27.9362, val_loss: 28.2525, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 9/1000000, train_loss: 27.9498, val_loss: 28.1432, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 10/1000000, train_loss: 27.7441, val_loss: 28.0642, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 11/1000000, train_loss: 27.7292, val_loss: 28.0107, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 12/1000000, train_loss: 27.6179, val_loss: 27.9412, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 13/1000000, train_loss: 27.5977, val_loss: 27.8008, time: 0.26s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 14/1000000, train_loss: 27.4705, val_loss: 27.7588, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 15/1000000, train_loss: 27.3930, val_loss: 27.6359, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 16/1000000, train_loss: 27.2751, val_loss: 27.5452, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 17/1000000, train_loss: 27.2219, val_loss: 27.5016, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 18/1000000, train_loss: 27.0385, val_loss: 27.3852, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 19/1000000, train_loss: 26.9889, val_loss: 27.3247, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 20/1000000, train_loss: 26.9810, val_loss: 27.2069, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 21/1000000, train_loss: 26.8222, val_loss: 27.1156, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 22/1000000, train_loss: 26.8153, val_loss: 27.0347, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 23/1000000, train_loss: 26.6139, val_loss: 26.9079, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 24/1000000, train_loss: 26.5810, val_loss: 26.7975, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 25/1000000, train_loss: 26.5113, val_loss: 26.7455, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 26/1000000, train_loss: 26.3526, val_loss: 26.6701, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 27/1000000, train_loss: 26.2623, val_loss: 26.5614, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 28/1000000, train_loss: 26.2598, val_loss: 26.4345, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 29/1000000, train_loss: 26.1784, val_loss: 26.3962, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 30/1000000, train_loss: 26.0247, val_loss: 26.3403, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 31/1000000, train_loss: 25.9179, val_loss: 26.2395, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 32/1000000, train_loss: 25.9358, val_loss: 26.1897, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 33/1000000, train_loss: 25.7784, val_loss: 26.0913, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 34/1000000, train_loss: 25.7324, val_loss: 26.0085, time: 0.26s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 35/1000000, train_loss: 25.7714, val_loss: 25.9709, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 36/1000000, train_loss: 25.6652, val_loss: 25.8955, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 37/1000000, train_loss: 25.5257, val_loss: 25.8399, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 38/1000000, train_loss: 25.5226, val_loss: 25.7691, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 39/1000000, train_loss: 25.4043, val_loss: 25.6422, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 40/1000000, train_loss: 25.3696, val_loss: 25.6086, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 41/1000000, train_loss: 25.2820, val_loss: 25.5262, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 42/1000000, train_loss: 25.2578, val_loss: 25.4861, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 43/1000000, train_loss: 25.2026, val_loss: 25.4197, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 44/1000000, train_loss: 25.1387, val_loss: 25.3373, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 45/1000000, train_loss: 25.0751, val_loss: 25.2776, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 46/1000000, train_loss: 25.0095, val_loss: 25.2239, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 47/1000000, train_loss: 24.9655, val_loss: 25.1782, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 48/1000000, train_loss: 24.7886, val_loss: 25.0857, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 49/1000000, train_loss: 24.7660, val_loss: 25.0681, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 50/1000000, train_loss: 24.6993, val_loss: 24.9836, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 51/1000000, train_loss: 24.6435, val_loss: 24.9335, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 52/1000000, train_loss: 24.6271, val_loss: 24.8402, time: 0.16s\n",
      "Epoch 53/1000000, train_loss: 24.5937, val_loss: 24.8508, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 54/1000000, train_loss: 24.5523, val_loss: 24.7337, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 55/1000000, train_loss: 24.4651, val_loss: 24.7152, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 56/1000000, train_loss: 24.3986, val_loss: 24.6495, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 57/1000000, train_loss: 24.2646, val_loss: 24.5806, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 58/1000000, train_loss: 24.2517, val_loss: 24.5227, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 59/1000000, train_loss: 24.2837, val_loss: 24.4983, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 60/1000000, train_loss: 24.2277, val_loss: 24.4095, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 61/1000000, train_loss: 24.1838, val_loss: 24.3658, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 62/1000000, train_loss: 24.0652, val_loss: 24.3300, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 63/1000000, train_loss: 23.9713, val_loss: 24.2717, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 64/1000000, train_loss: 24.0028, val_loss: 24.1932, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 65/1000000, train_loss: 23.8380, val_loss: 24.1611, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 66/1000000, train_loss: 23.8108, val_loss: 24.1096, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 67/1000000, train_loss: 23.8166, val_loss: 24.0533, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 68/1000000, train_loss: 23.8143, val_loss: 24.0480, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 69/1000000, train_loss: 23.6558, val_loss: 23.9519, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 70/1000000, train_loss: 23.6197, val_loss: 23.8825, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 71/1000000, train_loss: 23.6396, val_loss: 23.8481, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 72/1000000, train_loss: 23.5935, val_loss: 23.7944, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 73/1000000, train_loss: 23.5122, val_loss: 23.7668, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 74/1000000, train_loss: 23.4075, val_loss: 23.7011, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 75/1000000, train_loss: 23.3975, val_loss: 23.6523, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 76/1000000, train_loss: 23.3727, val_loss: 23.6008, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 77/1000000, train_loss: 23.3046, val_loss: 23.5598, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 78/1000000, train_loss: 23.3572, val_loss: 23.4936, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 79/1000000, train_loss: 23.1821, val_loss: 23.4365, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 80/1000000, train_loss: 23.1689, val_loss: 23.3863, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 81/1000000, train_loss: 23.1351, val_loss: 23.3688, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 82/1000000, train_loss: 23.0311, val_loss: 23.3212, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 83/1000000, train_loss: 22.9153, val_loss: 23.2739, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 84/1000000, train_loss: 22.9380, val_loss: 23.1962, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 85/1000000, train_loss: 22.9965, val_loss: 23.1150, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 86/1000000, train_loss: 22.9345, val_loss: 23.0984, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 87/1000000, train_loss: 22.8754, val_loss: 23.0430, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 88/1000000, train_loss: 22.7213, val_loss: 22.9867, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 89/1000000, train_loss: 22.7924, val_loss: 22.9384, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 90/1000000, train_loss: 22.6297, val_loss: 22.8763, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 91/1000000, train_loss: 22.6304, val_loss: 22.8508, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 92/1000000, train_loss: 22.5377, val_loss: 22.7769, time: 0.16s\n",
      "Epoch 93/1000000, train_loss: 22.5640, val_loss: 22.7833, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 94/1000000, train_loss: 22.5488, val_loss: 22.6986, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 95/1000000, train_loss: 22.4575, val_loss: 22.6893, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 96/1000000, train_loss: 22.2934, val_loss: 22.6267, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 97/1000000, train_loss: 22.3792, val_loss: 22.5656, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 98/1000000, train_loss: 22.3305, val_loss: 22.5501, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 99/1000000, train_loss: 22.2116, val_loss: 22.5047, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 100/1000000, train_loss: 22.2010, val_loss: 22.4317, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 101/1000000, train_loss: 22.1938, val_loss: 22.3930, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 102/1000000, train_loss: 22.1015, val_loss: 22.3049, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 103/1000000, train_loss: 21.9906, val_loss: 22.2872, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 104/1000000, train_loss: 22.0617, val_loss: 22.2087, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 105/1000000, train_loss: 21.9535, val_loss: 22.1996, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 106/1000000, train_loss: 21.8904, val_loss: 22.1678, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 107/1000000, train_loss: 21.9077, val_loss: 22.1051, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 108/1000000, train_loss: 21.8433, val_loss: 22.0199, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 109/1000000, train_loss: 21.7738, val_loss: 22.0164, time: 0.22s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 110/1000000, train_loss: 21.8054, val_loss: 21.9560, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 111/1000000, train_loss: 21.7420, val_loss: 21.8991, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 112/1000000, train_loss: 21.7380, val_loss: 21.8551, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 113/1000000, train_loss: 21.6216, val_loss: 21.8018, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 114/1000000, train_loss: 21.5615, val_loss: 21.7742, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 115/1000000, train_loss: 21.5124, val_loss: 21.7183, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 116/1000000, train_loss: 21.4554, val_loss: 21.6753, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 117/1000000, train_loss: 21.4404, val_loss: 21.6523, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 118/1000000, train_loss: 21.3579, val_loss: 21.5819, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 119/1000000, train_loss: 21.3867, val_loss: 21.5059, time: 0.16s\n",
      "Epoch 120/1000000, train_loss: 21.2897, val_loss: 21.5441, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 121/1000000, train_loss: 21.2135, val_loss: 21.4508, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 122/1000000, train_loss: 21.1962, val_loss: 21.3981, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 123/1000000, train_loss: 21.1321, val_loss: 21.3722, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 124/1000000, train_loss: 21.1456, val_loss: 21.2861, time: 0.16s\n",
      "Epoch 125/1000000, train_loss: 21.0810, val_loss: 21.2881, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 126/1000000, train_loss: 20.9728, val_loss: 21.2141, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 127/1000000, train_loss: 20.9904, val_loss: 21.2098, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 128/1000000, train_loss: 20.8765, val_loss: 21.1528, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 129/1000000, train_loss: 20.8643, val_loss: 21.0951, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 130/1000000, train_loss: 20.7945, val_loss: 21.0635, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 131/1000000, train_loss: 20.7609, val_loss: 21.0107, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 132/1000000, train_loss: 20.7791, val_loss: 20.9889, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 133/1000000, train_loss: 20.7275, val_loss: 20.9502, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 134/1000000, train_loss: 20.6899, val_loss: 20.8957, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 135/1000000, train_loss: 20.6187, val_loss: 20.8366, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 136/1000000, train_loss: 20.5291, val_loss: 20.7888, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 137/1000000, train_loss: 20.5254, val_loss: 20.7484, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 138/1000000, train_loss: 20.4666, val_loss: 20.7207, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 139/1000000, train_loss: 20.4480, val_loss: 20.7011, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 140/1000000, train_loss: 20.4264, val_loss: 20.6303, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 141/1000000, train_loss: 20.3457, val_loss: 20.6036, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 142/1000000, train_loss: 20.2871, val_loss: 20.5821, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 143/1000000, train_loss: 20.2813, val_loss: 20.5058, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 144/1000000, train_loss: 20.2010, val_loss: 20.4683, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 145/1000000, train_loss: 20.2177, val_loss: 20.4149, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 146/1000000, train_loss: 20.0988, val_loss: 20.3801, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 147/1000000, train_loss: 20.1097, val_loss: 20.3101, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 148/1000000, train_loss: 20.0715, val_loss: 20.2815, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 149/1000000, train_loss: 20.0687, val_loss: 20.2519, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 150/1000000, train_loss: 20.0296, val_loss: 20.2076, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 151/1000000, train_loss: 19.8872, val_loss: 20.1869, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 152/1000000, train_loss: 19.8943, val_loss: 20.1242, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 153/1000000, train_loss: 19.8292, val_loss: 20.1098, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 154/1000000, train_loss: 19.8110, val_loss: 20.0379, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 155/1000000, train_loss: 19.7346, val_loss: 19.9967, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 156/1000000, train_loss: 19.7213, val_loss: 19.9508, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 157/1000000, train_loss: 19.6520, val_loss: 19.8994, time: 0.16s\n",
      "Epoch 158/1000000, train_loss: 19.6881, val_loss: 19.8999, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 159/1000000, train_loss: 19.5087, val_loss: 19.8394, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 160/1000000, train_loss: 19.6393, val_loss: 19.8222, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 161/1000000, train_loss: 19.5053, val_loss: 19.7427, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 162/1000000, train_loss: 19.5374, val_loss: 19.6964, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 163/1000000, train_loss: 19.4960, val_loss: 19.6780, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 164/1000000, train_loss: 19.3695, val_loss: 19.6327, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 165/1000000, train_loss: 19.3007, val_loss: 19.6095, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 166/1000000, train_loss: 19.3376, val_loss: 19.5426, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 167/1000000, train_loss: 19.2537, val_loss: 19.5385, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 168/1000000, train_loss: 19.2405, val_loss: 19.4678, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 169/1000000, train_loss: 19.1992, val_loss: 19.4191, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 170/1000000, train_loss: 19.1125, val_loss: 19.3870, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 171/1000000, train_loss: 19.0543, val_loss: 19.3458, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 172/1000000, train_loss: 19.0142, val_loss: 19.3200, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 173/1000000, train_loss: 18.9932, val_loss: 19.2906, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 174/1000000, train_loss: 18.9964, val_loss: 19.2302, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 175/1000000, train_loss: 18.9796, val_loss: 19.1611, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 176/1000000, train_loss: 18.8660, val_loss: 19.1362, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 177/1000000, train_loss: 18.8572, val_loss: 19.1166, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 178/1000000, train_loss: 18.8529, val_loss: 19.0520, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 179/1000000, train_loss: 18.8289, val_loss: 19.0183, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 180/1000000, train_loss: 18.7920, val_loss: 18.9716, time: 0.16s\n",
      "Epoch 181/1000000, train_loss: 18.6633, val_loss: 18.9727, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 182/1000000, train_loss: 18.7015, val_loss: 18.9034, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 183/1000000, train_loss: 18.6612, val_loss: 18.8422, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 184/1000000, train_loss: 18.6095, val_loss: 18.8110, time: 0.15s\n",
      "Epoch 185/1000000, train_loss: 18.5270, val_loss: 18.8138, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 186/1000000, train_loss: 18.5565, val_loss: 18.7400, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 187/1000000, train_loss: 18.4776, val_loss: 18.7030, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 188/1000000, train_loss: 18.4475, val_loss: 18.6755, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 189/1000000, train_loss: 18.3709, val_loss: 18.6284, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 190/1000000, train_loss: 18.3504, val_loss: 18.5485, time: 0.16s\n",
      "Epoch 191/1000000, train_loss: 18.2985, val_loss: 18.5528, time: 0.24s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 192/1000000, train_loss: 18.3092, val_loss: 18.5272, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 193/1000000, train_loss: 18.2037, val_loss: 18.4847, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 194/1000000, train_loss: 18.1503, val_loss: 18.4149, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 195/1000000, train_loss: 18.1436, val_loss: 18.3692, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 196/1000000, train_loss: 18.1073, val_loss: 18.3493, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 197/1000000, train_loss: 18.1241, val_loss: 18.3013, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 198/1000000, train_loss: 18.0413, val_loss: 18.2870, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 199/1000000, train_loss: 17.9622, val_loss: 18.2215, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 200/1000000, train_loss: 17.9533, val_loss: 18.1906, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 201/1000000, train_loss: 18.0244, val_loss: 18.1379, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 202/1000000, train_loss: 17.8808, val_loss: 18.0972, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 203/1000000, train_loss: 17.8847, val_loss: 18.0763, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 204/1000000, train_loss: 17.8404, val_loss: 18.0151, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 205/1000000, train_loss: 17.7824, val_loss: 17.9860, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 206/1000000, train_loss: 17.7612, val_loss: 17.9626, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 207/1000000, train_loss: 17.7098, val_loss: 17.8984, time: 0.15s\n",
      "Epoch 208/1000000, train_loss: 17.6870, val_loss: 17.9063, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 209/1000000, train_loss: 17.6078, val_loss: 17.8107, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 210/1000000, train_loss: 17.6027, val_loss: 17.7697, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 211/1000000, train_loss: 17.5124, val_loss: 17.7639, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 212/1000000, train_loss: 17.4537, val_loss: 17.7214, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 213/1000000, train_loss: 17.4111, val_loss: 17.6927, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 214/1000000, train_loss: 17.3954, val_loss: 17.6499, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 215/1000000, train_loss: 17.4213, val_loss: 17.5847, time: 0.16s\n",
      "Epoch 216/1000000, train_loss: 17.3569, val_loss: 17.6050, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 217/1000000, train_loss: 17.3336, val_loss: 17.5248, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 218/1000000, train_loss: 17.2995, val_loss: 17.5187, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 219/1000000, train_loss: 17.2188, val_loss: 17.4453, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 220/1000000, train_loss: 17.1733, val_loss: 17.3952, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 221/1000000, train_loss: 17.1280, val_loss: 17.3836, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 222/1000000, train_loss: 17.1056, val_loss: 17.3720, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 223/1000000, train_loss: 17.1334, val_loss: 17.2799, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 224/1000000, train_loss: 17.0645, val_loss: 17.2636, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 225/1000000, train_loss: 17.0185, val_loss: 17.1953, time: 0.15s\n",
      "Epoch 226/1000000, train_loss: 16.9971, val_loss: 17.2037, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 227/1000000, train_loss: 16.9152, val_loss: 17.1609, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 228/1000000, train_loss: 16.8921, val_loss: 17.1318, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 229/1000000, train_loss: 16.8713, val_loss: 17.0337, time: 0.15s\n",
      "Epoch 230/1000000, train_loss: 16.8974, val_loss: 17.0615, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 231/1000000, train_loss: 16.7424, val_loss: 16.9921, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 232/1000000, train_loss: 16.7507, val_loss: 16.9435, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 233/1000000, train_loss: 16.7558, val_loss: 16.9102, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 234/1000000, train_loss: 16.6642, val_loss: 16.8653, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 235/1000000, train_loss: 16.5754, val_loss: 16.8522, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 236/1000000, train_loss: 16.6180, val_loss: 16.8044, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 237/1000000, train_loss: 16.5953, val_loss: 16.7965, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 238/1000000, train_loss: 16.5496, val_loss: 16.7496, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 239/1000000, train_loss: 16.4624, val_loss: 16.7089, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 240/1000000, train_loss: 16.4145, val_loss: 16.6714, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 241/1000000, train_loss: 16.3919, val_loss: 16.6249, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 242/1000000, train_loss: 16.4005, val_loss: 16.6007, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 243/1000000, train_loss: 16.3464, val_loss: 16.5768, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 244/1000000, train_loss: 16.2820, val_loss: 16.5275, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 245/1000000, train_loss: 16.2803, val_loss: 16.4859, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 246/1000000, train_loss: 16.2225, val_loss: 16.4852, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 247/1000000, train_loss: 16.1491, val_loss: 16.4098, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 248/1000000, train_loss: 16.1447, val_loss: 16.3669, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 249/1000000, train_loss: 16.0089, val_loss: 16.3335, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 250/1000000, train_loss: 16.0375, val_loss: 16.3182, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 251/1000000, train_loss: 15.9868, val_loss: 16.2527, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 252/1000000, train_loss: 16.0151, val_loss: 16.2114, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 253/1000000, train_loss: 16.0025, val_loss: 16.1619, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 254/1000000, train_loss: 15.9316, val_loss: 16.1495, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 255/1000000, train_loss: 15.8885, val_loss: 16.1295, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 256/1000000, train_loss: 15.8643, val_loss: 16.0965, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 257/1000000, train_loss: 15.8060, val_loss: 16.0556, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 258/1000000, train_loss: 15.8434, val_loss: 16.0113, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 259/1000000, train_loss: 15.7387, val_loss: 15.9988, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 260/1000000, train_loss: 15.6922, val_loss: 15.9483, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 261/1000000, train_loss: 15.6492, val_loss: 15.8770, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 262/1000000, train_loss: 15.6657, val_loss: 15.8697, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 263/1000000, train_loss: 15.5958, val_loss: 15.8303, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 264/1000000, train_loss: 15.6654, val_loss: 15.7953, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 265/1000000, train_loss: 15.5592, val_loss: 15.7664, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 266/1000000, train_loss: 15.5142, val_loss: 15.7455, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 267/1000000, train_loss: 15.4638, val_loss: 15.6868, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 268/1000000, train_loss: 15.4261, val_loss: 15.6654, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 269/1000000, train_loss: 15.3930, val_loss: 15.6343, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 270/1000000, train_loss: 15.3612, val_loss: 15.5866, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 271/1000000, train_loss: 15.3281, val_loss: 15.5532, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 272/1000000, train_loss: 15.2697, val_loss: 15.4659, time: 0.16s\n",
      "Epoch 273/1000000, train_loss: 15.3137, val_loss: 15.4912, time: 0.25s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 274/1000000, train_loss: 15.2120, val_loss: 15.4264, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 275/1000000, train_loss: 15.1821, val_loss: 15.4013, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 276/1000000, train_loss: 15.2031, val_loss: 15.3598, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 277/1000000, train_loss: 15.1525, val_loss: 15.3139, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 278/1000000, train_loss: 15.0861, val_loss: 15.2827, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 279/1000000, train_loss: 15.1121, val_loss: 15.2705, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 280/1000000, train_loss: 15.0552, val_loss: 15.2177, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 281/1000000, train_loss: 14.9129, val_loss: 15.2093, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 282/1000000, train_loss: 14.9431, val_loss: 15.1973, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 283/1000000, train_loss: 14.9078, val_loss: 15.1490, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 284/1000000, train_loss: 14.9074, val_loss: 15.1035, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 285/1000000, train_loss: 14.8401, val_loss: 15.0868, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 286/1000000, train_loss: 14.7913, val_loss: 15.0246, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 287/1000000, train_loss: 14.7466, val_loss: 14.9773, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 288/1000000, train_loss: 14.7464, val_loss: 14.9362, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 289/1000000, train_loss: 14.6485, val_loss: 14.9102, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 290/1000000, train_loss: 14.6632, val_loss: 14.8989, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 291/1000000, train_loss: 14.6962, val_loss: 14.8533, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 292/1000000, train_loss: 14.6694, val_loss: 14.8358, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 293/1000000, train_loss: 14.5970, val_loss: 14.8031, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 294/1000000, train_loss: 14.5929, val_loss: 14.7207, time: 0.16s\n",
      "Epoch 295/1000000, train_loss: 14.4603, val_loss: 14.7461, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 296/1000000, train_loss: 14.4251, val_loss: 14.6821, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 297/1000000, train_loss: 14.4264, val_loss: 14.6483, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 298/1000000, train_loss: 14.3721, val_loss: 14.6046, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 299/1000000, train_loss: 14.3198, val_loss: 14.5812, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 300/1000000, train_loss: 14.3497, val_loss: 14.5632, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 301/1000000, train_loss: 14.3141, val_loss: 14.4927, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 302/1000000, train_loss: 14.2269, val_loss: 14.4727, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 303/1000000, train_loss: 14.3333, val_loss: 14.4430, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 304/1000000, train_loss: 14.2595, val_loss: 14.4097, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 305/1000000, train_loss: 14.1272, val_loss: 14.3621, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 306/1000000, train_loss: 14.1371, val_loss: 14.3621, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 307/1000000, train_loss: 14.0699, val_loss: 14.3076, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 308/1000000, train_loss: 14.0651, val_loss: 14.2569, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 309/1000000, train_loss: 13.9978, val_loss: 14.2331, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 310/1000000, train_loss: 13.9152, val_loss: 14.1844, time: 0.16s\n",
      "Epoch 311/1000000, train_loss: 13.9853, val_loss: 14.2064, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 312/1000000, train_loss: 13.9255, val_loss: 14.1357, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 313/1000000, train_loss: 13.9217, val_loss: 14.1354, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 314/1000000, train_loss: 13.8188, val_loss: 14.0931, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 315/1000000, train_loss: 13.8591, val_loss: 14.0317, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 316/1000000, train_loss: 13.7593, val_loss: 14.0193, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 317/1000000, train_loss: 13.8070, val_loss: 13.9909, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 318/1000000, train_loss: 13.7479, val_loss: 13.9772, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 319/1000000, train_loss: 13.7069, val_loss: 13.9232, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 320/1000000, train_loss: 13.7105, val_loss: 13.9122, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 321/1000000, train_loss: 13.6198, val_loss: 13.8733, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 322/1000000, train_loss: 13.6182, val_loss: 13.8031, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 323/1000000, train_loss: 13.6003, val_loss: 13.7826, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 324/1000000, train_loss: 13.6016, val_loss: 13.7413, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 325/1000000, train_loss: 13.5167, val_loss: 13.7305, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 326/1000000, train_loss: 13.4639, val_loss: 13.6789, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 327/1000000, train_loss: 13.4798, val_loss: 13.6388, time: 0.16s\n",
      "Epoch 328/1000000, train_loss: 13.4313, val_loss: 13.6490, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 329/1000000, train_loss: 13.4228, val_loss: 13.5894, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 330/1000000, train_loss: 13.3850, val_loss: 13.5444, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 331/1000000, train_loss: 13.3838, val_loss: 13.5330, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 332/1000000, train_loss: 13.3557, val_loss: 13.5017, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 333/1000000, train_loss: 13.2733, val_loss: 13.4538, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 334/1000000, train_loss: 13.2744, val_loss: 13.4413, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 335/1000000, train_loss: 13.2566, val_loss: 13.4210, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 336/1000000, train_loss: 13.1997, val_loss: 13.3958, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 337/1000000, train_loss: 13.1620, val_loss: 13.3292, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 338/1000000, train_loss: 13.1466, val_loss: 13.3171, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 339/1000000, train_loss: 13.1107, val_loss: 13.2812, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 340/1000000, train_loss: 13.1164, val_loss: 13.2635, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 341/1000000, train_loss: 13.0742, val_loss: 13.2210, time: 0.16s\n",
      "Epoch 342/1000000, train_loss: 13.0344, val_loss: 13.2223, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 343/1000000, train_loss: 13.0452, val_loss: 13.1857, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 344/1000000, train_loss: 12.9438, val_loss: 13.1468, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 345/1000000, train_loss: 12.9762, val_loss: 13.0834, time: 0.16s\n",
      "Epoch 346/1000000, train_loss: 12.9204, val_loss: 13.1014, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 347/1000000, train_loss: 12.8878, val_loss: 13.0254, time: 0.16s\n",
      "Epoch 348/1000000, train_loss: 12.9181, val_loss: 13.0273, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 349/1000000, train_loss: 12.8712, val_loss: 12.9743, time: 0.16s\n",
      "Epoch 350/1000000, train_loss: 12.7901, val_loss: 12.9757, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 351/1000000, train_loss: 12.7747, val_loss: 12.9468, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 352/1000000, train_loss: 12.7845, val_loss: 12.9002, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 353/1000000, train_loss: 12.7587, val_loss: 12.8765, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 354/1000000, train_loss: 12.6375, val_loss: 12.8347, time: 0.15s\n",
      "Epoch 355/1000000, train_loss: 12.7207, val_loss: 12.8457, time: 0.24s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 356/1000000, train_loss: 12.6116, val_loss: 12.7875, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 357/1000000, train_loss: 12.6601, val_loss: 12.7729, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 358/1000000, train_loss: 12.6131, val_loss: 12.7106, time: 0.15s\n",
      "Epoch 359/1000000, train_loss: 12.5152, val_loss: 12.7219, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 360/1000000, train_loss: 12.5354, val_loss: 12.6879, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 361/1000000, train_loss: 12.5744, val_loss: 12.6595, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 362/1000000, train_loss: 12.5205, val_loss: 12.6472, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 363/1000000, train_loss: 12.4341, val_loss: 12.6035, time: 0.16s\n",
      "Epoch 364/1000000, train_loss: 12.4797, val_loss: 12.6046, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 365/1000000, train_loss: 12.3993, val_loss: 12.5571, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 366/1000000, train_loss: 12.4106, val_loss: 12.5476, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 367/1000000, train_loss: 12.3956, val_loss: 12.4848, time: 0.16s\n",
      "Epoch 368/1000000, train_loss: 12.3988, val_loss: 12.4858, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 369/1000000, train_loss: 12.3622, val_loss: 12.4669, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 370/1000000, train_loss: 12.3141, val_loss: 12.4341, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 371/1000000, train_loss: 12.2465, val_loss: 12.4224, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 372/1000000, train_loss: 12.2773, val_loss: 12.3884, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 373/1000000, train_loss: 12.2880, val_loss: 12.3883, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 374/1000000, train_loss: 12.2646, val_loss: 12.3492, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 375/1000000, train_loss: 12.2582, val_loss: 12.2970, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 376/1000000, train_loss: 12.1494, val_loss: 12.2559, time: 0.16s\n",
      "Epoch 377/1000000, train_loss: 12.2066, val_loss: 12.2814, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 378/1000000, train_loss: 12.1320, val_loss: 12.2463, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 379/1000000, train_loss: 12.1106, val_loss: 12.2215, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 380/1000000, train_loss: 12.0945, val_loss: 12.2075, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 381/1000000, train_loss: 12.0693, val_loss: 12.1614, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 382/1000000, train_loss: 12.0138, val_loss: 12.1249, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 383/1000000, train_loss: 12.0447, val_loss: 12.1193, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 384/1000000, train_loss: 12.0511, val_loss: 12.1133, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 385/1000000, train_loss: 11.9927, val_loss: 12.0374, time: 0.16s\n",
      "Epoch 386/1000000, train_loss: 12.0001, val_loss: 12.0646, time: 0.16s\n",
      "Epoch 387/1000000, train_loss: 11.9067, val_loss: 12.0699, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 388/1000000, train_loss: 11.9322, val_loss: 12.0153, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 389/1000000, train_loss: 11.9091, val_loss: 11.9952, time: 0.16s\n",
      "Epoch 390/1000000, train_loss: 11.8147, val_loss: 11.9959, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 391/1000000, train_loss: 11.8508, val_loss: 11.9334, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 392/1000000, train_loss: 11.8426, val_loss: 11.9192, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 393/1000000, train_loss: 11.7886, val_loss: 11.8883, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 394/1000000, train_loss: 11.7668, val_loss: 11.8813, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 395/1000000, train_loss: 11.7402, val_loss: 11.8595, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 396/1000000, train_loss: 11.7574, val_loss: 11.8191, time: 0.16s\n",
      "Epoch 397/1000000, train_loss: 11.7247, val_loss: 11.8261, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 398/1000000, train_loss: 11.7006, val_loss: 11.7991, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 399/1000000, train_loss: 11.6599, val_loss: 11.7933, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 400/1000000, train_loss: 11.6696, val_loss: 11.7500, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 401/1000000, train_loss: 11.6660, val_loss: 11.7366, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 402/1000000, train_loss: 11.6180, val_loss: 11.6973, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 403/1000000, train_loss: 11.5933, val_loss: 11.6925, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 404/1000000, train_loss: 11.5568, val_loss: 11.6566, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 405/1000000, train_loss: 11.5750, val_loss: 11.6259, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 406/1000000, train_loss: 11.5920, val_loss: 11.6230, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 407/1000000, train_loss: 11.5255, val_loss: 11.5994, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 408/1000000, train_loss: 11.5528, val_loss: 11.5863, time: 0.15s\n",
      "Epoch 409/1000000, train_loss: 11.5311, val_loss: 11.5935, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 410/1000000, train_loss: 11.5134, val_loss: 11.5320, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 411/1000000, train_loss: 11.4638, val_loss: 11.5289, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 412/1000000, train_loss: 11.4652, val_loss: 11.5026, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 413/1000000, train_loss: 11.4417, val_loss: 11.4673, time: 0.16s\n",
      "Epoch 414/1000000, train_loss: 11.4250, val_loss: 11.4695, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 415/1000000, train_loss: 11.3522, val_loss: 11.4478, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 416/1000000, train_loss: 11.4356, val_loss: 11.4073, time: 0.16s\n",
      "Epoch 417/1000000, train_loss: 11.3348, val_loss: 11.4153, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 418/1000000, train_loss: 11.3068, val_loss: 11.3727, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 419/1000000, train_loss: 11.3523, val_loss: 11.3668, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 420/1000000, train_loss: 11.3473, val_loss: 11.3423, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 421/1000000, train_loss: 11.2502, val_loss: 11.3146, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 422/1000000, train_loss: 11.2787, val_loss: 11.3024, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 423/1000000, train_loss: 11.2136, val_loss: 11.2731, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 424/1000000, train_loss: 11.1510, val_loss: 11.2683, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 425/1000000, train_loss: 11.2408, val_loss: 11.2511, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 426/1000000, train_loss: 11.2204, val_loss: 11.2420, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 427/1000000, train_loss: 11.1633, val_loss: 11.2276, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 428/1000000, train_loss: 11.1407, val_loss: 11.1778, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 429/1000000, train_loss: 11.1567, val_loss: 11.1747, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 430/1000000, train_loss: 11.1075, val_loss: 11.1228, time: 0.16s\n",
      "Epoch 431/1000000, train_loss: 11.0975, val_loss: 11.1548, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 432/1000000, train_loss: 11.0971, val_loss: 11.1150, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 433/1000000, train_loss: 11.0718, val_loss: 11.0929, time: 0.16s\n",
      "Epoch 434/1000000, train_loss: 10.9958, val_loss: 11.0933, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 435/1000000, train_loss: 11.0136, val_loss: 11.0595, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 436/1000000, train_loss: 11.0436, val_loss: 11.0207, time: 0.16s\n",
      "Epoch 437/1000000, train_loss: 11.0047, val_loss: 11.0264, time: 0.16s\n",
      "Epoch 438/1000000, train_loss: 10.9910, val_loss: 11.0515, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 439/1000000, train_loss: 10.9598, val_loss: 11.0008, time: 0.26s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 440/1000000, train_loss: 10.9548, val_loss: 10.9829, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 441/1000000, train_loss: 10.9486, val_loss: 10.9575, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 442/1000000, train_loss: 10.9471, val_loss: 10.9412, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 443/1000000, train_loss: 10.8744, val_loss: 10.9246, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 444/1000000, train_loss: 10.9590, val_loss: 10.8996, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 445/1000000, train_loss: 10.8666, val_loss: 10.8944, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 446/1000000, train_loss: 10.8775, val_loss: 10.8839, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 447/1000000, train_loss: 10.8537, val_loss: 10.8286, time: 0.16s\n",
      "Epoch 448/1000000, train_loss: 10.7878, val_loss: 10.8374, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 449/1000000, train_loss: 10.8013, val_loss: 10.8080, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 450/1000000, train_loss: 10.7516, val_loss: 10.7820, time: 0.16s\n",
      "Epoch 451/1000000, train_loss: 10.7361, val_loss: 10.7910, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 452/1000000, train_loss: 10.8148, val_loss: 10.7705, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 453/1000000, train_loss: 10.7588, val_loss: 10.7667, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 454/1000000, train_loss: 10.7439, val_loss: 10.7524, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 455/1000000, train_loss: 10.7168, val_loss: 10.7369, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 456/1000000, train_loss: 10.6720, val_loss: 10.7010, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 457/1000000, train_loss: 10.6906, val_loss: 10.7007, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 458/1000000, train_loss: 10.7073, val_loss: 10.6714, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 459/1000000, train_loss: 10.6676, val_loss: 10.6498, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 460/1000000, train_loss: 10.6241, val_loss: 10.6372, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 461/1000000, train_loss: 10.6159, val_loss: 10.6326, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 462/1000000, train_loss: 10.5954, val_loss: 10.5951, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 463/1000000, train_loss: 10.6415, val_loss: 10.5936, time: 0.15s\n",
      "Epoch 464/1000000, train_loss: 10.5737, val_loss: 10.6024, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 465/1000000, train_loss: 10.5225, val_loss: 10.5593, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 466/1000000, train_loss: 10.5875, val_loss: 10.5479, time: 0.15s\n",
      "Epoch 467/1000000, train_loss: 10.5551, val_loss: 10.5509, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 468/1000000, train_loss: 10.5399, val_loss: 10.5053, time: 0.17s\n",
      "Epoch 469/1000000, train_loss: 10.5728, val_loss: 10.5215, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 470/1000000, train_loss: 10.5040, val_loss: 10.4937, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 471/1000000, train_loss: 10.4513, val_loss: 10.4763, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 472/1000000, train_loss: 10.4466, val_loss: 10.4690, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 473/1000000, train_loss: 10.4575, val_loss: 10.4513, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 474/1000000, train_loss: 10.4348, val_loss: 10.4444, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 475/1000000, train_loss: 10.4696, val_loss: 10.4175, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 476/1000000, train_loss: 10.4460, val_loss: 10.3819, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 477/1000000, train_loss: 10.3573, val_loss: 10.3787, time: 0.15s\n",
      "Epoch 478/1000000, train_loss: 10.4384, val_loss: 10.3790, time: 0.15s\n",
      "Epoch 479/1000000, train_loss: 10.3810, val_loss: 10.3813, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 480/1000000, train_loss: 10.3553, val_loss: 10.3422, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 481/1000000, train_loss: 10.3170, val_loss: 10.3270, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 482/1000000, train_loss: 10.3486, val_loss: 10.3147, time: 0.15s\n",
      "Epoch 483/1000000, train_loss: 10.3384, val_loss: 10.3447, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 484/1000000, train_loss: 10.3468, val_loss: 10.3043, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 485/1000000, train_loss: 10.3228, val_loss: 10.2920, time: 0.16s\n",
      "Epoch 486/1000000, train_loss: 10.2984, val_loss: 10.3098, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 487/1000000, train_loss: 10.2941, val_loss: 10.2808, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 488/1000000, train_loss: 10.3129, val_loss: 10.2544, time: 0.16s\n",
      "Epoch 489/1000000, train_loss: 10.2481, val_loss: 10.2556, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 490/1000000, train_loss: 10.2624, val_loss: 10.2539, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 491/1000000, train_loss: 10.2657, val_loss: 10.2334, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 492/1000000, train_loss: 10.2280, val_loss: 10.2007, time: 0.15s\n",
      "Epoch 493/1000000, train_loss: 10.2485, val_loss: 10.2021, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 494/1000000, train_loss: 10.1904, val_loss: 10.1907, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 495/1000000, train_loss: 10.1766, val_loss: 10.1679, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 496/1000000, train_loss: 10.2378, val_loss: 10.1437, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 497/1000000, train_loss: 10.2011, val_loss: 10.1387, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 498/1000000, train_loss: 10.1813, val_loss: 10.1357, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 499/1000000, train_loss: 10.1208, val_loss: 10.1148, time: 0.15s\n",
      "Epoch 500/1000000, train_loss: 10.1199, val_loss: 10.1373, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 501/1000000, train_loss: 10.1116, val_loss: 10.0808, time: 0.15s\n",
      "Epoch 502/1000000, train_loss: 10.1055, val_loss: 10.0826, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 503/1000000, train_loss: 10.1055, val_loss: 10.0618, time: 0.15s\n",
      "Epoch 504/1000000, train_loss: 10.1280, val_loss: 10.0749, time: 0.15s\n",
      "Epoch 505/1000000, train_loss: 10.0596, val_loss: 10.0652, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 506/1000000, train_loss: 10.0273, val_loss: 10.0328, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 507/1000000, train_loss: 10.0408, val_loss: 10.0219, time: 0.15s\n",
      "Epoch 508/1000000, train_loss: 10.0990, val_loss: 10.0475, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 509/1000000, train_loss: 10.0352, val_loss: 9.9820, time: 0.15s\n",
      "Epoch 510/1000000, train_loss: 10.0562, val_loss: 10.0162, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 511/1000000, train_loss: 9.9868, val_loss: 9.9794, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 512/1000000, train_loss: 10.0341, val_loss: 9.9690, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 513/1000000, train_loss: 10.0360, val_loss: 9.9424, time: 0.15s\n",
      "Epoch 514/1000000, train_loss: 9.9637, val_loss: 9.9501, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 515/1000000, train_loss: 9.9670, val_loss: 9.9367, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 516/1000000, train_loss: 9.9904, val_loss: 9.9311, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 517/1000000, train_loss: 9.9872, val_loss: 9.9261, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 518/1000000, train_loss: 9.9396, val_loss: 9.8943, time: 0.16s\n",
      "Epoch 519/1000000, train_loss: 9.9640, val_loss: 9.9061, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 520/1000000, train_loss: 9.9614, val_loss: 9.8842, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 521/1000000, train_loss: 9.9089, val_loss: 9.8834, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 522/1000000, train_loss: 9.9054, val_loss: 9.8582, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 523/1000000, train_loss: 9.9010, val_loss: 9.8249, time: 0.25s\n",
      "Epoch 524/1000000, train_loss: 9.9293, val_loss: 9.8494, time: 0.16s\n",
      "Epoch 525/1000000, train_loss: 9.9090, val_loss: 9.8405, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 526/1000000, train_loss: 9.8595, val_loss: 9.8115, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 527/1000000, train_loss: 9.8619, val_loss: 9.8039, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 528/1000000, train_loss: 9.8198, val_loss: 9.7917, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 529/1000000, train_loss: 9.8287, val_loss: 9.7746, time: 0.16s\n",
      "Epoch 530/1000000, train_loss: 9.8592, val_loss: 9.7794, time: 0.16s\n",
      "Epoch 531/1000000, train_loss: 9.7717, val_loss: 9.7769, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 532/1000000, train_loss: 9.8563, val_loss: 9.7625, time: 0.16s\n",
      "Epoch 533/1000000, train_loss: 9.8357, val_loss: 9.7629, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 534/1000000, train_loss: 9.8038, val_loss: 9.7294, time: 0.16s\n",
      "Epoch 535/1000000, train_loss: 9.7791, val_loss: 9.7500, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 536/1000000, train_loss: 9.7492, val_loss: 9.7040, time: 0.16s\n",
      "Epoch 537/1000000, train_loss: 9.7744, val_loss: 9.7148, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 538/1000000, train_loss: 9.7602, val_loss: 9.6934, time: 0.16s\n",
      "Epoch 539/1000000, train_loss: 9.7602, val_loss: 9.6949, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 540/1000000, train_loss: 9.6912, val_loss: 9.6911, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 541/1000000, train_loss: 9.7062, val_loss: 9.6503, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 542/1000000, train_loss: 9.7498, val_loss: 9.6498, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 543/1000000, train_loss: 9.7090, val_loss: 9.6325, time: 0.16s\n",
      "Epoch 544/1000000, train_loss: 9.7148, val_loss: 9.6357, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 545/1000000, train_loss: 9.6720, val_loss: 9.6073, time: 0.16s\n",
      "Epoch 546/1000000, train_loss: 9.6704, val_loss: 9.6210, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 547/1000000, train_loss: 9.7053, val_loss: 9.6033, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 548/1000000, train_loss: 9.7177, val_loss: 9.5779, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 549/1000000, train_loss: 9.6619, val_loss: 9.5729, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 550/1000000, train_loss: 9.5967, val_loss: 9.5462, time: 0.16s\n",
      "Epoch 551/1000000, train_loss: 9.5803, val_loss: 9.5716, time: 0.15s\n",
      "Epoch 552/1000000, train_loss: 9.6358, val_loss: 9.5501, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 553/1000000, train_loss: 9.6713, val_loss: 9.5337, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 554/1000000, train_loss: 9.6020, val_loss: 9.5278, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 555/1000000, train_loss: 9.5811, val_loss: 9.5209, time: 0.15s\n",
      "Epoch 556/1000000, train_loss: 9.6249, val_loss: 9.5454, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 557/1000000, train_loss: 9.5941, val_loss: 9.5012, time: 0.15s\n",
      "Epoch 558/1000000, train_loss: 9.6230, val_loss: 9.5035, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 559/1000000, train_loss: 9.5763, val_loss: 9.4795, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 560/1000000, train_loss: 9.5726, val_loss: 9.4689, time: 0.16s\n",
      "Epoch 561/1000000, train_loss: 9.5588, val_loss: 9.4868, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 562/1000000, train_loss: 9.6178, val_loss: 9.4533, time: 0.17s\n",
      "Epoch 563/1000000, train_loss: 9.5064, val_loss: 9.4714, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 564/1000000, train_loss: 9.5255, val_loss: 9.4241, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 565/1000000, train_loss: 9.5162, val_loss: 9.4184, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 566/1000000, train_loss: 9.5185, val_loss: 9.4055, time: 0.16s\n",
      "Epoch 567/1000000, train_loss: 9.4950, val_loss: 9.4206, time: 0.16s\n",
      "Epoch 568/1000000, train_loss: 9.4487, val_loss: 9.4178, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 569/1000000, train_loss: 9.4938, val_loss: 9.3865, time: 0.16s\n",
      "Epoch 570/1000000, train_loss: 9.5425, val_loss: 9.3999, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 571/1000000, train_loss: 9.4716, val_loss: 9.3499, time: 0.15s\n",
      "Epoch 572/1000000, train_loss: 9.4890, val_loss: 9.3634, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 573/1000000, train_loss: 9.4963, val_loss: 9.3341, time: 0.16s\n",
      "Epoch 574/1000000, train_loss: 9.4188, val_loss: 9.3644, time: 0.16s\n",
      "Epoch 575/1000000, train_loss: 9.4322, val_loss: 9.3528, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 576/1000000, train_loss: 9.4497, val_loss: 9.3257, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 577/1000000, train_loss: 9.4274, val_loss: 9.3085, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 578/1000000, train_loss: 9.4349, val_loss: 9.3038, time: 0.16s\n",
      "Epoch 579/1000000, train_loss: 9.3788, val_loss: 9.3237, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 580/1000000, train_loss: 9.3958, val_loss: 9.2931, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 581/1000000, train_loss: 9.4166, val_loss: 9.2904, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 582/1000000, train_loss: 9.3974, val_loss: 9.2796, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 583/1000000, train_loss: 9.3728, val_loss: 9.2548, time: 0.15s\n",
      "Epoch 584/1000000, train_loss: 9.3930, val_loss: 9.2598, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 585/1000000, train_loss: 9.3578, val_loss: 9.2402, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 586/1000000, train_loss: 9.3953, val_loss: 9.2320, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 587/1000000, train_loss: 9.3135, val_loss: 9.2233, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 588/1000000, train_loss: 9.3255, val_loss: 9.2060, time: 0.15s\n",
      "Epoch 589/1000000, train_loss: 9.3542, val_loss: 9.2153, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 590/1000000, train_loss: 9.3280, val_loss: 9.1970, time: 0.15s\n",
      "Epoch 591/1000000, train_loss: 9.2887, val_loss: 9.2020, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 592/1000000, train_loss: 9.2751, val_loss: 9.1951, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 593/1000000, train_loss: 9.2693, val_loss: 9.1787, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 594/1000000, train_loss: 9.2795, val_loss: 9.1623, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 595/1000000, train_loss: 9.2846, val_loss: 9.1590, time: 0.15s\n",
      "Epoch 596/1000000, train_loss: 9.2674, val_loss: 9.1621, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 597/1000000, train_loss: 9.2391, val_loss: 9.1544, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 598/1000000, train_loss: 9.2808, val_loss: 9.1416, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 599/1000000, train_loss: 9.2648, val_loss: 9.1195, time: 0.15s\n",
      "Epoch 600/1000000, train_loss: 9.2336, val_loss: 9.1197, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 601/1000000, train_loss: 9.2360, val_loss: 9.1077, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 602/1000000, train_loss: 9.1974, val_loss: 9.0793, time: 0.16s\n",
      "Epoch 603/1000000, train_loss: 9.2150, val_loss: 9.0902, time: 0.16s\n",
      "Epoch 604/1000000, train_loss: 9.2360, val_loss: 9.0837, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 605/1000000, train_loss: 9.2384, val_loss: 9.0638, time: 0.15s\n",
      "Epoch 606/1000000, train_loss: 9.1568, val_loss: 9.0702, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 607/1000000, train_loss: 9.2178, val_loss: 9.0466, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 608/1000000, train_loss: 9.1590, val_loss: 9.0432, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 609/1000000, train_loss: 9.1655, val_loss: 9.0357, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 610/1000000, train_loss: 9.1884, val_loss: 9.0199, time: 0.16s\n",
      "Epoch 611/1000000, train_loss: 9.1389, val_loss: 9.0216, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 612/1000000, train_loss: 9.1804, val_loss: 9.0037, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 613/1000000, train_loss: 9.1580, val_loss: 8.9996, time: 0.22s\n",
      "Epoch 614/1000000, train_loss: 9.1086, val_loss: 9.0153, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 615/1000000, train_loss: 9.1068, val_loss: 8.9671, time: 0.16s\n",
      "Epoch 616/1000000, train_loss: 9.1338, val_loss: 8.9773, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 617/1000000, train_loss: 9.1636, val_loss: 8.9604, time: 0.16s\n",
      "Epoch 618/1000000, train_loss: 9.0900, val_loss: 8.9681, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 619/1000000, train_loss: 9.0759, val_loss: 8.9377, time: 0.16s\n",
      "Epoch 620/1000000, train_loss: 9.0535, val_loss: 8.9432, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 621/1000000, train_loss: 9.0736, val_loss: 8.9290, time: 0.16s\n",
      "Epoch 622/1000000, train_loss: 9.0812, val_loss: 8.9341, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 623/1000000, train_loss: 9.0702, val_loss: 8.9274, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 624/1000000, train_loss: 9.0884, val_loss: 8.8969, time: 0.16s\n",
      "Epoch 625/1000000, train_loss: 9.0757, val_loss: 8.9031, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 626/1000000, train_loss: 9.0232, val_loss: 8.8945, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 627/1000000, train_loss: 9.0788, val_loss: 8.8840, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 628/1000000, train_loss: 9.0435, val_loss: 8.8772, time: 0.16s\n",
      "Epoch 629/1000000, train_loss: 9.0214, val_loss: 8.8775, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 630/1000000, train_loss: 9.0441, val_loss: 8.8575, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 631/1000000, train_loss: 9.0068, val_loss: 8.8567, time: 0.16s\n",
      "Epoch 632/1000000, train_loss: 8.9954, val_loss: 8.8597, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 633/1000000, train_loss: 8.9698, val_loss: 8.8457, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 634/1000000, train_loss: 8.9818, val_loss: 8.8329, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 635/1000000, train_loss: 8.9430, val_loss: 8.8121, time: 0.15s\n",
      "Epoch 636/1000000, train_loss: 9.0149, val_loss: 8.8141, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 637/1000000, train_loss: 9.0482, val_loss: 8.8057, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 638/1000000, train_loss: 8.9473, val_loss: 8.8051, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 639/1000000, train_loss: 8.9201, val_loss: 8.7892, time: 0.16s\n",
      "Epoch 640/1000000, train_loss: 8.9446, val_loss: 8.7940, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 641/1000000, train_loss: 8.8880, val_loss: 8.7750, time: 0.16s\n",
      "Epoch 642/1000000, train_loss: 8.9858, val_loss: 8.7825, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 643/1000000, train_loss: 8.9148, val_loss: 8.7529, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 644/1000000, train_loss: 8.9408, val_loss: 8.7529, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 645/1000000, train_loss: 8.9126, val_loss: 8.7268, time: 0.16s\n",
      "Epoch 646/1000000, train_loss: 8.9024, val_loss: 8.7291, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 647/1000000, train_loss: 8.8898, val_loss: 8.7064, time: 0.16s\n",
      "Epoch 648/1000000, train_loss: 8.8535, val_loss: 8.7292, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 649/1000000, train_loss: 8.8862, val_loss: 8.7038, time: 0.16s\n",
      "Epoch 650/1000000, train_loss: 8.8738, val_loss: 8.7126, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 651/1000000, train_loss: 8.8770, val_loss: 8.6767, time: 0.16s\n",
      "Epoch 652/1000000, train_loss: 8.8899, val_loss: 8.6893, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 653/1000000, train_loss: 8.8391, val_loss: 8.6735, time: 0.16s\n",
      "Epoch 654/1000000, train_loss: 8.8502, val_loss: 8.6836, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 655/1000000, train_loss: 8.8637, val_loss: 8.6601, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 656/1000000, train_loss: 8.8197, val_loss: 8.6458, time: 0.16s\n",
      "Epoch 657/1000000, train_loss: 8.7970, val_loss: 8.6551, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 658/1000000, train_loss: 8.7981, val_loss: 8.6336, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 659/1000000, train_loss: 8.8145, val_loss: 8.6222, time: 0.15s\n",
      "Epoch 660/1000000, train_loss: 8.8325, val_loss: 8.6349, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 661/1000000, train_loss: 8.7844, val_loss: 8.6039, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 662/1000000, train_loss: 8.8255, val_loss: 8.6031, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 663/1000000, train_loss: 8.7419, val_loss: 8.5934, time: 0.15s\n",
      "Epoch 664/1000000, train_loss: 8.8056, val_loss: 8.6000, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 665/1000000, train_loss: 8.7591, val_loss: 8.5704, time: 0.15s\n",
      "Epoch 666/1000000, train_loss: 8.7330, val_loss: 8.5716, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 667/1000000, train_loss: 8.7835, val_loss: 8.5676, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 668/1000000, train_loss: 8.7426, val_loss: 8.5587, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 669/1000000, train_loss: 8.7229, val_loss: 8.5550, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 670/1000000, train_loss: 8.7269, val_loss: 8.5299, time: 0.16s\n",
      "Epoch 671/1000000, train_loss: 8.7349, val_loss: 8.5324, time: 0.16s\n",
      "Epoch 672/1000000, train_loss: 8.7266, val_loss: 8.5305, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 673/1000000, train_loss: 8.7044, val_loss: 8.5147, time: 0.17s\n",
      "Epoch 674/1000000, train_loss: 8.7101, val_loss: 8.5186, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 675/1000000, train_loss: 8.7159, val_loss: 8.5104, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 676/1000000, train_loss: 8.6711, val_loss: 8.4871, time: 0.15s\n",
      "Epoch 677/1000000, train_loss: 8.6711, val_loss: 8.4982, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 678/1000000, train_loss: 8.6925, val_loss: 8.4781, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 679/1000000, train_loss: 8.6724, val_loss: 8.4542, time: 0.16s\n",
      "Epoch 680/1000000, train_loss: 8.6320, val_loss: 8.4564, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 681/1000000, train_loss: 8.7527, val_loss: 8.4431, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 682/1000000, train_loss: 8.6549, val_loss: 8.4329, time: 0.16s\n",
      "Epoch 683/1000000, train_loss: 8.6735, val_loss: 8.4493, time: 0.16s\n",
      "Epoch 684/1000000, train_loss: 8.6370, val_loss: 8.4398, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 685/1000000, train_loss: 8.6587, val_loss: 8.4152, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 686/1000000, train_loss: 8.5795, val_loss: 8.4079, time: 0.16s\n",
      "Epoch 687/1000000, train_loss: 8.6046, val_loss: 8.4175, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 688/1000000, train_loss: 8.6255, val_loss: 8.3845, time: 0.16s\n",
      "Epoch 689/1000000, train_loss: 8.5916, val_loss: 8.3911, time: 0.16s\n",
      "Epoch 690/1000000, train_loss: 8.5768, val_loss: 8.3871, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 691/1000000, train_loss: 8.5551, val_loss: 8.3692, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 692/1000000, train_loss: 8.5374, val_loss: 8.3628, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 693/1000000, train_loss: 8.5774, val_loss: 8.3525, time: 0.16s\n",
      "Epoch 694/1000000, train_loss: 8.5373, val_loss: 8.3588, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 695/1000000, train_loss: 8.5671, val_loss: 8.3370, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 696/1000000, train_loss: 8.5703, val_loss: 8.3299, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 697/1000000, train_loss: 8.5108, val_loss: 8.3269, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 698/1000000, train_loss: 8.5423, val_loss: 8.3251, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 699/1000000, train_loss: 8.5385, val_loss: 8.3144, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 700/1000000, train_loss: 8.4920, val_loss: 8.3044, time: 0.16s\n",
      "Epoch 701/1000000, train_loss: 8.5171, val_loss: 8.3083, time: 0.24s\n",
      "Epoch 702/1000000, train_loss: 8.5255, val_loss: 8.3051, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 703/1000000, train_loss: 8.5137, val_loss: 8.2976, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 704/1000000, train_loss: 8.5145, val_loss: 8.2690, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 705/1000000, train_loss: 8.4795, val_loss: 8.2575, time: 0.16s\n",
      "Epoch 706/1000000, train_loss: 8.4753, val_loss: 8.2628, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 707/1000000, train_loss: 8.4826, val_loss: 8.2414, time: 0.15s\n",
      "Epoch 708/1000000, train_loss: 8.4882, val_loss: 8.2484, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 709/1000000, train_loss: 8.4516, val_loss: 8.2370, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 710/1000000, train_loss: 8.4369, val_loss: 8.2235, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 711/1000000, train_loss: 8.4521, val_loss: 8.2201, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 712/1000000, train_loss: 8.4693, val_loss: 8.2060, time: 0.15s\n",
      "Epoch 713/1000000, train_loss: 8.4415, val_loss: 8.2160, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 714/1000000, train_loss: 8.4609, val_loss: 8.1885, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 715/1000000, train_loss: 8.4750, val_loss: 8.1845, time: 0.17s\n",
      "Epoch 716/1000000, train_loss: 8.4099, val_loss: 8.1877, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 717/1000000, train_loss: 8.4138, val_loss: 8.1795, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 718/1000000, train_loss: 8.4054, val_loss: 8.1535, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 719/1000000, train_loss: 8.4002, val_loss: 8.1497, time: 0.15s\n",
      "Epoch 720/1000000, train_loss: 8.3903, val_loss: 8.1552, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 721/1000000, train_loss: 8.3701, val_loss: 8.1335, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 722/1000000, train_loss: 8.4210, val_loss: 8.1296, time: 0.16s\n",
      "Epoch 723/1000000, train_loss: 8.4286, val_loss: 8.1345, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 724/1000000, train_loss: 8.3506, val_loss: 8.1262, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 725/1000000, train_loss: 8.3585, val_loss: 8.1067, time: 0.16s\n",
      "Epoch 726/1000000, train_loss: 8.3401, val_loss: 8.1071, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 727/1000000, train_loss: 8.3760, val_loss: 8.0953, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 728/1000000, train_loss: 8.3449, val_loss: 8.0937, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 729/1000000, train_loss: 8.3605, val_loss: 8.0920, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 730/1000000, train_loss: 8.3140, val_loss: 8.0796, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 731/1000000, train_loss: 8.3309, val_loss: 8.0526, time: 0.16s\n",
      "Epoch 732/1000000, train_loss: 8.3071, val_loss: 8.0660, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 733/1000000, train_loss: 8.3333, val_loss: 8.0519, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 734/1000000, train_loss: 8.2936, val_loss: 8.0509, time: 0.16s\n",
      "Epoch 735/1000000, train_loss: 8.3310, val_loss: 8.0511, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 736/1000000, train_loss: 8.2644, val_loss: 8.0429, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 737/1000000, train_loss: 8.3122, val_loss: 8.0238, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 738/1000000, train_loss: 8.2694, val_loss: 8.0190, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 739/1000000, train_loss: 8.2737, val_loss: 8.0111, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 740/1000000, train_loss: 8.2738, val_loss: 7.9884, time: 0.16s\n",
      "Epoch 741/1000000, train_loss: 8.2614, val_loss: 7.9942, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 742/1000000, train_loss: 8.2601, val_loss: 7.9842, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 743/1000000, train_loss: 8.2246, val_loss: 7.9622, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 744/1000000, train_loss: 8.2532, val_loss: 7.9523, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 745/1000000, train_loss: 8.2383, val_loss: 7.9390, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 746/1000000, train_loss: 8.2280, val_loss: 7.9194, time: 0.16s\n",
      "Epoch 747/1000000, train_loss: 8.1939, val_loss: 7.9250, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 748/1000000, train_loss: 8.2001, val_loss: 7.9042, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 749/1000000, train_loss: 8.1617, val_loss: 7.8807, time: 0.15s\n",
      "Epoch 750/1000000, train_loss: 8.1626, val_loss: 7.8810, time: 0.15s\n",
      "Epoch 751/1000000, train_loss: 8.1419, val_loss: 7.8862, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 752/1000000, train_loss: 8.1204, val_loss: 7.8616, time: 0.16s\n",
      "Epoch 753/1000000, train_loss: 8.1335, val_loss: 7.8684, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 754/1000000, train_loss: 8.1597, val_loss: 7.8448, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 755/1000000, train_loss: 8.1191, val_loss: 7.8388, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 756/1000000, train_loss: 8.1345, val_loss: 7.8291, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 757/1000000, train_loss: 8.1590, val_loss: 7.8227, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 758/1000000, train_loss: 8.1016, val_loss: 7.8123, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 759/1000000, train_loss: 8.1232, val_loss: 7.8114, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 760/1000000, train_loss: 8.0748, val_loss: 7.7887, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 761/1000000, train_loss: 8.0603, val_loss: 7.7882, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 762/1000000, train_loss: 8.0560, val_loss: 7.7750, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 763/1000000, train_loss: 8.0580, val_loss: 7.7714, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 764/1000000, train_loss: 8.1190, val_loss: 7.7680, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 765/1000000, train_loss: 8.0837, val_loss: 7.7517, time: 0.15s\n",
      "Epoch 766/1000000, train_loss: 8.0153, val_loss: 7.7581, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 767/1000000, train_loss: 8.0733, val_loss: 7.7315, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 768/1000000, train_loss: 8.0281, val_loss: 7.7260, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 769/1000000, train_loss: 8.0101, val_loss: 7.7106, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 770/1000000, train_loss: 8.0282, val_loss: 7.7047, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 771/1000000, train_loss: 8.0134, val_loss: 7.6999, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 772/1000000, train_loss: 7.9989, val_loss: 7.6957, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 773/1000000, train_loss: 7.9937, val_loss: 7.6788, time: 0.16s\n",
      "Epoch 774/1000000, train_loss: 8.0022, val_loss: 7.6887, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 775/1000000, train_loss: 8.0147, val_loss: 7.6761, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 776/1000000, train_loss: 7.9686, val_loss: 7.6634, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 777/1000000, train_loss: 8.0799, val_loss: 7.6501, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 778/1000000, train_loss: 7.9812, val_loss: 7.6458, time: 0.16s\n",
      "Epoch 779/1000000, train_loss: 7.9737, val_loss: 7.6507, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 780/1000000, train_loss: 7.9765, val_loss: 7.6430, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 781/1000000, train_loss: 7.9497, val_loss: 7.6323, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 782/1000000, train_loss: 7.9146, val_loss: 7.6166, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 783/1000000, train_loss: 7.9355, val_loss: 7.6113, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 784/1000000, train_loss: 7.9144, val_loss: 7.6038, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 785/1000000, train_loss: 7.9188, val_loss: 7.5962, time: 0.23s\n",
      "Epoch 786/1000000, train_loss: 7.9302, val_loss: 7.6038, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 787/1000000, train_loss: 7.9080, val_loss: 7.5949, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 788/1000000, train_loss: 7.9144, val_loss: 7.5731, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 789/1000000, train_loss: 7.9300, val_loss: 7.5653, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 790/1000000, train_loss: 7.9073, val_loss: 7.5556, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 791/1000000, train_loss: 7.8838, val_loss: 7.5528, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 792/1000000, train_loss: 7.8605, val_loss: 7.5483, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 793/1000000, train_loss: 7.8922, val_loss: 7.5409, time: 0.17s\n",
      "Epoch 794/1000000, train_loss: 7.8791, val_loss: 7.5410, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 795/1000000, train_loss: 7.8765, val_loss: 7.5282, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 796/1000000, train_loss: 7.8365, val_loss: 7.5105, time: 0.16s\n",
      "Epoch 797/1000000, train_loss: 7.8679, val_loss: 7.5191, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 798/1000000, train_loss: 7.8570, val_loss: 7.5011, time: 0.16s\n",
      "Epoch 799/1000000, train_loss: 7.8719, val_loss: 7.5125, time: 0.15s\n",
      "Epoch 800/1000000, train_loss: 7.8173, val_loss: 7.5113, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 801/1000000, train_loss: 7.7958, val_loss: 7.4877, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 802/1000000, train_loss: 7.8093, val_loss: 7.4875, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 803/1000000, train_loss: 7.7919, val_loss: 7.4800, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 804/1000000, train_loss: 7.8366, val_loss: 7.4717, time: 0.15s\n",
      "Epoch 805/1000000, train_loss: 7.8069, val_loss: 7.4746, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 806/1000000, train_loss: 7.8111, val_loss: 7.4593, time: 0.15s\n",
      "Epoch 807/1000000, train_loss: 7.7937, val_loss: 7.4605, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 808/1000000, train_loss: 7.7558, val_loss: 7.4578, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 809/1000000, train_loss: 7.7613, val_loss: 7.4340, time: 0.16s\n",
      "Epoch 810/1000000, train_loss: 7.7600, val_loss: 7.4439, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 811/1000000, train_loss: 7.7471, val_loss: 7.4232, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 812/1000000, train_loss: 7.8086, val_loss: 7.4194, time: 0.16s\n",
      "Epoch 813/1000000, train_loss: 7.7583, val_loss: 7.4228, time: 0.16s\n",
      "Epoch 814/1000000, train_loss: 7.7514, val_loss: 7.4236, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 815/1000000, train_loss: 7.7189, val_loss: 7.4057, time: 0.16s\n",
      "Epoch 816/1000000, train_loss: 7.7276, val_loss: 7.4105, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 817/1000000, train_loss: 7.7449, val_loss: 7.3924, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 818/1000000, train_loss: 7.7645, val_loss: 7.3811, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 819/1000000, train_loss: 7.7345, val_loss: 7.3724, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 820/1000000, train_loss: 7.7340, val_loss: 7.3688, time: 0.16s\n",
      "Epoch 821/1000000, train_loss: 7.7122, val_loss: 7.3717, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 822/1000000, train_loss: 7.7134, val_loss: 7.3632, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 823/1000000, train_loss: 7.7700, val_loss: 7.3397, time: 0.16s\n",
      "Epoch 824/1000000, train_loss: 7.7493, val_loss: 7.3413, time: 0.15s\n",
      "Epoch 825/1000000, train_loss: 7.6673, val_loss: 7.3427, time: 0.16s\n",
      "Epoch 826/1000000, train_loss: 7.6639, val_loss: 7.3411, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 827/1000000, train_loss: 7.6869, val_loss: 7.3306, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 828/1000000, train_loss: 7.6604, val_loss: 7.3263, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 829/1000000, train_loss: 7.6956, val_loss: 7.3166, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 830/1000000, train_loss: 7.6320, val_loss: 7.3161, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 831/1000000, train_loss: 7.6492, val_loss: 7.3065, time: 0.17s\n",
      "Epoch 832/1000000, train_loss: 7.6527, val_loss: 7.3147, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 833/1000000, train_loss: 7.6083, val_loss: 7.2893, time: 0.16s\n",
      "Epoch 834/1000000, train_loss: 7.6697, val_loss: 7.3011, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 835/1000000, train_loss: 7.6373, val_loss: 7.2785, time: 0.16s\n",
      "Epoch 836/1000000, train_loss: 7.6181, val_loss: 7.2893, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 837/1000000, train_loss: 7.6220, val_loss: 7.2601, time: 0.16s\n",
      "Epoch 838/1000000, train_loss: 7.6206, val_loss: 7.2733, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 839/1000000, train_loss: 7.6287, val_loss: 7.2588, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 840/1000000, train_loss: 7.6112, val_loss: 7.2483, time: 0.15s\n",
      "Epoch 841/1000000, train_loss: 7.6026, val_loss: 7.2572, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 842/1000000, train_loss: 7.5869, val_loss: 7.2457, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 843/1000000, train_loss: 7.6179, val_loss: 7.2309, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 844/1000000, train_loss: 7.5649, val_loss: 7.2271, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 845/1000000, train_loss: 7.5731, val_loss: 7.2235, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 846/1000000, train_loss: 7.5911, val_loss: 7.2141, time: 0.16s\n",
      "Epoch 847/1000000, train_loss: 7.5480, val_loss: 7.2199, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 848/1000000, train_loss: 7.6017, val_loss: 7.2082, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 849/1000000, train_loss: 7.5569, val_loss: 7.1961, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 850/1000000, train_loss: 7.5461, val_loss: 7.1808, time: 0.16s\n",
      "Epoch 851/1000000, train_loss: 7.5566, val_loss: 7.1941, time: 0.16s\n",
      "Epoch 852/1000000, train_loss: 7.5516, val_loss: 7.1813, time: 0.16s\n",
      "Epoch 853/1000000, train_loss: 7.5488, val_loss: 7.1838, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 854/1000000, train_loss: 7.5421, val_loss: 7.1686, time: 0.16s\n",
      "Epoch 855/1000000, train_loss: 7.5144, val_loss: 7.1697, time: 0.16s\n",
      "Epoch 856/1000000, train_loss: 7.5269, val_loss: 7.1736, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 857/1000000, train_loss: 7.5246, val_loss: 7.1489, time: 0.16s\n",
      "Epoch 858/1000000, train_loss: 7.5208, val_loss: 7.1538, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 859/1000000, train_loss: 7.4777, val_loss: 7.1462, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 860/1000000, train_loss: 7.5076, val_loss: 7.1358, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 861/1000000, train_loss: 7.4885, val_loss: 7.1280, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 862/1000000, train_loss: 7.5045, val_loss: 7.1234, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 863/1000000, train_loss: 7.4917, val_loss: 7.1112, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 864/1000000, train_loss: 7.4638, val_loss: 7.1070, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 865/1000000, train_loss: 7.5026, val_loss: 7.1047, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 866/1000000, train_loss: 7.5032, val_loss: 7.0853, time: 0.15s\n",
      "Epoch 867/1000000, train_loss: 7.4427, val_loss: 7.1015, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 868/1000000, train_loss: 7.4516, val_loss: 7.0850, time: 0.15s\n",
      "Epoch 869/1000000, train_loss: 7.4511, val_loss: 7.0851, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 870/1000000, train_loss: 7.4341, val_loss: 7.0796, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 871/1000000, train_loss: 7.4184, val_loss: 7.0732, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 872/1000000, train_loss: 7.4295, val_loss: 7.0587, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 873/1000000, train_loss: 7.4281, val_loss: 7.0537, time: 0.24s\n",
      "Epoch 874/1000000, train_loss: 7.4175, val_loss: 7.0561, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 875/1000000, train_loss: 7.4282, val_loss: 7.0463, time: 0.16s\n",
      "Epoch 876/1000000, train_loss: 7.4268, val_loss: 7.0528, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 877/1000000, train_loss: 7.3995, val_loss: 7.0384, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 878/1000000, train_loss: 7.3991, val_loss: 7.0270, time: 0.16s\n",
      "Epoch 879/1000000, train_loss: 7.4130, val_loss: 7.0290, time: 0.15s\n",
      "Epoch 880/1000000, train_loss: 7.4068, val_loss: 7.0304, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 881/1000000, train_loss: 7.3727, val_loss: 7.0183, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 882/1000000, train_loss: 7.4057, val_loss: 7.0182, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 883/1000000, train_loss: 7.3905, val_loss: 7.0069, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 884/1000000, train_loss: 7.3673, val_loss: 7.0057, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 885/1000000, train_loss: 7.3770, val_loss: 6.9846, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 886/1000000, train_loss: 7.3603, val_loss: 6.9756, time: 0.16s\n",
      "Epoch 887/1000000, train_loss: 7.3367, val_loss: 6.9778, time: 0.16s\n",
      "Epoch 888/1000000, train_loss: 7.3542, val_loss: 6.9890, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 889/1000000, train_loss: 7.3422, val_loss: 6.9630, time: 0.16s\n",
      "Epoch 890/1000000, train_loss: 7.3548, val_loss: 6.9702, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 891/1000000, train_loss: 7.3710, val_loss: 6.9574, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 892/1000000, train_loss: 7.3228, val_loss: 6.9564, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 893/1000000, train_loss: 7.3312, val_loss: 6.9459, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 894/1000000, train_loss: 7.3053, val_loss: 6.9417, time: 0.15s\n",
      "Epoch 895/1000000, train_loss: 7.3181, val_loss: 6.9432, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 896/1000000, train_loss: 7.3053, val_loss: 6.9411, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 897/1000000, train_loss: 7.3153, val_loss: 6.9313, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 898/1000000, train_loss: 7.2994, val_loss: 6.9179, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 899/1000000, train_loss: 7.3220, val_loss: 6.9146, time: 0.15s\n",
      "Epoch 900/1000000, train_loss: 7.2935, val_loss: 6.9294, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 901/1000000, train_loss: 7.3238, val_loss: 6.9018, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 902/1000000, train_loss: 7.2692, val_loss: 6.8881, time: 0.16s\n",
      "Epoch 903/1000000, train_loss: 7.2891, val_loss: 6.8899, time: 0.15s\n",
      "Epoch 904/1000000, train_loss: 7.3044, val_loss: 6.8922, time: 0.15s\n",
      "Epoch 905/1000000, train_loss: 7.2598, val_loss: 6.8895, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 906/1000000, train_loss: 7.2546, val_loss: 6.8847, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 907/1000000, train_loss: 7.2730, val_loss: 6.8705, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 908/1000000, train_loss: 7.2670, val_loss: 6.8617, time: 0.15s\n",
      "Epoch 909/1000000, train_loss: 7.2519, val_loss: 6.8724, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 910/1000000, train_loss: 7.2521, val_loss: 6.8507, time: 0.15s\n",
      "Epoch 911/1000000, train_loss: 7.3120, val_loss: 6.8588, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 912/1000000, train_loss: 7.2447, val_loss: 6.8410, time: 0.16s\n",
      "Epoch 913/1000000, train_loss: 7.2290, val_loss: 6.8456, time: 0.15s\n",
      "Epoch 914/1000000, train_loss: 7.2244, val_loss: 6.8525, time: 0.15s\n",
      "Epoch 915/1000000, train_loss: 7.2384, val_loss: 6.8452, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 916/1000000, train_loss: 7.2090, val_loss: 6.8292, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 917/1000000, train_loss: 7.2029, val_loss: 6.8192, time: 0.15s\n",
      "Epoch 918/1000000, train_loss: 7.2162, val_loss: 6.8218, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 919/1000000, train_loss: 7.1906, val_loss: 6.8050, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 920/1000000, train_loss: 7.1798, val_loss: 6.7952, time: 0.16s\n",
      "Epoch 921/1000000, train_loss: 7.1746, val_loss: 6.8054, time: 0.16s\n",
      "Epoch 922/1000000, train_loss: 7.1933, val_loss: 6.8055, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 923/1000000, train_loss: 7.2219, val_loss: 6.7882, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 924/1000000, train_loss: 7.1609, val_loss: 6.7815, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 925/1000000, train_loss: 7.1662, val_loss: 6.7691, time: 0.16s\n",
      "Epoch 926/1000000, train_loss: 7.1891, val_loss: 6.7736, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 927/1000000, train_loss: 7.1594, val_loss: 6.7591, time: 0.16s\n",
      "Epoch 928/1000000, train_loss: 7.1438, val_loss: 6.7703, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 929/1000000, train_loss: 7.1529, val_loss: 6.7587, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 930/1000000, train_loss: 7.1433, val_loss: 6.7566, time: 0.16s\n",
      "Epoch 931/1000000, train_loss: 7.1514, val_loss: 6.7608, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 932/1000000, train_loss: 7.1356, val_loss: 6.7516, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 933/1000000, train_loss: 7.1226, val_loss: 6.7356, time: 0.16s\n",
      "Epoch 934/1000000, train_loss: 7.1425, val_loss: 6.7421, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 935/1000000, train_loss: 7.1571, val_loss: 6.7332, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 936/1000000, train_loss: 7.1469, val_loss: 6.7009, time: 0.16s\n",
      "Epoch 937/1000000, train_loss: 7.1043, val_loss: 6.7101, time: 0.17s\n",
      "Epoch 938/1000000, train_loss: 7.1225, val_loss: 6.7253, time: 0.16s\n",
      "Epoch 939/1000000, train_loss: 7.1241, val_loss: 6.7070, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 940/1000000, train_loss: 7.0877, val_loss: 6.6993, time: 0.16s\n",
      "Epoch 941/1000000, train_loss: 7.1115, val_loss: 6.7047, time: 0.15s\n",
      "Epoch 942/1000000, train_loss: 7.1272, val_loss: 6.7003, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 943/1000000, train_loss: 7.0877, val_loss: 6.6828, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 944/1000000, train_loss: 7.0959, val_loss: 6.6825, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 945/1000000, train_loss: 7.0670, val_loss: 6.6813, time: 0.16s\n",
      "Epoch 946/1000000, train_loss: 7.1089, val_loss: 6.6905, time: 0.16s\n",
      "Epoch 947/1000000, train_loss: 7.0627, val_loss: 6.6853, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 948/1000000, train_loss: 7.0979, val_loss: 6.6576, time: 0.15s\n",
      "Epoch 949/1000000, train_loss: 7.0737, val_loss: 6.6603, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 950/1000000, train_loss: 7.0443, val_loss: 6.6538, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 951/1000000, train_loss: 7.0744, val_loss: 6.6364, time: 0.16s\n",
      "Epoch 952/1000000, train_loss: 7.0410, val_loss: 6.6521, time: 0.16s\n",
      "Epoch 953/1000000, train_loss: 7.0413, val_loss: 6.6395, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 954/1000000, train_loss: 7.0438, val_loss: 6.6330, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 955/1000000, train_loss: 7.0319, val_loss: 6.6221, time: 0.16s\n",
      "Epoch 956/1000000, train_loss: 7.0192, val_loss: 6.6339, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 957/1000000, train_loss: 7.0453, val_loss: 6.6208, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 958/1000000, train_loss: 7.0038, val_loss: 6.5986, time: 0.16s\n",
      "Epoch 959/1000000, train_loss: 7.0476, val_loss: 6.6122, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 960/1000000, train_loss: 7.0224, val_loss: 6.5946, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 961/1000000, train_loss: 7.0164, val_loss: 6.5906, time: 0.16s\n",
      "Epoch 962/1000000, train_loss: 6.9820, val_loss: 6.5961, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 963/1000000, train_loss: 6.9994, val_loss: 6.5888, time: 0.16s\n",
      "Epoch 964/1000000, train_loss: 6.9976, val_loss: 6.5962, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 965/1000000, train_loss: 6.9860, val_loss: 6.5841, time: 0.25s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 966/1000000, train_loss: 6.9704, val_loss: 6.5781, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 967/1000000, train_loss: 6.9845, val_loss: 6.5690, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 968/1000000, train_loss: 6.9688, val_loss: 6.5585, time: 0.16s\n",
      "Epoch 969/1000000, train_loss: 6.9781, val_loss: 6.5644, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 970/1000000, train_loss: 7.0052, val_loss: 6.5394, time: 0.16s\n",
      "Epoch 971/1000000, train_loss: 6.9620, val_loss: 6.5569, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 972/1000000, train_loss: 6.9520, val_loss: 6.5374, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 973/1000000, train_loss: 6.9601, val_loss: 6.5285, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 974/1000000, train_loss: 6.9390, val_loss: 6.5276, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 975/1000000, train_loss: 6.9438, val_loss: 6.5250, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 976/1000000, train_loss: 6.9545, val_loss: 6.5174, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 977/1000000, train_loss: 6.9168, val_loss: 6.5080, time: 0.16s\n",
      "Epoch 978/1000000, train_loss: 6.9289, val_loss: 6.5166, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 979/1000000, train_loss: 6.9250, val_loss: 6.5002, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 980/1000000, train_loss: 6.9030, val_loss: 6.4971, time: 0.16s\n",
      "Epoch 981/1000000, train_loss: 6.9251, val_loss: 6.4981, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 982/1000000, train_loss: 6.9074, val_loss: 6.4880, time: 0.16s\n",
      "Epoch 983/1000000, train_loss: 6.9242, val_loss: 6.4888, time: 0.16s\n",
      "Epoch 984/1000000, train_loss: 6.9120, val_loss: 6.4887, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 985/1000000, train_loss: 6.9116, val_loss: 6.4854, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 986/1000000, train_loss: 6.9108, val_loss: 6.4816, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 987/1000000, train_loss: 6.8891, val_loss: 6.4678, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 988/1000000, train_loss: 6.8834, val_loss: 6.4556, time: 0.16s\n",
      "Epoch 989/1000000, train_loss: 6.8778, val_loss: 6.4613, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 990/1000000, train_loss: 6.8857, val_loss: 6.4534, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 991/1000000, train_loss: 6.8657, val_loss: 6.4311, time: 0.15s\n",
      "Epoch 992/1000000, train_loss: 6.8572, val_loss: 6.4415, time: 0.16s\n",
      "Epoch 993/1000000, train_loss: 6.8530, val_loss: 6.4414, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 994/1000000, train_loss: 6.8578, val_loss: 6.4186, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 995/1000000, train_loss: 6.8797, val_loss: 6.4123, time: 0.16s\n",
      "Epoch 996/1000000, train_loss: 6.8627, val_loss: 6.4148, time: 0.16s\n",
      "Epoch 997/1000000, train_loss: 6.8497, val_loss: 6.4232, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 998/1000000, train_loss: 6.8375, val_loss: 6.4087, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 999/1000000, train_loss: 6.8164, val_loss: 6.4059, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1000/1000000, train_loss: 6.8204, val_loss: 6.4023, time: 0.16s\n",
      "Epoch 1001/1000000, train_loss: 6.8178, val_loss: 6.4057, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1002/1000000, train_loss: 6.8148, val_loss: 6.3818, time: 0.16s\n",
      "Epoch 1003/1000000, train_loss: 6.8198, val_loss: 6.3842, time: 0.18s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1004/1000000, train_loss: 6.8050, val_loss: 6.3765, time: 0.16s\n",
      "Epoch 1005/1000000, train_loss: 6.7989, val_loss: 6.3781, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1006/1000000, train_loss: 6.8021, val_loss: 6.3683, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1007/1000000, train_loss: 6.8280, val_loss: 6.3597, time: 0.15s\n",
      "Epoch 1008/1000000, train_loss: 6.7905, val_loss: 6.3608, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1009/1000000, train_loss: 6.7985, val_loss: 6.3583, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1010/1000000, train_loss: 6.7879, val_loss: 6.3499, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1011/1000000, train_loss: 6.7946, val_loss: 6.3363, time: 0.16s\n",
      "Epoch 1012/1000000, train_loss: 6.7677, val_loss: 6.3467, time: 0.16s\n",
      "Epoch 1013/1000000, train_loss: 6.7929, val_loss: 6.3508, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1014/1000000, train_loss: 6.7631, val_loss: 6.3336, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1015/1000000, train_loss: 6.7766, val_loss: 6.3181, time: 0.16s\n",
      "Epoch 1016/1000000, train_loss: 6.7584, val_loss: 6.3262, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1017/1000000, train_loss: 6.7690, val_loss: 6.3108, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1018/1000000, train_loss: 6.7439, val_loss: 6.3105, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1019/1000000, train_loss: 6.7330, val_loss: 6.3030, time: 0.16s\n",
      "Epoch 1020/1000000, train_loss: 6.7639, val_loss: 6.3051, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1021/1000000, train_loss: 6.7448, val_loss: 6.2951, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1022/1000000, train_loss: 6.7455, val_loss: 6.2731, time: 0.16s\n",
      "Epoch 1023/1000000, train_loss: 6.7231, val_loss: 6.2983, time: 0.16s\n",
      "Epoch 1024/1000000, train_loss: 6.7905, val_loss: 6.2777, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1025/1000000, train_loss: 6.6980, val_loss: 6.2719, time: 0.16s\n",
      "Epoch 1026/1000000, train_loss: 6.7036, val_loss: 6.2843, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1027/1000000, train_loss: 6.7082, val_loss: 6.2667, time: 0.16s\n",
      "Epoch 1028/1000000, train_loss: 6.7320, val_loss: 6.2748, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1029/1000000, train_loss: 6.7089, val_loss: 6.2543, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1030/1000000, train_loss: 6.7353, val_loss: 6.2496, time: 0.16s\n",
      "Epoch 1031/1000000, train_loss: 6.7021, val_loss: 6.2520, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1032/1000000, train_loss: 6.7260, val_loss: 6.2454, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1033/1000000, train_loss: 6.6791, val_loss: 6.2335, time: 0.16s\n",
      "Epoch 1034/1000000, train_loss: 6.6928, val_loss: 6.2502, time: 0.16s\n",
      "Epoch 1035/1000000, train_loss: 6.6787, val_loss: 6.2394, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1036/1000000, train_loss: 6.6668, val_loss: 6.2212, time: 0.16s\n",
      "Epoch 1037/1000000, train_loss: 6.6677, val_loss: 6.2249, time: 0.16s\n",
      "Epoch 1038/1000000, train_loss: 6.6599, val_loss: 6.2237, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1039/1000000, train_loss: 6.6618, val_loss: 6.2211, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1040/1000000, train_loss: 6.6492, val_loss: 6.1976, time: 0.16s\n",
      "Epoch 1041/1000000, train_loss: 6.6675, val_loss: 6.2009, time: 0.16s\n",
      "Epoch 1042/1000000, train_loss: 6.6749, val_loss: 6.2120, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1043/1000000, train_loss: 6.6359, val_loss: 6.1862, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1044/1000000, train_loss: 6.6546, val_loss: 6.1833, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1045/1000000, train_loss: 6.6445, val_loss: 6.1741, time: 0.16s\n",
      "Epoch 1046/1000000, train_loss: 6.6260, val_loss: 6.1860, time: 0.16s\n",
      "Epoch 1047/1000000, train_loss: 6.6443, val_loss: 6.1792, time: 0.16s\n",
      "Epoch 1048/1000000, train_loss: 6.6262, val_loss: 6.1813, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1049/1000000, train_loss: 6.6283, val_loss: 6.1639, time: 0.16s\n",
      "Epoch 1050/1000000, train_loss: 6.6267, val_loss: 6.1680, time: 0.15s\n",
      "Epoch 1051/1000000, train_loss: 6.6042, val_loss: 6.1675, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1052/1000000, train_loss: 6.6201, val_loss: 6.1606, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1053/1000000, train_loss: 6.6119, val_loss: 6.1465, time: 0.24s\n",
      "Epoch 1054/1000000, train_loss: 6.6039, val_loss: 6.1466, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1055/1000000, train_loss: 6.5855, val_loss: 6.1410, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1056/1000000, train_loss: 6.5965, val_loss: 6.1384, time: 0.16s\n",
      "Epoch 1057/1000000, train_loss: 6.5910, val_loss: 6.1465, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1058/1000000, train_loss: 6.5808, val_loss: 6.1280, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1059/1000000, train_loss: 6.6095, val_loss: 6.1242, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1060/1000000, train_loss: 6.6179, val_loss: 6.1211, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1061/1000000, train_loss: 6.5701, val_loss: 6.1119, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1062/1000000, train_loss: 6.5627, val_loss: 6.1085, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1063/1000000, train_loss: 6.5756, val_loss: 6.0968, time: 0.16s\n",
      "Epoch 1064/1000000, train_loss: 6.5961, val_loss: 6.1004, time: 0.15s\n",
      "Epoch 1065/1000000, train_loss: 6.5486, val_loss: 6.1024, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1066/1000000, train_loss: 6.5578, val_loss: 6.0912, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1067/1000000, train_loss: 6.5439, val_loss: 6.0899, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1068/1000000, train_loss: 6.5470, val_loss: 6.0892, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1069/1000000, train_loss: 6.5383, val_loss: 6.0841, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1070/1000000, train_loss: 6.5332, val_loss: 6.0809, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1071/1000000, train_loss: 6.5218, val_loss: 6.0759, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1072/1000000, train_loss: 6.5565, val_loss: 6.0724, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1073/1000000, train_loss: 6.5975, val_loss: 6.0643, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1074/1000000, train_loss: 6.5311, val_loss: 6.0410, time: 0.16s\n",
      "Epoch 1075/1000000, train_loss: 6.5582, val_loss: 6.0572, time: 0.16s\n",
      "Epoch 1076/1000000, train_loss: 6.5441, val_loss: 6.0592, time: 0.16s\n",
      "Epoch 1077/1000000, train_loss: 6.5136, val_loss: 6.0413, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1078/1000000, train_loss: 6.5159, val_loss: 6.0322, time: 0.16s\n",
      "Epoch 1079/1000000, train_loss: 6.5018, val_loss: 6.0329, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1080/1000000, train_loss: 6.5042, val_loss: 6.0197, time: 0.16s\n",
      "Epoch 1081/1000000, train_loss: 6.5241, val_loss: 6.0336, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1082/1000000, train_loss: 6.4899, val_loss: 6.0186, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1083/1000000, train_loss: 6.4870, val_loss: 6.0164, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1084/1000000, train_loss: 6.4805, val_loss: 6.0133, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1085/1000000, train_loss: 6.4796, val_loss: 6.0070, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1086/1000000, train_loss: 6.4730, val_loss: 6.0019, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1087/1000000, train_loss: 6.4730, val_loss: 5.9976, time: 0.16s\n",
      "Epoch 1088/1000000, train_loss: 6.5084, val_loss: 6.0014, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1089/1000000, train_loss: 6.4608, val_loss: 5.9919, time: 0.16s\n",
      "Epoch 1090/1000000, train_loss: 6.4755, val_loss: 5.9919, time: 0.16s\n",
      "Epoch 1091/1000000, train_loss: 6.4745, val_loss: 5.9976, time: 0.16s\n",
      "Epoch 1092/1000000, train_loss: 6.4848, val_loss: 5.9923, time: 0.16s\n",
      "Epoch 1093/1000000, train_loss: 6.4554, val_loss: 5.9925, time: 0.16s\n",
      "Epoch 1094/1000000, train_loss: 6.4525, val_loss: 5.9987, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1095/1000000, train_loss: 6.4458, val_loss: 5.9552, time: 0.17s\n",
      "Epoch 1096/1000000, train_loss: 6.4407, val_loss: 5.9639, time: 0.15s\n",
      "Epoch 1097/1000000, train_loss: 6.4476, val_loss: 5.9720, time: 0.15s\n",
      "Epoch 1098/1000000, train_loss: 6.4424, val_loss: 5.9728, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1099/1000000, train_loss: 6.4276, val_loss: 5.9520, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1100/1000000, train_loss: 6.4261, val_loss: 5.9493, time: 0.16s\n",
      "Epoch 1101/1000000, train_loss: 6.4166, val_loss: 5.9533, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1102/1000000, train_loss: 6.4189, val_loss: 5.9361, time: 0.16s\n",
      "Epoch 1103/1000000, train_loss: 6.4333, val_loss: 5.9509, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1104/1000000, train_loss: 6.4225, val_loss: 5.9333, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1105/1000000, train_loss: 6.3999, val_loss: 5.9292, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1106/1000000, train_loss: 6.4201, val_loss: 5.9265, time: 0.16s\n",
      "Epoch 1107/1000000, train_loss: 6.4068, val_loss: 5.9270, time: 0.15s\n",
      "Epoch 1108/1000000, train_loss: 6.4026, val_loss: 5.9317, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1109/1000000, train_loss: 6.3898, val_loss: 5.9227, time: 0.15s\n",
      "Epoch 1110/1000000, train_loss: 6.3964, val_loss: 5.9230, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1111/1000000, train_loss: 6.4019, val_loss: 5.9102, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1112/1000000, train_loss: 6.3804, val_loss: 5.9050, time: 0.15s\n",
      "Epoch 1113/1000000, train_loss: 6.3727, val_loss: 5.9072, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1114/1000000, train_loss: 6.3757, val_loss: 5.8914, time: 0.16s\n",
      "Epoch 1115/1000000, train_loss: 6.3766, val_loss: 5.9028, time: 0.16s\n",
      "Epoch 1116/1000000, train_loss: 6.3689, val_loss: 5.8949, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1117/1000000, train_loss: 6.3711, val_loss: 5.8913, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1118/1000000, train_loss: 6.3624, val_loss: 5.8856, time: 0.16s\n",
      "Epoch 1119/1000000, train_loss: 6.4090, val_loss: 5.8861, time: 0.16s\n",
      "Epoch 1120/1000000, train_loss: 6.3699, val_loss: 5.8899, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1121/1000000, train_loss: 6.3583, val_loss: 5.8779, time: 0.16s\n",
      "Epoch 1122/1000000, train_loss: 6.3704, val_loss: 5.8798, time: 0.15s\n",
      "Epoch 1123/1000000, train_loss: 6.3549, val_loss: 5.8822, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1124/1000000, train_loss: 6.3385, val_loss: 5.8648, time: 0.16s\n",
      "Epoch 1125/1000000, train_loss: 6.3378, val_loss: 5.8725, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1126/1000000, train_loss: 6.3444, val_loss: 5.8609, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1127/1000000, train_loss: 6.3386, val_loss: 5.8457, time: 0.16s\n",
      "Epoch 1128/1000000, train_loss: 6.3264, val_loss: 5.8520, time: 0.16s\n",
      "Epoch 1129/1000000, train_loss: 6.3300, val_loss: 5.8585, time: 0.15s\n",
      "Epoch 1130/1000000, train_loss: 6.3588, val_loss: 5.8480, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1131/1000000, train_loss: 6.3435, val_loss: 5.8431, time: 0.15s\n",
      "Epoch 1132/1000000, train_loss: 6.3290, val_loss: 5.8533, time: 0.15s\n",
      "Epoch 1133/1000000, train_loss: 6.3217, val_loss: 5.8478, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1134/1000000, train_loss: 6.3185, val_loss: 5.8388, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1135/1000000, train_loss: 6.2997, val_loss: 5.8290, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1136/1000000, train_loss: 6.3077, val_loss: 5.8208, time: 0.16s\n",
      "Epoch 1137/1000000, train_loss: 6.3319, val_loss: 5.8290, time: 0.16s\n",
      "Epoch 1138/1000000, train_loss: 6.3062, val_loss: 5.8339, time: 0.16s\n",
      "Epoch 1139/1000000, train_loss: 6.2967, val_loss: 5.8214, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1140/1000000, train_loss: 6.3034, val_loss: 5.8153, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1141/1000000, train_loss: 6.3281, val_loss: 5.8139, time: 0.16s\n",
      "Epoch 1142/1000000, train_loss: 6.3209, val_loss: 5.8169, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1143/1000000, train_loss: 6.2954, val_loss: 5.8063, time: 0.25s\n",
      "Epoch 1144/1000000, train_loss: 6.2828, val_loss: 5.8081, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1145/1000000, train_loss: 6.2737, val_loss: 5.8024, time: 0.16s\n",
      "Epoch 1146/1000000, train_loss: 6.2812, val_loss: 5.8046, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1147/1000000, train_loss: 6.2838, val_loss: 5.7923, time: 0.16s\n",
      "Epoch 1148/1000000, train_loss: 6.3023, val_loss: 5.8092, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1149/1000000, train_loss: 6.2891, val_loss: 5.7897, time: 0.16s\n",
      "Epoch 1150/1000000, train_loss: 6.2606, val_loss: 5.7971, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1151/1000000, train_loss: 6.2536, val_loss: 5.7847, time: 0.18s\n",
      "Epoch 1152/1000000, train_loss: 6.2474, val_loss: 5.7968, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1153/1000000, train_loss: 6.2479, val_loss: 5.7835, time: 0.15s\n",
      "Epoch 1154/1000000, train_loss: 6.2667, val_loss: 5.7874, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1155/1000000, train_loss: 6.2420, val_loss: 5.7773, time: 0.16s\n",
      "Epoch 1156/1000000, train_loss: 6.2692, val_loss: 5.7864, time: 0.16s\n",
      "Epoch 1157/1000000, train_loss: 6.2426, val_loss: 5.7804, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1158/1000000, train_loss: 6.2364, val_loss: 5.7737, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1159/1000000, train_loss: 6.2381, val_loss: 5.7717, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1160/1000000, train_loss: 6.2660, val_loss: 5.7684, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1161/1000000, train_loss: 6.2424, val_loss: 5.7657, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1162/1000000, train_loss: 6.2276, val_loss: 5.7596, time: 0.16s\n",
      "Epoch 1163/1000000, train_loss: 6.2396, val_loss: 5.7659, time: 0.16s\n",
      "Epoch 1164/1000000, train_loss: 6.2303, val_loss: 5.7863, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1165/1000000, train_loss: 6.2511, val_loss: 5.7538, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1166/1000000, train_loss: 6.2354, val_loss: 5.7435, time: 0.16s\n",
      "Epoch 1167/1000000, train_loss: 6.2453, val_loss: 5.7615, time: 0.16s\n",
      "Epoch 1168/1000000, train_loss: 6.2198, val_loss: 5.7465, time: 0.16s\n",
      "Epoch 1169/1000000, train_loss: 6.2069, val_loss: 5.7526, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1170/1000000, train_loss: 6.2094, val_loss: 5.7412, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1171/1000000, train_loss: 6.2065, val_loss: 5.7372, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1172/1000000, train_loss: 6.2010, val_loss: 5.7338, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1173/1000000, train_loss: 6.1983, val_loss: 5.7324, time: 0.16s\n",
      "Epoch 1174/1000000, train_loss: 6.2179, val_loss: 5.7377, time: 0.16s\n",
      "Epoch 1175/1000000, train_loss: 6.1975, val_loss: 5.7522, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1176/1000000, train_loss: 6.1967, val_loss: 5.7321, time: 0.16s\n",
      "Epoch 1177/1000000, train_loss: 6.1788, val_loss: 5.7412, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1178/1000000, train_loss: 6.1929, val_loss: 5.7192, time: 0.16s\n",
      "Epoch 1179/1000000, train_loss: 6.2086, val_loss: 5.7220, time: 0.17s\n",
      "Epoch 1180/1000000, train_loss: 6.2002, val_loss: 5.7265, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1181/1000000, train_loss: 6.1730, val_loss: 5.7159, time: 0.16s\n",
      "Epoch 1182/1000000, train_loss: 6.1856, val_loss: 5.7220, time: 0.16s\n",
      "Epoch 1183/1000000, train_loss: 6.1704, val_loss: 5.7207, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1184/1000000, train_loss: 6.1668, val_loss: 5.7115, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1185/1000000, train_loss: 6.1678, val_loss: 5.7079, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1186/1000000, train_loss: 6.1641, val_loss: 5.7074, time: 0.15s\n",
      "Epoch 1187/1000000, train_loss: 6.1567, val_loss: 5.7084, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1188/1000000, train_loss: 6.1549, val_loss: 5.7019, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1189/1000000, train_loss: 6.1574, val_loss: 5.6894, time: 0.15s\n",
      "Epoch 1190/1000000, train_loss: 6.1604, val_loss: 5.7052, time: 0.15s\n",
      "Epoch 1191/1000000, train_loss: 6.1536, val_loss: 5.6901, time: 0.15s\n",
      "Epoch 1192/1000000, train_loss: 6.1644, val_loss: 5.6970, time: 0.16s\n",
      "Epoch 1193/1000000, train_loss: 6.1339, val_loss: 5.6899, time: 0.15s\n",
      "Epoch 1194/1000000, train_loss: 6.1517, val_loss: 5.6896, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1195/1000000, train_loss: 6.1323, val_loss: 5.6887, time: 0.15s\n",
      "Epoch 1196/1000000, train_loss: 6.1328, val_loss: 5.6896, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1197/1000000, train_loss: 6.1321, val_loss: 5.6830, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1198/1000000, train_loss: 6.1412, val_loss: 5.6808, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1199/1000000, train_loss: 6.1299, val_loss: 5.6708, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1200/1000000, train_loss: 6.1377, val_loss: 5.6688, time: 0.16s\n",
      "Epoch 1201/1000000, train_loss: 6.1274, val_loss: 5.6735, time: 0.15s\n",
      "Epoch 1202/1000000, train_loss: 6.1135, val_loss: 5.6848, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1203/1000000, train_loss: 6.1350, val_loss: 5.6684, time: 0.15s\n",
      "Epoch 1204/1000000, train_loss: 6.1369, val_loss: 5.6732, time: 0.15s\n",
      "Epoch 1205/1000000, train_loss: 6.1406, val_loss: 5.6695, time: 0.15s\n",
      "Epoch 1206/1000000, train_loss: 6.1219, val_loss: 5.6699, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1207/1000000, train_loss: 6.1014, val_loss: 5.6568, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1208/1000000, train_loss: 6.1121, val_loss: 5.6562, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1209/1000000, train_loss: 6.1284, val_loss: 5.6496, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1210/1000000, train_loss: 6.1260, val_loss: 5.6397, time: 0.16s\n",
      "Epoch 1211/1000000, train_loss: 6.1003, val_loss: 5.6680, time: 0.15s\n",
      "Epoch 1212/1000000, train_loss: 6.1170, val_loss: 5.6465, time: 0.15s\n",
      "Epoch 1213/1000000, train_loss: 6.1015, val_loss: 5.6423, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1214/1000000, train_loss: 6.1088, val_loss: 5.6392, time: 0.16s\n",
      "Epoch 1215/1000000, train_loss: 6.0810, val_loss: 5.6484, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1216/1000000, train_loss: 6.0984, val_loss: 5.6313, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1217/1000000, train_loss: 6.0811, val_loss: 5.6282, time: 0.16s\n",
      "Epoch 1218/1000000, train_loss: 6.0972, val_loss: 5.6318, time: 0.16s\n",
      "Epoch 1219/1000000, train_loss: 6.0897, val_loss: 5.6302, time: 0.15s\n",
      "Epoch 1220/1000000, train_loss: 6.0798, val_loss: 5.6291, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1221/1000000, train_loss: 6.0789, val_loss: 5.6204, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1222/1000000, train_loss: 6.0630, val_loss: 5.6102, time: 0.16s\n",
      "Epoch 1223/1000000, train_loss: 6.0714, val_loss: 5.6316, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1224/1000000, train_loss: 6.0945, val_loss: 5.6077, time: 0.15s\n",
      "Epoch 1225/1000000, train_loss: 6.0735, val_loss: 5.6116, time: 0.16s\n",
      "Epoch 1226/1000000, train_loss: 6.0617, val_loss: 5.6108, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1227/1000000, train_loss: 6.0748, val_loss: 5.6058, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1228/1000000, train_loss: 6.0444, val_loss: 5.5971, time: 0.15s\n",
      "Epoch 1229/1000000, train_loss: 6.0589, val_loss: 5.5982, time: 0.15s\n",
      "Epoch 1230/1000000, train_loss: 6.0728, val_loss: 5.6011, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1231/1000000, train_loss: 6.0373, val_loss: 5.5968, time: 0.25s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1232/1000000, train_loss: 6.0845, val_loss: 5.5944, time: 0.16s\n",
      "Epoch 1233/1000000, train_loss: 6.0406, val_loss: 5.5964, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1234/1000000, train_loss: 6.0291, val_loss: 5.5900, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1235/1000000, train_loss: 6.0491, val_loss: 5.5840, time: 0.16s\n",
      "Epoch 1236/1000000, train_loss: 6.0471, val_loss: 5.5861, time: 0.16s\n",
      "Epoch 1237/1000000, train_loss: 6.0720, val_loss: 5.5881, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1238/1000000, train_loss: 6.0427, val_loss: 5.5687, time: 0.16s\n",
      "Epoch 1239/1000000, train_loss: 6.0511, val_loss: 5.5910, time: 0.16s\n",
      "Epoch 1240/1000000, train_loss: 6.0246, val_loss: 5.5737, time: 0.16s\n",
      "Epoch 1241/1000000, train_loss: 6.0302, val_loss: 5.5708, time: 0.16s\n",
      "Epoch 1242/1000000, train_loss: 6.0265, val_loss: 5.5691, time: 0.16s\n",
      "Epoch 1243/1000000, train_loss: 6.0388, val_loss: 5.5704, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1244/1000000, train_loss: 6.0226, val_loss: 5.5626, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1245/1000000, train_loss: 6.0339, val_loss: 5.5562, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1246/1000000, train_loss: 6.0147, val_loss: 5.5541, time: 0.16s\n",
      "Epoch 1247/1000000, train_loss: 6.0093, val_loss: 5.5646, time: 0.16s\n",
      "Epoch 1248/1000000, train_loss: 6.0489, val_loss: 5.5660, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1249/1000000, train_loss: 6.0107, val_loss: 5.5430, time: 0.16s\n",
      "Epoch 1250/1000000, train_loss: 6.0163, val_loss: 5.5440, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1251/1000000, train_loss: 6.0351, val_loss: 5.5383, time: 0.16s\n",
      "Epoch 1252/1000000, train_loss: 6.0099, val_loss: 5.5552, time: 0.16s\n",
      "Epoch 1253/1000000, train_loss: 5.9854, val_loss: 5.5464, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1254/1000000, train_loss: 5.9997, val_loss: 5.5352, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1255/1000000, train_loss: 5.9977, val_loss: 5.5348, time: 0.16s\n",
      "Epoch 1256/1000000, train_loss: 5.9981, val_loss: 5.5397, time: 0.16s\n",
      "Epoch 1257/1000000, train_loss: 6.0361, val_loss: 5.5351, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1258/1000000, train_loss: 6.0031, val_loss: 5.5285, time: 0.16s\n",
      "Epoch 1259/1000000, train_loss: 5.9847, val_loss: 5.5302, time: 0.17s\n",
      "Epoch 1260/1000000, train_loss: 5.9952, val_loss: 5.5291, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1261/1000000, train_loss: 5.9959, val_loss: 5.5207, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1262/1000000, train_loss: 5.9860, val_loss: 5.5128, time: 0.17s\n",
      "Epoch 1263/1000000, train_loss: 5.9913, val_loss: 5.5187, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1264/1000000, train_loss: 5.9916, val_loss: 5.5087, time: 0.16s\n",
      "Epoch 1265/1000000, train_loss: 5.9890, val_loss: 5.5100, time: 0.16s\n",
      "Epoch 1266/1000000, train_loss: 5.9737, val_loss: 5.5168, time: 0.16s\n",
      "Epoch 1267/1000000, train_loss: 5.9824, val_loss: 5.5173, time: 0.16s\n",
      "Epoch 1268/1000000, train_loss: 5.9867, val_loss: 5.5134, time: 0.16s\n",
      "Epoch 1269/1000000, train_loss: 5.9727, val_loss: 5.5123, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1270/1000000, train_loss: 5.9620, val_loss: 5.4931, time: 0.16s\n",
      "Epoch 1271/1000000, train_loss: 6.0006, val_loss: 5.5060, time: 0.16s\n",
      "Epoch 1272/1000000, train_loss: 5.9723, val_loss: 5.4994, time: 0.16s\n",
      "Epoch 1273/1000000, train_loss: 5.9613, val_loss: 5.4995, time: 0.16s\n",
      "Epoch 1274/1000000, train_loss: 5.9526, val_loss: 5.5040, time: 0.16s\n",
      "Epoch 1275/1000000, train_loss: 5.9446, val_loss: 5.5013, time: 0.16s\n",
      "Epoch 1276/1000000, train_loss: 5.9640, val_loss: 5.5023, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1277/1000000, train_loss: 5.9733, val_loss: 5.4889, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1278/1000000, train_loss: 5.9732, val_loss: 5.4813, time: 0.16s\n",
      "Epoch 1279/1000000, train_loss: 5.9446, val_loss: 5.4919, time: 0.16s\n",
      "Epoch 1280/1000000, train_loss: 5.9558, val_loss: 5.5004, time: 0.16s\n",
      "Epoch 1281/1000000, train_loss: 5.9467, val_loss: 5.4825, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1282/1000000, train_loss: 5.9378, val_loss: 5.4684, time: 0.16s\n",
      "Epoch 1283/1000000, train_loss: 5.9443, val_loss: 5.4797, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1284/1000000, train_loss: 5.9429, val_loss: 5.4580, time: 0.16s\n",
      "Epoch 1285/1000000, train_loss: 5.9208, val_loss: 5.4732, time: 0.17s\n",
      "Epoch 1286/1000000, train_loss: 5.9617, val_loss: 5.4674, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1287/1000000, train_loss: 5.9710, val_loss: 5.4563, time: 0.16s\n",
      "Epoch 1288/1000000, train_loss: 5.9713, val_loss: 5.4619, time: 0.15s\n",
      "Epoch 1289/1000000, train_loss: 5.9560, val_loss: 5.4815, time: 0.15s\n",
      "Epoch 1290/1000000, train_loss: 5.9324, val_loss: 5.4589, time: 0.15s\n",
      "Epoch 1291/1000000, train_loss: 5.9221, val_loss: 5.4643, time: 0.15s\n",
      "Epoch 1292/1000000, train_loss: 5.9233, val_loss: 5.4567, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1293/1000000, train_loss: 5.9491, val_loss: 5.4463, time: 0.16s\n",
      "Epoch 1294/1000000, train_loss: 5.9245, val_loss: 5.4692, time: 0.16s\n",
      "Epoch 1295/1000000, train_loss: 5.9213, val_loss: 5.4496, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1296/1000000, train_loss: 5.9334, val_loss: 5.4460, time: 0.16s\n",
      "Epoch 1297/1000000, train_loss: 5.9174, val_loss: 5.4526, time: 0.15s\n",
      "Epoch 1298/1000000, train_loss: 5.9164, val_loss: 5.4598, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1299/1000000, train_loss: 5.9179, val_loss: 5.4413, time: 0.15s\n",
      "Epoch 1300/1000000, train_loss: 5.9034, val_loss: 5.4594, time: 0.16s\n",
      "Epoch 1301/1000000, train_loss: 5.9121, val_loss: 5.4546, time: 0.16s\n",
      "Epoch 1302/1000000, train_loss: 5.9065, val_loss: 5.4482, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1303/1000000, train_loss: 5.9106, val_loss: 5.4355, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1304/1000000, train_loss: 5.9245, val_loss: 5.4347, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1305/1000000, train_loss: 5.9479, val_loss: 5.4183, time: 0.16s\n",
      "Epoch 1306/1000000, train_loss: 5.9239, val_loss: 5.4344, time: 0.15s\n",
      "Epoch 1307/1000000, train_loss: 5.9153, val_loss: 5.4392, time: 0.17s\n",
      "Epoch 1308/1000000, train_loss: 5.9106, val_loss: 5.4317, time: 0.16s\n",
      "Epoch 1309/1000000, train_loss: 5.8976, val_loss: 5.4328, time: 0.16s\n",
      "Epoch 1310/1000000, train_loss: 5.8997, val_loss: 5.4304, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1311/1000000, train_loss: 5.8832, val_loss: 5.4103, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1312/1000000, train_loss: 5.9061, val_loss: 5.4082, time: 0.16s\n",
      "Epoch 1313/1000000, train_loss: 5.8925, val_loss: 5.4182, time: 0.16s\n",
      "Epoch 1314/1000000, train_loss: 5.9000, val_loss: 5.4151, time: 0.15s\n",
      "Epoch 1315/1000000, train_loss: 5.8863, val_loss: 5.4124, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1316/1000000, train_loss: 5.8812, val_loss: 5.4025, time: 0.15s\n",
      "Epoch 1317/1000000, train_loss: 5.8523, val_loss: 5.4088, time: 0.15s\n",
      "Epoch 1318/1000000, train_loss: 5.8817, val_loss: 5.4177, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1319/1000000, train_loss: 5.8962, val_loss: 5.3998, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1320/1000000, train_loss: 5.8675, val_loss: 5.3930, time: 0.16s\n",
      "Epoch 1321/1000000, train_loss: 5.8801, val_loss: 5.3942, time: 0.25s\n",
      "Epoch 1322/1000000, train_loss: 5.8678, val_loss: 5.3937, time: 0.17s\n",
      "Epoch 1323/1000000, train_loss: 5.8787, val_loss: 5.3987, time: 0.15s\n",
      "Epoch 1324/1000000, train_loss: 5.8954, val_loss: 5.4023, time: 0.17s\n",
      "Epoch 1325/1000000, train_loss: 5.8447, val_loss: 5.4048, time: 0.16s\n",
      "Epoch 1326/1000000, train_loss: 5.8547, val_loss: 5.3999, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1327/1000000, train_loss: 5.8592, val_loss: 5.3904, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1328/1000000, train_loss: 5.8483, val_loss: 5.3847, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1329/1000000, train_loss: 5.8695, val_loss: 5.3756, time: 0.16s\n",
      "Epoch 1330/1000000, train_loss: 5.8639, val_loss: 5.3826, time: 0.16s\n",
      "Epoch 1331/1000000, train_loss: 5.8689, val_loss: 5.3864, time: 0.16s\n",
      "Epoch 1332/1000000, train_loss: 5.8558, val_loss: 5.3882, time: 0.16s\n",
      "Epoch 1333/1000000, train_loss: 5.8440, val_loss: 5.3775, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1334/1000000, train_loss: 5.8433, val_loss: 5.3694, time: 0.16s\n",
      "Epoch 1335/1000000, train_loss: 5.8597, val_loss: 5.3711, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1336/1000000, train_loss: 5.8493, val_loss: 5.3624, time: 0.16s\n",
      "Epoch 1337/1000000, train_loss: 5.8327, val_loss: 5.3773, time: 0.16s\n",
      "Epoch 1338/1000000, train_loss: 5.8573, val_loss: 5.3663, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1339/1000000, train_loss: 5.8687, val_loss: 5.3498, time: 0.16s\n",
      "Epoch 1340/1000000, train_loss: 5.8432, val_loss: 5.3678, time: 0.16s\n",
      "Epoch 1341/1000000, train_loss: 5.8102, val_loss: 5.3781, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1342/1000000, train_loss: 5.8538, val_loss: 5.3463, time: 0.16s\n",
      "Epoch 1343/1000000, train_loss: 5.8005, val_loss: 5.3504, time: 0.15s\n",
      "Epoch 1344/1000000, train_loss: 5.8297, val_loss: 5.3652, time: 0.15s\n",
      "Epoch 1345/1000000, train_loss: 5.8362, val_loss: 5.3520, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1346/1000000, train_loss: 5.8376, val_loss: 5.3358, time: 0.15s\n",
      "Epoch 1347/1000000, train_loss: 5.8455, val_loss: 5.3403, time: 0.16s\n",
      "Epoch 1348/1000000, train_loss: 5.8395, val_loss: 5.3425, time: 0.16s\n",
      "Epoch 1349/1000000, train_loss: 5.8206, val_loss: 5.3418, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1350/1000000, train_loss: 5.8364, val_loss: 5.3240, time: 0.16s\n",
      "Epoch 1351/1000000, train_loss: 5.8323, val_loss: 5.3357, time: 0.16s\n",
      "Epoch 1352/1000000, train_loss: 5.8306, val_loss: 5.3341, time: 0.16s\n",
      "Epoch 1353/1000000, train_loss: 5.8149, val_loss: 5.3342, time: 0.16s\n",
      "Epoch 1354/1000000, train_loss: 5.8001, val_loss: 5.3300, time: 0.16s\n",
      "Epoch 1355/1000000, train_loss: 5.8091, val_loss: 5.3284, time: 0.16s\n",
      "Epoch 1356/1000000, train_loss: 5.8149, val_loss: 5.3288, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1357/1000000, train_loss: 5.7836, val_loss: 5.3184, time: 0.16s\n",
      "Epoch 1358/1000000, train_loss: 5.7931, val_loss: 5.3253, time: 0.16s\n",
      "Epoch 1359/1000000, train_loss: 5.7841, val_loss: 5.3219, time: 0.19s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1360/1000000, train_loss: 5.7892, val_loss: 5.3162, time: 0.16s\n",
      "Epoch 1361/1000000, train_loss: 5.8158, val_loss: 5.3215, time: 0.15s\n",
      "Epoch 1362/1000000, train_loss: 5.8184, val_loss: 5.3298, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1363/1000000, train_loss: 5.7954, val_loss: 5.3090, time: 0.15s\n",
      "Epoch 1364/1000000, train_loss: 5.7806, val_loss: 5.3223, time: 0.15s\n",
      "Epoch 1365/1000000, train_loss: 5.7949, val_loss: 5.3401, time: 0.16s\n",
      "Epoch 1366/1000000, train_loss: 5.7829, val_loss: 5.3161, time: 0.16s\n",
      "Epoch 1367/1000000, train_loss: 5.8014, val_loss: 5.3185, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1368/1000000, train_loss: 5.7773, val_loss: 5.2943, time: 0.16s\n",
      "Epoch 1369/1000000, train_loss: 5.7897, val_loss: 5.3030, time: 0.17s\n",
      "Epoch 1370/1000000, train_loss: 5.7688, val_loss: 5.3057, time: 0.16s\n",
      "Epoch 1371/1000000, train_loss: 5.8017, val_loss: 5.2958, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1372/1000000, train_loss: 5.7670, val_loss: 5.2869, time: 0.16s\n",
      "Epoch 1373/1000000, train_loss: 5.7844, val_loss: 5.3161, time: 0.15s\n",
      "Epoch 1374/1000000, train_loss: 5.7490, val_loss: 5.3037, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1375/1000000, train_loss: 5.7676, val_loss: 5.2857, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1376/1000000, train_loss: 5.7711, val_loss: 5.2849, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1377/1000000, train_loss: 5.7931, val_loss: 5.2743, time: 0.16s\n",
      "Epoch 1378/1000000, train_loss: 5.7683, val_loss: 5.2990, time: 0.16s\n",
      "Epoch 1379/1000000, train_loss: 5.7662, val_loss: 5.2839, time: 0.16s\n",
      "Epoch 1380/1000000, train_loss: 5.7642, val_loss: 5.2858, time: 0.15s\n",
      "Epoch 1381/1000000, train_loss: 5.7715, val_loss: 5.2932, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1382/1000000, train_loss: 5.7726, val_loss: 5.2742, time: 0.16s\n",
      "Epoch 1383/1000000, train_loss: 5.7743, val_loss: 5.2854, time: 0.16s\n",
      "Epoch 1384/1000000, train_loss: 5.7522, val_loss: 5.3024, time: 0.16s\n",
      "Epoch 1385/1000000, train_loss: 5.7942, val_loss: 5.2850, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1386/1000000, train_loss: 5.7633, val_loss: 5.2736, time: 0.16s\n",
      "Epoch 1387/1000000, train_loss: 5.7462, val_loss: 5.2816, time: 0.16s\n",
      "Epoch 1388/1000000, train_loss: 5.7633, val_loss: 5.2772, time: 0.16s\n",
      "Epoch 1389/1000000, train_loss: 5.7757, val_loss: 5.2745, time: 0.16s\n",
      "Epoch 1390/1000000, train_loss: 5.7361, val_loss: 5.2793, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1391/1000000, train_loss: 5.7318, val_loss: 5.2602, time: 0.16s\n",
      "Epoch 1392/1000000, train_loss: 5.7214, val_loss: 5.2659, time: 0.16s\n",
      "Epoch 1393/1000000, train_loss: 5.7407, val_loss: 5.2795, time: 0.16s\n",
      "Epoch 1394/1000000, train_loss: 5.7428, val_loss: 5.2788, time: 0.16s\n",
      "Epoch 1395/1000000, train_loss: 5.7347, val_loss: 5.2617, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1396/1000000, train_loss: 5.7293, val_loss: 5.2390, time: 0.16s\n",
      "Epoch 1397/1000000, train_loss: 5.7402, val_loss: 5.2562, time: 0.15s\n",
      "Epoch 1398/1000000, train_loss: 5.7383, val_loss: 5.2563, time: 0.15s\n",
      "Epoch 1399/1000000, train_loss: 5.7119, val_loss: 5.2727, time: 0.15s\n",
      "Epoch 1400/1000000, train_loss: 5.7369, val_loss: 5.2436, time: 0.15s\n",
      "Epoch 1401/1000000, train_loss: 5.7027, val_loss: 5.2571, time: 0.15s\n",
      "Epoch 1402/1000000, train_loss: 5.7197, val_loss: 5.2557, time: 0.15s\n",
      "Epoch 1403/1000000, train_loss: 5.7049, val_loss: 5.2399, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1404/1000000, train_loss: 5.7068, val_loss: 5.2276, time: 0.16s\n",
      "Epoch 1405/1000000, train_loss: 5.7260, val_loss: 5.2494, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1406/1000000, train_loss: 5.7128, val_loss: 5.2233, time: 0.15s\n",
      "Epoch 1407/1000000, train_loss: 5.7169, val_loss: 5.2513, time: 0.15s\n",
      "Epoch 1408/1000000, train_loss: 5.7137, val_loss: 5.2258, time: 0.15s\n",
      "Epoch 1409/1000000, train_loss: 5.7132, val_loss: 5.2386, time: 0.19s\n",
      "Epoch 1410/1000000, train_loss: 5.7092, val_loss: 5.2373, time: 0.16s\n",
      "Epoch 1411/1000000, train_loss: 5.6793, val_loss: 5.2469, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1412/1000000, train_loss: 5.7152, val_loss: 5.2208, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1413/1000000, train_loss: 5.6847, val_loss: 5.2095, time: 0.25s\n",
      "Epoch 1414/1000000, train_loss: 5.6841, val_loss: 5.2228, time: 0.16s\n",
      "Epoch 1415/1000000, train_loss: 5.7354, val_loss: 5.2308, time: 0.15s\n",
      "Epoch 1416/1000000, train_loss: 5.6851, val_loss: 5.2298, time: 0.16s\n",
      "Epoch 1417/1000000, train_loss: 5.6942, val_loss: 5.2195, time: 0.16s\n",
      "Epoch 1418/1000000, train_loss: 5.7024, val_loss: 5.2237, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1419/1000000, train_loss: 5.6836, val_loss: 5.2038, time: 0.16s\n",
      "Epoch 1420/1000000, train_loss: 5.6978, val_loss: 5.2135, time: 0.16s\n",
      "Epoch 1421/1000000, train_loss: 5.6799, val_loss: 5.2101, time: 0.16s\n",
      "Epoch 1422/1000000, train_loss: 5.6979, val_loss: 5.2316, time: 0.16s\n",
      "Epoch 1423/1000000, train_loss: 5.6895, val_loss: 5.2390, time: 0.16s\n",
      "Epoch 1424/1000000, train_loss: 5.6817, val_loss: 5.2193, time: 0.16s\n",
      "Epoch 1425/1000000, train_loss: 5.7077, val_loss: 5.2053, time: 0.16s\n",
      "Epoch 1426/1000000, train_loss: 5.6832, val_loss: 5.2119, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1427/1000000, train_loss: 5.6807, val_loss: 5.1966, time: 0.16s\n",
      "Epoch 1428/1000000, train_loss: 5.6572, val_loss: 5.2069, time: 0.16s\n",
      "Epoch 1429/1000000, train_loss: 5.6753, val_loss: 5.2007, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1430/1000000, train_loss: 5.6692, val_loss: 5.1940, time: 0.16s\n",
      "Epoch 1431/1000000, train_loss: 5.6842, val_loss: 5.2098, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1432/1000000, train_loss: 5.6655, val_loss: 5.1895, time: 0.16s\n",
      "Epoch 1433/1000000, train_loss: 5.6551, val_loss: 5.2024, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1434/1000000, train_loss: 5.6461, val_loss: 5.1854, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1435/1000000, train_loss: 5.6732, val_loss: 5.1812, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1436/1000000, train_loss: 5.6625, val_loss: 5.1768, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1437/1000000, train_loss: 5.6699, val_loss: 5.1631, time: 0.16s\n",
      "Epoch 1438/1000000, train_loss: 5.6672, val_loss: 5.1850, time: 0.16s\n",
      "Epoch 1439/1000000, train_loss: 5.6604, val_loss: 5.1809, time: 0.16s\n",
      "Epoch 1440/1000000, train_loss: 5.6489, val_loss: 5.1697, time: 0.16s\n",
      "Epoch 1441/1000000, train_loss: 5.6806, val_loss: 5.1911, time: 0.16s\n",
      "Epoch 1442/1000000, train_loss: 5.6333, val_loss: 5.1697, time: 0.16s\n",
      "Epoch 1443/1000000, train_loss: 5.6216, val_loss: 5.1799, time: 0.16s\n",
      "Epoch 1444/1000000, train_loss: 5.6322, val_loss: 5.1683, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1445/1000000, train_loss: 5.6404, val_loss: 5.1543, time: 0.16s\n",
      "Epoch 1446/1000000, train_loss: 5.6437, val_loss: 5.1607, time: 0.16s\n",
      "Epoch 1447/1000000, train_loss: 5.6205, val_loss: 5.1645, time: 0.16s\n",
      "Epoch 1448/1000000, train_loss: 5.6324, val_loss: 5.1578, time: 0.16s\n",
      "Epoch 1449/1000000, train_loss: 5.6378, val_loss: 5.1692, time: 0.16s\n",
      "Epoch 1450/1000000, train_loss: 5.6278, val_loss: 5.1564, time: 0.16s\n",
      "Epoch 1451/1000000, train_loss: 5.6272, val_loss: 5.1753, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1452/1000000, train_loss: 5.6293, val_loss: 5.1528, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1453/1000000, train_loss: 5.6278, val_loss: 5.1506, time: 0.16s\n",
      "Epoch 1454/1000000, train_loss: 5.6121, val_loss: 5.1533, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1455/1000000, train_loss: 5.6031, val_loss: 5.1370, time: 0.16s\n",
      "Epoch 1456/1000000, train_loss: 5.6122, val_loss: 5.1512, time: 0.16s\n",
      "Epoch 1457/1000000, train_loss: 5.6409, val_loss: 5.1446, time: 0.16s\n",
      "Epoch 1458/1000000, train_loss: 5.6383, val_loss: 5.1497, time: 0.16s\n",
      "Epoch 1459/1000000, train_loss: 5.6006, val_loss: 5.1498, time: 0.17s\n",
      "Epoch 1460/1000000, train_loss: 5.6028, val_loss: 5.1431, time: 0.16s\n",
      "Epoch 1461/1000000, train_loss: 5.5959, val_loss: 5.1488, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1462/1000000, train_loss: 5.6014, val_loss: 5.1274, time: 0.16s\n",
      "Epoch 1463/1000000, train_loss: 5.6132, val_loss: 5.1454, time: 0.16s\n",
      "Epoch 1464/1000000, train_loss: 5.5917, val_loss: 5.1367, time: 0.16s\n",
      "Epoch 1465/1000000, train_loss: 5.6266, val_loss: 5.1312, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1466/1000000, train_loss: 5.6014, val_loss: 5.1191, time: 0.16s\n",
      "Epoch 1467/1000000, train_loss: 5.6199, val_loss: 5.1491, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1468/1000000, train_loss: 5.5789, val_loss: 5.1023, time: 0.16s\n",
      "Epoch 1469/1000000, train_loss: 5.5756, val_loss: 5.1165, time: 0.16s\n",
      "Epoch 1470/1000000, train_loss: 5.5920, val_loss: 5.1182, time: 0.15s\n",
      "Epoch 1471/1000000, train_loss: 5.6042, val_loss: 5.1050, time: 0.15s\n",
      "Epoch 1472/1000000, train_loss: 5.6010, val_loss: 5.1281, time: 0.15s\n",
      "Epoch 1473/1000000, train_loss: 5.6254, val_loss: 5.1117, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1474/1000000, train_loss: 5.5842, val_loss: 5.0827, time: 0.15s\n",
      "Epoch 1475/1000000, train_loss: 5.5752, val_loss: 5.1184, time: 0.16s\n",
      "Epoch 1476/1000000, train_loss: 5.5749, val_loss: 5.1071, time: 0.16s\n",
      "Epoch 1477/1000000, train_loss: 5.5794, val_loss: 5.0968, time: 0.16s\n",
      "Epoch 1478/1000000, train_loss: 5.5753, val_loss: 5.1113, time: 0.16s\n",
      "Epoch 1479/1000000, train_loss: 5.5655, val_loss: 5.1057, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1480/1000000, train_loss: 5.5820, val_loss: 5.0817, time: 0.16s\n",
      "Epoch 1481/1000000, train_loss: 5.5741, val_loss: 5.0952, time: 0.16s\n",
      "Epoch 1482/1000000, train_loss: 5.5955, val_loss: 5.0823, time: 0.16s\n",
      "Epoch 1483/1000000, train_loss: 5.5776, val_loss: 5.0966, time: 0.16s\n",
      "Epoch 1484/1000000, train_loss: 5.5776, val_loss: 5.0880, time: 0.15s\n",
      "Epoch 1485/1000000, train_loss: 5.5808, val_loss: 5.0993, time: 0.15s\n",
      "Epoch 1486/1000000, train_loss: 5.5338, val_loss: 5.0817, time: 0.15s\n",
      "Epoch 1487/1000000, train_loss: 5.5635, val_loss: 5.0834, time: 0.15s\n",
      "Epoch 1488/1000000, train_loss: 5.5744, val_loss: 5.0889, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1489/1000000, train_loss: 5.5706, val_loss: 5.0728, time: 0.15s\n",
      "Epoch 1490/1000000, train_loss: 5.5578, val_loss: 5.0885, time: 0.15s\n",
      "Epoch 1491/1000000, train_loss: 5.5392, val_loss: 5.0869, time: 0.15s\n",
      "Epoch 1492/1000000, train_loss: 5.5361, val_loss: 5.0733, time: 0.15s\n",
      "Epoch 1493/1000000, train_loss: 5.5582, val_loss: 5.0878, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1494/1000000, train_loss: 5.5555, val_loss: 5.0594, time: 0.16s\n",
      "Epoch 1495/1000000, train_loss: 5.5637, val_loss: 5.0683, time: 0.16s\n",
      "Epoch 1496/1000000, train_loss: 5.5518, val_loss: 5.0686, time: 0.16s\n",
      "Epoch 1497/1000000, train_loss: 5.5432, val_loss: 5.0616, time: 0.15s\n",
      "Epoch 1498/1000000, train_loss: 5.5378, val_loss: 5.0606, time: 0.15s\n",
      "Epoch 1499/1000000, train_loss: 5.5616, val_loss: 5.0609, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1500/1000000, train_loss: 5.5363, val_loss: 5.0578, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1501/1000000, train_loss: 5.5304, val_loss: 5.0508, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1502/1000000, train_loss: 5.5283, val_loss: 5.0375, time: 0.16s\n",
      "Epoch 1503/1000000, train_loss: 5.5137, val_loss: 5.0501, time: 0.15s\n",
      "Epoch 1504/1000000, train_loss: 5.5156, val_loss: 5.0574, time: 0.15s\n",
      "Epoch 1505/1000000, train_loss: 5.5184, val_loss: 5.0637, time: 0.23s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1506/1000000, train_loss: 5.5058, val_loss: 5.0373, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1507/1000000, train_loss: 5.5149, val_loss: 5.0353, time: 0.16s\n",
      "Epoch 1508/1000000, train_loss: 5.5032, val_loss: 5.0524, time: 0.15s\n",
      "Epoch 1509/1000000, train_loss: 5.5255, val_loss: 5.0568, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1510/1000000, train_loss: 5.5184, val_loss: 5.0329, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1511/1000000, train_loss: 5.5021, val_loss: 5.0322, time: 0.16s\n",
      "Epoch 1512/1000000, train_loss: 5.4981, val_loss: 5.0418, time: 0.16s\n",
      "Epoch 1513/1000000, train_loss: 5.5390, val_loss: 5.0525, time: 0.15s\n",
      "Epoch 1514/1000000, train_loss: 5.5049, val_loss: 5.0454, time: 0.15s\n",
      "Epoch 1515/1000000, train_loss: 5.5178, val_loss: 5.0373, time: 0.15s\n",
      "Epoch 1516/1000000, train_loss: 5.5273, val_loss: 5.0471, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1517/1000000, train_loss: 5.5002, val_loss: 5.0204, time: 0.16s\n",
      "Epoch 1518/1000000, train_loss: 5.4877, val_loss: 5.0265, time: 0.16s\n",
      "Epoch 1519/1000000, train_loss: 5.5133, val_loss: 5.0282, time: 0.15s\n",
      "Epoch 1520/1000000, train_loss: 5.4881, val_loss: 5.0369, time: 0.16s\n",
      "Epoch 1521/1000000, train_loss: 5.5013, val_loss: 5.0219, time: 0.16s\n",
      "Epoch 1522/1000000, train_loss: 5.4963, val_loss: 5.0244, time: 0.15s\n",
      "Epoch 1523/1000000, train_loss: 5.4828, val_loss: 5.0254, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1524/1000000, train_loss: 5.4834, val_loss: 5.0101, time: 0.16s\n",
      "Epoch 1525/1000000, train_loss: 5.4900, val_loss: 5.0143, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1526/1000000, train_loss: 5.4894, val_loss: 5.0087, time: 0.16s\n",
      "Epoch 1527/1000000, train_loss: 5.5037, val_loss: 5.0357, time: 0.16s\n",
      "Epoch 1528/1000000, train_loss: 5.4845, val_loss: 5.0114, time: 0.15s\n",
      "Epoch 1529/1000000, train_loss: 5.4805, val_loss: 5.0158, time: 0.17s\n",
      "Epoch 1530/1000000, train_loss: 5.4824, val_loss: 5.0089, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1531/1000000, train_loss: 5.4745, val_loss: 4.9916, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1532/1000000, train_loss: 5.4655, val_loss: 4.9902, time: 0.16s\n",
      "Epoch 1533/1000000, train_loss: 5.4742, val_loss: 5.0353, time: 0.16s\n",
      "Epoch 1534/1000000, train_loss: 5.4884, val_loss: 4.9956, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1535/1000000, train_loss: 5.4842, val_loss: 4.9722, time: 0.16s\n",
      "Epoch 1536/1000000, train_loss: 5.4526, val_loss: 4.9960, time: 0.16s\n",
      "Epoch 1537/1000000, train_loss: 5.4512, val_loss: 5.0027, time: 0.16s\n",
      "Epoch 1538/1000000, train_loss: 5.4623, val_loss: 4.9862, time: 0.15s\n",
      "Epoch 1539/1000000, train_loss: 5.4713, val_loss: 5.0050, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1540/1000000, train_loss: 5.4801, val_loss: 4.9650, time: 0.16s\n",
      "Epoch 1541/1000000, train_loss: 5.4508, val_loss: 4.9834, time: 0.15s\n",
      "Epoch 1542/1000000, train_loss: 5.4692, val_loss: 4.9874, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1543/1000000, train_loss: 5.4464, val_loss: 4.9630, time: 0.15s\n",
      "Epoch 1544/1000000, train_loss: 5.4452, val_loss: 4.9759, time: 0.16s\n",
      "Epoch 1545/1000000, train_loss: 5.4334, val_loss: 4.9842, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1546/1000000, train_loss: 5.4417, val_loss: 4.9572, time: 0.16s\n",
      "Epoch 1547/1000000, train_loss: 5.4380, val_loss: 4.9837, time: 0.15s\n",
      "Epoch 1548/1000000, train_loss: 5.4559, val_loss: 4.9712, time: 0.15s\n",
      "Epoch 1549/1000000, train_loss: 5.4477, val_loss: 4.9663, time: 0.16s\n",
      "Epoch 1550/1000000, train_loss: 5.4309, val_loss: 4.9663, time: 0.16s\n",
      "Epoch 1551/1000000, train_loss: 5.4324, val_loss: 4.9736, time: 0.16s\n",
      "Epoch 1552/1000000, train_loss: 5.4531, val_loss: 4.9601, time: 0.16s\n",
      "Epoch 1553/1000000, train_loss: 5.4304, val_loss: 4.9669, time: 0.17s\n",
      "Epoch 1554/1000000, train_loss: 5.4246, val_loss: 4.9658, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1555/1000000, train_loss: 5.4510, val_loss: 4.9358, time: 0.16s\n",
      "Epoch 1556/1000000, train_loss: 5.4186, val_loss: 4.9415, time: 0.16s\n",
      "Epoch 1557/1000000, train_loss: 5.4107, val_loss: 4.9495, time: 0.16s\n",
      "Epoch 1558/1000000, train_loss: 5.4061, val_loss: 4.9557, time: 0.16s\n",
      "Epoch 1559/1000000, train_loss: 5.4237, val_loss: 4.9626, time: 0.16s\n",
      "Epoch 1560/1000000, train_loss: 5.4239, val_loss: 4.9425, time: 0.16s\n",
      "Epoch 1561/1000000, train_loss: 5.4329, val_loss: 4.9492, time: 0.16s\n",
      "Epoch 1562/1000000, train_loss: 5.4166, val_loss: 4.9458, time: 0.16s\n",
      "Epoch 1563/1000000, train_loss: 5.4175, val_loss: 4.9453, time: 0.16s\n",
      "Epoch 1564/1000000, train_loss: 5.3845, val_loss: 4.9512, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1565/1000000, train_loss: 5.4267, val_loss: 4.9282, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1566/1000000, train_loss: 5.4285, val_loss: 4.9274, time: 0.16s\n",
      "Epoch 1567/1000000, train_loss: 5.3966, val_loss: 4.9374, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1568/1000000, train_loss: 5.4304, val_loss: 4.9265, time: 0.16s\n",
      "Epoch 1569/1000000, train_loss: 5.4105, val_loss: 4.9505, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1570/1000000, train_loss: 5.3948, val_loss: 4.9220, time: 0.16s\n",
      "Epoch 1571/1000000, train_loss: 5.4050, val_loss: 4.9307, time: 0.16s\n",
      "Epoch 1572/1000000, train_loss: 5.3881, val_loss: 4.9291, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1573/1000000, train_loss: 5.4035, val_loss: 4.9210, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1574/1000000, train_loss: 5.3869, val_loss: 4.9080, time: 0.15s\n",
      "Epoch 1575/1000000, train_loss: 5.4109, val_loss: 4.9211, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1576/1000000, train_loss: 5.4103, val_loss: 4.8905, time: 0.16s\n",
      "Epoch 1577/1000000, train_loss: 5.3837, val_loss: 4.9202, time: 0.16s\n",
      "Epoch 1578/1000000, train_loss: 5.4214, val_loss: 4.9023, time: 0.16s\n",
      "Epoch 1579/1000000, train_loss: 5.3969, val_loss: 4.9064, time: 0.16s\n",
      "Epoch 1580/1000000, train_loss: 5.4138, val_loss: 4.9199, time: 0.16s\n",
      "Epoch 1581/1000000, train_loss: 5.3825, val_loss: 4.9153, time: 0.16s\n",
      "Epoch 1582/1000000, train_loss: 5.3600, val_loss: 4.8992, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1583/1000000, train_loss: 5.3538, val_loss: 4.8905, time: 0.16s\n",
      "Epoch 1584/1000000, train_loss: 5.3582, val_loss: 4.8973, time: 0.16s\n",
      "Epoch 1585/1000000, train_loss: 5.3772, val_loss: 4.9113, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1586/1000000, train_loss: 5.3669, val_loss: 4.8895, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1587/1000000, train_loss: 5.3788, val_loss: 4.8888, time: 0.16s\n",
      "Epoch 1588/1000000, train_loss: 5.3722, val_loss: 4.9263, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1589/1000000, train_loss: 5.3660, val_loss: 4.8873, time: 0.15s\n",
      "Epoch 1590/1000000, train_loss: 5.3468, val_loss: 4.8981, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1591/1000000, train_loss: 5.3626, val_loss: 4.8678, time: 0.16s\n",
      "Epoch 1592/1000000, train_loss: 5.3464, val_loss: 4.8685, time: 0.15s\n",
      "Epoch 1593/1000000, train_loss: 5.3642, val_loss: 4.8968, time: 0.16s\n",
      "Epoch 1594/1000000, train_loss: 5.3576, val_loss: 4.8766, time: 0.16s\n",
      "Epoch 1595/1000000, train_loss: 5.3473, val_loss: 4.8891, time: 0.18s\n",
      "Epoch 1596/1000000, train_loss: 5.3573, val_loss: 4.8718, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1597/1000000, train_loss: 5.3496, val_loss: 4.8450, time: 0.25s\n",
      "Epoch 1598/1000000, train_loss: 5.3425, val_loss: 4.8617, time: 0.16s\n",
      "Epoch 1599/1000000, train_loss: 5.3686, val_loss: 4.8628, time: 0.15s\n",
      "Epoch 1600/1000000, train_loss: 5.3485, val_loss: 4.8659, time: 0.15s\n",
      "Epoch 1601/1000000, train_loss: 5.3311, val_loss: 4.8780, time: 0.15s\n",
      "Epoch 1602/1000000, train_loss: 5.3480, val_loss: 4.8906, time: 0.16s\n",
      "Epoch 1603/1000000, train_loss: 5.3255, val_loss: 4.8894, time: 0.16s\n",
      "Epoch 1604/1000000, train_loss: 5.3511, val_loss: 4.8611, time: 0.15s\n",
      "Epoch 1605/1000000, train_loss: 5.3359, val_loss: 4.8910, time: 0.16s\n",
      "Epoch 1606/1000000, train_loss: 5.3414, val_loss: 4.8705, time: 0.16s\n",
      "Epoch 1607/1000000, train_loss: 5.3279, val_loss: 4.8501, time: 0.16s\n",
      "Epoch 1608/1000000, train_loss: 5.3421, val_loss: 4.8685, time: 0.15s\n",
      "Epoch 1609/1000000, train_loss: 5.3206, val_loss: 4.8961, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1610/1000000, train_loss: 5.3433, val_loss: 4.8377, time: 0.16s\n",
      "Epoch 1611/1000000, train_loss: 5.3446, val_loss: 4.8916, time: 0.16s\n",
      "Epoch 1612/1000000, train_loss: 5.3409, val_loss: 4.8441, time: 0.15s\n",
      "Epoch 1613/1000000, train_loss: 5.3213, val_loss: 4.8384, time: 0.16s\n",
      "Epoch 1614/1000000, train_loss: 5.3341, val_loss: 4.8749, time: 0.16s\n",
      "Epoch 1615/1000000, train_loss: 5.3199, val_loss: 4.8716, time: 0.16s\n",
      "Epoch 1616/1000000, train_loss: 5.3091, val_loss: 4.8673, time: 0.15s\n",
      "Epoch 1617/1000000, train_loss: 5.3091, val_loss: 4.8560, time: 0.17s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1618/1000000, train_loss: 5.2943, val_loss: 4.8370, time: 0.16s\n",
      "Epoch 1619/1000000, train_loss: 5.3086, val_loss: 4.8371, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1620/1000000, train_loss: 5.3095, val_loss: 4.8179, time: 0.16s\n",
      "Epoch 1621/1000000, train_loss: 5.3089, val_loss: 4.8380, time: 0.16s\n",
      "Epoch 1622/1000000, train_loss: 5.3148, val_loss: 4.8459, time: 0.16s\n",
      "Epoch 1623/1000000, train_loss: 5.2909, val_loss: 4.8513, time: 0.15s\n",
      "Epoch 1624/1000000, train_loss: 5.3053, val_loss: 4.8403, time: 0.15s\n",
      "Epoch 1625/1000000, train_loss: 5.2976, val_loss: 4.8294, time: 0.15s\n",
      "Epoch 1626/1000000, train_loss: 5.3077, val_loss: 4.8203, time: 0.16s\n",
      "Epoch 1627/1000000, train_loss: 5.3210, val_loss: 4.8426, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1628/1000000, train_loss: 5.2980, val_loss: 4.8087, time: 0.16s\n",
      "Epoch 1629/1000000, train_loss: 5.2832, val_loss: 4.8177, time: 0.16s\n",
      "Epoch 1630/1000000, train_loss: 5.2984, val_loss: 4.8257, time: 0.15s\n",
      "Epoch 1631/1000000, train_loss: 5.2962, val_loss: 4.8359, time: 0.16s\n",
      "Epoch 1632/1000000, train_loss: 5.2906, val_loss: 4.8268, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1633/1000000, train_loss: 5.2883, val_loss: 4.8070, time: 0.16s\n",
      "Epoch 1634/1000000, train_loss: 5.2499, val_loss: 4.8256, time: 0.16s\n",
      "Epoch 1635/1000000, train_loss: 5.2726, val_loss: 4.8326, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1636/1000000, train_loss: 5.2980, val_loss: 4.7917, time: 0.16s\n",
      "Epoch 1637/1000000, train_loss: 5.2636, val_loss: 4.8026, time: 0.16s\n",
      "Epoch 1638/1000000, train_loss: 5.3042, val_loss: 4.7985, time: 0.16s\n",
      "Epoch 1639/1000000, train_loss: 5.2528, val_loss: 4.8081, time: 0.17s\n",
      "Epoch 1640/1000000, train_loss: 5.2764, val_loss: 4.8059, time: 0.16s\n",
      "Epoch 1641/1000000, train_loss: 5.2841, val_loss: 4.8074, time: 0.16s\n",
      "Epoch 1642/1000000, train_loss: 5.2881, val_loss: 4.8315, time: 0.16s\n",
      "Epoch 1643/1000000, train_loss: 5.2795, val_loss: 4.7990, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1644/1000000, train_loss: 5.2735, val_loss: 4.7738, time: 0.16s\n",
      "Epoch 1645/1000000, train_loss: 5.2700, val_loss: 4.7974, time: 0.16s\n",
      "Epoch 1646/1000000, train_loss: 5.2811, val_loss: 4.7867, time: 0.16s\n",
      "Epoch 1647/1000000, train_loss: 5.2585, val_loss: 4.7941, time: 0.16s\n",
      "Epoch 1648/1000000, train_loss: 5.2562, val_loss: 4.7968, time: 0.16s\n",
      "Epoch 1649/1000000, train_loss: 5.2759, val_loss: 4.7743, time: 0.16s\n",
      "Epoch 1650/1000000, train_loss: 5.2714, val_loss: 4.7786, time: 0.16s\n",
      "Epoch 1651/1000000, train_loss: 5.2697, val_loss: 4.7851, time: 0.16s\n",
      "Epoch 1652/1000000, train_loss: 5.2517, val_loss: 4.8085, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1653/1000000, train_loss: 5.2413, val_loss: 4.7688, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1654/1000000, train_loss: 5.2582, val_loss: 4.7626, time: 0.15s\n",
      "Epoch 1655/1000000, train_loss: 5.2497, val_loss: 4.7635, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1656/1000000, train_loss: 5.2644, val_loss: 4.7476, time: 0.15s\n",
      "Epoch 1657/1000000, train_loss: 5.2363, val_loss: 4.7649, time: 0.15s\n",
      "Epoch 1658/1000000, train_loss: 5.2239, val_loss: 4.7701, time: 0.16s\n",
      "Epoch 1659/1000000, train_loss: 5.2563, val_loss: 4.7915, time: 0.16s\n",
      "Epoch 1660/1000000, train_loss: 5.2463, val_loss: 4.7756, time: 0.15s\n",
      "Epoch 1661/1000000, train_loss: 5.2366, val_loss: 4.8080, time: 0.17s\n",
      "Epoch 1662/1000000, train_loss: 5.2245, val_loss: 4.7610, time: 0.18s\n",
      "Epoch 1663/1000000, train_loss: 5.2565, val_loss: 4.7866, time: 0.16s\n",
      "Epoch 1664/1000000, train_loss: 5.2499, val_loss: 4.7724, time: 0.16s\n",
      "Epoch 1665/1000000, train_loss: 5.2120, val_loss: 4.7545, time: 0.16s\n",
      "Epoch 1666/1000000, train_loss: 5.2094, val_loss: 4.7807, time: 0.16s\n",
      "Epoch 1667/1000000, train_loss: 5.2354, val_loss: 4.7614, time: 0.15s\n",
      "Epoch 1668/1000000, train_loss: 5.2675, val_loss: 4.7583, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1669/1000000, train_loss: 5.2278, val_loss: 4.7410, time: 0.16s\n",
      "Epoch 1670/1000000, train_loss: 5.2325, val_loss: 4.7642, time: 0.15s\n",
      "Epoch 1671/1000000, train_loss: 5.2199, val_loss: 4.7791, time: 0.15s\n",
      "Epoch 1672/1000000, train_loss: 5.2019, val_loss: 4.7704, time: 0.16s\n",
      "Epoch 1673/1000000, train_loss: 5.1955, val_loss: 4.7696, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1674/1000000, train_loss: 5.2196, val_loss: 4.7380, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1675/1000000, train_loss: 5.1968, val_loss: 4.7345, time: 0.16s\n",
      "Epoch 1676/1000000, train_loss: 5.1931, val_loss: 4.7521, time: 0.15s\n",
      "Epoch 1677/1000000, train_loss: 5.2259, val_loss: 4.7707, time: 0.15s\n",
      "Epoch 1678/1000000, train_loss: 5.2167, val_loss: 4.7623, time: 0.16s\n",
      "Epoch 1679/1000000, train_loss: 5.1918, val_loss: 4.7614, time: 0.15s\n",
      "Epoch 1680/1000000, train_loss: 5.1859, val_loss: 4.7519, time: 0.15s\n",
      "Epoch 1681/1000000, train_loss: 5.2027, val_loss: 4.7388, time: 0.17s\n",
      "Epoch 1682/1000000, train_loss: 5.1936, val_loss: 4.7524, time: 0.16s\n",
      "Epoch 1683/1000000, train_loss: 5.1711, val_loss: 4.7512, time: 0.15s\n",
      "Epoch 1684/1000000, train_loss: 5.2218, val_loss: 4.7434, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1685/1000000, train_loss: 5.1940, val_loss: 4.7269, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1686/1000000, train_loss: 5.2077, val_loss: 4.7198, time: 0.15s\n",
      "Epoch 1687/1000000, train_loss: 5.1963, val_loss: 4.7553, time: 0.16s\n",
      "Epoch 1688/1000000, train_loss: 5.1791, val_loss: 4.7259, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1689/1000000, train_loss: 5.1877, val_loss: 4.7012, time: 0.15s\n",
      "Epoch 1690/1000000, train_loss: 5.2010, val_loss: 4.7254, time: 0.15s\n",
      "Epoch 1691/1000000, train_loss: 5.1949, val_loss: 4.7228, time: 0.15s\n",
      "Epoch 1692/1000000, train_loss: 5.1993, val_loss: 4.7191, time: 0.15s\n",
      "Epoch 1693/1000000, train_loss: 5.1721, val_loss: 4.7168, time: 0.23s\n",
      "Epoch 1694/1000000, train_loss: 5.1936, val_loss: 4.7328, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1695/1000000, train_loss: 5.1942, val_loss: 4.6828, time: 0.16s\n",
      "Epoch 1696/1000000, train_loss: 5.1654, val_loss: 4.7231, time: 0.16s\n",
      "Epoch 1697/1000000, train_loss: 5.1784, val_loss: 4.7197, time: 0.16s\n",
      "Epoch 1698/1000000, train_loss: 5.1781, val_loss: 4.7066, time: 0.16s\n",
      "Epoch 1699/1000000, train_loss: 5.1449, val_loss: 4.7188, time: 0.15s\n",
      "Epoch 1700/1000000, train_loss: 5.1529, val_loss: 4.7114, time: 0.15s\n",
      "Epoch 1701/1000000, train_loss: 5.1816, val_loss: 4.7129, time: 0.17s\n",
      "Epoch 1702/1000000, train_loss: 5.1550, val_loss: 4.6877, time: 0.16s\n",
      "Epoch 1703/1000000, train_loss: 5.1521, val_loss: 4.7106, time: 0.15s\n",
      "Epoch 1704/1000000, train_loss: 5.1886, val_loss: 4.7097, time: 0.16s\n",
      "Epoch 1705/1000000, train_loss: 5.1667, val_loss: 4.7252, time: 0.15s\n",
      "Epoch 1706/1000000, train_loss: 5.1634, val_loss: 4.7168, time: 0.15s\n",
      "Epoch 1707/1000000, train_loss: 5.1571, val_loss: 4.6989, time: 0.15s\n",
      "Epoch 1708/1000000, train_loss: 5.1616, val_loss: 4.6881, time: 0.15s\n",
      "Epoch 1709/1000000, train_loss: 5.1569, val_loss: 4.7084, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1710/1000000, train_loss: 5.1726, val_loss: 4.6759, time: 0.16s\n",
      "Epoch 1711/1000000, train_loss: 5.1577, val_loss: 4.7380, time: 0.16s\n",
      "Epoch 1712/1000000, train_loss: 5.1636, val_loss: 4.6980, time: 0.16s\n",
      "Epoch 1713/1000000, train_loss: 5.1698, val_loss: 4.7156, time: 0.16s\n",
      "Epoch 1714/1000000, train_loss: 5.1433, val_loss: 4.6804, time: 0.16s\n",
      "Epoch 1715/1000000, train_loss: 5.1506, val_loss: 4.6796, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1716/1000000, train_loss: 5.1330, val_loss: 4.6707, time: 0.16s\n",
      "Epoch 1717/1000000, train_loss: 5.1757, val_loss: 4.7012, time: 0.16s\n",
      "Epoch 1718/1000000, train_loss: 5.1554, val_loss: 4.6823, time: 0.16s\n",
      "Epoch 1719/1000000, train_loss: 5.1335, val_loss: 4.7044, time: 0.16s\n",
      "Epoch 1720/1000000, train_loss: 5.1279, val_loss: 4.6835, time: 0.16s\n",
      "Epoch 1721/1000000, train_loss: 5.1346, val_loss: 4.6819, time: 0.17s\n",
      "Epoch 1722/1000000, train_loss: 5.1219, val_loss: 4.6934, time: 0.16s\n",
      "Epoch 1723/1000000, train_loss: 5.1434, val_loss: 4.6809, time: 0.16s\n",
      "Epoch 1724/1000000, train_loss: 5.1787, val_loss: 4.6744, time: 0.16s\n",
      "Epoch 1725/1000000, train_loss: 5.1672, val_loss: 4.6989, time: 0.16s\n",
      "Epoch 1726/1000000, train_loss: 5.1541, val_loss: 4.7049, time: 0.16s\n",
      "Epoch 1727/1000000, train_loss: 5.1331, val_loss: 4.6856, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1728/1000000, train_loss: 5.1325, val_loss: 4.6678, time: 0.16s\n",
      "Epoch 1729/1000000, train_loss: 5.1420, val_loss: 4.6834, time: 0.16s\n",
      "Epoch 1730/1000000, train_loss: 5.1068, val_loss: 4.6692, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1731/1000000, train_loss: 5.1275, val_loss: 4.6626, time: 0.16s\n",
      "Epoch 1732/1000000, train_loss: 5.1130, val_loss: 4.6911, time: 0.16s\n",
      "Epoch 1733/1000000, train_loss: 5.1206, val_loss: 4.6852, time: 0.16s\n",
      "Epoch 1734/1000000, train_loss: 5.1424, val_loss: 4.6868, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1735/1000000, train_loss: 5.1441, val_loss: 4.6598, time: 0.15s\n",
      "Epoch 1736/1000000, train_loss: 5.1128, val_loss: 4.6897, time: 0.16s\n",
      "Epoch 1737/1000000, train_loss: 5.1392, val_loss: 4.6948, time: 0.15s\n",
      "Epoch 1738/1000000, train_loss: 5.1596, val_loss: 4.6718, time: 0.16s\n",
      "Epoch 1739/1000000, train_loss: 5.1319, val_loss: 4.6975, time: 0.15s\n",
      "Epoch 1740/1000000, train_loss: 5.1485, val_loss: 4.6953, time: 0.16s\n",
      "Epoch 1741/1000000, train_loss: 5.1098, val_loss: 4.6806, time: 0.16s\n",
      "Epoch 1742/1000000, train_loss: 5.1157, val_loss: 4.6927, time: 0.15s\n",
      "Epoch 1743/1000000, train_loss: 5.1412, val_loss: 4.6666, time: 0.16s\n",
      "Epoch 1744/1000000, train_loss: 5.1378, val_loss: 4.6834, time: 0.17s\n",
      "Epoch 1745/1000000, train_loss: 5.1258, val_loss: 4.6761, time: 0.16s\n",
      "Epoch 1746/1000000, train_loss: 5.1163, val_loss: 4.6725, time: 0.16s\n",
      "Epoch 1747/1000000, train_loss: 5.1289, val_loss: 4.7036, time: 0.16s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1748/1000000, train_loss: 5.0841, val_loss: 4.6566, time: 0.16s\n",
      "Epoch 1749/1000000, train_loss: 5.1228, val_loss: 4.6800, time: 0.16s\n",
      "Epoch 1750/1000000, train_loss: 5.1105, val_loss: 4.6757, time: 0.16s\n",
      "Epoch 1751/1000000, train_loss: 5.1162, val_loss: 4.6968, time: 0.16s\n",
      "Epoch 1752/1000000, train_loss: 5.1135, val_loss: 4.6777, time: 0.15s\n",
      "Epoch 1753/1000000, train_loss: 5.1454, val_loss: 4.6656, time: 0.16s\n",
      "Epoch 1754/1000000, train_loss: 5.1591, val_loss: 4.6851, time: 0.16s\n",
      "Epoch 1755/1000000, train_loss: 5.1108, val_loss: 4.6726, time: 0.15s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1756/1000000, train_loss: 5.0962, val_loss: 4.6492, time: 0.16s\n",
      "Epoch 1757/1000000, train_loss: 5.0794, val_loss: 4.6695, time: 0.15s\n",
      "Epoch 1758/1000000, train_loss: 5.0826, val_loss: 4.6925, time: 0.15s\n",
      "Epoch 1759/1000000, train_loss: 5.1199, val_loss: 4.6982, time: 0.15s\n",
      "Epoch 1760/1000000, train_loss: 5.1191, val_loss: 4.7055, time: 0.15s\n",
      "Epoch 1761/1000000, train_loss: 5.1149, val_loss: 4.6846, time: 0.16s\n",
      "Epoch 1762/1000000, train_loss: 5.1088, val_loss: 4.6971, time: 0.15s\n",
      "Epoch 1763/1000000, train_loss: 5.1262, val_loss: 4.6789, time: 0.15s\n",
      "Epoch 1764/1000000, train_loss: 5.1185, val_loss: 4.6769, time: 0.16s\n",
      "Epoch 1765/1000000, train_loss: 5.1010, val_loss: 4.6785, time: 0.16s\n",
      "Epoch 1766/1000000, train_loss: 5.1112, val_loss: 4.6642, time: 0.17s\n",
      "Epoch 1767/1000000, train_loss: 5.1177, val_loss: 4.6798, time: 0.16s\n",
      "Epoch 1768/1000000, train_loss: 5.0852, val_loss: 4.6606, time: 0.16s\n",
      "Epoch 1769/1000000, train_loss: 5.0777, val_loss: 4.6946, time: 0.16s\n",
      "Epoch 1770/1000000, train_loss: 5.0862, val_loss: 4.6709, time: 0.16s\n",
      "Epoch 1771/1000000, train_loss: 5.0937, val_loss: 4.6666, time: 0.16s\n",
      "Epoch 1772/1000000, train_loss: 5.1101, val_loss: 4.6970, time: 0.16s\n",
      "Epoch 1773/1000000, train_loss: 5.1064, val_loss: 4.6809, time: 0.16s\n",
      "Epoch 1774/1000000, train_loss: 5.1020, val_loss: 4.6562, time: 0.16s\n",
      "Epoch 1775/1000000, train_loss: 5.0863, val_loss: 4.6495, time: 0.15s\n",
      "Early stopping on epoch 1776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'BiLSTM', 'Type': 'multi2multi', 'MAE': 4.806035391489664}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BiLSTM_multi2multi = BiLSTM(input_size=multi2multi_loader.in_variable, hidden_size=hidden_size, output_size=multi2multi_loader.out_variable, ahead=label_size, num_layers=num_layers)\n",
    "BiLSTM_multi2multi_manager = ModelManager(model=BiLSTM_multi2multi, train_loader=multi2multi_loader.train_loader, val_loader=multi2multi_loader.val_loader, lr=learning_rate, patience=patience)\n",
    "BiLSTM_multi2multi_manager.train(num_epochs=num_epochs, save_dir=os.path.join(weight_dir, sub_dir))\n",
    "results.append({\n",
    "    \"Name\": BiLSTM_multi2multi_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": BiLSTM_multi2multi_manager.evaluate(loader=multi2multi_loader.test_loader),\n",
    "})\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1/1000000, train_loss: 63.2115, val_loss: 95.1277, time: 0.48s\n",
      "Epoch 2/1000000, train_loss: 63.1705, val_loss: 95.2383, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 3/1000000, train_loss: 63.1975, val_loss: 95.0263, time: 0.38s\n",
      "Epoch 4/1000000, train_loss: 63.1768, val_loss: 95.1357, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 5/1000000, train_loss: 63.1657, val_loss: 94.9034, time: 0.38s\n",
      "Epoch 6/1000000, train_loss: 63.1810, val_loss: 95.1116, time: 0.38s\n",
      "Epoch 7/1000000, train_loss: 63.1545, val_loss: 95.1430, time: 0.38s\n",
      "Epoch 8/1000000, train_loss: 63.1553, val_loss: 95.1340, time: 0.38s\n",
      "Epoch 9/1000000, train_loss: 63.1617, val_loss: 95.0761, time: 0.38s\n",
      "Epoch 10/1000000, train_loss: 63.1216, val_loss: 95.1403, time: 0.38s\n",
      "Epoch 11/1000000, train_loss: 63.1220, val_loss: 95.0321, time: 0.38s\n",
      "Epoch 12/1000000, train_loss: 63.1126, val_loss: 94.9038, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 13/1000000, train_loss: 63.1113, val_loss: 94.8864, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 14/1000000, train_loss: 63.0931, val_loss: 94.7713, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 15/1000000, train_loss: 63.0770, val_loss: 94.6956, time: 0.38s\n",
      "Epoch 16/1000000, train_loss: 63.0450, val_loss: 94.9210, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 17/1000000, train_loss: 63.0269, val_loss: 94.6869, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 18/1000000, train_loss: 62.9863, val_loss: 94.6258, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 19/1000000, train_loss: 62.9653, val_loss: 94.3033, time: 0.38s\n",
      "Epoch 20/1000000, train_loss: 62.9332, val_loss: 94.4284, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 21/1000000, train_loss: 62.8928, val_loss: 94.2451, time: 0.38s\n",
      "Epoch 22/1000000, train_loss: 62.8395, val_loss: 94.2977, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 23/1000000, train_loss: 62.7974, val_loss: 94.1588, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 24/1000000, train_loss: 62.7868, val_loss: 94.0505, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 25/1000000, train_loss: 62.6958, val_loss: 94.0472, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 26/1000000, train_loss: 62.6552, val_loss: 93.8369, time: 0.41s\n",
      "Epoch 27/1000000, train_loss: 62.6382, val_loss: 93.8641, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 28/1000000, train_loss: 62.5894, val_loss: 93.6876, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 29/1000000, train_loss: 62.5213, val_loss: 93.5477, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 30/1000000, train_loss: 62.5242, val_loss: 93.3515, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 31/1000000, train_loss: 62.4809, val_loss: 93.3150, time: 0.38s\n",
      "Epoch 32/1000000, train_loss: 62.4428, val_loss: 93.3925, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 33/1000000, train_loss: 62.4048, val_loss: 93.2840, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 34/1000000, train_loss: 62.3734, val_loss: 93.1888, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 35/1000000, train_loss: 62.3242, val_loss: 92.9897, time: 0.40s\n",
      "Epoch 36/1000000, train_loss: 62.2706, val_loss: 93.0481, time: 0.43s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 37/1000000, train_loss: 62.2478, val_loss: 92.9178, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 38/1000000, train_loss: 62.2111, val_loss: 92.8116, time: 0.37s\n",
      "Epoch 39/1000000, train_loss: 62.1561, val_loss: 92.8936, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 40/1000000, train_loss: 62.1380, val_loss: 92.5061, time: 0.38s\n",
      "Epoch 41/1000000, train_loss: 62.0744, val_loss: 92.6600, time: 0.38s\n",
      "Epoch 42/1000000, train_loss: 62.0754, val_loss: 92.5579, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 43/1000000, train_loss: 62.0098, val_loss: 92.4500, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 44/1000000, train_loss: 61.9514, val_loss: 92.3457, time: 0.38s\n",
      "Epoch 45/1000000, train_loss: 61.9510, val_loss: 92.5705, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 46/1000000, train_loss: 61.8893, val_loss: 92.2681, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 47/1000000, train_loss: 61.8975, val_loss: 92.1558, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 48/1000000, train_loss: 61.8680, val_loss: 91.9120, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 49/1000000, train_loss: 61.8226, val_loss: 91.9039, time: 0.38s\n",
      "Epoch 50/1000000, train_loss: 61.7771, val_loss: 91.9785, time: 0.38s\n",
      "Epoch 51/1000000, train_loss: 61.7390, val_loss: 91.9731, time: 0.38s\n",
      "Epoch 52/1000000, train_loss: 61.7107, val_loss: 91.9380, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 53/1000000, train_loss: 61.6999, val_loss: 91.8648, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 54/1000000, train_loss: 61.6715, val_loss: 91.5924, time: 0.37s\n",
      "Epoch 55/1000000, train_loss: 61.6287, val_loss: 91.6827, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 56/1000000, train_loss: 61.5944, val_loss: 91.5670, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 57/1000000, train_loss: 61.5536, val_loss: 91.4198, time: 0.38s\n",
      "Epoch 58/1000000, train_loss: 61.5583, val_loss: 91.4993, time: 0.38s\n",
      "Epoch 59/1000000, train_loss: 61.4693, val_loss: 91.4254, time: 0.37s\n",
      "Epoch 60/1000000, train_loss: 61.4728, val_loss: 91.4460, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 61/1000000, train_loss: 61.4438, val_loss: 91.2750, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 62/1000000, train_loss: 61.4348, val_loss: 91.2307, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 63/1000000, train_loss: 61.3693, val_loss: 91.0850, time: 0.37s\n",
      "Epoch 64/1000000, train_loss: 61.3449, val_loss: 91.1056, time: 0.37s\n",
      "Epoch 65/1000000, train_loss: 61.3017, val_loss: 91.1356, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 66/1000000, train_loss: 61.2860, val_loss: 90.9998, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 67/1000000, train_loss: 61.2469, val_loss: 90.7659, time: 0.37s\n",
      "Epoch 68/1000000, train_loss: 61.2013, val_loss: 90.8395, time: 0.37s\n",
      "Epoch 69/1000000, train_loss: 61.1902, val_loss: 90.7869, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 70/1000000, train_loss: 61.1631, val_loss: 90.5695, time: 0.42s\n",
      "Epoch 71/1000000, train_loss: 61.1383, val_loss: 90.5773, time: 0.37s\n",
      "Epoch 72/1000000, train_loss: 61.0928, val_loss: 90.6319, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 73/1000000, train_loss: 61.0683, val_loss: 90.4837, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 74/1000000, train_loss: 61.0463, val_loss: 90.4616, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 75/1000000, train_loss: 61.0177, val_loss: 90.4403, time: 0.38s\n",
      "Epoch 76/1000000, train_loss: 60.9673, val_loss: 90.4460, time: 0.37s\n",
      "Epoch 77/1000000, train_loss: 60.9615, val_loss: 90.4839, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 78/1000000, train_loss: 60.9270, val_loss: 90.3723, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 79/1000000, train_loss: 60.8860, val_loss: 90.2976, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 80/1000000, train_loss: 60.8587, val_loss: 90.2561, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 81/1000000, train_loss: 60.8338, val_loss: 90.1154, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 82/1000000, train_loss: 60.8270, val_loss: 90.0450, time: 0.38s\n",
      "Epoch 83/1000000, train_loss: 60.7900, val_loss: 90.1160, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 84/1000000, train_loss: 60.7422, val_loss: 90.0437, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 85/1000000, train_loss: 60.7283, val_loss: 89.8580, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 86/1000000, train_loss: 60.6967, val_loss: 89.8174, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 87/1000000, train_loss: 60.6519, val_loss: 89.7290, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 88/1000000, train_loss: 60.6600, val_loss: 89.7067, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 89/1000000, train_loss: 60.6198, val_loss: 89.5558, time: 0.37s\n",
      "Epoch 90/1000000, train_loss: 60.5920, val_loss: 89.5854, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 91/1000000, train_loss: 60.5496, val_loss: 89.5190, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 92/1000000, train_loss: 60.5659, val_loss: 89.4886, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 93/1000000, train_loss: 60.5227, val_loss: 89.3388, time: 0.37s\n",
      "Epoch 94/1000000, train_loss: 60.4783, val_loss: 89.4378, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 95/1000000, train_loss: 60.4844, val_loss: 89.3203, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 96/1000000, train_loss: 60.4431, val_loss: 89.0993, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 97/1000000, train_loss: 60.4095, val_loss: 89.0380, time: 0.38s\n",
      "Epoch 98/1000000, train_loss: 60.4144, val_loss: 89.2095, time: 0.38s\n",
      "Epoch 99/1000000, train_loss: 60.3715, val_loss: 89.0848, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 100/1000000, train_loss: 60.3114, val_loss: 88.9030, time: 0.37s\n",
      "Epoch 101/1000000, train_loss: 60.3287, val_loss: 88.9059, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 102/1000000, train_loss: 60.2790, val_loss: 88.8440, time: 0.37s\n",
      "Epoch 103/1000000, train_loss: 60.2732, val_loss: 88.9489, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 104/1000000, train_loss: 60.2342, val_loss: 88.7073, time: 0.37s\n",
      "Epoch 105/1000000, train_loss: 60.2290, val_loss: 88.7085, time: 0.37s\n",
      "Epoch 106/1000000, train_loss: 60.1960, val_loss: 88.7126, time: 0.37s\n",
      "Epoch 107/1000000, train_loss: 60.1841, val_loss: 88.8885, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 108/1000000, train_loss: 60.1038, val_loss: 88.6303, time: 0.38s\n",
      "Epoch 109/1000000, train_loss: 60.1412, val_loss: 88.6722, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 110/1000000, train_loss: 60.0851, val_loss: 88.4471, time: 0.37s\n",
      "Epoch 111/1000000, train_loss: 60.0659, val_loss: 88.5757, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 112/1000000, train_loss: 60.0465, val_loss: 88.2566, time: 0.37s\n",
      "Epoch 113/1000000, train_loss: 60.0308, val_loss: 88.3907, time: 0.37s\n",
      "Epoch 114/1000000, train_loss: 59.9804, val_loss: 88.3729, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 115/1000000, train_loss: 59.9484, val_loss: 88.2099, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 116/1000000, train_loss: 59.9633, val_loss: 88.1870, time: 0.38s\n",
      "Epoch 117/1000000, train_loss: 59.8917, val_loss: 88.3306, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 118/1000000, train_loss: 59.9034, val_loss: 87.9574, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 119/1000000, train_loss: 59.8618, val_loss: 87.8876, time: 0.38s\n",
      "Epoch 120/1000000, train_loss: 59.8224, val_loss: 87.9708, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 121/1000000, train_loss: 59.8287, val_loss: 87.8804, time: 0.38s\n",
      "Epoch 122/1000000, train_loss: 59.7929, val_loss: 87.8995, time: 0.37s\n",
      "Epoch 123/1000000, train_loss: 59.7614, val_loss: 87.9395, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 124/1000000, train_loss: 59.7550, val_loss: 87.7180, time: 0.38s\n",
      "Epoch 125/1000000, train_loss: 59.7519, val_loss: 87.7264, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 126/1000000, train_loss: 59.7098, val_loss: 87.5839, time: 0.38s\n",
      "Epoch 127/1000000, train_loss: 59.6780, val_loss: 87.5855, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 128/1000000, train_loss: 59.6663, val_loss: 87.4637, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 129/1000000, train_loss: 59.6100, val_loss: 87.3902, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 130/1000000, train_loss: 59.5969, val_loss: 87.2710, time: 0.38s\n",
      "Epoch 131/1000000, train_loss: 59.5740, val_loss: 87.3556, time: 0.37s\n",
      "Epoch 132/1000000, train_loss: 59.5721, val_loss: 87.3290, time: 0.37s\n",
      "Epoch 133/1000000, train_loss: 59.5484, val_loss: 87.2821, time: 0.37s\n",
      "Epoch 134/1000000, train_loss: 59.5111, val_loss: 87.2985, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 135/1000000, train_loss: 59.4705, val_loss: 87.0669, time: 0.37s\n",
      "Epoch 136/1000000, train_loss: 59.4540, val_loss: 87.1493, time: 0.37s\n",
      "Epoch 137/1000000, train_loss: 59.4038, val_loss: 87.0827, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 138/1000000, train_loss: 59.3940, val_loss: 86.9727, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 139/1000000, train_loss: 59.3967, val_loss: 86.8743, time: 0.37s\n",
      "Epoch 140/1000000, train_loss: 59.3379, val_loss: 86.8914, time: 0.38s\n",
      "Epoch 141/1000000, train_loss: 59.3113, val_loss: 87.0129, time: 0.37s\n",
      "Epoch 142/1000000, train_loss: 59.2772, val_loss: 87.0300, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 143/1000000, train_loss: 59.2655, val_loss: 86.7994, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 144/1000000, train_loss: 59.2623, val_loss: 86.7077, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 145/1000000, train_loss: 59.2334, val_loss: 86.6488, time: 0.37s\n",
      "Epoch 146/1000000, train_loss: 59.1965, val_loss: 86.7865, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 147/1000000, train_loss: 59.1993, val_loss: 86.6297, time: 0.37s\n",
      "Epoch 148/1000000, train_loss: 59.1726, val_loss: 86.6598, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 149/1000000, train_loss: 59.1385, val_loss: 86.5334, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 150/1000000, train_loss: 59.1093, val_loss: 86.5044, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 151/1000000, train_loss: 59.0664, val_loss: 86.4603, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 152/1000000, train_loss: 59.0372, val_loss: 86.3575, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 153/1000000, train_loss: 59.0491, val_loss: 86.2098, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 154/1000000, train_loss: 59.0043, val_loss: 86.1828, time: 0.38s\n",
      "Epoch 155/1000000, train_loss: 58.9938, val_loss: 86.2546, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 156/1000000, train_loss: 58.9614, val_loss: 86.0577, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 157/1000000, train_loss: 58.9277, val_loss: 86.0147, time: 0.38s\n",
      "Epoch 158/1000000, train_loss: 58.9361, val_loss: 86.0358, time: 0.37s\n",
      "Epoch 159/1000000, train_loss: 58.8990, val_loss: 86.0294, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 160/1000000, train_loss: 58.8607, val_loss: 85.8965, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 161/1000000, train_loss: 58.8365, val_loss: 85.8543, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 162/1000000, train_loss: 58.8189, val_loss: 85.8099, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 163/1000000, train_loss: 58.7966, val_loss: 85.7077, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 164/1000000, train_loss: 58.7731, val_loss: 85.6413, time: 0.37s\n",
      "Epoch 165/1000000, train_loss: 58.7381, val_loss: 85.7220, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 166/1000000, train_loss: 58.7165, val_loss: 85.5184, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 167/1000000, train_loss: 58.6921, val_loss: 85.4736, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 168/1000000, train_loss: 58.6682, val_loss: 85.4319, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 169/1000000, train_loss: 58.6430, val_loss: 85.4234, time: 0.37s\n",
      "Epoch 170/1000000, train_loss: 58.6356, val_loss: 85.4949, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 171/1000000, train_loss: 58.6066, val_loss: 85.3286, time: 0.37s\n",
      "Epoch 172/1000000, train_loss: 58.5576, val_loss: 85.4954, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 173/1000000, train_loss: 58.5443, val_loss: 85.2553, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 174/1000000, train_loss: 58.5113, val_loss: 85.2045, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 175/1000000, train_loss: 58.4821, val_loss: 84.9673, time: 0.37s\n",
      "Epoch 176/1000000, train_loss: 58.4816, val_loss: 85.0326, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 177/1000000, train_loss: 58.4447, val_loss: 84.9303, time: 0.37s\n",
      "Epoch 178/1000000, train_loss: 58.4072, val_loss: 85.0507, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 179/1000000, train_loss: 58.3978, val_loss: 84.8934, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 180/1000000, train_loss: 58.3820, val_loss: 84.8550, time: 0.37s\n",
      "Epoch 181/1000000, train_loss: 58.3602, val_loss: 84.8623, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 182/1000000, train_loss: 58.3553, val_loss: 84.8324, time: 0.38s\n",
      "Epoch 183/1000000, train_loss: 58.3124, val_loss: 84.8651, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 184/1000000, train_loss: 58.2944, val_loss: 84.6032, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 185/1000000, train_loss: 58.2415, val_loss: 84.5525, time: 0.37s\n",
      "Epoch 186/1000000, train_loss: 58.2316, val_loss: 84.6225, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 187/1000000, train_loss: 58.2161, val_loss: 84.4494, time: 0.37s\n",
      "Epoch 188/1000000, train_loss: 58.1895, val_loss: 84.5758, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 189/1000000, train_loss: 58.1641, val_loss: 84.3140, time: 0.37s\n",
      "Epoch 190/1000000, train_loss: 58.1154, val_loss: 84.4545, time: 0.41s\n",
      "Epoch 191/1000000, train_loss: 58.1347, val_loss: 84.4781, time: 0.38s\n",
      "Epoch 192/1000000, train_loss: 58.0978, val_loss: 84.3446, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 193/1000000, train_loss: 58.0952, val_loss: 84.3093, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 194/1000000, train_loss: 58.0500, val_loss: 84.2370, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 195/1000000, train_loss: 58.0379, val_loss: 84.1421, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 196/1000000, train_loss: 57.9965, val_loss: 84.0353, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 197/1000000, train_loss: 57.9588, val_loss: 83.9792, time: 0.37s\n",
      "Epoch 198/1000000, train_loss: 57.9723, val_loss: 84.0175, time: 0.37s\n",
      "Epoch 199/1000000, train_loss: 57.9165, val_loss: 84.0928, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 200/1000000, train_loss: 57.8861, val_loss: 83.9607, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 201/1000000, train_loss: 57.8666, val_loss: 83.8396, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 202/1000000, train_loss: 57.8521, val_loss: 83.7400, time: 0.38s\n",
      "Epoch 203/1000000, train_loss: 57.8275, val_loss: 83.7795, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 204/1000000, train_loss: 57.7919, val_loss: 83.6598, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 205/1000000, train_loss: 57.7858, val_loss: 83.6504, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 206/1000000, train_loss: 57.7797, val_loss: 83.5056, time: 0.37s\n",
      "Epoch 207/1000000, train_loss: 57.7488, val_loss: 83.5817, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 208/1000000, train_loss: 57.7133, val_loss: 83.4433, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 209/1000000, train_loss: 57.6759, val_loss: 83.3526, time: 0.37s\n",
      "Epoch 210/1000000, train_loss: 57.6550, val_loss: 83.3766, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 211/1000000, train_loss: 57.6378, val_loss: 83.2573, time: 0.37s\n",
      "Epoch 212/1000000, train_loss: 57.6159, val_loss: 83.3289, time: 0.37s\n",
      "Epoch 213/1000000, train_loss: 57.5875, val_loss: 83.4196, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 214/1000000, train_loss: 57.5857, val_loss: 83.0494, time: 0.37s\n",
      "Epoch 215/1000000, train_loss: 57.5572, val_loss: 83.0543, time: 0.37s\n",
      "Epoch 216/1000000, train_loss: 57.4808, val_loss: 83.1181, time: 0.37s\n",
      "Epoch 217/1000000, train_loss: 57.4826, val_loss: 83.0942, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 218/1000000, train_loss: 57.4648, val_loss: 82.9302, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 219/1000000, train_loss: 57.4565, val_loss: 82.8927, time: 0.37s\n",
      "Epoch 220/1000000, train_loss: 57.4375, val_loss: 82.9037, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 221/1000000, train_loss: 57.4021, val_loss: 82.7987, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 222/1000000, train_loss: 57.3983, val_loss: 82.7284, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 223/1000000, train_loss: 57.3695, val_loss: 82.5700, time: 0.37s\n",
      "Epoch 224/1000000, train_loss: 57.3068, val_loss: 82.6192, time: 0.37s\n",
      "Epoch 225/1000000, train_loss: 57.3125, val_loss: 82.7619, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 226/1000000, train_loss: 57.2787, val_loss: 82.4926, time: 0.37s\n",
      "Epoch 227/1000000, train_loss: 57.2587, val_loss: 82.5597, time: 0.38s\n",
      "Epoch 228/1000000, train_loss: 57.2306, val_loss: 82.5245, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 229/1000000, train_loss: 57.2317, val_loss: 82.4067, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 230/1000000, train_loss: 57.1634, val_loss: 82.3681, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 231/1000000, train_loss: 57.1541, val_loss: 82.2803, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 232/1000000, train_loss: 57.1397, val_loss: 82.2469, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 233/1000000, train_loss: 57.1362, val_loss: 82.2370, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 234/1000000, train_loss: 57.0990, val_loss: 82.0995, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 235/1000000, train_loss: 57.0817, val_loss: 82.0047, time: 0.38s\n",
      "Epoch 236/1000000, train_loss: 57.0299, val_loss: 82.0435, time: 0.38s\n",
      "Epoch 237/1000000, train_loss: 57.0050, val_loss: 82.0261, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 238/1000000, train_loss: 56.9892, val_loss: 81.9755, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 239/1000000, train_loss: 56.9700, val_loss: 81.9122, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 240/1000000, train_loss: 56.9292, val_loss: 81.8612, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 241/1000000, train_loss: 56.9079, val_loss: 81.7595, time: 0.38s\n",
      "Epoch 242/1000000, train_loss: 56.9126, val_loss: 81.7653, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 243/1000000, train_loss: 56.8825, val_loss: 81.6445, time: 0.38s\n",
      "Epoch 244/1000000, train_loss: 56.8493, val_loss: 81.7231, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 245/1000000, train_loss: 56.8342, val_loss: 81.5896, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 246/1000000, train_loss: 56.7913, val_loss: 81.4535, time: 0.38s\n",
      "Epoch 247/1000000, train_loss: 56.7697, val_loss: 81.5146, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 248/1000000, train_loss: 56.7570, val_loss: 81.4433, time: 0.38s\n",
      "Epoch 249/1000000, train_loss: 56.7405, val_loss: 81.5007, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 250/1000000, train_loss: 56.6957, val_loss: 81.3930, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 251/1000000, train_loss: 56.6922, val_loss: 81.2642, time: 0.37s\n",
      "Epoch 252/1000000, train_loss: 56.6606, val_loss: 81.4175, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 253/1000000, train_loss: 56.6346, val_loss: 81.1654, time: 0.38s\n",
      "Epoch 254/1000000, train_loss: 56.6084, val_loss: 81.2025, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 255/1000000, train_loss: 56.5868, val_loss: 81.0316, time: 0.38s\n",
      "Epoch 256/1000000, train_loss: 56.5431, val_loss: 81.0620, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 257/1000000, train_loss: 56.5263, val_loss: 80.9441, time: 0.37s\n",
      "Epoch 258/1000000, train_loss: 56.5044, val_loss: 80.9547, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 259/1000000, train_loss: 56.4882, val_loss: 80.8043, time: 0.38s\n",
      "Epoch 260/1000000, train_loss: 56.4497, val_loss: 80.8278, time: 0.37s\n",
      "Epoch 261/1000000, train_loss: 56.4424, val_loss: 80.8402, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 262/1000000, train_loss: 56.4346, val_loss: 80.7521, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 263/1000000, train_loss: 56.4136, val_loss: 80.6844, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 264/1000000, train_loss: 56.3783, val_loss: 80.6027, time: 0.37s\n",
      "Epoch 265/1000000, train_loss: 56.4185, val_loss: 80.6688, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 266/1000000, train_loss: 56.4023, val_loss: 80.5815, time: 0.37s\n",
      "Epoch 267/1000000, train_loss: 56.3173, val_loss: 80.6110, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 268/1000000, train_loss: 56.2494, val_loss: 80.4435, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 269/1000000, train_loss: 56.2585, val_loss: 80.2628, time: 0.37s\n",
      "Epoch 270/1000000, train_loss: 56.2322, val_loss: 80.3250, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 271/1000000, train_loss: 56.2119, val_loss: 80.1565, time: 0.37s\n",
      "Epoch 272/1000000, train_loss: 56.1973, val_loss: 80.1605, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 273/1000000, train_loss: 56.1571, val_loss: 80.1281, time: 0.37s\n",
      "Epoch 274/1000000, train_loss: 56.1551, val_loss: 80.1513, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 275/1000000, train_loss: 56.1206, val_loss: 80.0629, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 276/1000000, train_loss: 56.0689, val_loss: 79.9825, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 277/1000000, train_loss: 56.0715, val_loss: 79.8850, time: 0.37s\n",
      "Epoch 278/1000000, train_loss: 56.0299, val_loss: 79.9068, time: 0.38s\n",
      "Epoch 279/1000000, train_loss: 56.0212, val_loss: 79.9457, time: 0.37s\n",
      "Epoch 280/1000000, train_loss: 55.9980, val_loss: 79.8895, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 281/1000000, train_loss: 55.9889, val_loss: 79.7182, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 282/1000000, train_loss: 55.9391, val_loss: 79.7146, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 283/1000000, train_loss: 55.9218, val_loss: 79.6967, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 284/1000000, train_loss: 55.9618, val_loss: 79.6890, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 285/1000000, train_loss: 55.9093, val_loss: 79.5564, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 286/1000000, train_loss: 55.8381, val_loss: 79.5318, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 287/1000000, train_loss: 55.8249, val_loss: 79.5097, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 288/1000000, train_loss: 55.8219, val_loss: 79.4053, time: 0.38s\n",
      "Epoch 289/1000000, train_loss: 55.7672, val_loss: 79.4521, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 290/1000000, train_loss: 55.7390, val_loss: 79.3772, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 291/1000000, train_loss: 55.7315, val_loss: 79.2419, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 292/1000000, train_loss: 55.7134, val_loss: 79.2209, time: 0.37s\n",
      "Epoch 293/1000000, train_loss: 55.6754, val_loss: 79.2311, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 294/1000000, train_loss: 55.6705, val_loss: 79.1811, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 295/1000000, train_loss: 55.6503, val_loss: 79.0234, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 296/1000000, train_loss: 55.6004, val_loss: 78.9364, time: 0.38s\n",
      "Epoch 297/1000000, train_loss: 55.5893, val_loss: 79.0272, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 298/1000000, train_loss: 55.5372, val_loss: 78.8825, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 299/1000000, train_loss: 55.5604, val_loss: 78.8334, time: 0.38s\n",
      "Epoch 300/1000000, train_loss: 55.5175, val_loss: 78.8591, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 301/1000000, train_loss: 55.4721, val_loss: 78.7022, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 302/1000000, train_loss: 55.4604, val_loss: 78.5332, time: 0.38s\n",
      "Epoch 303/1000000, train_loss: 55.4583, val_loss: 78.7487, time: 0.38s\n",
      "Epoch 304/1000000, train_loss: 55.4262, val_loss: 78.6152, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 305/1000000, train_loss: 55.3712, val_loss: 78.5055, time: 0.38s\n",
      "Epoch 306/1000000, train_loss: 55.3651, val_loss: 78.5663, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 307/1000000, train_loss: 55.3471, val_loss: 78.4667, time: 0.38s\n",
      "Epoch 308/1000000, train_loss: 55.3108, val_loss: 78.5101, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 309/1000000, train_loss: 55.2934, val_loss: 78.3269, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 310/1000000, train_loss: 55.2860, val_loss: 78.2353, time: 0.41s\n",
      "Epoch 311/1000000, train_loss: 55.2667, val_loss: 78.2710, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 312/1000000, train_loss: 55.2311, val_loss: 78.1581, time: 0.37s\n",
      "Epoch 313/1000000, train_loss: 55.2083, val_loss: 78.1979, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 314/1000000, train_loss: 55.1870, val_loss: 78.1276, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 315/1000000, train_loss: 55.1338, val_loss: 78.0611, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 316/1000000, train_loss: 55.1324, val_loss: 77.9473, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 317/1000000, train_loss: 55.1326, val_loss: 77.9049, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 318/1000000, train_loss: 55.1030, val_loss: 77.8430, time: 0.38s\n",
      "Epoch 319/1000000, train_loss: 55.0725, val_loss: 77.8553, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 320/1000000, train_loss: 55.0506, val_loss: 77.7464, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 321/1000000, train_loss: 55.0259, val_loss: 77.7299, time: 0.37s\n",
      "Epoch 322/1000000, train_loss: 54.9918, val_loss: 77.7596, time: 0.37s\n",
      "Epoch 323/1000000, train_loss: 54.9604, val_loss: 77.7703, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 324/1000000, train_loss: 54.9362, val_loss: 77.6054, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 325/1000000, train_loss: 54.9189, val_loss: 77.5550, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 326/1000000, train_loss: 54.8968, val_loss: 77.5108, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 327/1000000, train_loss: 54.8817, val_loss: 77.4154, time: 0.38s\n",
      "Epoch 328/1000000, train_loss: 54.8392, val_loss: 77.4494, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 329/1000000, train_loss: 54.8398, val_loss: 77.2985, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 330/1000000, train_loss: 54.7862, val_loss: 77.2507, time: 0.37s\n",
      "Epoch 331/1000000, train_loss: 54.7541, val_loss: 77.2906, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 332/1000000, train_loss: 54.7475, val_loss: 77.0508, time: 0.38s\n",
      "Epoch 333/1000000, train_loss: 54.7146, val_loss: 77.2015, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 334/1000000, train_loss: 54.7147, val_loss: 77.0051, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 335/1000000, train_loss: 54.6874, val_loss: 76.9988, time: 0.38s\n",
      "Epoch 336/1000000, train_loss: 54.6717, val_loss: 77.0144, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 337/1000000, train_loss: 54.6363, val_loss: 76.9572, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 338/1000000, train_loss: 54.6123, val_loss: 76.8592, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 339/1000000, train_loss: 54.5886, val_loss: 76.7587, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 340/1000000, train_loss: 54.5584, val_loss: 76.6860, time: 0.38s\n",
      "Epoch 341/1000000, train_loss: 54.5458, val_loss: 76.8227, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 342/1000000, train_loss: 54.5242, val_loss: 76.6435, time: 0.37s\n",
      "Epoch 343/1000000, train_loss: 54.4850, val_loss: 76.6497, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 344/1000000, train_loss: 54.4619, val_loss: 76.5964, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 345/1000000, train_loss: 54.4466, val_loss: 76.4991, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 346/1000000, train_loss: 54.4242, val_loss: 76.4967, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 347/1000000, train_loss: 54.3971, val_loss: 76.3270, time: 0.38s\n",
      "Epoch 348/1000000, train_loss: 54.3766, val_loss: 76.3797, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 349/1000000, train_loss: 54.3400, val_loss: 76.3127, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 350/1000000, train_loss: 54.3248, val_loss: 76.2994, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 351/1000000, train_loss: 54.3026, val_loss: 76.2854, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 352/1000000, train_loss: 54.2708, val_loss: 76.1115, time: 0.38s\n",
      "Epoch 353/1000000, train_loss: 54.2663, val_loss: 76.1369, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 354/1000000, train_loss: 54.2202, val_loss: 76.0740, time: 0.38s\n",
      "Epoch 355/1000000, train_loss: 54.2204, val_loss: 76.1008, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 356/1000000, train_loss: 54.1754, val_loss: 75.9994, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 357/1000000, train_loss: 54.1633, val_loss: 75.8707, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 358/1000000, train_loss: 54.1550, val_loss: 75.7826, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 359/1000000, train_loss: 54.0949, val_loss: 75.7633, time: 0.37s\n",
      "Epoch 360/1000000, train_loss: 54.0792, val_loss: 75.7798, time: 0.37s\n",
      "Epoch 361/1000000, train_loss: 54.0728, val_loss: 75.8142, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 362/1000000, train_loss: 54.0277, val_loss: 75.6051, time: 0.37s\n",
      "Epoch 363/1000000, train_loss: 54.0020, val_loss: 75.7487, time: 0.37s\n",
      "Epoch 364/1000000, train_loss: 53.9951, val_loss: 75.6727, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 365/1000000, train_loss: 53.9625, val_loss: 75.4718, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 366/1000000, train_loss: 53.9242, val_loss: 75.3763, time: 0.37s\n",
      "Epoch 367/1000000, train_loss: 53.9146, val_loss: 75.4254, time: 0.37s\n",
      "Epoch 368/1000000, train_loss: 53.8691, val_loss: 75.4047, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 369/1000000, train_loss: 53.9047, val_loss: 75.3707, time: 0.37s\n",
      "Epoch 370/1000000, train_loss: 53.8887, val_loss: 75.3929, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 371/1000000, train_loss: 53.8175, val_loss: 75.1730, time: 0.42s\n",
      "Epoch 372/1000000, train_loss: 53.7849, val_loss: 75.2347, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 373/1000000, train_loss: 53.7819, val_loss: 75.1089, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 374/1000000, train_loss: 53.7517, val_loss: 75.0567, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 375/1000000, train_loss: 53.7207, val_loss: 75.0462, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 376/1000000, train_loss: 53.6985, val_loss: 74.9600, time: 0.38s\n",
      "Epoch 377/1000000, train_loss: 53.6950, val_loss: 74.9711, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 378/1000000, train_loss: 53.6275, val_loss: 74.8633, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 379/1000000, train_loss: 53.6221, val_loss: 74.8366, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 380/1000000, train_loss: 53.5811, val_loss: 74.7496, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 381/1000000, train_loss: 53.5864, val_loss: 74.6565, time: 0.37s\n",
      "Epoch 382/1000000, train_loss: 53.5513, val_loss: 74.7266, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 383/1000000, train_loss: 53.5174, val_loss: 74.6490, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 384/1000000, train_loss: 53.5084, val_loss: 74.5281, time: 0.37s\n",
      "Epoch 385/1000000, train_loss: 53.4780, val_loss: 74.5330, time: 0.37s\n",
      "Epoch 386/1000000, train_loss: 53.4721, val_loss: 74.5329, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 387/1000000, train_loss: 53.4399, val_loss: 74.4319, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 388/1000000, train_loss: 53.4181, val_loss: 74.3401, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 389/1000000, train_loss: 53.4069, val_loss: 74.2911, time: 0.37s\n",
      "Epoch 390/1000000, train_loss: 53.3711, val_loss: 74.3234, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 391/1000000, train_loss: 53.3475, val_loss: 74.2282, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 392/1000000, train_loss: 53.3148, val_loss: 74.1781, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 393/1000000, train_loss: 53.2922, val_loss: 74.0390, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 394/1000000, train_loss: 53.2669, val_loss: 74.0061, time: 0.37s\n",
      "Epoch 395/1000000, train_loss: 53.2479, val_loss: 74.0290, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 396/1000000, train_loss: 53.2149, val_loss: 73.9518, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 397/1000000, train_loss: 53.1965, val_loss: 73.9035, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 398/1000000, train_loss: 53.1442, val_loss: 73.8828, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 399/1000000, train_loss: 53.1551, val_loss: 73.8024, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 400/1000000, train_loss: 53.1429, val_loss: 73.7908, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 401/1000000, train_loss: 53.1017, val_loss: 73.6733, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 402/1000000, train_loss: 53.0711, val_loss: 73.6267, time: 0.38s\n",
      "Epoch 403/1000000, train_loss: 53.0599, val_loss: 73.6577, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 404/1000000, train_loss: 53.0334, val_loss: 73.5922, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 405/1000000, train_loss: 52.9755, val_loss: 73.4878, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 406/1000000, train_loss: 52.9735, val_loss: 73.3616, time: 0.38s\n",
      "Epoch 407/1000000, train_loss: 52.9614, val_loss: 73.3642, time: 0.37s\n",
      "Epoch 408/1000000, train_loss: 52.9395, val_loss: 73.4565, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 409/1000000, train_loss: 52.8964, val_loss: 73.3055, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 410/1000000, train_loss: 52.8912, val_loss: 73.2345, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 411/1000000, train_loss: 52.8657, val_loss: 73.1703, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 412/1000000, train_loss: 52.8449, val_loss: 73.1136, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 413/1000000, train_loss: 52.8051, val_loss: 73.0352, time: 0.43s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 414/1000000, train_loss: 52.8234, val_loss: 72.9701, time: 0.38s\n",
      "Epoch 415/1000000, train_loss: 52.7628, val_loss: 72.9758, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 416/1000000, train_loss: 52.7339, val_loss: 72.9675, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 417/1000000, train_loss: 52.7259, val_loss: 72.9067, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 418/1000000, train_loss: 52.7140, val_loss: 72.8555, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 419/1000000, train_loss: 52.6652, val_loss: 72.7844, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 420/1000000, train_loss: 52.6370, val_loss: 72.7651, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 421/1000000, train_loss: 52.6355, val_loss: 72.5940, time: 0.38s\n",
      "Epoch 422/1000000, train_loss: 52.5999, val_loss: 72.6835, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 423/1000000, train_loss: 52.5853, val_loss: 72.5003, time: 0.38s\n",
      "Epoch 424/1000000, train_loss: 52.6094, val_loss: 72.6037, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 425/1000000, train_loss: 52.5468, val_loss: 72.4732, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 426/1000000, train_loss: 52.5130, val_loss: 72.4067, time: 0.38s\n",
      "Epoch 427/1000000, train_loss: 52.4732, val_loss: 72.4195, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 428/1000000, train_loss: 52.4706, val_loss: 72.2903, time: 0.38s\n",
      "Epoch 429/1000000, train_loss: 52.4455, val_loss: 72.3208, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 430/1000000, train_loss: 52.3938, val_loss: 72.2194, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 431/1000000, train_loss: 52.3958, val_loss: 72.1276, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 432/1000000, train_loss: 52.3766, val_loss: 72.1225, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 433/1000000, train_loss: 52.3422, val_loss: 72.0547, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 434/1000000, train_loss: 52.3225, val_loss: 71.9766, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 435/1000000, train_loss: 52.2959, val_loss: 71.9510, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 436/1000000, train_loss: 52.2753, val_loss: 71.8869, time: 0.37s\n",
      "Epoch 437/1000000, train_loss: 52.2363, val_loss: 71.9259, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 438/1000000, train_loss: 52.2026, val_loss: 71.6908, time: 0.38s\n",
      "Epoch 439/1000000, train_loss: 52.1778, val_loss: 71.7651, time: 0.37s\n",
      "Epoch 440/1000000, train_loss: 52.1507, val_loss: 71.7260, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 441/1000000, train_loss: 52.1299, val_loss: 71.6319, time: 0.38s\n",
      "Epoch 442/1000000, train_loss: 52.1065, val_loss: 71.6702, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 443/1000000, train_loss: 52.1022, val_loss: 71.5274, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 444/1000000, train_loss: 52.0802, val_loss: 71.4495, time: 0.37s\n",
      "Epoch 445/1000000, train_loss: 52.0598, val_loss: 71.5302, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 446/1000000, train_loss: 52.0360, val_loss: 71.4184, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 447/1000000, train_loss: 51.9999, val_loss: 71.4058, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 448/1000000, train_loss: 51.9996, val_loss: 71.2736, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 449/1000000, train_loss: 51.9551, val_loss: 71.1856, time: 0.37s\n",
      "Epoch 450/1000000, train_loss: 51.9234, val_loss: 71.1863, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 451/1000000, train_loss: 51.9028, val_loss: 71.1518, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 452/1000000, train_loss: 51.8891, val_loss: 71.1235, time: 0.37s\n",
      "Epoch 453/1000000, train_loss: 51.8521, val_loss: 71.1240, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 454/1000000, train_loss: 51.8210, val_loss: 70.9958, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 455/1000000, train_loss: 51.8147, val_loss: 70.9914, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 456/1000000, train_loss: 51.7896, val_loss: 70.8868, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 457/1000000, train_loss: 51.7653, val_loss: 70.8102, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 458/1000000, train_loss: 51.7375, val_loss: 70.7814, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 459/1000000, train_loss: 51.7077, val_loss: 70.7542, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 460/1000000, train_loss: 51.6945, val_loss: 70.6741, time: 0.37s\n",
      "Epoch 461/1000000, train_loss: 51.6786, val_loss: 70.6803, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 462/1000000, train_loss: 51.6703, val_loss: 70.5896, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 463/1000000, train_loss: 51.6179, val_loss: 70.5362, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 464/1000000, train_loss: 51.5845, val_loss: 70.4535, time: 0.37s\n",
      "Epoch 465/1000000, train_loss: 51.5803, val_loss: 70.4582, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 466/1000000, train_loss: 51.5431, val_loss: 70.4307, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 467/1000000, train_loss: 51.5265, val_loss: 70.2952, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 468/1000000, train_loss: 51.4897, val_loss: 70.2772, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 469/1000000, train_loss: 51.4848, val_loss: 70.2134, time: 0.37s\n",
      "Epoch 470/1000000, train_loss: 51.4405, val_loss: 70.2496, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 471/1000000, train_loss: 51.4400, val_loss: 70.1604, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 472/1000000, train_loss: 51.4026, val_loss: 70.1003, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 473/1000000, train_loss: 51.4006, val_loss: 69.9840, time: 0.37s\n",
      "Epoch 474/1000000, train_loss: 51.3669, val_loss: 70.0439, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 475/1000000, train_loss: 51.3323, val_loss: 69.8503, time: 0.37s\n",
      "Epoch 476/1000000, train_loss: 51.2936, val_loss: 69.9381, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 477/1000000, train_loss: 51.2806, val_loss: 69.8421, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 478/1000000, train_loss: 51.2550, val_loss: 69.7575, time: 0.38s\n",
      "Epoch 479/1000000, train_loss: 51.2492, val_loss: 69.7852, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 480/1000000, train_loss: 51.2147, val_loss: 69.6947, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 481/1000000, train_loss: 51.1987, val_loss: 69.6334, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 482/1000000, train_loss: 51.1779, val_loss: 69.6003, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 483/1000000, train_loss: 51.1250, val_loss: 69.5174, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 484/1000000, train_loss: 51.1318, val_loss: 69.4773, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 485/1000000, train_loss: 51.1294, val_loss: 69.4079, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 486/1000000, train_loss: 51.0873, val_loss: 69.3208, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 487/1000000, train_loss: 51.0671, val_loss: 69.3153, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 488/1000000, train_loss: 51.0377, val_loss: 69.2914, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 489/1000000, train_loss: 51.0075, val_loss: 69.2286, time: 0.37s\n",
      "Epoch 490/1000000, train_loss: 50.9840, val_loss: 69.2298, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 491/1000000, train_loss: 50.9652, val_loss: 69.1009, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 492/1000000, train_loss: 50.9261, val_loss: 69.0661, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 493/1000000, train_loss: 50.9169, val_loss: 68.9400, time: 0.37s\n",
      "Epoch 494/1000000, train_loss: 50.8920, val_loss: 68.9456, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 495/1000000, train_loss: 50.8560, val_loss: 68.8974, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 496/1000000, train_loss: 50.8295, val_loss: 68.8889, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 497/1000000, train_loss: 50.8139, val_loss: 68.8294, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 498/1000000, train_loss: 50.7777, val_loss: 68.6821, time: 0.37s\n",
      "Epoch 499/1000000, train_loss: 50.7649, val_loss: 68.7295, time: 0.37s\n",
      "Epoch 500/1000000, train_loss: 50.7378, val_loss: 68.7152, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 501/1000000, train_loss: 50.7152, val_loss: 68.6259, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 502/1000000, train_loss: 50.6720, val_loss: 68.6159, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 503/1000000, train_loss: 50.6615, val_loss: 68.5388, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 504/1000000, train_loss: 50.6467, val_loss: 68.4001, time: 0.37s\n",
      "Epoch 505/1000000, train_loss: 50.6167, val_loss: 68.5075, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 506/1000000, train_loss: 50.6109, val_loss: 68.3182, time: 0.38s\n",
      "Epoch 507/1000000, train_loss: 50.5653, val_loss: 68.3469, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 508/1000000, train_loss: 50.5513, val_loss: 68.2637, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 509/1000000, train_loss: 50.5249, val_loss: 68.2434, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 510/1000000, train_loss: 50.4975, val_loss: 68.1185, time: 0.37s\n",
      "Epoch 511/1000000, train_loss: 50.4864, val_loss: 68.1503, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 512/1000000, train_loss: 50.4526, val_loss: 68.0562, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 513/1000000, train_loss: 50.4324, val_loss: 68.0275, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 514/1000000, train_loss: 50.3965, val_loss: 67.8924, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 515/1000000, train_loss: 50.4546, val_loss: 67.8895, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 516/1000000, train_loss: 50.3644, val_loss: 67.8363, time: 0.37s\n",
      "Epoch 517/1000000, train_loss: 50.3164, val_loss: 67.8475, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 518/1000000, train_loss: 50.3019, val_loss: 67.7709, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 519/1000000, train_loss: 50.2944, val_loss: 67.6890, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 520/1000000, train_loss: 50.2604, val_loss: 67.5704, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 521/1000000, train_loss: 50.2431, val_loss: 67.5621, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 522/1000000, train_loss: 50.2047, val_loss: 67.5243, time: 0.37s\n",
      "Epoch 523/1000000, train_loss: 50.1884, val_loss: 67.5452, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 524/1000000, train_loss: 50.1593, val_loss: 67.4541, time: 0.37s\n",
      "Epoch 525/1000000, train_loss: 50.1335, val_loss: 67.4711, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 526/1000000, train_loss: 50.1236, val_loss: 67.3718, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 527/1000000, train_loss: 50.0623, val_loss: 67.2343, time: 0.37s\n",
      "Epoch 528/1000000, train_loss: 50.0525, val_loss: 67.2567, time: 0.37s\n",
      "Epoch 529/1000000, train_loss: 50.0422, val_loss: 67.2925, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 530/1000000, train_loss: 50.0157, val_loss: 67.1278, time: 0.37s\n",
      "Epoch 531/1000000, train_loss: 49.9989, val_loss: 67.1463, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 532/1000000, train_loss: 49.9584, val_loss: 66.9729, time: 0.37s\n",
      "Epoch 533/1000000, train_loss: 49.9386, val_loss: 67.0337, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 534/1000000, train_loss: 49.9179, val_loss: 66.8853, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 535/1000000, train_loss: 49.8944, val_loss: 66.8541, time: 0.37s\n",
      "Epoch 536/1000000, train_loss: 49.8676, val_loss: 66.8717, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 537/1000000, train_loss: 49.8624, val_loss: 66.8080, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 538/1000000, train_loss: 49.8245, val_loss: 66.6891, time: 0.37s\n",
      "Epoch 539/1000000, train_loss: 49.8169, val_loss: 66.8063, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 540/1000000, train_loss: 49.7998, val_loss: 66.6825, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 541/1000000, train_loss: 49.7360, val_loss: 66.5719, time: 0.37s\n",
      "Epoch 542/1000000, train_loss: 49.7270, val_loss: 66.5919, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 543/1000000, train_loss: 49.7046, val_loss: 66.5185, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 544/1000000, train_loss: 49.6801, val_loss: 66.4671, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 545/1000000, train_loss: 49.6557, val_loss: 66.4262, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 546/1000000, train_loss: 49.6486, val_loss: 66.3355, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 547/1000000, train_loss: 49.6121, val_loss: 66.3144, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 548/1000000, train_loss: 49.5841, val_loss: 66.1936, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 549/1000000, train_loss: 49.5664, val_loss: 66.1877, time: 0.37s\n",
      "Epoch 550/1000000, train_loss: 49.5524, val_loss: 66.2092, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 551/1000000, train_loss: 49.5180, val_loss: 66.1143, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 552/1000000, train_loss: 49.4883, val_loss: 66.0633, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 553/1000000, train_loss: 49.4720, val_loss: 65.9582, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 554/1000000, train_loss: 49.4406, val_loss: 65.9157, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 555/1000000, train_loss: 49.4368, val_loss: 65.8594, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 556/1000000, train_loss: 49.4106, val_loss: 65.8463, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 557/1000000, train_loss: 49.3665, val_loss: 65.7901, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 558/1000000, train_loss: 49.3523, val_loss: 65.7071, time: 0.37s\n",
      "Epoch 559/1000000, train_loss: 49.3254, val_loss: 65.7627, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 560/1000000, train_loss: 49.2948, val_loss: 65.5786, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 561/1000000, train_loss: 49.2834, val_loss: 65.5031, time: 0.37s\n",
      "Epoch 562/1000000, train_loss: 49.2551, val_loss: 65.5211, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 563/1000000, train_loss: 49.2332, val_loss: 65.4386, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 564/1000000, train_loss: 49.2061, val_loss: 65.4230, time: 0.37s\n",
      "Epoch 565/1000000, train_loss: 49.1757, val_loss: 65.4406, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 566/1000000, train_loss: 49.1476, val_loss: 65.3614, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 567/1000000, train_loss: 49.1337, val_loss: 65.2613, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 568/1000000, train_loss: 49.1058, val_loss: 65.2286, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 569/1000000, train_loss: 49.1029, val_loss: 65.1858, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 570/1000000, train_loss: 49.0514, val_loss: 65.1571, time: 0.37s\n",
      "Epoch 571/1000000, train_loss: 49.0423, val_loss: 65.1635, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 572/1000000, train_loss: 49.0103, val_loss: 65.0183, time: 0.37s\n",
      "Epoch 573/1000000, train_loss: 48.9999, val_loss: 65.0377, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 574/1000000, train_loss: 48.9999, val_loss: 64.8511, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 575/1000000, train_loss: 48.9684, val_loss: 64.8195, time: 0.37s\n",
      "Epoch 576/1000000, train_loss: 48.9248, val_loss: 64.8500, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 577/1000000, train_loss: 48.9001, val_loss: 64.7383, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 578/1000000, train_loss: 48.8801, val_loss: 64.6994, time: 0.37s\n",
      "Epoch 579/1000000, train_loss: 48.8617, val_loss: 64.7164, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 580/1000000, train_loss: 48.8221, val_loss: 64.6535, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 581/1000000, train_loss: 48.8350, val_loss: 64.5520, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 582/1000000, train_loss: 48.7977, val_loss: 64.5406, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 583/1000000, train_loss: 48.7567, val_loss: 64.4783, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 584/1000000, train_loss: 48.7375, val_loss: 64.4432, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 585/1000000, train_loss: 48.7059, val_loss: 64.4275, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 586/1000000, train_loss: 48.6856, val_loss: 64.3485, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 587/1000000, train_loss: 48.6744, val_loss: 64.2516, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 588/1000000, train_loss: 48.6321, val_loss: 64.2011, time: 0.38s\n",
      "Epoch 589/1000000, train_loss: 48.6006, val_loss: 64.2195, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 590/1000000, train_loss: 48.5843, val_loss: 64.1146, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 591/1000000, train_loss: 48.5574, val_loss: 64.0724, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 592/1000000, train_loss: 48.5425, val_loss: 64.0374, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 593/1000000, train_loss: 48.5148, val_loss: 63.9654, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 594/1000000, train_loss: 48.4696, val_loss: 63.8840, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 595/1000000, train_loss: 48.4742, val_loss: 63.8702, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 596/1000000, train_loss: 48.4401, val_loss: 63.7841, time: 0.38s\n",
      "Epoch 597/1000000, train_loss: 48.4293, val_loss: 63.7894, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 598/1000000, train_loss: 48.3919, val_loss: 63.6922, time: 0.38s\n",
      "Epoch 599/1000000, train_loss: 48.3707, val_loss: 63.6946, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 600/1000000, train_loss: 48.3514, val_loss: 63.6240, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 601/1000000, train_loss: 48.3316, val_loss: 63.5779, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 602/1000000, train_loss: 48.3110, val_loss: 63.5099, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 603/1000000, train_loss: 48.2998, val_loss: 63.4370, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 604/1000000, train_loss: 48.2800, val_loss: 63.4241, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 605/1000000, train_loss: 48.2226, val_loss: 63.3740, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 606/1000000, train_loss: 48.1848, val_loss: 63.3155, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 607/1000000, train_loss: 48.1532, val_loss: 63.2815, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 608/1000000, train_loss: 48.1462, val_loss: 63.1717, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 609/1000000, train_loss: 48.1261, val_loss: 63.1522, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 610/1000000, train_loss: 48.1018, val_loss: 63.0744, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 611/1000000, train_loss: 48.0873, val_loss: 63.0622, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 612/1000000, train_loss: 48.0687, val_loss: 63.0280, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 613/1000000, train_loss: 48.0470, val_loss: 62.9744, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 614/1000000, train_loss: 48.0197, val_loss: 62.8688, time: 0.37s\n",
      "Epoch 615/1000000, train_loss: 48.0024, val_loss: 62.8757, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 616/1000000, train_loss: 47.9771, val_loss: 62.7690, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 617/1000000, train_loss: 47.9467, val_loss: 62.7549, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 618/1000000, train_loss: 47.9078, val_loss: 62.6789, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 619/1000000, train_loss: 47.8973, val_loss: 62.6489, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 620/1000000, train_loss: 47.8521, val_loss: 62.6169, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 621/1000000, train_loss: 47.8598, val_loss: 62.5260, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 622/1000000, train_loss: 47.8212, val_loss: 62.4487, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 623/1000000, train_loss: 47.7986, val_loss: 62.4166, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 624/1000000, train_loss: 47.7670, val_loss: 62.3622, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 625/1000000, train_loss: 47.7609, val_loss: 62.3464, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 626/1000000, train_loss: 47.7357, val_loss: 62.2877, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 627/1000000, train_loss: 47.7004, val_loss: 62.2535, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 628/1000000, train_loss: 47.6736, val_loss: 62.1571, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 629/1000000, train_loss: 47.6645, val_loss: 62.1027, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 630/1000000, train_loss: 47.7438, val_loss: 62.0831, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 631/1000000, train_loss: 47.6276, val_loss: 62.0278, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 632/1000000, train_loss: 47.5946, val_loss: 62.0126, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 633/1000000, train_loss: 47.5621, val_loss: 61.8981, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 634/1000000, train_loss: 47.5286, val_loss: 61.8855, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 635/1000000, train_loss: 47.5183, val_loss: 61.8405, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 636/1000000, train_loss: 47.4856, val_loss: 61.7355, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 637/1000000, train_loss: 47.4597, val_loss: 61.7313, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 638/1000000, train_loss: 47.4378, val_loss: 61.7284, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 639/1000000, train_loss: 47.4199, val_loss: 61.6488, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 640/1000000, train_loss: 47.3948, val_loss: 61.5534, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 641/1000000, train_loss: 47.3532, val_loss: 61.4957, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 642/1000000, train_loss: 47.3590, val_loss: 61.4574, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 643/1000000, train_loss: 47.3342, val_loss: 61.4120, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 644/1000000, train_loss: 47.3101, val_loss: 61.3550, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 645/1000000, train_loss: 47.2702, val_loss: 61.3393, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 646/1000000, train_loss: 47.2447, val_loss: 61.2221, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 647/1000000, train_loss: 47.2382, val_loss: 61.2054, time: 0.38s\n",
      "Epoch 648/1000000, train_loss: 47.2074, val_loss: 61.2072, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 649/1000000, train_loss: 47.1880, val_loss: 61.0850, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 650/1000000, train_loss: 47.1492, val_loss: 61.0724, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 651/1000000, train_loss: 47.1395, val_loss: 61.0098, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 652/1000000, train_loss: 47.1117, val_loss: 60.9579, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 653/1000000, train_loss: 47.0662, val_loss: 60.9275, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 654/1000000, train_loss: 47.0625, val_loss: 60.8404, time: 0.38s\n",
      "Epoch 655/1000000, train_loss: 47.0394, val_loss: 60.8627, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 656/1000000, train_loss: 47.0163, val_loss: 60.7556, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 657/1000000, train_loss: 47.0056, val_loss: 60.7133, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 658/1000000, train_loss: 46.9563, val_loss: 60.6459, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 659/1000000, train_loss: 46.9368, val_loss: 60.6373, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 660/1000000, train_loss: 46.9107, val_loss: 60.5606, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 661/1000000, train_loss: 46.8770, val_loss: 60.4323, time: 0.37s\n",
      "Epoch 662/1000000, train_loss: 46.8711, val_loss: 60.4780, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 663/1000000, train_loss: 46.8512, val_loss: 60.3814, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 664/1000000, train_loss: 46.8239, val_loss: 60.3542, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 665/1000000, train_loss: 46.7787, val_loss: 60.3018, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 666/1000000, train_loss: 46.7645, val_loss: 60.2056, time: 0.37s\n",
      "Epoch 667/1000000, train_loss: 46.7484, val_loss: 60.2339, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 668/1000000, train_loss: 46.7327, val_loss: 60.2032, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 669/1000000, train_loss: 46.7027, val_loss: 60.1059, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 670/1000000, train_loss: 46.6826, val_loss: 60.0140, time: 0.38s\n",
      "Epoch 671/1000000, train_loss: 46.6526, val_loss: 60.0163, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 672/1000000, train_loss: 46.6333, val_loss: 59.9583, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 673/1000000, train_loss: 46.6177, val_loss: 59.9419, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 674/1000000, train_loss: 46.5937, val_loss: 59.8391, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 675/1000000, train_loss: 46.5655, val_loss: 59.8054, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 676/1000000, train_loss: 46.5477, val_loss: 59.7558, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 677/1000000, train_loss: 46.5143, val_loss: 59.6907, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 678/1000000, train_loss: 46.4990, val_loss: 59.6677, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 679/1000000, train_loss: 46.4795, val_loss: 59.5748, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 680/1000000, train_loss: 46.4382, val_loss: 59.5575, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 681/1000000, train_loss: 46.4054, val_loss: 59.5225, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 682/1000000, train_loss: 46.3813, val_loss: 59.4570, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 683/1000000, train_loss: 46.3682, val_loss: 59.4008, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 684/1000000, train_loss: 46.3377, val_loss: 59.3353, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 685/1000000, train_loss: 46.3101, val_loss: 59.2641, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 686/1000000, train_loss: 46.2989, val_loss: 59.2528, time: 0.38s\n",
      "Epoch 687/1000000, train_loss: 46.2638, val_loss: 59.2556, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 688/1000000, train_loss: 46.2596, val_loss: 59.1602, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 689/1000000, train_loss: 46.2277, val_loss: 59.0370, time: 0.38s\n",
      "Epoch 690/1000000, train_loss: 46.2044, val_loss: 59.0485, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 691/1000000, train_loss: 46.1859, val_loss: 59.0258, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 692/1000000, train_loss: 46.1651, val_loss: 58.9623, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 693/1000000, train_loss: 46.1301, val_loss: 58.8886, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 694/1000000, train_loss: 46.0999, val_loss: 58.8561, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 695/1000000, train_loss: 46.0766, val_loss: 58.8041, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 696/1000000, train_loss: 46.0628, val_loss: 58.7492, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 697/1000000, train_loss: 46.0412, val_loss: 58.6678, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 698/1000000, train_loss: 46.0118, val_loss: 58.6022, time: 0.38s\n",
      "Epoch 699/1000000, train_loss: 45.9729, val_loss: 58.6023, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 700/1000000, train_loss: 45.9652, val_loss: 58.5250, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 701/1000000, train_loss: 45.9416, val_loss: 58.4936, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 702/1000000, train_loss: 45.9132, val_loss: 58.4310, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 703/1000000, train_loss: 45.8894, val_loss: 58.3551, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 704/1000000, train_loss: 45.8711, val_loss: 58.3202, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 705/1000000, train_loss: 45.8434, val_loss: 58.2795, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 706/1000000, train_loss: 45.8181, val_loss: 58.2395, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 707/1000000, train_loss: 45.7944, val_loss: 58.2146, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 708/1000000, train_loss: 45.7713, val_loss: 58.1318, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 709/1000000, train_loss: 45.7531, val_loss: 58.1205, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 710/1000000, train_loss: 45.7188, val_loss: 58.0311, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 711/1000000, train_loss: 45.7114, val_loss: 57.9610, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 712/1000000, train_loss: 45.6737, val_loss: 57.9581, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 713/1000000, train_loss: 45.6722, val_loss: 57.8633, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 714/1000000, train_loss: 45.7338, val_loss: 57.8294, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 715/1000000, train_loss: 45.6407, val_loss: 57.7589, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 716/1000000, train_loss: 45.5804, val_loss: 57.7365, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 717/1000000, train_loss: 45.5665, val_loss: 57.6497, time: 0.38s\n",
      "Epoch 718/1000000, train_loss: 45.5265, val_loss: 57.6553, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 719/1000000, train_loss: 45.5059, val_loss: 57.5785, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 720/1000000, train_loss: 45.4842, val_loss: 57.5558, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 721/1000000, train_loss: 45.4626, val_loss: 57.4882, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 722/1000000, train_loss: 45.4325, val_loss: 57.4027, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 723/1000000, train_loss: 45.4157, val_loss: 57.3834, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 724/1000000, train_loss: 45.3870, val_loss: 57.2968, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 725/1000000, train_loss: 45.3662, val_loss: 57.2677, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 726/1000000, train_loss: 45.3310, val_loss: 57.2134, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 727/1000000, train_loss: 45.3175, val_loss: 57.1654, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 728/1000000, train_loss: 45.2999, val_loss: 57.0997, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 729/1000000, train_loss: 45.2524, val_loss: 57.0714, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 730/1000000, train_loss: 45.2499, val_loss: 57.0270, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 731/1000000, train_loss: 45.3906, val_loss: 56.9773, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 732/1000000, train_loss: 45.2660, val_loss: 56.8801, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 733/1000000, train_loss: 45.1916, val_loss: 56.8542, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 734/1000000, train_loss: 45.1565, val_loss: 56.8198, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 735/1000000, train_loss: 45.1412, val_loss: 56.7780, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 736/1000000, train_loss: 45.1116, val_loss: 56.7115, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 737/1000000, train_loss: 45.0716, val_loss: 56.6654, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 738/1000000, train_loss: 45.0530, val_loss: 56.5961, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 739/1000000, train_loss: 45.0445, val_loss: 56.5665, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 740/1000000, train_loss: 45.0073, val_loss: 56.4994, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 741/1000000, train_loss: 44.9891, val_loss: 56.4631, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 742/1000000, train_loss: 44.9742, val_loss: 56.3943, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 743/1000000, train_loss: 44.9273, val_loss: 56.3675, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 744/1000000, train_loss: 44.9116, val_loss: 56.3344, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 745/1000000, train_loss: 44.9012, val_loss: 56.2558, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 746/1000000, train_loss: 44.8673, val_loss: 56.2074, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 747/1000000, train_loss: 44.8344, val_loss: 56.1705, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 748/1000000, train_loss: 44.8026, val_loss: 56.1089, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 749/1000000, train_loss: 44.7988, val_loss: 56.0574, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 750/1000000, train_loss: 44.7561, val_loss: 56.0078, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 751/1000000, train_loss: 44.7494, val_loss: 55.9355, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 752/1000000, train_loss: 44.7033, val_loss: 55.8828, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 753/1000000, train_loss: 44.6822, val_loss: 55.8599, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 754/1000000, train_loss: 44.6678, val_loss: 55.8073, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 755/1000000, train_loss: 44.6497, val_loss: 55.7251, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 756/1000000, train_loss: 44.7105, val_loss: 55.6980, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 757/1000000, train_loss: 44.6615, val_loss: 55.6375, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 758/1000000, train_loss: 44.5822, val_loss: 55.6011, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 759/1000000, train_loss: 44.5533, val_loss: 55.5415, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 760/1000000, train_loss: 44.5298, val_loss: 55.4844, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 761/1000000, train_loss: 44.5000, val_loss: 55.4441, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 762/1000000, train_loss: 44.4911, val_loss: 55.3801, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 763/1000000, train_loss: 44.4597, val_loss: 55.3362, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 764/1000000, train_loss: 44.4395, val_loss: 55.2860, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 765/1000000, train_loss: 44.4151, val_loss: 55.2517, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 766/1000000, train_loss: 44.3824, val_loss: 55.2003, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 767/1000000, train_loss: 44.3668, val_loss: 55.1397, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 768/1000000, train_loss: 44.3297, val_loss: 55.0782, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 769/1000000, train_loss: 44.3201, val_loss: 55.0280, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 770/1000000, train_loss: 44.3099, val_loss: 54.9788, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 771/1000000, train_loss: 44.2696, val_loss: 54.9608, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 772/1000000, train_loss: 44.2492, val_loss: 54.8957, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 773/1000000, train_loss: 44.2115, val_loss: 54.8332, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 774/1000000, train_loss: 44.1893, val_loss: 54.7694, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 775/1000000, train_loss: 44.1736, val_loss: 54.7379, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 776/1000000, train_loss: 44.1389, val_loss: 54.7000, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 777/1000000, train_loss: 44.1414, val_loss: 54.6421, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 778/1000000, train_loss: 44.1266, val_loss: 54.5617, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 779/1000000, train_loss: 44.0784, val_loss: 54.5177, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 780/1000000, train_loss: 44.0708, val_loss: 54.4807, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 781/1000000, train_loss: 44.0456, val_loss: 54.4445, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 782/1000000, train_loss: 43.9898, val_loss: 54.3762, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 783/1000000, train_loss: 43.9871, val_loss: 54.3464, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 784/1000000, train_loss: 43.9684, val_loss: 54.2848, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 785/1000000, train_loss: 43.9435, val_loss: 54.2171, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 786/1000000, train_loss: 43.9057, val_loss: 54.1619, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 787/1000000, train_loss: 43.8747, val_loss: 54.1346, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 788/1000000, train_loss: 43.8638, val_loss: 54.0810, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 789/1000000, train_loss: 43.8333, val_loss: 54.0184, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 790/1000000, train_loss: 43.8216, val_loss: 53.9693, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 791/1000000, train_loss: 43.8097, val_loss: 53.9293, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 792/1000000, train_loss: 43.7615, val_loss: 53.8690, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 793/1000000, train_loss: 43.7381, val_loss: 53.8208, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 794/1000000, train_loss: 43.7208, val_loss: 53.7692, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 795/1000000, train_loss: 43.6975, val_loss: 53.7237, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 796/1000000, train_loss: 43.6665, val_loss: 53.6742, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 797/1000000, train_loss: 43.6290, val_loss: 53.6161, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 798/1000000, train_loss: 43.6219, val_loss: 53.5750, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 799/1000000, train_loss: 43.5984, val_loss: 53.5032, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 800/1000000, train_loss: 43.5745, val_loss: 53.4654, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 801/1000000, train_loss: 43.5484, val_loss: 53.3969, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 802/1000000, train_loss: 43.5318, val_loss: 53.3743, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 803/1000000, train_loss: 43.5021, val_loss: 53.3071, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 804/1000000, train_loss: 43.4728, val_loss: 53.2607, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 805/1000000, train_loss: 43.4641, val_loss: 53.2343, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 806/1000000, train_loss: 43.4319, val_loss: 53.1621, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 807/1000000, train_loss: 43.4112, val_loss: 53.1138, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 808/1000000, train_loss: 43.3768, val_loss: 53.0614, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 809/1000000, train_loss: 43.3654, val_loss: 53.0076, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 810/1000000, train_loss: 43.3338, val_loss: 52.9634, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 811/1000000, train_loss: 43.3149, val_loss: 52.9030, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 812/1000000, train_loss: 43.2825, val_loss: 52.8575, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 813/1000000, train_loss: 43.2710, val_loss: 52.8068, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 814/1000000, train_loss: 43.2460, val_loss: 52.7591, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 815/1000000, train_loss: 43.2219, val_loss: 52.6954, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 816/1000000, train_loss: 43.1900, val_loss: 52.6632, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 817/1000000, train_loss: 43.1710, val_loss: 52.6049, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 818/1000000, train_loss: 43.1266, val_loss: 52.5525, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 819/1000000, train_loss: 43.1137, val_loss: 52.5048, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 820/1000000, train_loss: 43.1043, val_loss: 52.4489, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 821/1000000, train_loss: 43.0889, val_loss: 52.4019, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 822/1000000, train_loss: 43.0657, val_loss: 52.3533, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 823/1000000, train_loss: 43.3144, val_loss: 52.2967, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 824/1000000, train_loss: 43.2113, val_loss: 52.2529, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 825/1000000, train_loss: 43.0117, val_loss: 52.1901, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 826/1000000, train_loss: 42.9465, val_loss: 52.1509, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 827/1000000, train_loss: 42.9433, val_loss: 52.1011, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 828/1000000, train_loss: 42.9246, val_loss: 52.0497, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 829/1000000, train_loss: 42.8887, val_loss: 52.0011, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 830/1000000, train_loss: 42.8556, val_loss: 51.9391, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 831/1000000, train_loss: 42.8451, val_loss: 51.9005, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 832/1000000, train_loss: 42.8185, val_loss: 51.8496, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 833/1000000, train_loss: 42.7942, val_loss: 51.7955, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 834/1000000, train_loss: 42.7665, val_loss: 51.7488, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 835/1000000, train_loss: 42.7336, val_loss: 51.6910, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 836/1000000, train_loss: 42.7110, val_loss: 51.6432, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 837/1000000, train_loss: 42.6794, val_loss: 51.5919, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 838/1000000, train_loss: 42.6746, val_loss: 51.5416, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 839/1000000, train_loss: 42.6442, val_loss: 51.4877, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 840/1000000, train_loss: 42.6115, val_loss: 51.4392, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 841/1000000, train_loss: 42.5987, val_loss: 51.3856, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 842/1000000, train_loss: 42.5644, val_loss: 51.3327, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 843/1000000, train_loss: 42.5612, val_loss: 51.2819, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 844/1000000, train_loss: 42.5174, val_loss: 51.2364, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 845/1000000, train_loss: 42.5212, val_loss: 51.1812, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 846/1000000, train_loss: 42.4916, val_loss: 51.1340, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 847/1000000, train_loss: 42.4558, val_loss: 51.0856, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 848/1000000, train_loss: 42.4251, val_loss: 51.0320, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 849/1000000, train_loss: 42.4091, val_loss: 50.9827, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 850/1000000, train_loss: 42.3888, val_loss: 50.9332, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 851/1000000, train_loss: 42.3558, val_loss: 50.8826, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 852/1000000, train_loss: 42.3258, val_loss: 50.8301, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 853/1000000, train_loss: 42.2974, val_loss: 50.7800, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 854/1000000, train_loss: 42.2936, val_loss: 50.7291, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 855/1000000, train_loss: 42.2615, val_loss: 50.6770, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 856/1000000, train_loss: 42.2452, val_loss: 50.6306, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 857/1000000, train_loss: 42.2210, val_loss: 50.5789, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 858/1000000, train_loss: 42.1920, val_loss: 50.5261, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 859/1000000, train_loss: 42.1647, val_loss: 50.4765, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 860/1000000, train_loss: 42.1552, val_loss: 50.4232, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 861/1000000, train_loss: 42.1213, val_loss: 50.3739, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 862/1000000, train_loss: 42.1147, val_loss: 50.3234, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 863/1000000, train_loss: 42.0644, val_loss: 50.2710, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 864/1000000, train_loss: 42.0408, val_loss: 50.2232, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 865/1000000, train_loss: 42.0460, val_loss: 50.1710, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 866/1000000, train_loss: 42.0170, val_loss: 50.1186, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 867/1000000, train_loss: 41.9862, val_loss: 50.0694, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 868/1000000, train_loss: 41.9526, val_loss: 50.0188, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 869/1000000, train_loss: 41.9643, val_loss: 49.9687, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 870/1000000, train_loss: 41.9182, val_loss: 49.9176, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 871/1000000, train_loss: 41.8885, val_loss: 49.8674, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 872/1000000, train_loss: 41.8982, val_loss: 49.8162, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 873/1000000, train_loss: 41.8409, val_loss: 49.7662, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 874/1000000, train_loss: 41.8218, val_loss: 49.7165, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 875/1000000, train_loss: 41.7901, val_loss: 49.6650, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 876/1000000, train_loss: 41.8472, val_loss: 49.6143, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 877/1000000, train_loss: 41.8927, val_loss: 49.5640, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 878/1000000, train_loss: 41.7852, val_loss: 49.5126, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 879/1000000, train_loss: 41.7519, val_loss: 49.4628, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 880/1000000, train_loss: 42.3513, val_loss: 49.4139, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 881/1000000, train_loss: 41.8627, val_loss: 49.3639, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 882/1000000, train_loss: 41.7238, val_loss: 49.3126, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 883/1000000, train_loss: 41.6699, val_loss: 49.2633, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 884/1000000, train_loss: 41.6339, val_loss: 49.2123, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 885/1000000, train_loss: 41.6065, val_loss: 49.1605, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 886/1000000, train_loss: 41.5567, val_loss: 49.1121, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 887/1000000, train_loss: 41.5526, val_loss: 49.0591, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 888/1000000, train_loss: 41.5135, val_loss: 49.0078, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 889/1000000, train_loss: 41.4967, val_loss: 48.9577, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 890/1000000, train_loss: 41.4602, val_loss: 48.9048, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 891/1000000, train_loss: 41.4439, val_loss: 48.8611, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 892/1000000, train_loss: 41.4086, val_loss: 48.8084, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 893/1000000, train_loss: 41.3984, val_loss: 48.7512, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 894/1000000, train_loss: 41.3472, val_loss: 48.7031, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 895/1000000, train_loss: 41.3353, val_loss: 48.6555, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 896/1000000, train_loss: 41.3012, val_loss: 48.6003, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 897/1000000, train_loss: 41.5283, val_loss: 48.5509, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 898/1000000, train_loss: 42.3241, val_loss: 48.5001, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 899/1000000, train_loss: 41.7606, val_loss: 48.4555, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 900/1000000, train_loss: 41.3810, val_loss: 48.4046, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 901/1000000, train_loss: 41.2888, val_loss: 48.3542, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 902/1000000, train_loss: 41.4117, val_loss: 48.3118, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 903/1000000, train_loss: 41.2675, val_loss: 48.2527, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 904/1000000, train_loss: 41.2051, val_loss: 48.2017, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 905/1000000, train_loss: 41.1699, val_loss: 48.1525, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 906/1000000, train_loss: 41.1252, val_loss: 48.0899, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 907/1000000, train_loss: 41.0846, val_loss: 48.0456, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 908/1000000, train_loss: 41.0662, val_loss: 48.0015, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 909/1000000, train_loss: 41.0422, val_loss: 47.9513, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 910/1000000, train_loss: 41.0032, val_loss: 47.8895, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 911/1000000, train_loss: 40.9817, val_loss: 47.8402, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 912/1000000, train_loss: 40.9580, val_loss: 47.7959, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 913/1000000, train_loss: 40.9331, val_loss: 47.7494, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 914/1000000, train_loss: 40.9296, val_loss: 47.6923, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 915/1000000, train_loss: 40.9683, val_loss: 47.6477, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 916/1000000, train_loss: 40.8880, val_loss: 47.5908, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 917/1000000, train_loss: 40.9048, val_loss: 47.5469, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 918/1000000, train_loss: 40.8708, val_loss: 47.4963, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 919/1000000, train_loss: 40.8287, val_loss: 47.4327, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 920/1000000, train_loss: 40.7953, val_loss: 47.3869, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 921/1000000, train_loss: 40.7609, val_loss: 47.3376, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 922/1000000, train_loss: 40.7233, val_loss: 47.2928, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 923/1000000, train_loss: 40.6812, val_loss: 47.2285, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 924/1000000, train_loss: 40.6526, val_loss: 47.1926, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 925/1000000, train_loss: 40.6292, val_loss: 47.1427, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 926/1000000, train_loss: 40.5962, val_loss: 47.0766, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 927/1000000, train_loss: 40.5878, val_loss: 47.0371, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 928/1000000, train_loss: 40.5437, val_loss: 46.9940, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 929/1000000, train_loss: 40.5236, val_loss: 46.9184, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 930/1000000, train_loss: 40.5050, val_loss: 46.8891, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 931/1000000, train_loss: 40.4875, val_loss: 46.8410, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 932/1000000, train_loss: 40.4549, val_loss: 46.7780, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 933/1000000, train_loss: 40.4450, val_loss: 46.7412, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 934/1000000, train_loss: 40.4233, val_loss: 46.6837, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 935/1000000, train_loss: 40.4057, val_loss: 46.6425, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 936/1000000, train_loss: 40.3836, val_loss: 46.5926, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 937/1000000, train_loss: 40.3554, val_loss: 46.5173, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 938/1000000, train_loss: 40.3266, val_loss: 46.4731, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 939/1000000, train_loss: 40.2995, val_loss: 46.4264, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 940/1000000, train_loss: 40.2562, val_loss: 46.3769, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 941/1000000, train_loss: 40.2600, val_loss: 46.3150, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 942/1000000, train_loss: 40.2141, val_loss: 46.2661, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 943/1000000, train_loss: 40.1958, val_loss: 46.2162, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 944/1000000, train_loss: 40.1683, val_loss: 46.1796, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 945/1000000, train_loss: 40.1756, val_loss: 46.1248, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 946/1000000, train_loss: 40.1227, val_loss: 46.0693, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 947/1000000, train_loss: 40.1537, val_loss: 46.0165, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 948/1000000, train_loss: 40.0870, val_loss: 45.9701, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 949/1000000, train_loss: 40.0401, val_loss: 45.9265, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 950/1000000, train_loss: 40.0065, val_loss: 45.8635, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 951/1000000, train_loss: 40.0036, val_loss: 45.8326, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 952/1000000, train_loss: 39.9819, val_loss: 45.7630, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 953/1000000, train_loss: 40.0076, val_loss: 45.7198, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 954/1000000, train_loss: 39.9437, val_loss: 45.6470, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 955/1000000, train_loss: 39.9052, val_loss: 45.6022, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 956/1000000, train_loss: 39.8743, val_loss: 45.5476, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 957/1000000, train_loss: 39.8519, val_loss: 45.5227, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 958/1000000, train_loss: 39.8082, val_loss: 45.4538, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 959/1000000, train_loss: 39.7978, val_loss: 45.4206, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 960/1000000, train_loss: 39.7746, val_loss: 45.3759, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 961/1000000, train_loss: 39.7531, val_loss: 45.3186, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 962/1000000, train_loss: 39.7207, val_loss: 45.2583, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 963/1000000, train_loss: 39.6949, val_loss: 45.1859, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 964/1000000, train_loss: 39.6839, val_loss: 45.1783, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 965/1000000, train_loss: 39.6546, val_loss: 45.0803, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 966/1000000, train_loss: 39.6189, val_loss: 45.0720, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 967/1000000, train_loss: 39.6045, val_loss: 45.0102, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 968/1000000, train_loss: 39.5776, val_loss: 44.9558, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 969/1000000, train_loss: 39.5532, val_loss: 44.9049, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 970/1000000, train_loss: 39.5342, val_loss: 44.8514, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 971/1000000, train_loss: 39.5122, val_loss: 44.7949, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 972/1000000, train_loss: 39.4881, val_loss: 44.7426, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 973/1000000, train_loss: 39.4661, val_loss: 44.6998, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 974/1000000, train_loss: 39.4355, val_loss: 44.6407, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 975/1000000, train_loss: 39.4111, val_loss: 44.6218, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 976/1000000, train_loss: 39.3882, val_loss: 44.5573, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 977/1000000, train_loss: 39.3565, val_loss: 44.4980, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 978/1000000, train_loss: 39.3436, val_loss: 44.4401, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 979/1000000, train_loss: 39.3199, val_loss: 44.4078, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 980/1000000, train_loss: 39.2988, val_loss: 44.3502, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 981/1000000, train_loss: 39.2690, val_loss: 44.2610, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 982/1000000, train_loss: 39.2534, val_loss: 44.2410, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 983/1000000, train_loss: 39.2159, val_loss: 44.1857, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 984/1000000, train_loss: 39.1991, val_loss: 44.1190, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 985/1000000, train_loss: 39.2022, val_loss: 44.1074, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 986/1000000, train_loss: 39.1546, val_loss: 44.0228, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 987/1000000, train_loss: 39.1302, val_loss: 43.9978, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 988/1000000, train_loss: 39.0944, val_loss: 43.9246, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 989/1000000, train_loss: 39.0718, val_loss: 43.9040, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 990/1000000, train_loss: 39.0482, val_loss: 43.8312, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 991/1000000, train_loss: 39.0271, val_loss: 43.7910, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 992/1000000, train_loss: 39.0062, val_loss: 43.7480, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 993/1000000, train_loss: 38.9804, val_loss: 43.6705, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 994/1000000, train_loss: 38.9588, val_loss: 43.6440, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 995/1000000, train_loss: 39.0320, val_loss: 43.5734, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 996/1000000, train_loss: 38.9701, val_loss: 43.5296, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 997/1000000, train_loss: 38.9142, val_loss: 43.5109, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 998/1000000, train_loss: 38.8777, val_loss: 43.4101, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 999/1000000, train_loss: 39.1766, val_loss: 43.3490, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1000/1000000, train_loss: 38.9183, val_loss: 43.3178, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1001/1000000, train_loss: 38.8488, val_loss: 43.2538, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1002/1000000, train_loss: 38.8065, val_loss: 43.2536, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1003/1000000, train_loss: 38.7921, val_loss: 43.1932, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1004/1000000, train_loss: 38.7647, val_loss: 43.1543, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1005/1000000, train_loss: 38.7329, val_loss: 43.0653, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1006/1000000, train_loss: 38.7060, val_loss: 43.0627, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1007/1000000, train_loss: 38.6858, val_loss: 42.9740, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1008/1000000, train_loss: 38.6477, val_loss: 42.9292, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1009/1000000, train_loss: 38.6216, val_loss: 42.8628, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1010/1000000, train_loss: 38.5870, val_loss: 42.8401, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1011/1000000, train_loss: 38.6167, val_loss: 42.7742, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1012/1000000, train_loss: 38.6279, val_loss: 42.7090, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1013/1000000, train_loss: 38.5590, val_loss: 42.6699, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1014/1000000, train_loss: 38.5030, val_loss: 42.6345, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1015/1000000, train_loss: 38.4818, val_loss: 42.5804, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1016/1000000, train_loss: 38.4555, val_loss: 42.5337, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1017/1000000, train_loss: 38.4181, val_loss: 42.4764, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1018/1000000, train_loss: 38.4301, val_loss: 42.4278, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1019/1000000, train_loss: 38.3771, val_loss: 42.3729, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1020/1000000, train_loss: 38.3466, val_loss: 42.3098, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1021/1000000, train_loss: 38.3508, val_loss: 42.2597, time: 0.37s\n",
      "Epoch 1022/1000000, train_loss: 38.2987, val_loss: 42.2671, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1023/1000000, train_loss: 38.2740, val_loss: 42.1767, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1024/1000000, train_loss: 38.7079, val_loss: 42.0774, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1025/1000000, train_loss: 38.7502, val_loss: 42.0487, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1026/1000000, train_loss: 38.3837, val_loss: 42.0438, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1027/1000000, train_loss: 38.3078, val_loss: 41.9796, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1028/1000000, train_loss: 38.2396, val_loss: 41.8912, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1029/1000000, train_loss: 38.1912, val_loss: 41.8576, time: 0.37s\n",
      "Epoch 1030/1000000, train_loss: 38.9464, val_loss: 54.0259, time: 0.37s\n",
      "Epoch 1031/1000000, train_loss: 39.2070, val_loss: 43.1473, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1032/1000000, train_loss: 38.3485, val_loss: 41.7007, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1033/1000000, train_loss: 38.0973, val_loss: 41.6826, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1034/1000000, train_loss: 38.0599, val_loss: 41.6093, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1035/1000000, train_loss: 38.0222, val_loss: 41.5419, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1036/1000000, train_loss: 37.9958, val_loss: 41.5248, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1037/1000000, train_loss: 37.9715, val_loss: 41.4641, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1038/1000000, train_loss: 37.9422, val_loss: 41.4073, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1039/1000000, train_loss: 37.9252, val_loss: 41.3174, time: 0.38s\n",
      "Epoch 1040/1000000, train_loss: 37.8978, val_loss: 41.3465, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1041/1000000, train_loss: 37.8732, val_loss: 41.2658, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1042/1000000, train_loss: 37.8919, val_loss: 41.2253, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1043/1000000, train_loss: 37.8811, val_loss: 41.1334, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1044/1000000, train_loss: 37.8106, val_loss: 41.0605, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1045/1000000, train_loss: 37.7902, val_loss: 41.0399, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1046/1000000, train_loss: 37.7462, val_loss: 40.9772, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1047/1000000, train_loss: 37.7213, val_loss: 40.9374, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1048/1000000, train_loss: 37.7081, val_loss: 40.9049, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1049/1000000, train_loss: 37.6758, val_loss: 40.8442, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1050/1000000, train_loss: 37.6576, val_loss: 40.7778, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1051/1000000, train_loss: 37.6262, val_loss: 40.7751, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1052/1000000, train_loss: 37.6192, val_loss: 40.6854, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1053/1000000, train_loss: 37.6124, val_loss: 40.6393, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1054/1000000, train_loss: 37.5548, val_loss: 40.6232, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1055/1000000, train_loss: 37.5351, val_loss: 40.5580, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1056/1000000, train_loss: 37.5148, val_loss: 40.5142, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1057/1000000, train_loss: 37.4866, val_loss: 40.4398, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1058/1000000, train_loss: 37.4532, val_loss: 40.3670, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1059/1000000, train_loss: 37.4285, val_loss: 40.3610, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1060/1000000, train_loss: 37.4115, val_loss: 40.3090, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1061/1000000, train_loss: 37.3774, val_loss: 40.2522, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1062/1000000, train_loss: 37.3473, val_loss: 40.1721, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1063/1000000, train_loss: 37.3420, val_loss: 40.1266, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1064/1000000, train_loss: 37.3215, val_loss: 40.1236, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1065/1000000, train_loss: 37.2803, val_loss: 40.0434, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1066/1000000, train_loss: 37.2626, val_loss: 39.9685, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1067/1000000, train_loss: 37.2753, val_loss: 39.8775, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1068/1000000, train_loss: 37.2559, val_loss: 39.8705, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1069/1000000, train_loss: 37.1988, val_loss: 39.8522, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1070/1000000, train_loss: 37.1632, val_loss: 39.8085, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1071/1000000, train_loss: 37.1341, val_loss: 39.7401, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1072/1000000, train_loss: 37.1336, val_loss: 39.6967, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1073/1000000, train_loss: 37.1470, val_loss: 39.6703, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1074/1000000, train_loss: 37.1160, val_loss: 39.5909, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1075/1000000, train_loss: 37.0744, val_loss: 39.5368, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1076/1000000, train_loss: 37.0302, val_loss: 39.5348, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1077/1000000, train_loss: 37.0240, val_loss: 39.4033, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1078/1000000, train_loss: 36.9926, val_loss: 39.3696, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1079/1000000, train_loss: 36.9577, val_loss: 39.2797, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1080/1000000, train_loss: 36.9298, val_loss: 39.2571, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1081/1000000, train_loss: 36.8965, val_loss: 39.1940, time: 0.37s\n",
      "Epoch 1082/1000000, train_loss: 36.8896, val_loss: 39.1992, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1083/1000000, train_loss: 36.8519, val_loss: 39.1202, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1084/1000000, train_loss: 36.8276, val_loss: 39.0747, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1085/1000000, train_loss: 36.8030, val_loss: 39.0031, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1086/1000000, train_loss: 36.7817, val_loss: 38.9431, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1087/1000000, train_loss: 36.7543, val_loss: 38.9172, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1088/1000000, train_loss: 36.7215, val_loss: 38.8716, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1089/1000000, train_loss: 36.7144, val_loss: 38.8136, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1090/1000000, train_loss: 36.6839, val_loss: 38.7648, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1091/1000000, train_loss: 36.6640, val_loss: 38.6922, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1092/1000000, train_loss: 36.6415, val_loss: 38.6467, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1093/1000000, train_loss: 36.5974, val_loss: 38.5934, time: 0.37s\n",
      "Epoch 1094/1000000, train_loss: 36.5846, val_loss: 38.5994, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1095/1000000, train_loss: 36.5546, val_loss: 38.5100, time: 0.37s\n",
      "Epoch 1096/1000000, train_loss: 36.5335, val_loss: 38.5239, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1097/1000000, train_loss: 36.5033, val_loss: 38.4411, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1098/1000000, train_loss: 36.4784, val_loss: 38.3911, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1099/1000000, train_loss: 36.4694, val_loss: 38.3096, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1100/1000000, train_loss: 36.4515, val_loss: 38.2425, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1101/1000000, train_loss: 36.4335, val_loss: 38.1885, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1102/1000000, train_loss: 36.4032, val_loss: 38.1508, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1103/1000000, train_loss: 36.3709, val_loss: 38.1016, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1104/1000000, train_loss: 36.3466, val_loss: 38.0666, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1105/1000000, train_loss: 36.3257, val_loss: 37.9589, time: 0.37s\n",
      "Epoch 1106/1000000, train_loss: 36.2940, val_loss: 37.9822, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1107/1000000, train_loss: 36.2736, val_loss: 37.8862, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1108/1000000, train_loss: 36.2546, val_loss: 37.8541, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1109/1000000, train_loss: 36.2324, val_loss: 37.7787, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1110/1000000, train_loss: 36.2005, val_loss: 37.7706, time: 0.37s\n",
      "Epoch 1111/1000000, train_loss: 36.1775, val_loss: 37.7877, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1112/1000000, train_loss: 36.1406, val_loss: 37.6569, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1113/1000000, train_loss: 36.2326, val_loss: 37.5845, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1114/1000000, train_loss: 36.2808, val_loss: 37.5473, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1115/1000000, train_loss: 36.5033, val_loss: 37.5172, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1116/1000000, train_loss: 36.1715, val_loss: 37.4202, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1117/1000000, train_loss: 36.1026, val_loss: 37.3975, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1118/1000000, train_loss: 36.0545, val_loss: 37.3899, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1119/1000000, train_loss: 36.0279, val_loss: 37.3121, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1120/1000000, train_loss: 35.9915, val_loss: 37.2574, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1121/1000000, train_loss: 35.9747, val_loss: 37.2077, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1122/1000000, train_loss: 36.0517, val_loss: 37.1489, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1123/1000000, train_loss: 35.9568, val_loss: 37.0499, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1124/1000000, train_loss: 35.9725, val_loss: 37.0101, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1125/1000000, train_loss: 35.9070, val_loss: 36.9786, time: 0.37s\n",
      "Epoch 1126/1000000, train_loss: 35.8663, val_loss: 36.9963, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1127/1000000, train_loss: 35.8356, val_loss: 36.8772, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1128/1000000, train_loss: 35.8116, val_loss: 36.8652, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1129/1000000, train_loss: 35.7624, val_loss: 36.7886, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1130/1000000, train_loss: 35.7445, val_loss: 36.7664, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1131/1000000, train_loss: 35.7270, val_loss: 36.6933, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1132/1000000, train_loss: 35.6956, val_loss: 36.6211, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1133/1000000, train_loss: 35.6765, val_loss: 36.5864, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1134/1000000, train_loss: 35.6431, val_loss: 36.5175, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1135/1000000, train_loss: 35.6212, val_loss: 36.4960, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1136/1000000, train_loss: 35.5948, val_loss: 36.4067, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1137/1000000, train_loss: 35.5686, val_loss: 36.3889, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1138/1000000, train_loss: 35.5309, val_loss: 36.3267, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1139/1000000, train_loss: 35.5273, val_loss: 36.3061, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1140/1000000, train_loss: 35.4966, val_loss: 36.2250, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1141/1000000, train_loss: 35.4753, val_loss: 36.1579, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1142/1000000, train_loss: 35.4403, val_loss: 36.0970, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1143/1000000, train_loss: 35.4134, val_loss: 36.0436, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1144/1000000, train_loss: 35.5319, val_loss: 35.9883, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1145/1000000, train_loss: 36.7301, val_loss: 35.9862, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1146/1000000, train_loss: 36.0673, val_loss: 35.9732, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1147/1000000, train_loss: 36.0514, val_loss: 35.8524, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1148/1000000, train_loss: 36.6611, val_loss: 35.8224, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1149/1000000, train_loss: 35.7402, val_loss: 35.7383, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1150/1000000, train_loss: 35.6442, val_loss: 35.7076, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1151/1000000, train_loss: 35.6110, val_loss: 35.6393, time: 0.37s\n",
      "Epoch 1152/1000000, train_loss: 35.5514, val_loss: 35.6418, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1153/1000000, train_loss: 35.4926, val_loss: 35.5577, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1154/1000000, train_loss: 35.4098, val_loss: 35.5460, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1155/1000000, train_loss: 35.2664, val_loss: 35.4719, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1156/1000000, train_loss: 35.1523, val_loss: 35.4625, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1157/1000000, train_loss: 35.1013, val_loss: 35.3427, time: 0.37s\n",
      "Epoch 1158/1000000, train_loss: 35.0760, val_loss: 35.3480, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1159/1000000, train_loss: 35.0422, val_loss: 35.3131, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1160/1000000, train_loss: 35.0275, val_loss: 35.2243, time: 0.37s\n",
      "Epoch 1161/1000000, train_loss: 34.9925, val_loss: 35.2307, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1162/1000000, train_loss: 34.9708, val_loss: 35.1267, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1163/1000000, train_loss: 34.9397, val_loss: 35.0686, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1164/1000000, train_loss: 34.9210, val_loss: 35.0305, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1165/1000000, train_loss: 34.8890, val_loss: 34.9689, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1166/1000000, train_loss: 34.8663, val_loss: 34.9421, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1167/1000000, train_loss: 34.8473, val_loss: 34.8201, time: 0.38s\n",
      "Epoch 1168/1000000, train_loss: 34.8284, val_loss: 34.8424, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1169/1000000, train_loss: 34.7908, val_loss: 34.8000, time: 0.38s\n",
      "Epoch 1170/1000000, train_loss: 34.7725, val_loss: 34.8211, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1171/1000000, train_loss: 34.7587, val_loss: 34.6875, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1172/1000000, train_loss: 34.7303, val_loss: 34.6210, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1173/1000000, train_loss: 34.7070, val_loss: 34.5535, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1174/1000000, train_loss: 34.6700, val_loss: 34.5055, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1175/1000000, train_loss: 34.6637, val_loss: 34.4320, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1176/1000000, train_loss: 34.6311, val_loss: 34.3973, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1177/1000000, train_loss: 34.6058, val_loss: 34.3344, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1178/1000000, train_loss: 34.7340, val_loss: 34.2629, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1179/1000000, train_loss: 34.9454, val_loss: 34.2211, time: 0.37s\n",
      "Epoch 1180/1000000, train_loss: 34.6371, val_loss: 34.2261, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1181/1000000, train_loss: 34.5374, val_loss: 34.2084, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1182/1000000, train_loss: 34.4953, val_loss: 34.1052, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1183/1000000, train_loss: 34.4692, val_loss: 34.0868, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1184/1000000, train_loss: 34.4516, val_loss: 33.9712, time: 0.38s\n",
      "Epoch 1185/1000000, train_loss: 34.4253, val_loss: 33.9827, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1186/1000000, train_loss: 34.3949, val_loss: 33.9170, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1187/1000000, train_loss: 34.3738, val_loss: 33.8581, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1188/1000000, train_loss: 34.3463, val_loss: 33.8277, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1189/1000000, train_loss: 34.3250, val_loss: 33.7294, time: 0.37s\n",
      "Epoch 1190/1000000, train_loss: 34.3044, val_loss: 33.7674, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1191/1000000, train_loss: 34.2719, val_loss: 33.5990, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1192/1000000, train_loss: 34.2581, val_loss: 33.5864, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1193/1000000, train_loss: 34.2286, val_loss: 33.5051, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1194/1000000, train_loss: 34.2049, val_loss: 33.4792, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1195/1000000, train_loss: 34.1777, val_loss: 33.4753, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1196/1000000, train_loss: 34.1542, val_loss: 33.3963, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1197/1000000, train_loss: 34.1291, val_loss: 33.2983, time: 0.38s\n",
      "Epoch 1198/1000000, train_loss: 34.1279, val_loss: 33.3749, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1199/1000000, train_loss: 34.0855, val_loss: 33.2610, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1200/1000000, train_loss: 34.0599, val_loss: 33.2002, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1201/1000000, train_loss: 34.0241, val_loss: 33.1828, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1202/1000000, train_loss: 34.0080, val_loss: 33.0767, time: 0.37s\n",
      "Epoch 1203/1000000, train_loss: 33.9747, val_loss: 33.0837, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1204/1000000, train_loss: 33.9568, val_loss: 32.9791, time: 0.38s\n",
      "Epoch 1205/1000000, train_loss: 33.9342, val_loss: 32.9842, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1206/1000000, train_loss: 33.9075, val_loss: 32.8868, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1207/1000000, train_loss: 33.9000, val_loss: 32.8274, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1208/1000000, train_loss: 33.8677, val_loss: 32.7659, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1209/1000000, train_loss: 33.8425, val_loss: 32.6978, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1210/1000000, train_loss: 34.2204, val_loss: 32.6935, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1211/1000000, train_loss: 34.1304, val_loss: 32.6738, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1212/1000000, train_loss: 33.9555, val_loss: 32.6183, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1213/1000000, train_loss: 33.8024, val_loss: 32.5222, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1214/1000000, train_loss: 33.7473, val_loss: 32.4652, time: 0.38s\n",
      "Epoch 1215/1000000, train_loss: 33.7070, val_loss: 32.4797, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1216/1000000, train_loss: 33.6963, val_loss: 32.3551, time: 0.38s\n",
      "Epoch 1217/1000000, train_loss: 33.6645, val_loss: 32.4307, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1218/1000000, train_loss: 33.6346, val_loss: 32.2976, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1219/1000000, train_loss: 33.6187, val_loss: 32.2712, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1220/1000000, train_loss: 33.5866, val_loss: 32.2387, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1221/1000000, train_loss: 33.5593, val_loss: 32.1928, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1222/1000000, train_loss: 33.5341, val_loss: 32.0893, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1223/1000000, train_loss: 33.5331, val_loss: 32.0395, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1224/1000000, train_loss: 33.5208, val_loss: 32.0026, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1225/1000000, train_loss: 33.5085, val_loss: 31.9857, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1226/1000000, train_loss: 33.4664, val_loss: 31.8950, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1227/1000000, train_loss: 33.4428, val_loss: 31.8156, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1228/1000000, train_loss: 33.3996, val_loss: 31.8021, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1229/1000000, train_loss: 33.3809, val_loss: 31.6993, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1230/1000000, train_loss: 33.3508, val_loss: 31.6248, time: 0.35s\n",
      "Epoch 1231/1000000, train_loss: 33.4738, val_loss: 31.6907, time: 0.36s\n",
      "Epoch 1232/1000000, train_loss: 34.4619, val_loss: 31.6512, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1233/1000000, train_loss: 33.8920, val_loss: 31.4650, time: 0.35s\n",
      "Epoch 1234/1000000, train_loss: 33.6961, val_loss: 31.5335, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1235/1000000, train_loss: 33.6187, val_loss: 31.4648, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1236/1000000, train_loss: 33.5616, val_loss: 31.4373, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1237/1000000, train_loss: 33.5148, val_loss: 31.3594, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1238/1000000, train_loss: 33.4962, val_loss: 31.2550, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1239/1000000, train_loss: 33.4003, val_loss: 31.2197, time: 0.35s\n",
      "Epoch 1240/1000000, train_loss: 33.3722, val_loss: 31.2529, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1241/1000000, train_loss: 33.3810, val_loss: 31.1227, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1242/1000000, train_loss: 33.4339, val_loss: 31.0796, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1243/1000000, train_loss: 33.3518, val_loss: 30.9658, time: 0.36s\n",
      "Epoch 1244/1000000, train_loss: 33.3129, val_loss: 31.0108, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1245/1000000, train_loss: 33.3320, val_loss: 30.8637, time: 0.35s\n",
      "Epoch 1246/1000000, train_loss: 33.1945, val_loss: 30.9506, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1247/1000000, train_loss: 32.9917, val_loss: 30.7882, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1248/1000000, train_loss: 32.9556, val_loss: 30.7818, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1249/1000000, train_loss: 32.9284, val_loss: 30.6993, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1250/1000000, train_loss: 32.9019, val_loss: 30.6181, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1251/1000000, train_loss: 32.8686, val_loss: 30.5949, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1252/1000000, train_loss: 32.8481, val_loss: 30.5869, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1253/1000000, train_loss: 32.8120, val_loss: 30.5096, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1254/1000000, train_loss: 32.7996, val_loss: 30.5017, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1255/1000000, train_loss: 32.7758, val_loss: 30.3451, time: 0.35s\n",
      "Epoch 1256/1000000, train_loss: 32.7470, val_loss: 30.4005, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1257/1000000, train_loss: 32.7218, val_loss: 30.3210, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1258/1000000, train_loss: 32.6907, val_loss: 30.2789, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1259/1000000, train_loss: 32.6697, val_loss: 30.2273, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1260/1000000, train_loss: 32.6346, val_loss: 30.1728, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1261/1000000, train_loss: 32.6193, val_loss: 30.1056, time: 0.36s\n",
      "Epoch 1262/1000000, train_loss: 32.5958, val_loss: 30.1321, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1263/1000000, train_loss: 32.5689, val_loss: 29.9851, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1264/1000000, train_loss: 32.5525, val_loss: 29.9196, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1265/1000000, train_loss: 32.5206, val_loss: 29.9098, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1266/1000000, train_loss: 32.4978, val_loss: 29.8435, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1267/1000000, train_loss: 32.4685, val_loss: 29.7880, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1268/1000000, train_loss: 32.4523, val_loss: 29.7098, time: 0.36s\n",
      "Epoch 1269/1000000, train_loss: 32.4187, val_loss: 29.7534, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1270/1000000, train_loss: 32.4001, val_loss: 29.6486, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1271/1000000, train_loss: 32.3778, val_loss: 29.5953, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1272/1000000, train_loss: 32.3610, val_loss: 29.5764, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1273/1000000, train_loss: 32.4492, val_loss: 29.5187, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1274/1000000, train_loss: 32.9355, val_loss: 29.4392, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1275/1000000, train_loss: 32.7090, val_loss: 29.3365, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1276/1000000, train_loss: 32.4351, val_loss: 29.3135, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1277/1000000, train_loss: 32.3625, val_loss: 29.2235, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1278/1000000, train_loss: 32.3260, val_loss: 29.2151, time: 0.36s\n",
      "Epoch 1279/1000000, train_loss: 32.3028, val_loss: 29.2352, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1280/1000000, train_loss: 32.2624, val_loss: 29.1938, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1281/1000000, train_loss: 32.2563, val_loss: 28.9902, time: 0.35s\n",
      "Epoch 1282/1000000, train_loss: 32.2279, val_loss: 29.1102, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1283/1000000, train_loss: 32.2074, val_loss: 28.9448, time: 0.35s\n",
      "Epoch 1284/1000000, train_loss: 32.1606, val_loss: 29.0089, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1285/1000000, train_loss: 32.1483, val_loss: 28.8900, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1286/1000000, train_loss: 32.2395, val_loss: 28.8829, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1287/1000000, train_loss: 32.0134, val_loss: 28.7032, time: 0.36s\n",
      "Epoch 1288/1000000, train_loss: 32.0074, val_loss: 28.7676, time: 0.35s\n",
      "Epoch 1289/1000000, train_loss: 31.9628, val_loss: 28.8221, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1290/1000000, train_loss: 31.9485, val_loss: 28.6876, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1291/1000000, train_loss: 31.9200, val_loss: 28.6230, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1292/1000000, train_loss: 31.8939, val_loss: 28.6138, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1293/1000000, train_loss: 31.8599, val_loss: 28.4964, time: 0.36s\n",
      "Epoch 1294/1000000, train_loss: 31.8705, val_loss: 28.5071, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1295/1000000, train_loss: 31.8153, val_loss: 28.3522, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1296/1000000, train_loss: 31.7901, val_loss: 28.1411, time: 0.36s\n",
      "Epoch 1297/1000000, train_loss: 31.7617, val_loss: 28.1890, time: 0.36s\n",
      "Epoch 1298/1000000, train_loss: 31.7375, val_loss: 28.2060, time: 0.35s\n",
      "Epoch 1299/1000000, train_loss: 31.7173, val_loss: 28.2679, time: 0.35s\n",
      "Epoch 1300/1000000, train_loss: 31.7003, val_loss: 28.1851, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1301/1000000, train_loss: 31.6756, val_loss: 28.0945, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1302/1000000, train_loss: 31.6373, val_loss: 28.0039, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1303/1000000, train_loss: 31.6212, val_loss: 28.0020, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1304/1000000, train_loss: 31.5939, val_loss: 27.9341, time: 0.35s\n",
      "Epoch 1305/1000000, train_loss: 31.5752, val_loss: 27.9423, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1306/1000000, train_loss: 31.5421, val_loss: 27.8601, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1307/1000000, train_loss: 31.5231, val_loss: 27.8222, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1308/1000000, train_loss: 31.5033, val_loss: 27.7296, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1309/1000000, train_loss: 31.4647, val_loss: 27.6320, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1310/1000000, train_loss: 31.4415, val_loss: 27.5653, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1311/1000000, train_loss: 31.4245, val_loss: 27.5502, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1312/1000000, train_loss: 31.3877, val_loss: 27.4562, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1313/1000000, train_loss: 31.3713, val_loss: 27.4460, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1314/1000000, train_loss: 31.3399, val_loss: 27.3907, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1315/1000000, train_loss: 31.3266, val_loss: 27.3903, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1316/1000000, train_loss: 31.2945, val_loss: 27.3781, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1317/1000000, train_loss: 31.2736, val_loss: 27.3687, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1318/1000000, train_loss: 31.2674, val_loss: 27.2192, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1319/1000000, train_loss: 31.3942, val_loss: 27.1649, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1320/1000000, train_loss: 31.2840, val_loss: 27.1181, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1321/1000000, train_loss: 31.2483, val_loss: 27.0797, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1322/1000000, train_loss: 31.2866, val_loss: 26.9647, time: 0.35s\n",
      "Epoch 1323/1000000, train_loss: 31.2535, val_loss: 26.9941, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1324/1000000, train_loss: 31.2191, val_loss: 26.9378, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1325/1000000, train_loss: 31.2112, val_loss: 26.8872, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1326/1000000, train_loss: 31.1538, val_loss: 26.8141, time: 0.35s\n",
      "Epoch 1327/1000000, train_loss: 31.1188, val_loss: 26.8351, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1328/1000000, train_loss: 31.0613, val_loss: 26.6364, time: 0.35s\n",
      "Epoch 1329/1000000, train_loss: 31.1181, val_loss: 26.7059, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1330/1000000, train_loss: 31.0823, val_loss: 26.5949, time: 0.36s\n",
      "Epoch 1331/1000000, train_loss: 31.0225, val_loss: 26.6090, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1332/1000000, train_loss: 31.0052, val_loss: 26.5648, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1333/1000000, train_loss: 31.0004, val_loss: 26.4477, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1334/1000000, train_loss: 30.9507, val_loss: 26.4043, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1335/1000000, train_loss: 30.9068, val_loss: 26.3546, time: 0.40s\n",
      "Epoch 1336/1000000, train_loss: 30.8795, val_loss: 26.4775, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1337/1000000, train_loss: 30.8540, val_loss: 26.2323, time: 0.35s\n",
      "Epoch 1338/1000000, train_loss: 30.8406, val_loss: 26.2790, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1339/1000000, train_loss: 30.9309, val_loss: 26.1782, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1340/1000000, train_loss: 30.7908, val_loss: 26.0082, time: 0.35s\n",
      "Epoch 1341/1000000, train_loss: 30.7403, val_loss: 26.0296, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1342/1000000, train_loss: 30.7368, val_loss: 26.0031, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1343/1000000, train_loss: 30.6936, val_loss: 25.9359, time: 0.35s\n",
      "Epoch 1344/1000000, train_loss: 30.7011, val_loss: 25.9383, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1345/1000000, train_loss: 30.8964, val_loss: 25.8073, time: 0.36s\n",
      "Epoch 1346/1000000, train_loss: 30.6426, val_loss: 25.8337, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1347/1000000, train_loss: 30.7547, val_loss: 25.7147, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1348/1000000, train_loss: 30.5891, val_loss: 25.6844, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1349/1000000, train_loss: 30.5419, val_loss: 25.5654, time: 0.36s\n",
      "Epoch 1350/1000000, train_loss: 30.5211, val_loss: 25.5775, time: 0.35s\n",
      "Epoch 1351/1000000, train_loss: 30.4922, val_loss: 25.6275, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1352/1000000, train_loss: 30.4520, val_loss: 25.5616, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1353/1000000, train_loss: 30.4187, val_loss: 25.3969, time: 0.35s\n",
      "Epoch 1354/1000000, train_loss: 30.4055, val_loss: 25.4535, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1355/1000000, train_loss: 30.3721, val_loss: 25.3392, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1356/1000000, train_loss: 30.3544, val_loss: 25.3038, time: 0.35s\n",
      "Epoch 1357/1000000, train_loss: 30.3216, val_loss: 25.3114, time: 0.35s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1358/1000000, train_loss: 30.3162, val_loss: 25.1311, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1359/1000000, train_loss: 30.2816, val_loss: 25.0748, time: 0.36s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1360/1000000, train_loss: 30.2529, val_loss: 25.0701, time: 0.36s\n",
      "Epoch 1361/1000000, train_loss: 30.2299, val_loss: 25.0746, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1362/1000000, train_loss: 30.2062, val_loss: 24.9838, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1363/1000000, train_loss: 30.1805, val_loss: 24.9626, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1364/1000000, train_loss: 30.1485, val_loss: 24.8490, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1365/1000000, train_loss: 30.1373, val_loss: 24.8434, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1366/1000000, train_loss: 30.1026, val_loss: 24.8160, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1367/1000000, train_loss: 30.0783, val_loss: 24.7134, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1368/1000000, train_loss: 30.0576, val_loss: 24.6234, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1369/1000000, train_loss: 30.0375, val_loss: 24.5971, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1370/1000000, train_loss: 30.0077, val_loss: 24.5816, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1371/1000000, train_loss: 29.9775, val_loss: 24.4270, time: 0.38s\n",
      "Epoch 1372/1000000, train_loss: 29.9626, val_loss: 24.5552, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1373/1000000, train_loss: 29.9220, val_loss: 24.4206, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1374/1000000, train_loss: 29.9118, val_loss: 24.4052, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1375/1000000, train_loss: 29.9067, val_loss: 24.2577, time: 0.37s\n",
      "Epoch 1376/1000000, train_loss: 29.8625, val_loss: 24.3562, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1377/1000000, train_loss: 29.8444, val_loss: 24.2167, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1378/1000000, train_loss: 29.8143, val_loss: 24.1765, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1379/1000000, train_loss: 29.8154, val_loss: 24.1299, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1380/1000000, train_loss: 29.7876, val_loss: 24.0635, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1381/1000000, train_loss: 29.7518, val_loss: 23.9814, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1382/1000000, train_loss: 29.7305, val_loss: 23.9367, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1383/1000000, train_loss: 29.6931, val_loss: 23.8706, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1384/1000000, train_loss: 29.6640, val_loss: 23.7889, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1385/1000000, train_loss: 29.6475, val_loss: 23.7451, time: 0.38s\n",
      "Epoch 1386/1000000, train_loss: 29.6244, val_loss: 23.7689, time: 0.38s\n",
      "Epoch 1387/1000000, train_loss: 29.5877, val_loss: 23.7509, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1388/1000000, train_loss: 29.5729, val_loss: 23.6705, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1389/1000000, train_loss: 29.5542, val_loss: 23.5694, time: 0.39s\n",
      "Epoch 1390/1000000, train_loss: 29.5295, val_loss: 23.6756, time: 0.38s\n",
      "Epoch 1391/1000000, train_loss: 29.5125, val_loss: 23.5919, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1392/1000000, train_loss: 29.4751, val_loss: 23.5221, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1393/1000000, train_loss: 29.4585, val_loss: 23.4297, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1394/1000000, train_loss: 29.4383, val_loss: 23.3964, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1395/1000000, train_loss: 29.5576, val_loss: 23.3300, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1396/1000000, train_loss: 29.4805, val_loss: 23.2262, time: 0.37s\n",
      "Epoch 1397/1000000, train_loss: 29.5212, val_loss: 23.2611, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1398/1000000, train_loss: 29.4555, val_loss: 23.1222, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1399/1000000, train_loss: 29.3747, val_loss: 23.0384, time: 0.37s\n",
      "Epoch 1400/1000000, train_loss: 29.3101, val_loss: 23.1911, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1401/1000000, train_loss: 29.2812, val_loss: 23.0077, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1402/1000000, train_loss: 32.2235, val_loss: 22.8308, time: 0.37s\n",
      "Epoch 1403/1000000, train_loss: 31.1574, val_loss: 22.9253, time: 0.37s\n",
      "Epoch 1404/1000000, train_loss: 29.4945, val_loss: 22.8754, time: 0.37s\n",
      "Epoch 1405/1000000, train_loss: 29.3112, val_loss: 22.8312, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1406/1000000, train_loss: 29.2425, val_loss: 22.8191, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1407/1000000, train_loss: 29.2049, val_loss: 22.7574, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1408/1000000, train_loss: 29.5421, val_loss: 22.6298, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1409/1000000, train_loss: 29.4047, val_loss: 22.5623, time: 0.38s\n",
      "Epoch 1410/1000000, train_loss: 29.2070, val_loss: 22.5641, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1411/1000000, train_loss: 29.1269, val_loss: 22.5318, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1412/1000000, train_loss: 29.0726, val_loss: 22.4102, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1413/1000000, train_loss: 29.0566, val_loss: 22.3371, time: 0.37s\n",
      "Epoch 1414/1000000, train_loss: 28.9998, val_loss: 22.4263, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1415/1000000, train_loss: 28.9712, val_loss: 22.2348, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1416/1000000, train_loss: 28.9400, val_loss: 22.2326, time: 0.43s\n",
      "Epoch 1417/1000000, train_loss: 28.9050, val_loss: 22.2436, time: 0.39s\n",
      "Epoch 1418/1000000, train_loss: 28.8829, val_loss: 22.2440, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1419/1000000, train_loss: 28.8557, val_loss: 22.0569, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1420/1000000, train_loss: 28.8377, val_loss: 22.0017, time: 0.38s\n",
      "Epoch 1421/1000000, train_loss: 28.8034, val_loss: 22.0060, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1422/1000000, train_loss: 28.7850, val_loss: 21.8150, time: 0.38s\n",
      "Epoch 1423/1000000, train_loss: 28.7737, val_loss: 21.8793, time: 0.42s\n",
      "Epoch 1424/1000000, train_loss: 28.7359, val_loss: 21.8549, time: 0.37s\n",
      "Epoch 1425/1000000, train_loss: 28.7073, val_loss: 21.9051, time: 0.37s\n",
      "Epoch 1426/1000000, train_loss: 28.6823, val_loss: 21.8268, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1427/1000000, train_loss: 28.6522, val_loss: 21.6019, time: 0.38s\n",
      "Epoch 1428/1000000, train_loss: 28.6327, val_loss: 21.7946, time: 0.39s\n",
      "Epoch 1429/1000000, train_loss: 28.6251, val_loss: 21.6755, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1430/1000000, train_loss: 28.6174, val_loss: 21.5577, time: 0.39s\n",
      "Epoch 1431/1000000, train_loss: 28.5898, val_loss: 21.6285, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1432/1000000, train_loss: 28.5567, val_loss: 21.4494, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1433/1000000, train_loss: 28.5364, val_loss: 21.4229, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1434/1000000, train_loss: 28.5080, val_loss: 21.3420, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1435/1000000, train_loss: 28.4756, val_loss: 21.2671, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1436/1000000, train_loss: 28.4485, val_loss: 21.2289, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1437/1000000, train_loss: 28.4246, val_loss: 21.1666, time: 0.38s\n",
      "Epoch 1438/1000000, train_loss: 28.3929, val_loss: 21.2442, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1439/1000000, train_loss: 28.3673, val_loss: 21.0521, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1440/1000000, train_loss: 28.9470, val_loss: 21.0152, time: 0.38s\n",
      "Epoch 1441/1000000, train_loss: 29.8580, val_loss: 21.1000, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1442/1000000, train_loss: 28.7871, val_loss: 20.9425, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1443/1000000, train_loss: 28.5605, val_loss: 20.8880, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1444/1000000, train_loss: 28.4889, val_loss: 20.7965, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1445/1000000, train_loss: 28.4310, val_loss: 20.7169, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1446/1000000, train_loss: 28.3182, val_loss: 20.6601, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1447/1000000, train_loss: 28.2903, val_loss: 20.6563, time: 0.38s\n",
      "Epoch 1448/1000000, train_loss: 28.2458, val_loss: 20.6599, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1449/1000000, train_loss: 28.2088, val_loss: 20.5526, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1450/1000000, train_loss: 28.1836, val_loss: 20.5051, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1451/1000000, train_loss: 28.1435, val_loss: 20.4224, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1452/1000000, train_loss: 28.1060, val_loss: 20.4131, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1453/1000000, train_loss: 28.0797, val_loss: 20.3689, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1454/1000000, train_loss: 28.0333, val_loss: 20.2687, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1455/1000000, train_loss: 28.0099, val_loss: 20.2392, time: 0.38s\n",
      "Epoch 1456/1000000, train_loss: 27.9830, val_loss: 20.4131, time: 0.37s\n",
      "Epoch 1457/1000000, train_loss: 27.9595, val_loss: 20.2630, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1458/1000000, train_loss: 27.9275, val_loss: 20.1874, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1459/1000000, train_loss: 27.9621, val_loss: 20.1251, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1460/1000000, train_loss: 27.9373, val_loss: 20.0444, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1461/1000000, train_loss: 27.8985, val_loss: 19.9608, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1462/1000000, train_loss: 27.8850, val_loss: 19.8229, time: 0.38s\n",
      "Epoch 1463/1000000, train_loss: 27.8544, val_loss: 19.9770, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1464/1000000, train_loss: 27.8260, val_loss: 19.8163, time: 0.38s\n",
      "Epoch 1465/1000000, train_loss: 27.7761, val_loss: 19.8206, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1466/1000000, train_loss: 27.7480, val_loss: 19.7171, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1467/1000000, train_loss: 27.7065, val_loss: 19.6952, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1468/1000000, train_loss: 27.6911, val_loss: 19.5587, time: 0.38s\n",
      "Epoch 1469/1000000, train_loss: 27.6653, val_loss: 19.6189, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1470/1000000, train_loss: 27.6424, val_loss: 19.4605, time: 0.38s\n",
      "Epoch 1471/1000000, train_loss: 27.6219, val_loss: 19.5418, time: 0.38s\n",
      "Epoch 1472/1000000, train_loss: 27.5934, val_loss: 19.4727, time: 0.38s\n",
      "Epoch 1473/1000000, train_loss: 27.5672, val_loss: 19.5035, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1474/1000000, train_loss: 27.5387, val_loss: 19.2782, time: 0.40s\n",
      "Epoch 1475/1000000, train_loss: 27.5202, val_loss: 19.4625, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1476/1000000, train_loss: 27.4857, val_loss: 19.0815, time: 0.38s\n",
      "Epoch 1477/1000000, train_loss: 27.4766, val_loss: 19.1693, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1478/1000000, train_loss: 27.4347, val_loss: 19.0187, time: 0.38s\n",
      "Epoch 1479/1000000, train_loss: 27.4105, val_loss: 19.0489, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1480/1000000, train_loss: 27.3823, val_loss: 18.9485, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1481/1000000, train_loss: 27.3588, val_loss: 18.8843, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1482/1000000, train_loss: 27.3400, val_loss: 18.8519, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1483/1000000, train_loss: 27.3133, val_loss: 18.8266, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1484/1000000, train_loss: 27.3038, val_loss: 18.7634, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1485/1000000, train_loss: 27.2632, val_loss: 18.7372, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1486/1000000, train_loss: 27.2507, val_loss: 18.6987, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1487/1000000, train_loss: 27.2229, val_loss: 18.6299, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1488/1000000, train_loss: 27.2153, val_loss: 18.4456, time: 0.43s\n",
      "Epoch 1489/1000000, train_loss: 27.1983, val_loss: 18.5499, time: 0.38s\n",
      "Epoch 1490/1000000, train_loss: 27.1880, val_loss: 18.4906, time: 0.38s\n",
      "Epoch 1491/1000000, train_loss: 27.1555, val_loss: 18.4590, time: 0.38s\n",
      "Epoch 1492/1000000, train_loss: 27.1052, val_loss: 18.4506, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1493/1000000, train_loss: 27.0759, val_loss: 18.2780, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1494/1000000, train_loss: 27.0481, val_loss: 18.2734, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1495/1000000, train_loss: 27.0253, val_loss: 18.1836, time: 0.38s\n",
      "Epoch 1496/1000000, train_loss: 26.9920, val_loss: 18.2322, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1497/1000000, train_loss: 26.9818, val_loss: 18.1411, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1498/1000000, train_loss: 26.9581, val_loss: 18.0844, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1499/1000000, train_loss: 26.9321, val_loss: 18.0204, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1500/1000000, train_loss: 26.8999, val_loss: 18.0190, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1501/1000000, train_loss: 26.8735, val_loss: 17.9270, time: 0.37s\n",
      "Epoch 1502/1000000, train_loss: 26.8450, val_loss: 18.0508, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1503/1000000, train_loss: 26.8328, val_loss: 17.9020, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1504/1000000, train_loss: 26.8094, val_loss: 17.8320, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1505/1000000, train_loss: 26.7872, val_loss: 17.7985, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1506/1000000, train_loss: 26.7671, val_loss: 17.6588, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1507/1000000, train_loss: 26.7434, val_loss: 17.6014, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1508/1000000, train_loss: 26.7177, val_loss: 17.5829, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1509/1000000, train_loss: 26.6864, val_loss: 17.5381, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1510/1000000, train_loss: 26.6709, val_loss: 17.3611, time: 0.38s\n",
      "Epoch 1511/1000000, train_loss: 26.6384, val_loss: 17.4834, time: 0.40s\n",
      "Epoch 1512/1000000, train_loss: 26.6099, val_loss: 17.3673, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1513/1000000, train_loss: 26.5906, val_loss: 17.3570, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1514/1000000, train_loss: 26.5689, val_loss: 17.2586, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1515/1000000, train_loss: 26.5522, val_loss: 17.2528, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1516/1000000, train_loss: 26.5249, val_loss: 17.1966, time: 0.37s\n",
      "Epoch 1517/1000000, train_loss: 26.5083, val_loss: 17.2141, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1518/1000000, train_loss: 26.4831, val_loss: 17.0544, time: 0.37s\n",
      "Epoch 1519/1000000, train_loss: 26.4536, val_loss: 17.0577, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1520/1000000, train_loss: 26.4272, val_loss: 16.8854, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1521/1000000, train_loss: 26.3889, val_loss: 16.8611, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1522/1000000, train_loss: 26.3756, val_loss: 16.8188, time: 0.38s\n",
      "Epoch 1523/1000000, train_loss: 26.3563, val_loss: 16.8532, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1524/1000000, train_loss: 26.3188, val_loss: 16.6288, time: 0.38s\n",
      "Epoch 1525/1000000, train_loss: 26.2982, val_loss: 16.7534, time: 0.37s\n",
      "Epoch 1526/1000000, train_loss: 26.2696, val_loss: 16.6880, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1527/1000000, train_loss: 26.2649, val_loss: 16.5372, time: 0.38s\n",
      "Epoch 1528/1000000, train_loss: 26.2716, val_loss: 16.5874, time: 0.37s\n",
      "Epoch 1529/1000000, train_loss: 26.2225, val_loss: 16.5458, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1530/1000000, train_loss: 26.1883, val_loss: 16.4266, time: 0.37s\n",
      "Epoch 1531/1000000, train_loss: 26.1628, val_loss: 16.5457, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1532/1000000, train_loss: 26.1319, val_loss: 16.3496, time: 0.38s\n",
      "Epoch 1533/1000000, train_loss: 26.1161, val_loss: 16.5004, time: 0.38s\n",
      "Epoch 1534/1000000, train_loss: 26.1093, val_loss: 16.4018, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1535/1000000, train_loss: 26.0707, val_loss: 16.3097, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1536/1000000, train_loss: 26.0654, val_loss: 16.2682, time: 0.42s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1537/1000000, train_loss: 26.0198, val_loss: 16.2013, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1538/1000000, train_loss: 26.0072, val_loss: 16.1929, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1539/1000000, train_loss: 26.4061, val_loss: 16.0099, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1540/1000000, train_loss: 26.3020, val_loss: 15.9123, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1541/1000000, train_loss: 26.0718, val_loss: 15.8826, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1542/1000000, train_loss: 26.0279, val_loss: 15.8438, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1543/1000000, train_loss: 25.9942, val_loss: 15.7266, time: 0.37s\n",
      "Epoch 1544/1000000, train_loss: 25.9950, val_loss: 15.8775, time: 0.37s\n",
      "Epoch 1545/1000000, train_loss: 25.9333, val_loss: 15.8047, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1546/1000000, train_loss: 25.9018, val_loss: 15.6574, time: 0.37s\n",
      "Epoch 1547/1000000, train_loss: 25.9146, val_loss: 15.6713, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1548/1000000, train_loss: 25.9311, val_loss: 15.4222, time: 0.37s\n",
      "Epoch 1549/1000000, train_loss: 25.8878, val_loss: 15.4696, time: 0.37s\n",
      "Epoch 1550/1000000, train_loss: 25.8235, val_loss: 15.4604, time: 0.37s\n",
      "Epoch 1551/1000000, train_loss: 25.8372, val_loss: 15.5564, time: 0.37s\n",
      "Epoch 1552/1000000, train_loss: 25.7544, val_loss: 15.4636, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1553/1000000, train_loss: 25.7093, val_loss: 15.3174, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1554/1000000, train_loss: 25.6509, val_loss: 15.1782, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1555/1000000, train_loss: 25.6278, val_loss: 15.0885, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1556/1000000, train_loss: 25.5977, val_loss: 15.0215, time: 0.37s\n",
      "Epoch 1557/1000000, train_loss: 25.5711, val_loss: 15.1589, time: 0.37s\n",
      "Epoch 1558/1000000, train_loss: 25.5376, val_loss: 15.1064, time: 0.37s\n",
      "Epoch 1559/1000000, train_loss: 25.5187, val_loss: 15.0879, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1560/1000000, train_loss: 25.5009, val_loss: 14.8682, time: 0.37s\n",
      "Epoch 1561/1000000, train_loss: 25.5068, val_loss: 15.0394, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1562/1000000, train_loss: 25.4427, val_loss: 14.7968, time: 0.37s\n",
      "Epoch 1563/1000000, train_loss: 25.4130, val_loss: 14.8812, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1564/1000000, train_loss: 25.4107, val_loss: 14.6378, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1565/1000000, train_loss: 25.3839, val_loss: 14.5514, time: 0.37s\n",
      "Epoch 1566/1000000, train_loss: 25.3584, val_loss: 14.6789, time: 0.37s\n",
      "Epoch 1567/1000000, train_loss: 25.3217, val_loss: 14.6000, time: 0.37s\n",
      "Epoch 1568/1000000, train_loss: 25.2884, val_loss: 14.6199, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1569/1000000, train_loss: 25.2710, val_loss: 14.4479, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1570/1000000, train_loss: 25.2463, val_loss: 14.4047, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1571/1000000, train_loss: 25.2172, val_loss: 14.3977, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1572/1000000, train_loss: 25.1887, val_loss: 14.1796, time: 0.37s\n",
      "Epoch 1573/1000000, train_loss: 25.1787, val_loss: 14.2014, time: 0.37s\n",
      "Epoch 1574/1000000, train_loss: 25.1669, val_loss: 14.1995, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1575/1000000, train_loss: 25.1325, val_loss: 14.0762, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1576/1000000, train_loss: 25.1236, val_loss: 14.0606, time: 0.37s\n",
      "Epoch 1577/1000000, train_loss: 25.0878, val_loss: 14.1554, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1578/1000000, train_loss: 25.0600, val_loss: 14.0352, time: 0.37s\n",
      "Epoch 1579/1000000, train_loss: 25.0310, val_loss: 14.0690, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1580/1000000, train_loss: 25.0076, val_loss: 13.8797, time: 0.37s\n",
      "Epoch 1581/1000000, train_loss: 24.9744, val_loss: 13.9128, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1582/1000000, train_loss: 24.9551, val_loss: 13.7974, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1583/1000000, train_loss: 25.0432, val_loss: 13.7628, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1584/1000000, train_loss: 25.0189, val_loss: 13.7254, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1585/1000000, train_loss: 24.9183, val_loss: 13.6860, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1586/1000000, train_loss: 24.8723, val_loss: 13.6370, time: 0.37s\n",
      "Epoch 1587/1000000, train_loss: 24.8476, val_loss: 13.6529, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1588/1000000, train_loss: 24.7967, val_loss: 13.5115, time: 0.37s\n",
      "Epoch 1589/1000000, train_loss: 24.7859, val_loss: 13.5739, time: 0.37s\n",
      "Epoch 1590/1000000, train_loss: 24.7620, val_loss: 13.5279, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1591/1000000, train_loss: 24.7304, val_loss: 13.2860, time: 0.37s\n",
      "Epoch 1592/1000000, train_loss: 24.7138, val_loss: 13.3601, time: 0.37s\n",
      "Epoch 1593/1000000, train_loss: 24.6901, val_loss: 13.3463, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1594/1000000, train_loss: 24.6654, val_loss: 13.1327, time: 0.37s\n",
      "Epoch 1595/1000000, train_loss: 24.6299, val_loss: 13.1551, time: 0.42s\n",
      "Epoch 1596/1000000, train_loss: 24.6230, val_loss: 13.3080, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1597/1000000, train_loss: 24.5904, val_loss: 13.0269, time: 0.37s\n",
      "Epoch 1598/1000000, train_loss: 24.5746, val_loss: 13.0488, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1599/1000000, train_loss: 24.5412, val_loss: 12.8700, time: 0.37s\n",
      "Epoch 1600/1000000, train_loss: 24.5197, val_loss: 12.9163, time: 0.37s\n",
      "Epoch 1601/1000000, train_loss: 24.4947, val_loss: 12.9512, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1602/1000000, train_loss: 24.4648, val_loss: 12.7483, time: 0.37s\n",
      "Epoch 1603/1000000, train_loss: 24.4382, val_loss: 12.8574, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1604/1000000, train_loss: 24.4410, val_loss: 12.6839, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1605/1000000, train_loss: 24.3976, val_loss: 12.5857, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1606/1000000, train_loss: 24.3736, val_loss: 12.5651, time: 0.37s\n",
      "Epoch 1607/1000000, train_loss: 24.3455, val_loss: 12.6521, time: 0.37s\n",
      "Epoch 1608/1000000, train_loss: 24.3242, val_loss: 12.6045, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1609/1000000, train_loss: 24.3037, val_loss: 12.4371, time: 0.37s\n",
      "Epoch 1610/1000000, train_loss: 24.2721, val_loss: 12.5333, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1611/1000000, train_loss: 24.2458, val_loss: 12.3516, time: 0.37s\n",
      "Epoch 1612/1000000, train_loss: 24.2273, val_loss: 12.4082, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1613/1000000, train_loss: 24.2077, val_loss: 12.1718, time: 0.37s\n",
      "Epoch 1614/1000000, train_loss: 24.1690, val_loss: 12.2999, time: 0.37s\n",
      "Epoch 1615/1000000, train_loss: 24.1518, val_loss: 12.1940, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1616/1000000, train_loss: 24.1243, val_loss: 12.1341, time: 0.37s\n",
      "Epoch 1617/1000000, train_loss: 24.1103, val_loss: 12.2388, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1618/1000000, train_loss: 24.0880, val_loss: 11.9901, time: 0.37s\n",
      "Epoch 1619/1000000, train_loss: 24.0584, val_loss: 12.0377, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1620/1000000, train_loss: 24.0384, val_loss: 11.8700, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1621/1000000, train_loss: 24.0233, val_loss: 11.7270, time: 0.37s\n",
      "Epoch 1622/1000000, train_loss: 23.9892, val_loss: 11.8557, time: 0.37s\n",
      "Epoch 1623/1000000, train_loss: 23.9690, val_loss: 11.7730, time: 0.37s\n",
      "Epoch 1624/1000000, train_loss: 23.9383, val_loss: 11.8769, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1625/1000000, train_loss: 23.9104, val_loss: 11.6347, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1626/1000000, train_loss: 23.8927, val_loss: 11.5900, time: 0.37s\n",
      "Epoch 1627/1000000, train_loss: 23.8606, val_loss: 11.6474, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1628/1000000, train_loss: 23.8386, val_loss: 11.5730, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1629/1000000, train_loss: 23.8054, val_loss: 11.3592, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1630/1000000, train_loss: 23.7907, val_loss: 11.3246, time: 0.37s\n",
      "Epoch 1631/1000000, train_loss: 23.7889, val_loss: 11.3897, time: 0.37s\n",
      "Epoch 1632/1000000, train_loss: 23.7485, val_loss: 11.4026, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1633/1000000, train_loss: 23.7246, val_loss: 11.1485, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1634/1000000, train_loss: 23.7068, val_loss: 11.1123, time: 0.37s\n",
      "Epoch 1635/1000000, train_loss: 23.6886, val_loss: 11.1806, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1636/1000000, train_loss: 23.6545, val_loss: 10.8445, time: 0.37s\n",
      "Epoch 1637/1000000, train_loss: 23.6262, val_loss: 10.9823, time: 0.37s\n",
      "Epoch 1638/1000000, train_loss: 23.6047, val_loss: 11.0042, time: 0.37s\n",
      "Epoch 1639/1000000, train_loss: 23.5779, val_loss: 11.1031, time: 0.37s\n",
      "Epoch 1640/1000000, train_loss: 23.5486, val_loss: 10.8641, time: 0.37s\n",
      "Epoch 1641/1000000, train_loss: 23.5356, val_loss: 10.9549, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1642/1000000, train_loss: 23.5085, val_loss: 10.7552, time: 0.41s\n",
      "Epoch 1643/1000000, train_loss: 23.4845, val_loss: 10.7672, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1644/1000000, train_loss: 23.4590, val_loss: 10.7249, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1645/1000000, train_loss: 23.4586, val_loss: 10.6486, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1646/1000000, train_loss: 23.4143, val_loss: 10.6405, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1647/1000000, train_loss: 23.3824, val_loss: 10.5544, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1648/1000000, train_loss: 23.3782, val_loss: 10.4797, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1649/1000000, train_loss: 23.3438, val_loss: 10.4694, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1650/1000000, train_loss: 23.3280, val_loss: 10.3799, time: 0.37s\n",
      "Epoch 1651/1000000, train_loss: 23.3048, val_loss: 10.5119, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1652/1000000, train_loss: 23.2645, val_loss: 10.2391, time: 0.37s\n",
      "Epoch 1653/1000000, train_loss: 23.2519, val_loss: 10.2793, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1654/1000000, train_loss: 23.2208, val_loss: 10.1694, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1655/1000000, train_loss: 23.1857, val_loss: 10.1188, time: 0.37s\n",
      "Epoch 1656/1000000, train_loss: 23.1630, val_loss: 10.2049, time: 0.41s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1657/1000000, train_loss: 23.1529, val_loss: 9.9172, time: 0.37s\n",
      "Epoch 1658/1000000, train_loss: 23.1288, val_loss: 9.9663, time: 0.37s\n",
      "Epoch 1659/1000000, train_loss: 23.1025, val_loss: 9.9560, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1660/1000000, train_loss: 23.0782, val_loss: 9.8155, time: 0.37s\n",
      "Epoch 1661/1000000, train_loss: 23.0751, val_loss: 9.8378, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1662/1000000, train_loss: 23.0420, val_loss: 9.7123, time: 0.37s\n",
      "Epoch 1663/1000000, train_loss: 23.0026, val_loss: 9.7931, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1664/1000000, train_loss: 22.9939, val_loss: 9.5784, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1665/1000000, train_loss: 22.9692, val_loss: 9.4617, time: 0.37s\n",
      "Epoch 1666/1000000, train_loss: 22.9904, val_loss: 9.5188, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1667/1000000, train_loss: 23.1952, val_loss: 9.4357, time: 0.37s\n",
      "Epoch 1668/1000000, train_loss: 24.0321, val_loss: 9.5977, time: 0.37s\n",
      "Epoch 1669/1000000, train_loss: 23.5790, val_loss: 9.9768, time: 0.37s\n",
      "Epoch 1670/1000000, train_loss: 23.5157, val_loss: 10.1995, time: 0.37s\n",
      "Epoch 1671/1000000, train_loss: 23.3892, val_loss: 10.5222, time: 0.37s\n",
      "Epoch 1672/1000000, train_loss: 23.3133, val_loss: 9.8582, time: 0.37s\n",
      "Epoch 1673/1000000, train_loss: 23.2812, val_loss: 9.5585, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1674/1000000, train_loss: 23.2712, val_loss: 9.3520, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1675/1000000, train_loss: 23.1624, val_loss: 9.1212, time: 0.37s\n",
      "Epoch 1676/1000000, train_loss: 23.1076, val_loss: 9.2769, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1677/1000000, train_loss: 23.0201, val_loss: 9.0648, time: 0.37s\n",
      "Epoch 1678/1000000, train_loss: 22.9828, val_loss: 9.2424, time: 0.37s\n",
      "Epoch 1679/1000000, train_loss: 23.0281, val_loss: 9.1997, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1680/1000000, train_loss: 23.0483, val_loss: 8.9327, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1681/1000000, train_loss: 22.9633, val_loss: 8.9327, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1682/1000000, train_loss: 22.9209, val_loss: 8.7104, time: 0.37s\n",
      "Epoch 1683/1000000, train_loss: 22.8793, val_loss: 9.0021, time: 0.37s\n",
      "Epoch 1684/1000000, train_loss: 22.8427, val_loss: 8.8888, time: 0.37s\n",
      "Epoch 1685/1000000, train_loss: 22.7770, val_loss: 8.8696, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1686/1000000, train_loss: 22.7203, val_loss: 8.6304, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1687/1000000, train_loss: 22.8146, val_loss: 8.5337, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1688/1000000, train_loss: 23.7778, val_loss: 8.3693, time: 0.37s\n",
      "Epoch 1689/1000000, train_loss: 23.0658, val_loss: 8.3770, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1690/1000000, train_loss: 22.7592, val_loss: 8.3061, time: 0.37s\n",
      "Epoch 1691/1000000, train_loss: 22.6541, val_loss: 8.3076, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1692/1000000, train_loss: 22.6230, val_loss: 8.2403, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1693/1000000, train_loss: 22.5855, val_loss: 7.9975, time: 0.37s\n",
      "Epoch 1694/1000000, train_loss: 22.5480, val_loss: 8.1308, time: 0.37s\n",
      "Epoch 1695/1000000, train_loss: 22.5266, val_loss: 8.0879, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1696/1000000, train_loss: 22.5355, val_loss: 7.8426, time: 0.37s\n",
      "Epoch 1697/1000000, train_loss: 22.4927, val_loss: 7.9606, time: 0.37s\n",
      "Epoch 1698/1000000, train_loss: 22.4439, val_loss: 7.9796, time: 0.37s\n",
      "Epoch 1699/1000000, train_loss: 22.3793, val_loss: 7.9367, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1700/1000000, train_loss: 22.3251, val_loss: 7.8035, time: 0.37s\n",
      "Epoch 1701/1000000, train_loss: 22.3006, val_loss: 7.8901, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1702/1000000, train_loss: 22.2557, val_loss: 7.7346, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1703/1000000, train_loss: 22.2148, val_loss: 7.6597, time: 0.37s\n",
      "Epoch 1704/1000000, train_loss: 22.1859, val_loss: 7.6599, time: 0.37s\n",
      "Epoch 1705/1000000, train_loss: 22.4440, val_loss: 7.7377, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1706/1000000, train_loss: 22.4489, val_loss: 7.4550, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1707/1000000, train_loss: 22.2815, val_loss: 7.4282, time: 0.37s\n",
      "Epoch 1708/1000000, train_loss: 22.2045, val_loss: 7.5354, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1709/1000000, train_loss: 22.1443, val_loss: 7.4182, time: 0.37s\n",
      "Epoch 1710/1000000, train_loss: 22.1171, val_loss: 7.4186, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1711/1000000, train_loss: 22.0893, val_loss: 7.2023, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1712/1000000, train_loss: 22.0207, val_loss: 7.1952, time: 0.37s\n",
      "Epoch 1713/1000000, train_loss: 22.1054, val_loss: 7.2246, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1714/1000000, train_loss: 22.2354, val_loss: 6.9719, time: 0.37s\n",
      "Epoch 1715/1000000, train_loss: 22.1476, val_loss: 7.1841, time: 0.37s\n",
      "Epoch 1716/1000000, train_loss: 22.0727, val_loss: 7.1920, time: 0.41s\n",
      "Epoch 1717/1000000, train_loss: 22.0369, val_loss: 7.0929, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1718/1000000, train_loss: 21.9663, val_loss: 6.9255, time: 0.38s\n",
      "Epoch 1719/1000000, train_loss: 21.9169, val_loss: 6.9376, time: 0.37s\n",
      "Epoch 1720/1000000, train_loss: 21.8890, val_loss: 6.9663, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1721/1000000, train_loss: 21.8555, val_loss: 6.7049, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1722/1000000, train_loss: 21.8294, val_loss: 6.6778, time: 0.37s\n",
      "Epoch 1723/1000000, train_loss: 21.7831, val_loss: 6.7777, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1724/1000000, train_loss: 21.7497, val_loss: 6.5963, time: 0.37s\n",
      "Epoch 1725/1000000, train_loss: 21.7600, val_loss: 6.6523, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1726/1000000, train_loss: 21.8123, val_loss: 6.4389, time: 0.37s\n",
      "Epoch 1727/1000000, train_loss: 21.8093, val_loss: 6.5680, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1728/1000000, train_loss: 21.7653, val_loss: 6.3751, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1729/1000000, train_loss: 21.7194, val_loss: 6.2888, time: 0.37s\n",
      "Epoch 1730/1000000, train_loss: 21.6260, val_loss: 6.2905, time: 0.37s\n",
      "Epoch 1731/1000000, train_loss: 21.5933, val_loss: 6.4441, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1732/1000000, train_loss: 21.6004, val_loss: 6.1392, time: 0.37s\n",
      "Epoch 1733/1000000, train_loss: 22.7796, val_loss: 6.1700, time: 0.37s\n",
      "Epoch 1734/1000000, train_loss: 22.6458, val_loss: 6.1582, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1735/1000000, train_loss: 22.5040, val_loss: 6.0768, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1736/1000000, train_loss: 22.4060, val_loss: 5.9845, time: 0.37s\n",
      "Epoch 1737/1000000, train_loss: 22.3566, val_loss: 6.0635, time: 0.37s\n",
      "Epoch 1738/1000000, train_loss: 22.2771, val_loss: 5.9852, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1739/1000000, train_loss: 22.2293, val_loss: 5.9824, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1740/1000000, train_loss: 22.1675, val_loss: 5.8459, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1741/1000000, train_loss: 22.0850, val_loss: 5.7935, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1742/1000000, train_loss: 21.9998, val_loss: 5.7677, time: 0.37s\n",
      "Epoch 1743/1000000, train_loss: 21.9740, val_loss: 5.9793, time: 0.37s\n",
      "Epoch 1744/1000000, train_loss: 21.9237, val_loss: 5.7997, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1745/1000000, train_loss: 21.8373, val_loss: 5.6223, time: 0.37s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1746/1000000, train_loss: 21.6407, val_loss: 5.5823, time: 0.37s\n",
      "Epoch 1747/1000000, train_loss: 21.5835, val_loss: 5.6523, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1748/1000000, train_loss: 21.4735, val_loss: 5.5129, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1749/1000000, train_loss: 21.4591, val_loss: 5.4941, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1750/1000000, train_loss: 21.3740, val_loss: 5.4595, time: 0.43s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1751/1000000, train_loss: 21.3872, val_loss: 5.2951, time: 0.38s\n",
      "Epoch 1752/1000000, train_loss: 21.6566, val_loss: 7.5445, time: 0.38s\n",
      "Epoch 1753/1000000, train_loss: 21.5560, val_loss: 6.1332, time: 0.38s\n",
      "Epoch 1754/1000000, train_loss: 21.5057, val_loss: 5.6273, time: 0.37s\n",
      "Epoch 1755/1000000, train_loss: 23.0459, val_loss: 5.7197, time: 0.38s\n",
      "Epoch 1756/1000000, train_loss: 23.0871, val_loss: 5.7405, time: 0.38s\n",
      "Epoch 1757/1000000, train_loss: 23.0225, val_loss: 6.0840, time: 0.38s\n",
      "Epoch 1758/1000000, train_loss: 22.8874, val_loss: 5.4601, time: 0.37s\n",
      "Epoch 1759/1000000, train_loss: 22.7562, val_loss: 5.5686, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1760/1000000, train_loss: 22.7044, val_loss: 5.2105, time: 0.38s\n",
      "Epoch 1761/1000000, train_loss: 22.6248, val_loss: 5.3617, time: 0.38s\n",
      "Epoch 1762/1000000, train_loss: 22.5685, val_loss: 5.2855, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1763/1000000, train_loss: 22.5132, val_loss: 4.9968, time: 0.43s\n",
      "Epoch 1764/1000000, train_loss: 22.4178, val_loss: 5.4121, time: 0.38s\n",
      "Epoch 1765/1000000, train_loss: 22.3822, val_loss: 5.2876, time: 0.38s\n",
      "Epoch 1766/1000000, train_loss: 22.2817, val_loss: 5.0398, time: 0.38s\n",
      "Epoch 1767/1000000, train_loss: 22.2307, val_loss: 5.1736, time: 0.38s\n",
      "Epoch 1768/1000000, train_loss: 22.1588, val_loss: 5.5947, time: 0.40s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1769/1000000, train_loss: 22.0914, val_loss: 4.9396, time: 0.39s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1770/1000000, train_loss: 22.0512, val_loss: 4.9345, time: 0.41s\n",
      "Epoch 1771/1000000, train_loss: 22.0040, val_loss: 5.0950, time: 0.38s\n",
      "Epoch 1772/1000000, train_loss: 21.9398, val_loss: 5.0815, time: 0.38s\n",
      "Epoch 1773/1000000, train_loss: 21.8361, val_loss: 5.0336, time: 0.38s\n",
      "Epoch 1774/1000000, train_loss: 21.7141, val_loss: 5.1437, time: 0.38s\n",
      "Epoch 1775/1000000, train_loss: 21.6461, val_loss: 5.7691, time: 0.38s\n",
      "Epoch 1776/1000000, train_loss: 21.6187, val_loss: 4.9586, time: 0.38s\n",
      "Epoch 1777/1000000, train_loss: 21.5889, val_loss: 5.0085, time: 0.37s\n",
      "Epoch 1778/1000000, train_loss: 21.5354, val_loss: 5.0686, time: 0.37s\n",
      "Epoch 1779/1000000, train_loss: 21.4866, val_loss: 4.9980, time: 0.42s\n",
      "Epoch 1780/1000000, train_loss: 21.4654, val_loss: 5.0366, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1781/1000000, train_loss: 21.4466, val_loss: 4.7435, time: 0.38s\n",
      "Epoch 1782/1000000, train_loss: 21.4413, val_loss: 4.9907, time: 0.38s\n",
      "Epoch 1783/1000000, train_loss: 21.4267, val_loss: 4.8889, time: 0.38s\n",
      "Epoch 1784/1000000, train_loss: 21.4014, val_loss: 4.8321, time: 0.37s\n",
      "Epoch 1785/1000000, train_loss: 21.3762, val_loss: 4.7573, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1786/1000000, train_loss: 21.3536, val_loss: 4.7244, time: 0.38s\n",
      "Epoch 1787/1000000, train_loss: 21.3385, val_loss: 4.8215, time: 0.38s\n",
      "Epoch 1788/1000000, train_loss: 21.3092, val_loss: 4.8712, time: 0.38s\n",
      "Epoch 1789/1000000, train_loss: 21.2830, val_loss: 5.0235, time: 0.37s\n",
      "Epoch 1790/1000000, train_loss: 21.2785, val_loss: 5.0473, time: 0.37s\n",
      "Epoch 1791/1000000, train_loss: 21.2530, val_loss: 4.7857, time: 0.38s\n",
      "Epoch 1792/1000000, train_loss: 21.2386, val_loss: 4.9669, time: 0.38s\n",
      "Epoch 1793/1000000, train_loss: 21.2377, val_loss: 4.9268, time: 0.38s\n",
      "Model saved to weights/multi2multi/best-BiLSTM.pth\n",
      "Epoch 1794/1000000, train_loss: 21.2127, val_loss: 4.5275, time: 0.38s\n",
      "Epoch 1795/1000000, train_loss: 21.2112, val_loss: 4.8931, time: 0.37s\n",
      "Epoch 1796/1000000, train_loss: 21.1901, val_loss: 4.9356, time: 0.39s\n",
      "Epoch 1797/1000000, train_loss: 21.1790, val_loss: 4.7663, time: 0.38s\n",
      "Epoch 1798/1000000, train_loss: 21.1667, val_loss: 4.6524, time: 0.38s\n",
      "Epoch 1799/1000000, train_loss: 21.1318, val_loss: 4.8156, time: 0.38s\n",
      "Epoch 1800/1000000, train_loss: 21.1134, val_loss: 4.7019, time: 0.37s\n",
      "Epoch 1801/1000000, train_loss: 21.0934, val_loss: 4.6443, time: 0.40s\n",
      "Epoch 1802/1000000, train_loss: 21.0728, val_loss: 4.7440, time: 0.44s\n",
      "Epoch 1803/1000000, train_loss: 21.0707, val_loss: 4.7788, time: 0.44s\n",
      "Epoch 1804/1000000, train_loss: 21.0712, val_loss: 4.9352, time: 0.43s\n",
      "Epoch 1805/1000000, train_loss: 21.0830, val_loss: 4.8367, time: 0.40s\n",
      "Epoch 1806/1000000, train_loss: 21.1041, val_loss: 4.7542, time: 0.38s\n",
      "Epoch 1807/1000000, train_loss: 21.0575, val_loss: 4.8056, time: 0.39s\n",
      "Epoch 1808/1000000, train_loss: 21.0185, val_loss: 4.6671, time: 0.38s\n",
      "Epoch 1809/1000000, train_loss: 21.0014, val_loss: 4.7774, time: 0.37s\n",
      "Epoch 1810/1000000, train_loss: 20.9990, val_loss: 4.7777, time: 0.37s\n",
      "Epoch 1811/1000000, train_loss: 20.9803, val_loss: 4.6671, time: 0.37s\n",
      "Epoch 1812/1000000, train_loss: 20.9491, val_loss: 4.7502, time: 0.38s\n",
      "Epoch 1813/1000000, train_loss: 20.9556, val_loss: 4.8519, time: 0.38s\n",
      "Early stopping on epoch 1814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'BiLSTM', 'Type': 'multi2multi', 'MAE': 27.172881807599747}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BiLSTM_multi2uni = BiLSTM(input_size=multi2uni_loader.in_variable, hidden_size=hidden_size, output_size=multi2uni_loader.out_variable, ahead=label_size, num_layers=num_layers)\n",
    "BiLSTM_multi2uni_manager = ModelManager(model=BiLSTM_multi2uni, train_loader=multi2uni_loader.train_loader, val_loader=multi2uni_loader.val_loader, lr=learning_rate, patience=patience)\n",
    "BiLSTM_multi2uni_manager.train(num_epochs=num_epochs, save_dir=os.path.join(weight_dir, sub_dir))\n",
    "results.append({\n",
    "    \"Name\": BiLSTM_multi2uni_manager.model.__class__.__name__,\n",
    "    \"Type\": sub_dir,\n",
    "    \"MAE\": BiLSTM_multi2uni_manager.evaluate(loader=multi2uni_loader.test_loader),\n",
    "})\n",
    "results[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
